[{"categories":["技术"],"content":" 本文主要翻译自 Practical-Cryptography-for-Developers-Book，但是笔者也补充了许多代码示例及算法细节。 《写给开发人员的实用密码学》系列文章目录： 「译」写给开发人员的实用密码学（一）—— 概览 「译」写给开发人员的实用密码学（二）—— 哈希函数 「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF 「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器 「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE 「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法 待续 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:0:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"零、术语介绍 两个常用动词： 加密：cipher 或者 encrypt 解密：decipher 或者 decrypt 另外有几个名词有必要解释： cipher: 指用于加解密的「密码算法」，有时也被直接翻译成「密码」 cryptographic algorithm: 密码学算法，泛指密码学相关的各类算法 ciphertext: 密文，即加密后的信息。对应的词是明文 plaintext password: 这个应该不需要解释，就是我们日常用的各种字符或者数字密码，也可称作口令。 passphrase: 翻译成「密码词组」或者「密碼片語」，通常指用于保护密钥或者其他敏感数据的一个 password 如果你用 ssh/gpg/openssl 等工具生成或使用过密钥，应该对它不陌生。 在密码学里面，最容易搞混的词估计就是「密码」了，cipher/password/passphrase 都可以被翻译成「密码」，需要注意下其中区别。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:1:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"一、什么是对称加密 在密码学中，有两种加密方案被广泛使用：「对称加密」与「非对称加密」。 对称加密是指，使用相同的密钥进行消息的加密与解密。因为这个特性，我们也称这个密钥为「共享密钥（Shared Secret Key）」，示意图如下： 现代密码学中广泛使用的对称加密算法（ciphers）有：AES（AES-128、AES-192、AES-256）、ChaCha20、Twofish、IDEA、Serpent、Camelia、RC6、CAST 等。 其中绝大多数都是「块密码算法（Block Cipher）」或者叫「分组密码算法」，这种算法一次只能加密固定大小的块（例如 128 位）； 少部分是「流密码算法（Stream Cipher）」，流密码算法将数据逐字节地加密为密文流。 通过使用称为「分组密码工作模式」的技术，可以将「分组密码算法」转换为「流密码算法」。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:2:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"量子安全性 即使计算机进入量子时代，仍然可以沿用当前的对称密码算法。因为对称密钥密码算法是抗量子的（quantum-resistant），这意味当使用长度足够的密钥时，强大的量子计算机无法破坏其安全性。 目前来看 256 位的 AES/Twofish 在很长一段时间内都将是 量子安全 的。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:2:1","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"二、对称加密方案的结构 我们在第一章「概览」里介绍过，单纯使用数据加密算法只能保证数据的安全性，并不能满足我们对消息真实性、完整性与不可否认性的需求，因此通常我们会将对称加密算法跟其他算法组合成一个「对称加密方案」来使用，这种多个密码学算法组成的「加密方案」能同时保证数据的安全性、真实性、完整性与不可否认性。 一个分组加密方案通常会包含如下几种算法： 将密码转换为密钥的密钥派生算法 KDF（如 Scrypt 或 Argon2）：通过使用 KDF，加密方案可以允许用户使用字符密码作为「Shared Secret Key」，并使密码的破解变得困难和缓慢。 分组密码到流密码的转换算法（即分组密码模式，如 CBC 或 CTR）+ 消息填充算法（如 PKCS7）：分组密码算法（如 AES）需要借助这两种算法，才能加密任意大小的数据。 分组密码算法（如 AES）：使用密钥安全地加密固定长度的数据块。 大多数流行的对称加密算法，都是分组密码算法。 消息认证算法（如HMAC）：用于验证消息的真实性、完整性、不可否认性。 而一个流密码加密方案本身就能加密任意长度的数据，因此不需要「分组密码模式」与「消息填充算法」。 如 AES-256-CTR-HMAC-SHA256 就表示一个使用 AES-256 与 Counter 分组模式进行加密，使用 HMAC-SHA256 进行消息认证的加密方案。 其他流行的对称加密方案还有 ChaCha20-Poly1305 和 AES-128-GCM 等，其中 ChaCha20-Poly130 是一个流密码加密方案。我们会在后面单独介绍这两种加密方案。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:3:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"三、分组密码工作模式 - Block cipher mode of operation 前面简单介绍了「分组密码工作模式」可以将「分组密码算法」转换为「流密码算法」，从而实现加密任意长度的数据，这里主要就具体介绍下这个分组密码工作模式（下文简称为「分组模式」或者「XXX 模式」）。 加密方案的名称中就带有具体的「分组模式」名称，如： AES-256-GCM - 具有 256 位加密密钥和 GCM 分组模式的 AES 密码 AES-128-CTR - 具有 128 位加密密钥和 CTR 分组模式的 AES 密码 Serpent-128-CBC - 具有 128 位加密密钥和 CBC 分组模式的 Serpent 密码 「分组密码工作模式」背后的主要思想是把明文分成多个长度固定的组，再在这些分组上重复应用分组密码算法进行加密/解密，以实现安全地加密/解密任意长度的数据。 某些分组模式（如 CBC）要求将输入拆分为分组，并使用填充算法（例如添加特殊填充字符）将最末尾的分组填充到块大小。 也有些分组模式（如 CTR、CFB、OFB、CCM、EAX 和 GCM）根本不需要填充，因为它们在每个步骤中，都直接在明文部分和内部密码状态之间执行异或（XOR）运算. 加密大量输入数据的工作方式基本如下： 初始化加密算法状态（使用加密密钥 + 随机盐） 加密数据的第一部分（例如块或块的一部分） 使用加密密钥和其他参数转换加密状态 加密下一部分 再次转换加密状态 再加密下一部分 依此类推，直到处理完所有输入数据 解密的工作方式跟加密完全类似。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:4:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"0. 初始向量 IV 密码学中的初始向量 IV（Initialization Vector, 有时也被称作 Salt/Nonce），通常是一个随机数。主要作用是往密文中添加随机性，使同样的明文被多次加密也会产生不同的密文，从而确保密文的不可预测性。 IV 的大小应与密码块大小相同，例如 AES、Serpent 和 Camellia 都只支持 128 位密码块，那么它们需要的 IV 也必须也 128 位。 IV 通常无需保密，但是应当足够随机（无法预测），而且不允许重用，应该对每条加密消息使用随机且不可预测的 IV。 一个常见错误是使用相同的对称密钥和相同的 IV 加密多条消息，这使得针对大多数分组模式的各种加密攻击成为可能。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:4:1","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"1. CTR (Counter) 分组模式 参考文档: https://csrc.nist.gov/publications/detail/sp/800-38a/final 下图说明了明文的分组（块）如何在 CTR 分组工作模式下使用分组密码算法一个接一个地加密与解密： 可以看到两图中左边的第一个步骤，涉及到三个参数： Nonce，初始向量 IV 的别名，前面已经介绍过了。 Counter: 一个计数器，最常用的 Counter 实现是「从 0 开始，每次计算都自增 1」 Key: 对称加密的密钥 Plaintext: 明文的一个分组。除了最后一个分组外，其他分组的长度应该跟 Key 相同 CTR 模式加解密的算法使用公式来表示如下： $$ \\begin{alignedat}{2} C_i \u0026= P_i \\oplus O_i, \\ \u0026\\text{for } i \u0026= 1, 2 … n-1 \\\\ P_i \u0026= C_i \\oplus O_i, \\ \u0026\\text{for } i \u0026= 1, 2 … n-1 \\\\ O_i \u0026= \\text{CIPH}_{key}(\\text{Nonce} + I_i), \\ \u0026\\text{for } i \u0026= 1, 2 … n-1 \\end{alignedat} $$ 公式的符号说明如下 $C_i$ 表示密文的第 $i$ 个分组 $P_i$ 表示明文的第 $i$ 个 分组 $I_i$ 表示计数器返回的第 $i$ 个值，其长度应与分组的长度相同 $\\text{CIPH}_{key}$ 表示使用密钥 $key$ 的对称加密算法 上面的公式只描述了 $ 0 \\ge i \\le n-1$ 的场景，最后一个分组 $i = n$ 要特殊一些——它的长度可能比 Key 要短。 CTR 模式加解密这最后这个分组时，会直接忽略掉 $O_n$ 末尾多余的 bytes. 这种处理方式使得 CTR 模式不需要使用填充算法对最后一个分组进行填充，而且还使密文跟明文的长度完全一致。 我们假设最后一个分组的长度为 $u$，它的加解密算法描述如下（$MSB_u(O_n)$ 表示取 $O_n$ 的 u 个最高有效位）： $$ \\begin{alignedat}{2} C_{n} \u0026= P_{n} \\oplus {MSB_u}(O_n) \\\\ P_{n} \u0026= C_{n} \\oplus {MSB_u}(O_n)\\\\ O_n \u0026= \\text{CIPH}_{key}(\\text{Nonce} + I_n) \\end{alignedat} $$ 可以看到，因为异或 XOR 的对称性，加密跟解密的算法是完全相同的，直接 XOR $O_i$ 即可。 Python 中最流行的加密库是 cryptography，requests/flask 底层就使用了它，下面我们使用这个库来演示下 AES-256-CTR 算法： # pip install cryptography==36.0.1 import os from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes plaintext = b\"this is a test message, hahahahahaha~\" # 使用 32bytes 的 key，即使用算法 AES-256-CTR key = os.urandom(32) # key =\u003e b'\\x96\\xec.\\xc7\\xd5\\x1b/5\\xa1\\x10s\\x9d\\xd5\\x10z\\xdc\\x90\\xb5\\x1cm\"\u003ex\\xfd \\xd5\\xc5\\xaf\\x19\\xd1Z\\xbb' # AES 算法的 block 大小是固定的 128bits，即 16 bytes, IV 长度需要与 block 一致 iv = os.urandom(16) # iv =\u003e b'\\x88[\\xc9\\n`\\xe4\\xc2^\\xaf\\xdc\\x1e\\xfd.c\u003e=' # 1. 发送方加密数据 ## 构建 AES-256-CTR 的 cipher，然后加密数据，得到密文 cipher = Cipher(algorithms.AES(key), modes.CTR(iv)) encryptor = cipher.encryptor() ciphertext = encryptor.update(plaintext) + encryptor.finalize() # ciphertext =\u003e b'\\x9b6(\\x1d\\xfd\\xde\\x96S\\x8b\\x8f\\x90\\xc5}ou\\x9e\\xb1\\xbd\\x9af\\xb8\\xdc\\xec\\xbf\\xa3\"\\x18^\\xac\\x14\\xc8s2*\\x1a\\xcf\\x1d' # 2. 发送方将 iv + ciphertext 发送给接收方 # 3. 接收方解密数据 # 接收方使用自己的 key + 接收到的 iv，构建 cipher，然后解密出原始数据 cipher = Cipher(algorithms.AES(key), modes.CTR(iv)) decryptor = cipher.decryptor() decryptor.update(ciphertext) + decryptor.finalize() 从上面的算法描述能感觉到，CTR 算法还蛮简单的。下面我使用 Python 写一个能够 work 的 CTR 实现： def xor_bytes(a, b): \"\"\"Returns a new byte array with the elements xor'ed. if len(a) != len(b), extra parts are discard. \"\"\" return bytes(i^j for i, j in zip(a, b)) def inc_bytes(a): \"\"\" Returns a new byte array with the value increment by 1 \"\"\" out = list(a) for i in reversed(range(len(out))): if out[i] == 0xFF: out[i] = 0 else: out[i] += 1 break return bytes(out) def split_blocks(message, block_size, require_padding=True): \"\"\" Split `message` with fixed length `block_size` \"\"\" assert len(message) % block_size == 0 or not require_padding return [message[i:i+16] for i in range(0, len(message), block_size)] def encrypt_ctr(block_cipher, plaintext, iv): \"\"\" Encrypts `plaintext` using CTR mode with the given nounce/IV. \"\"\" assert len(iv) == 16 blocks = [] nonce = iv for plaintext_block in split_blocks(plaintext, block_size=16, require_padding=False): # CTR mode encrypt: plaintext_block XOR encrypt(nonce) o = bytes(block_cipher.encrypt(nonce)) block = xor_bytes(plaintext_block, o) # extra parts of `o` are discard in this step blocks.append(block) nonce = inc_bytes(nonce) return b''.join(blocks) # 加密与解密的算法完全一致 decrypt_ctr = encrypt_ctr 接下来验证下算法的正确性： # Python 官方库未提供 AES 实现，因此需要先装下这个库： # pip install pyaes==1.6.1 from pyaes import AES # AES-256-CTR - plaintext key 都与前面的测试代码完全一致 plaintext = b\"this is a test message, hahahahahaha~\" key = b'\\x96\\xec.\\xc7\\xd5\\x1b/5\\xa1\\x10s\\x9d\\xd5\\x10z\\xdc\\x90\\xb5\\x1cm\"\u003ex\\xfd\\xd5\\xc5\\xaf\\x19\\xd1Z\\xbb' # 1. 发送方加密数据 # 首先生成一个随机 IV，为了对比，这里使用前面生成好的数据 iv = b'\\x88[\\xc9\\n`\\xe4\\xc2^\\xaf\\xdc\\x1e\\xfd.c\u003e=' aes_cipher = AES(key) ciphertext = encrypt_ctr(aes_cipher, plaintext, iv) print(\"ciphertext =\u003e\", bytes(ciphertext)) # 输出应该与前面用 cryptography 计算出来的完全","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:4:2","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"2. GCM (Galois/Counter) 分组模式 GCM (Galois/Counter) 模式在 CTR 模式的基础上，添加了消息认证的功能，而且同时还具有与 CTR 模式相同的并行计算能力。因此相比 CTR 模式，GCM 不仅速度一样快，还能额外提供对消息完整性、真实性的验证能力。 下图直观地解释了 GCM 块模式（Galois/Counter 模式）的工作原理： GCM 模式新增的 Auth Tag，计算起来会有些复杂，我们就直接略过了，对原理感兴趣的可以看下 Galois/Counter_Mode_wiki. ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:4:3","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"3. 如何选用块模式 一些 Tips: 常用的安全块模式是 CBC（密码块链接）、CTR（计数器）和 GCM（伽罗瓦/计数器模式），它们需要一个随机（不可预测的）初始化向量 (IV)，也称为 nonce 或 salt 「CTR（Counter）」块模式在大多数情况下是一个不错的选择，因为它具有很强的安全性和并行处理能力，允许任意输入数据长度（无填充）。但它不提供身份验证和完整性，只提供加密 GCM（Galois/Counter Mode）块模式继承了 CTR 模式的所有优点，并增加了加密消息认证能力。GCM 是在对称密码中实现认证加密的快速有效的方法，强烈推荐 CBC 模式在固定大小的分组上工作。因此，在将输入数据拆分为分组后，应使用填充算法使最后一个分组的长度一致。大多数应用程序使用 PKCS7 填充方案或 ANSI X.923. 在某些情况下，CBC 阻塞模式可能容易受到「padding oracle」攻击，因此最好避免使用 CBC 模式 众所周知的不安全块模式是 ECB（电子密码本），它将相等的输入块加密为相等的输出块（无加密扩散能力）。不要使用 ECB 块模式！它可能会危及整个加密方案。 CBC、CTR 和 GCM 模式等大多数块都支持「随机访问」解密。比如在视频播放器中的任意时间偏移处寻找，播放加密的视频流 总之，建议使用 CTR (Counter) 或 GCM (Galois/Counter) 分组模式。 其他的分组在某些情况下可能会有所帮助，但很可能有安全隐患，因此除非你很清楚自己在做什么，否则不要使用其他分组模式！ CTR 和 GCM 加密模式有很多优点：它们是安全的（目前没有已知的重大缺陷），可以加密任意长度的数据而无需填充，可以并行加密和解密分组（在多核 CPU 中）并可以直接解密任意一个密文分组。 因此它们适用于加密加密钱包、文档和流视频（用户可以按时间查找）。 GCM 还提供消息认证，是一般情况下密码块模式的推荐选择。 请注意，GCM、CTR 和其他分组模式会泄漏原始消息的长度，因为它们生成的密文长度与明文消息的长度相同。 如果您想避免泄露原始明文长度，可以在加密前向明文添加一些随机字节（额外的填充数据），并在解密后将其删除。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:4:4","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"四、对称加密算法与对称加密方案 前面啰嗦了这么多，下面进入正题：对称加密算法 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:5:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"0. 对称认证加密算法 AE / AEAD 我们在前面第三篇文章「MAC 与密钥派生函数 KDF」中介绍过 AE 认证加密及其变体 AEAD. 一些对称加密方案提供集成身份验证加密（AEAD），比如使用了 GCM 分组模式的加密方案 AES-GCM，而其他加密方案（如 AES-CBC 和 AES-CTR）自身不提供身份验证能力，需要额外添加。 最流行的认证加密（AEAD）方案： ChaCha20-Poly1305 具有集成 Poly1305 身份验证器的 ChaCha20 流密码（集成身份验证 AEAD 加密） 使用 256 位密钥和 96 位随机数 极高的性能 AES-256-GCM 我们在前面的 GCM 模式一节，使用 Python 实现并验证了这个 AES-256-GCM 加密方案 使用 256 位密钥和 128 位随机数（初始向量） 较高的性能 今天的大多数应用程序应该优先选用上面这些加密方案进行对称加密，而不是自己造轮子。 上述方案是高度安全的、经过验证的、经过良好测试的，并且大多数加密库都已经提供了高效的实现，可以说是开箱即用。 通常更建议使用 ChaCha20-Poly1305，因为它的性能要强劲很多，在移动设备上比 AES-128-GCM 快 3 倍。 下一节会简要介绍下 AES-256-GCM 跟 ChaCha20-Poly1305 这两个加密方案。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:5:1","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"1. 安全的对称加密算法 这里仅简单介绍下流行的对称加密算法，后面会单独列两小节介绍下 AES 跟 ChaCha20 的算法细节。 1. AES (Rijndael) wiki: https://en.wikipedia.org/wiki/Advanced_Encryption_Standard AES（高级加密标准，也称为 Rijndael）是现代 IT 行业中最流行和广泛使用的对称加密算法。AES 被证明是高度安全、快速且标准化的，到目前为止没有发现任何明显的弱点或攻击手段，而且几乎在所有平台上都得到了很好的支持。 AES 是 128 位分组密码，使用 128、192 或 256 位密钥。它通常与分组模式组合成分组加密方案（如 AES-CTR 或 AES-GCM）以处理流数据。 在大多数分组模式中，AES 还需要一个随机的 128 位初始向量 IV。 Rijndael (AES) 算法可免费用于任何用途，而且非常流行。很多站点都选择 AES 作为 TLS 协议的一部分，以实现安全通信。 现代 CPU 硬件基本都在微处理器级别实现了 AES 指令以加速 AES 加密解密操作。 这里有一个纯 Python 的 AES 实现可供参考: AES encryption in pure Python - boppreh 我们在前面的 CTR 分组模式中已经使用 Python 实践了 AES-256-CTR 加密方案。 而实际上更常用的是支持集成身份验证加密（AEAD）的 AES-256-GCM 加密方案，它的优势我们前面已经介绍过了，这里我们使用 Python 演示下如何使用： # pip install cryptography==36.0.1 import os from cryptography.hazmat.primitives.ciphers import ( Cipher, algorithms, modes ) def encrypt(key, plaintext, associated_data): # Generate a random 96-bit IV. iv = os.urandom(12) # Construct an AES-GCM Cipher object with the given key and a # randomly generated IV. encryptor = Cipher( algorithms.AES(key), modes.GCM(iv), ).encryptor() # associated_data will be authenticated but not encrypted, # it must also be passed in on decryption. encryptor.authenticate_additional_data(associated_data) # Encrypt the plaintext and get the associated ciphertext. # GCM does not require padding. ciphertext = encryptor.update(plaintext) + encryptor.finalize() return (iv, ciphertext, encryptor.tag) def decrypt(key, associated_data, iv, ciphertext, tag): # Construct a Cipher object, with the key, iv, and additionally the # GCM tag used for authenticating the message. decryptor = Cipher( algorithms.AES(key), modes.GCM(iv, tag), ).decryptor() # We put associated_data back in or the tag will fail to verify # when we finalize the decryptor. decryptor.authenticate_additional_data(associated_data) # Decryption gets us the authenticated plaintext. # If the tag does not match an InvalidTag exception will be raised. return decryptor.update(ciphertext) + decryptor.finalize() # 接下来进行算法验证 plaintext = b\"this is a paintext, hahahahahaha~\" key = b'\\x96\\xec.\\xc7\\xd5\\x1b/5\\xa1\\x10s\\x9d\\xd5\\x10z\\xdc\\x90\\xb5\\x1cm\"\u003ex\\xfd\\xd5\\xc5\\xaf\\x19\\xd1Z\\xbb' associated_data = b\"authenticated but not encrypted payload\" # 被用于消息认证的关联数据 # 1. 发送方加密消息 iv, ciphertext, tag = encrypt( key, plaintext, associated_data ) # 2. 发送方将 associated_data iv ciphertext tag 打包发送给接收方 # 3. 接收方使用自己的 key 验证并解密数据 descrypt_text = decrypt( key, associated_data, iv, ciphertext, tag ) 2. Salsa20 / ChaCha20 wiki: https://en.wikipedia.org/wiki/Salsa20#ChaCha_variant Salsa20 及其改进的变体 ChaCha（ChaCha8、ChaCha12、ChaCha20）和 XSalsa20 是由密码学家 Daniel Bernstein 设计的现代、快速的对称流密码家族。 Salsa20 密码是对称流密码设计竞赛 eSTREAM（2004-2008）的决赛选手之一，它随后与相关的 BLAKE 哈希函数一起被广泛采用。 Salsa20 及其变体是免版税的，没有专利。 Salsa20 密码将 128 位或 256 位对称密钥 + 随机生成的 64 位随机数（初始向量）和无限长度的数据流作为输入，并生成长度相同的加密数据流作为输出输入流。 Salsa20 应用最为广泛的是认证加密方案：ChaCha20-Poly1305，即组合使用 ChaCha20 与消息认证算法 Poly1305. 顺带一提，ChaCha20 与 Poly1305 都是密码学家 Bernstein 设计的。 以下是一个 ChaCha20 的 Python 示例： # pip install cryptography==36.0.1 import os from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes plaintext = b\"this is a paintext, hahahahahaha~\" key = b'\\x96\\xec.\\xc7\\xd5\\x1b/5\\xa1\\x10s\\x9d\\xd5\\x10z\\xdc\\x90\\xb5\\x1cm\"\u003ex\\xfd\\xd5\\xc5\\xaf\\x19\\xd1Z\\xbb' nonce = os.urandom(16) algorithm = algorithms.ChaCha20(key, nonce) # ChaCha20 是一个流密码，mode 必须为 None cipher = Cipher(algorithm, mode=None) # 1. 加密 encryptor = cipher.encryptor() ct = encryptor.update(plaintext) # 2. 解密 decryptor = cipher.decryptor() decryptor.update(ct) 3. 其他流行的对称加密算法 还有一些其他的现代安全对称密码，它们的应用不如 AES 和 ChaCha20 这么广泛，但在程序员和信息安全社区中仍然很流行： Serpent - 安全对称密钥分组密码（密钥大小：128、192 或 256 位），公众所有（Public Domain），完全免费 Twofish - 安全对称密钥分组密码（密钥大小：128、192 或 256 位），公众所有（Public Domain），完全免费 Camellia - 安全对称密钥分组密码（分组大小：128 位；密钥大小：128、192 和 256 位），专利算法，但完全免费 该算法由三菱和日本电信电话（NTT）在 2000 年共同发明 RC5 - 安全对称密钥分组密码（密钥大小：128 到 2040 位；分组大小：32、64 或 128 位；轮数：1 … 255），短密钥不安全（56 位密钥已被暴力破解） , 专利在 2015 年到期，现在完全免费 RC6 - 安全对称密钥分组密码，类似于 RC5，但更复杂（密钥大小：128 到 2040 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:5:2","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"不安全的对称加密算法 如下这些对称加密算法曾经很流行，但现在被认为是不安全的或有争议的安全性，不建议再使用： DES - 56 位密钥大小，可以被暴力破解 3DES（三重 DES, TDES）- 64 位密码，被认为不安全，已在 2017 年被 NIST 弃用. RC2 - 64 位密码，被认为不安全 RC4 - 流密码，已被破解，网上存在大量它的破解资料 Blowfish - 旧的 64 位密码，已被破坏 Sweet32: Birthday attacks on 64-bit block ciphers in TLS and OpenVPN GOST - 俄罗斯 64 位分组密码，有争议的安全性，被认为有风险 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:5:3","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"五、AES 算法案例：以太坊钱包加密 在这一小节我们研究一个现实中的 AES 应用场景：以太坊区块链的标准加密钱包文件格式。 我们将看到 AES-128-CTR 密码方案如何与 Scrypt 和 MAC 相结合，通过字符密码安全地实现经过身份验证的对称密钥加密。 以太坊 UTC / JSON 钱包 在比特币和以太坊等区块链网络中，区块链资产持有者的私钥存储在称为加密钱包的特殊密钥库中。 通常，这些加密钱包是本地硬盘上的文件，并使用字符密码加密。 在以太坊区块链中，加密钱包以一种特殊的加密格式在内部存储，称为「UTC / JSON 钱包（密钥库文件）」或「Web3 秘密存储定义」。 这是一种加密钱包的文件格式，被广泛应用在 geth 和 Parity（以太坊的主要协议实现）、MyEtherWallet（流行的在线客户端以太坊钱包）、MetaMask（广泛使用的浏览器内以太坊钱包）、ethers.js 和 Nethereum 库以及许多其他与以太坊相关的技术和工具中。 以太坊 UTC/JSON 密钥库将加密的私钥、加密数据、加密算法及其参数保存为 JSON 文本文档。 UTC / JSON 钱包的一个示例如下： {\"version\": 3,\"id\": \"07a9f767-93c5-4842-9afd-b3b083659f04\",\"address\": \"aef8cad64d29fcc4ed07629b9e896ebc3160a8d0\",\"Crypto\": {\"ciphertext\": \"99d0e66c67941a08690e48222a58843ef2481e110969325db7ff5284cd3d3093\",\"cipherparams\": { \"iv\": \"7d7fabf8dee2e77f0d7e3ff3b965fc23\"},\"cipher\": \"aes-128-ctr\",\"kdf\": \"scrypt\",\"kdfparams\": {\"dklen\": 32,\"salt\": \"85ad073989d461c72358ccaea3551f7ecb8e672503cb05c2ee80cfb6b922f4d4\",\"n\": 8192,\"r\": 8,\"p\": 1},\"mac\": \"06dcf1cc4bffe1616fafe94a2a7087fd79df444756bb17c93af588c3ab02a913\"}} 上述 json 内容也是认证对称加密的一个典型示例，可以很容易分析出它的一些组成成分： kdf: 用于从字符密码派生出密钥的 KDF 算法名称，这里用的是 scrypt kdfparams: KDF 算法的参数，如迭代参数、盐等… ciphertext: 钱包内容的密文，通常这就是一个被加密的 256 位私钥 cipher + cipherparams: 对称加密算法的名称及参数，这里使用了 AES-128-CTR，并给出了初始向量 IV mac: 由 MAC 算法生成的消息认证码，被用于验证解密密码的正确性 以太坊使用截取派生密钥的一部分，拼接上完整密文，然后进行 keccak-256 哈希运算得到 MAC 值 其他钱包相关的信息 默认情况下，密钥派生函数是 scrypt 并使用的是弱 scrypt 参数（n=8192 成本因子，r=8 块大小，p=1 并行化），因此建议使用长而复杂的密码以避免钱包被暴力解密。 ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:6:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["技术"],"content":"参考 Practical-Cryptography-for-Developers-Book A complete overview of SSL/TLS and its cryptographic system AES encryption in pure Python - boppreh Block_cipher_mode_of_operation_wiki Galois/Counter_Mode_wiki ","date":"2022-03-06","objectID":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/:7:0","tags":["Cryptography","密码学","对称加密","安全"],"title":"「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法","uri":"/posts/practical-cryptography-basics-6-symmetric-key-ciphers/"},{"categories":["随笔"],"content":" 原文：哪一刻你发现年轻人正在悄悄改变社会？ - 赦己 我的读后感：他的眼里有光！ 之前见过一个特别厉害的面试者，让我觉得，老一辈真的是老一辈了，他放弃了一个月薪一万三，十三薪的工作，他的演讲让我记忆非常深刻，也使得面试官面面相觑。 这个岗位算是万人过独木桥，不仅海内的很多大学生在竞争，海外的很多大学生也在努力，真个过程是这样的：简历筛选-线上一面-线上hr二面-线下主管面试-总裁轮面试（压力轮）。 我们都到了最后的一轮面试,本来就是压力轮面试，但是那天不知道为什么总裁的脾气很暴躁，对他冷嘲热讽，说了一些比较难听的话，大概的意思就是“你还小，以后需要认真学，你们太嫩了”，其实总裁的意思非常明确了，会招他，但是他太嫩需要学很多东西，但是就是他这样大人看小屁孩的感觉惹怒了他，后面他的演讲就是十分高能了，我尽量原文复述。 「你坐在我前面会不会有点点害怕呢？你看看你身边有什么人可以给你参考吗？你没有，你只能战战兢兢如履薄冰，走错一步都是深渊。你知道你在我眼里是什么吗？你只是一个猎物，一个我追逐的、猎杀的的目标，其实你哪里来的自信呢？就凭你是这个公司的总裁吗？来自职级和制度的压力我一概不屑，反而觉得是黔驴技穷，小人做法，我不会服气，只是照做而已。 其实我也很享受被统治的感觉，上一个能统治我的人已经很久了，你知道那种纯粹的实力压服吗？我可以毫无保留地顺从他的任何意见，我从来不怀疑他的任何决定，哪怕行动后面失败了我也觉得他是对的。但是你呢？只是来自制度的威力，你的每一个决定都会遭到我的质疑。 我最讨厌的就是别人和我说，我想让你去做点什么但是你能力还不够，简直瞎扯淡，其实是你能力不够，作为一个管理者，你甚至不知道怎么用我，我如何为你卖命啊？ 我渴望的是在一个稳定的环境默默耕耘，把坏的变成好的，但是前提是我们够团队，你呢？凭你作为一个过来人的经验吗？这些东西经过时间大家都会有的，你还有其他的吗？你真的有能力把我变成你的三头六臂吗？你真的控制得住我吗？」 复述其实没那么精彩了，他支着手目光瞪着总裁的眼睛的时候超级精彩，后面他去了一个对手小公司，相当于这边的市值来了，相差了十倍之多，但是七个月之后再见面已是兵刃交接，他成了六个人团队的小主管，耀武扬威地围着我们总部办公地盘下了一圈广告。 ","date":"2022-03-04","objectID":"/posts/the-thoughtful-youth/:0:0","tags":[],"title":"「转」且看有思想的年轻人","uri":"/posts/the-thoughtful-youth/"},{"categories":["技术"],"content":" 本文仍然在优化翻译质量、补充原文缺失的细节、代码示例。 本文主要翻译自 Practical-Cryptography-for-Developers-Book，但是笔者也补充了许多代码示例及算法细节。 《写给开发人员的实用密码学》系列文章目录： 「译」写给开发人员的实用密码学（一）—— 概览 「译」写给开发人员的实用密码学（二）—— 哈希函数 「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF 「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器 「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE 「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法 待续 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-5-key-exchange/:0:0","tags":["Cryptography","密码学","密钥交换","安全"],"title":"「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE","uri":"/posts/practical-cryptography-basics-5-key-exchange/"},{"categories":["技术"],"content":"一、前言 在密码学中密钥交换是一种协议，功能是在两方之间安全地交换加密密钥，其他任何人都无法获得密钥的副本。通常各种加密通讯协议的第一步都是密钥交换。 密钥交换技术具体来说有两种方案： 密钥协商：协议中的双方都参与了共享密钥的生成，两个代表算法是 Diffie-Hellman (DHKE) 和 Elliptic-Curve Diffie-Hellman (ECDH) 密钥传输：双方中其中一方生成出共享密钥，并通过此方案将共享密钥传输给另一方。密钥传输方案通常都通过公钥密码系统实现。比如在 RSA 密钥交换中，客户端使用它的私钥加密一个随机生成的会话密钥，然后将密文发送给服务端，服务端再使用它的公钥解密出会话密钥。 密钥交换协议无时无刻不在数字世界中运行，在你连接 WiFi 时，或者使用 HTTPS 协议访问一个网站，都会执行密钥交换协议。 密钥交换可以基于匿名的密钥协商协议如 DHKE，一个密码或预共享密钥，一个数字证书等等。有些通讯协议只在开始时交换一次密钥，而有些协议则会随着时间的推移不断地交换密钥。 认证密钥交换（AKE）是一种会同时认证相关方身份的密钥交换协议，比如个人 WiFi 通常就会使用 password-authenticated key agreement (PAKE)，而如果你连接的是公开 WiFi，则会使用匿名密钥交换协议。 目前有许多用于密钥交换的密码算法。其中一些使用公钥密码系统，而另一些则使用更简单的密钥交换方案（如 Diffie-Hellman 密钥交换）；其中有些算法涉及服务器身份验证，也有些涉及客户端身份验证；其中部分算法使用密码，另一部分使用数字证书或其他身份验证机制。下面列举一些知名的密钥交换算法： Diffie-Hellman Key Exchange (DHКЕ) ：传统的、应用最为广泛的密钥交换协议 椭圆曲线 Diffie-Hellman (ECDH) RSA-OAEP 和 RSA-KEM（RSA 密钥传输） PSK（预共享密钥） SRP（安全远程密码协议） FHMQV（Fully Hashed Menezes-Qu-Vanstone） ECMQV（Ellictic-Curve Menezes-Qu-Vanstone） CECPQ1（量子安全密钥协议） ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-5-key-exchange/:1:0","tags":["Cryptography","密码学","密钥交换","安全"],"title":"「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE","uri":"/posts/practical-cryptography-basics-5-key-exchange/"},{"categories":["技术"],"content":"二、Diffie–Hellman 密钥交换 迪菲-赫尔曼密钥交换（Diffie–Hellman Key Exchange）是一种安全协议，它可以让双方在完全没有对方任何预先信息的条件下通过不安全信道安全地协商出一个安全密钥，而且任何窃听者都无法得知密钥信息。 这个密钥可以在后续的通讯中作为对称密钥来加密通讯内容。 DHKE 可以抵抗嗅探攻击（窃听），但是无法抵挡中间人攻击（中继）。 DHKE 有两种实现方案： 传统的 DHKE 算法：使用离散对数实现 基于椭圆曲线密码学的 ECDH 为了理解 DHKE 如何实现在「大庭广众之下」安全地协商出密钥，我们首先使用色彩混合来形象地解释下它大致的思路。 跟编程语言的 Hello World 一样，密钥交换的解释通常会使用 Alice 跟 Bob 来作为通信双方。 现在他俩想要在公开的信道上，协商出一个秘密色彩出来，但是不希望其他任何人知道这个秘密色彩。他们可以这样做： 分步解释如下： 首先 Alice 跟 Bob 沟通，确定一个初始的色彩，比如黄色。这个沟通不需要保密。 然后，Alice 跟 Bob 分别偷偷地选择出一个自己的秘密色彩，这个就得保密啦。 现在 Alice 跟 Bob，分别将初始色彩跟自己选择的秘密色彩混合，分别得到两个混合色彩。 之后，Alice 跟 Bob 再回到公开信道上，交换双方的混合色彩。 我们假设在仅知道初始色彩跟混合色彩的情况下，很难推导出被混合的秘密色彩。这样第三方就猜不出 Bob 跟 Alice 分别选择了什么秘密色彩了。 最后 Alice 跟 Bob 再分别将自己的秘密色彩，跟对方的混合色彩混合，就得到了最终的秘密色彩。这个最终色彩只有 Alice 跟 Bob 知道，信道上的任何人都无法猜出来。 DHKE 协议也是基于类似的原理，但是使用的是离散对数（discrete logarithms）跟模幂（modular exponentiations ）而不是色彩混合。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-5-key-exchange/:2:0","tags":["Cryptography","密码学","密钥交换","安全"],"title":"「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE","uri":"/posts/practical-cryptography-basics-5-key-exchange/"},{"categories":["技术"],"content":"1. 基于离散对数的 DHKE 协议 首先介绍下「模幂」，它是指求 $g$ 的 $a$ 次幂模 $p$ 的值 $c$ 的过程，其中 $g$ $a$ $c$ 均为整数，公式如下： $$ g^a \\mod p = c $$ 已知使用计算机计算上述「模幂」是非常快速的，但是求它的逆运算——即离散对数，在已知 $g$ $p$ $c$ 的情况下，求幂指数 $a$——却是非常难的。 下面该轮到 Alice 跟 Bob 出场来介绍 DHKE 的过程了，先看图（下面绿色表示非秘密信息，红色表示秘密信息）： Alice 跟 Bob 协定使用两个比较独特的正整数 $p$ 跟 $g$ 假设 $p=23$, $g=5$ Alice 选择一个秘密整数 $a$，计算 $A$$\\ = g^a \\mod p$ 并发送给 Bob 假设 $a=4$，则 $A$$\\ = 5^4 \\mod 23 = 4$ Bob 也选择一个秘密整数 $b$，计算 $B$$\\ = g^b \\mod p$ 并发送给 Alice 假设 $b=3$，则 $B$$\\ = 5^3 \\mod 23 = 10$ Alice 计算 $S_1 = B^a \\mod p$ $S_1 = 10^4 \\mod 23 = 18$ Bob 计算 $S_2 = A^b \\mod p$ $S_2 = 4^3 \\mod 23 = 18$ 已知 $B^a \\mod p = g^{ab} \\mod p = A^b \\mod p$，因此 $S_1 = S_2 = S$ 这样 Alice 跟 Bob 就协商出了密钥 $S$ 因为离散对数的计算非常难，任何窃听者都几乎不可能通过公开的 $p$ $g$ $A$ $B$ 逆推出 $S$ 的值 在最常见的 DHKE 实现中（RFC3526），基数是 $g = 2$，模数 $$ 是一个 1536 到 8192 比特的大素数。 而整数 $p$ $g$ $A$ $B$ 通常会使用非常大的数字（1024、2048 或 4096 比特甚至更大）以防范暴力破解。 DHKE 协议基于 Diffie-Hellman 问题的实际难度，这是计算机科学中众所周知的离散对数问题（DLP）的变体，目前还不存在有效的算法。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-5-key-exchange/:2:1","tags":["Cryptography","密码学","密钥交换","安全"],"title":"「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE","uri":"/posts/practical-cryptography-basics-5-key-exchange/"},{"categories":["技术"],"content":"2. 基于椭圆曲线的 ECDH 协议 Elliptic-Curve Diffie-Hellman (ECDH) 是一种匿名密钥协商协议，它允许两方，每方都有一个椭圆曲线公钥-私钥对，它的功能也是让双方在完全没有对方任何预先信息的条件下通过不安全信道安全地协商出一个安全密钥。 ECDH 是经典 DHKE 协议的变体，其中模幂计算被椭圆曲线计算取代，以提高安全性。 我会在后面非对称密码系统的 ECC 部分详细介绍它。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-5-key-exchange/:2:2","tags":["Cryptography","密码学","密钥交换","安全"],"title":"「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE","uri":"/posts/practical-cryptography-basics-5-key-exchange/"},{"categories":["技术"],"content":"参考 Practical-Cryptography-for-Developers-Book A complete overview of SSL/TLS and its cryptographic system ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-5-key-exchange/:3:0","tags":["Cryptography","密码学","密钥交换","安全"],"title":"「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE","uri":"/posts/practical-cryptography-basics-5-key-exchange/"},{"categories":["技术"],"content":" 本文主要翻译自 Practical-Cryptography-for-Developers-Book，但是笔者也补充了许多代码示例及算法细节。 《写给开发人员的实用密码学》系列文章目录： 「译」写给开发人员的实用密码学（一）—— 概览 「译」写给开发人员的实用密码学（二）—— 哈希函数 「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF 「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器 「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE 「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法 待续 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:0:0","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"一、前言 在密码学中，随机性（熵）扮演了一个非常重要的角色，许多密码学算法都要求使用一个不可预测的随机数，只有在生成的随机数不可预测时，这些算法才能保证其安全性。 比如 MAC 算法中的 key 就必须是一个不可预测的值，在这个条件下 MAC 值才是不可伪造的。 另外许多的高性能算法如快速排序、布隆过滤器、蒙特卡洛方法等，都依赖于随机性，如果随机性可以被预测，或者能够找到特定的输入值使这些算法变得特别慢，那黑客就能借此对服务进行 DDoS 攻击，以很小的成本达到让服务不可用的目的。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:1:0","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"二、PRNG 伪随机数生成器 Pseudo-Random Number Generators(PRNG) 是一种数字序列的生成算法，它生成出的数字序列的统计学属性跟真正的随机数序列非常相似，但它生成的伪随机数序列并不是真正的随机数序列！因为该序列完全依赖于提供给 PRNG 的初始值，这个值被称为 PRNG 的种子。 算法流程如下，算法的每次迭代都生成出一个新的伪随机数： 如果输入的初始种子是相同的，PRNG 总是会生成出相同的伪随机数序列，因此 PRNG 也被称为 Deterministic Random Bit Generator (DRBG)，即确定性随机比特生成器。 实际上目前也有所谓的「硬件随机数生成器 TRNG」能生成出真正的随机数，但是因为 PRNG 的高速、低成本、可复现等原因，它仍然被大量使用在现代软件开发中。 PRNG 可用于从一个很小的初始随机性（熵）生成出大量的伪随机性，这被称做「拉伸（Stretching）」。 PRNG 被广泛应用在前面提到的各种依赖随机性的高性能算法以及密码学算法中。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:2:0","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"PRNG 的实现 我们在上一篇文章的「MAC 的应用」一节中提到，一个最简单的 PRNG 可以直接使用 MAC 算法实现，用 Python 实现如下： import hmac, hashlib def random_number_generator(seed: bytes, max_num: int): state = seed counter = 0 while True: state = hmac.new(state, bytes(counter), hashlib.sha1).digest() counter += 1 # 这里取余实际上是压缩了信息，某种程度上说，这可以保证内部的真实状态 state 不被逆向出来 yield int.from_bytes(state, byteorder=\"big\") % max_num # 测试下，计算 20 个 100 以内的随机数 gen = random_number_generator(b\"abc\", 100) print([next(gen) for _ in range(20)]) # =\u003e [71, 41, 52, 18, 51, 14, 58, 30, 70, 20, 59, 93, 3, 10, 81, 63, 48, 67, 18, 36] ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:2:1","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"三、随机性 - 熵 如果初始的 PRNG 种子是完全不可预测的，PRNG 就能保证整个随机序列都不可预测。 因此在 PRNG 中，生成出一个足够随机的种子，就变得非常重要了。 一个最简单的方法，就是收集随机性。对于桌面电脑，随机性可以从鼠标的移动点击、按键事件、网络状况等随机输入来收集。这个事情是由操作系统在内核中处理的，内核会直接为应用程序提供随机数获取的 API，比如 Linux/MacOSX 的 /dev/random 虚拟设备。 如果这个熵的生成有漏洞，就很可能造成严重的问题，一个现实事件就是安卓的 java.security.SecureRandom 漏洞导致安卓用户的比特币钱包失窃。 Python 的 random 库的默认会使用当前时间作为初始 seed，这显然是不够安全的——黑客如果知道你运行程序的大概时间，就能通过遍历的方式暴力破解出你的随机数来！ ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:3:0","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"四、CSPRNG 密码学安全随机数生成器 Cryptography Secure Random Number Generators(CSPRNG) 是一种适用于密码学领域的 PRNG，一个 PRNG 如果能够具备如下两个条件，它就是一个 CSPRNG: 能通过「下一比特测试 next-bit test」：即使有人获知了该 PRNG 的 k 位，他也无法使用合理的资源预测第 k+1 位的值 如果攻击者猜出了 PRNG 的内部状态或该状态因某种原因而泄漏，攻击者也无法重建出内部状态泄漏之前生成的所有随机数 有许多的设计都被证明可以用于构造一个 CSPRNG: 基于计数器(CTR)模式下的安全分组密码、流密码或安全散列函数的 CSPRNG 基于数论设计的 CSPRNG，它依靠整数分解问题（IFP）、离散对数问题（DLP）或椭圆曲线离散对数问题（ECDLP）的高难度来确保安全性 CSPRNG 基于加密安全随机性的特殊设计，例如 Yarrow algorithm 和 Fortuna，这俩分别被用于 MacOS 和 FreeBSD. 大多数的 CSPRNG 结合使用来自 OS 的熵与高质量的 PRNG，并且一旦系统生成了新的熵（这可能来自用户输入、磁盘 IO、系统中断、或者硬件 RNG），CSPRNG 会立即使用新的熵来作为 PRNG 新的种子。 这种不断重置 PRNG 种子的行为，使随机数变得非常难以预测。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:4:0","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"CSPRNG 的用途 加密程序：因为 OS 中熵的收集很缓慢，等待收集到足够多的熵再进行运算是不切实际的，因此很多的加密程序都使用 CSPRNG 来从系统的初始熵生成出足够多的伪随机熵。 其他需要安全随机数的场景 emmmm ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:4:1","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"如何在代码中使用 CSPRNG 多数系统都内置了 CSPRNG 算法并提供了内核 API，Unix-like 系统都通过如下两个虚拟设备提供 CSPRNG: /dev/random（受限阻塞随机生成器）: 从这个设备中读取到的是内核熵池中已经收集好的熵，如果熵池空了，此设备会一直阻塞，直到收集到新的环境噪声。 /dev/urandom（不受限非阻塞随机生成器）: 它可能会返回内核熵池中的熵，也可能返回使用「之前收集的熵 + CSPRNG」计算出的安全伪随机数。它不会阻塞。 编程语言的 CSPRNG 接口或库如下： Java: java.security.SecureRandom Python: secrets 库或者 os.urandom() C#: System.Security.Cryptography.RandomNumberGenerator.Create() JavaScript: 客户端可使用 window.crypto.getRandomValues(Uint8Array)，服务端可使用 crypto.randomBytes() ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:5:0","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":"参考 Practical-Cryptography-for-Developers-Book ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-4-secure-random-generators/:6:0","tags":["Cryptography","密码学","伪随机数","安全"],"title":"「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器","uri":"/posts/practical-cryptography-basics-4-secure-random-generators/"},{"categories":["技术"],"content":" 本文主要翻译自 Practical-Cryptography-for-Developers-Book，但是笔者也补充了许多代码示例及算法细节。 《写给开发人员的实用密码学》系列文章目录： 「译」写给开发人员的实用密码学（一）—— 概览 「译」写给开发人员的实用密码学（二）—— 哈希函数 「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF 「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器 「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE 「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法 待续 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-3-key-derivation-function/:0:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF","uri":"/posts/practical-cryptography-basics-3-key-derivation-function/"},{"categories":["技术"],"content":"一、MAC 消息认证码 MAC 消息认证码，即 Message Authentication Code，是用于验证消息的一小段信息。 换句话说，能用它确认消息的真实性——消息来自指定的发件人并且没有被篡改。 MAC 值通过允许验证者（也拥有密钥）检测消息内容的任何更改来保护消息的数据完整性及其真实性。 一个安全的 MAC 函数，跟加密哈希函数非常类似，也拥有如下特性： 快速：计算速度要足够快 确定性：对同样的消息跟密钥，应该总是产生同样的输出 难以分析：对消息或密钥的任何微小改动，都应该使输出完全发生变化 不可逆：从 MAC 值逆向演算出消息跟密钥应该是不可行的。 无碰撞：找到具有相同哈希的两条不同消息应该非常困难（或几乎不可能） 但是 MAC 算法比加密哈希函数多一个输入值：密钥，因此也被称为 keyed hash functions，即「加密钥的哈希函数」。 如下 Python 代码使用 key 跟 消息计算出对应的 HMAC-SHA256 值： import hashlib, hmac, binascii key = b\"key\" msg = b\"some msg\" mac = hmac.new(key, msg, hashlib.sha256).digest() print(f\"HMAC-SHA256({key}, {msg})\", binascii.hexlify(mac).decode('utf8')) # =\u003e HMAC-SHA256(b'key', b'some msg') = 32885b49c8a1009e6d66662f8462e7dd5df769a7b725d1d546574e6d5d6e76ad HMAC 的算法实际上非常简单，我参考 wiki/HMAC 给出的伪码，编写了下面这个 Python 实现，没几行代码，但是完全 work： import hashlib, binascii def xor_bytes(b1, b2): return bytes(a ^ c for a, c in zip(b1, b2)) def my_hmac(key, msg, hash_name): # hash =\u003e (block_size, output_size) # 单位是 bytes，数据来源于 https://en.wikipedia.org/wiki/HMAC hash_size_dict = { \"md5\": (64, 16), \"sha1\": (64, 20), \"sha224\": (64, 28), \"sha256\": (64, 32), # \"sha512/224\": (128, 28), # 这俩算法暂时不清楚在 hashlib 里叫啥名 # \"sha512/256\": (128, 32), \"sha_384\": (128, 48), \"sha_512\": (128, 64), \"sha3_224\": (144, 28), \"sha3_256\": (136, 32), \"sha3_384\": (104, 48), \"sha3_512\": (72, 64), } if hash_name not in hash_size_dict: raise ValueError(\"unknown hash_name\") block_size, output_size = hash_size_dict[hash_name] hash_ = getattr(hashlib, hash_name) # 确保 key 的长度为 block_size block_sized_key = key if len(key) \u003e block_size: block_sized_key = hash_(key).digest() # 用 hash 函数进行压缩 if len(key) \u003c block_size: block_sized_key += b'\\x00' * (block_size - len(key)) # 末尾补 0 o_key_pad = xor_bytes(block_sized_key, (b\"\\x5c\" * block_size)) # Outer padded key i_key_pad = xor_bytes(block_sized_key, (b\"\\x36\" * block_size)) # Inner padded key return hash_(o_key_pad + hash_(i_key_pad + msg).digest()).digest() # 下面验证下 key = b\"key\" msg = b\"some msg\" mac_ = my_hmac(key, msg, \"sha256\") print(f\"HMAC-SHA256({key}, {msg})\", binascii.hexlify(mac_).decode('utf8')) # 输出跟标准库完全一致： # =\u003e HMAC-SHA256(b'key', b'some msg') = 32885b49c8a1009e6d66662f8462e7dd5df769a7b725d1d546574e6d5d6e76ad ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-3-key-derivation-function/:1:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF","uri":"/posts/practical-cryptography-basics-3-key-derivation-function/"},{"categories":["技术"],"content":"MAC 与哈希函数、数字签名的区别 上一篇文章提到过，哈希函数只负责生成哈希值，不负责哈希值的可靠传递。 而数字签名呢，跟 MAC 非常相似，但是数字签名使用的是非对称加密系统，更复杂，计算速度也更慢。 MAC 的功能跟数字签名一致，都是验证消息的真实性（authenticity）、完整性（integrity）、不可否认性（non-repudiation），但是 MAC 使用哈希函数或者对称密码系统来做这件事情，速度要更快，算法也更简单。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-3-key-derivation-function/:1:1","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF","uri":"/posts/practical-cryptography-basics-3-key-derivation-function/"},{"categories":["技术"],"content":"MAC 的应用 1. 验证消息的真实性、完整性 这是最简单的一个应用场景，在通信双向都持有一个预共享密钥的前提下，通信时都附带上消息的 MAC 码。 接收方也使用「收到的消息+预共享密钥」计算出 MAC 码，如果跟收到的一致，就说明消息真实无误。 注意这种应用场景中，消息是不保密的！ 2. AE 认证加密 - Authenticated encryption 常用的加密方法只能保证数据的保密性，并不能保证数据的完整性。 而这里介绍的 MAC 算法，或者还未介绍的基于非对称加密的数字签名，都只能保证数据的真实性、完整性，不能保证数据被安全传输。 而认证加密，就是将加密算法与 MAC 算法结合使用的一种加密方案。 在确保 MAC 码「强不可伪造」的前提下，首先对数据进行加密，然后计算密文的 MAC 码，再同时传输密文与 MAC 码，就能同时保证数据的保密性、完整性、真实性，这种方法叫 Encrypt-then-MAC, 缩写做 EtM. 接收方在解密前先计算密文的 MAC 码与收到的对比，就能验证密文的完整性与真实性。 AE 有一种更安全的变体——带有关联数据的认证加密 (authenticated encryption with associated data，AEAD)。 AEAD 将「关联数据(Associated Data, AD)」——也称为「附加验证数据（Additional Authenticated Data, AAD）」——绑定到密文和它应该出现的上下文，以便可以检测和拒绝将有效密文“剪切并粘贴”到不同上下文的尝试。 AEAD 用于加密和未加密数据一起使用的场景（例如，在加密的网络协议中），并确保整个数据流经过身份验证和完整性保护。 换句话说，AEAD 增加了检查某些内容的完整性和真实性的能力。 我们会在第六章「对称加密算法」中看到如何通过 Python 使用 AEAD 加密方案 AES-256-GCM. 3. 基于 MAC 的伪随机数生成器 MAC 码的另一个用途就是伪随机数生成函数，相比直接使用熵+哈希函数的进行伪随机数计算，MAC 码因为多引入了一个变量 key，理论上它会更安全。 这种场景下，我们称 MAC 使用的密钥为 salt，即盐。 next_seed = MAC(salt, seed) ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-3-key-derivation-function/:1:2","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF","uri":"/posts/practical-cryptography-basics-3-key-derivation-function/"},{"categories":["技术"],"content":"二、KDF 密钥派生函数 我们都更喜欢使用密码来保护自己的数据而不是二进制的密钥，因为相比之下二进制密钥太难记忆了，字符形式的密码才是符合人类思维习惯的东西。 可对计算机而言就刚好相反了，现代密码学的很多算法都要求输入是一个大的数字，二进制的密钥就是这样一个大的数字。 因此显然我们需要一个将字符密码（Password）转换成密钥（Key）的函数，这就是密钥派生函数 Key Derivation Function. 直接使用 SHA256 之类的加密哈希函数来生成密钥是不安全的，因为为了方便记忆，通常密码并不会很长，绝大多数人的密码长度估计都不超过 15 位。 甚至很多人都在使用非常常见的弱密码，如 123456 admin 生日等等。 这就导致如果直接使用 SHA256 之类的算法，许多密码将很容易被暴力破解、字典攻击、彩虹表攻击等手段猜测出来！ KDF 目前主要从如下三个维度提升 hash 碰撞难度： 时间复杂度：对应 CPU/GPU 计算资源 空间复杂度：对应 Memory 内存资源 并行维度：使用无法分解的算法，锁定只允许单线程运算 主要手段是加盐，以及多次迭代。这种设计方法被称为「密钥拉伸 Key stretching」。 因为它的独特属性，KDF 也被称作慢哈希算法。 目前比较著名的 KDF 算法主要有如下几个： PBKDF2：这是一个非常简单的加密 KDF 算法，目前已经不推荐使用。 Bcrypt：安全性在下降，用得越来越少了。不建议使用。 Scrypt：可以灵活地设定使用的内存大小，在 argon2 不可用时，可使用它。 Argon2：目前最强的密码 Hash 算法，在 2015 年赢得了密码 Hash 竞赛。 如果你正在开发一个新的程序，需要使用到 KDF，建议选用 argon2/scrypt. 一个 scrypt 的 Python 示例： # 首先安装 Python 中最流行的加密库 [cryptography](https://github.com/pyca/cryptography) # pip install cryptography==36.0.1 import os from cryptography.hazmat.primitives.kdf.scrypt import Scrypt salt = os.urandom(16) # derive kdf = Scrypt( salt=salt, length=32, n=2**14, r=8, p=1, ) key = kdf.derive(b\"my great password\") # verify kdf = Scrypt( salt=salt, length=32, n=2**14, r=8, p=1, ) kdf.verify(b\"my great password\", key) ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-3-key-derivation-function/:2:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF","uri":"/posts/practical-cryptography-basics-3-key-derivation-function/"},{"categories":["技术"],"content":"参考 Practical-Cryptography-for-Developers-Book A complete overview of SSL/TLS and its cryptographic system ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-3-key-derivation-function/:3:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF","uri":"/posts/practical-cryptography-basics-3-key-derivation-function/"},{"categories":["技术"],"content":" 本文主要翻译自 Practical-Cryptography-for-Developers-Book，但是笔者也补充了许多代码示例及算法细节。 《写给开发人员的实用密码学》系列文章目录： 「译」写给开发人员的实用密码学（一）—— 概览 「译」写给开发人员的实用密码学（二）—— 哈希函数 「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF 「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器 「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE 「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法 待续 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:0:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"一、什么是哈希函数 哈希函数，或者叫散列函数，是一种从任何一种数据中创建一个数字指纹（摘要）的方法，散列函数把数据压缩压缩（或者放大）成一个长度固定的摘要。 哈希函数的输入空间（文本或者二进制数据）是无限大，但是输出空间（一个固定长度的摘要）却是有限的。将「无限」映射到「有限」，不可避免的会有概率不同的输入得到相同的输出，这种情况我们称为碰撞（collision）。 一个简单的哈希函数是直接对输入数据/文本的字节求和。 它会导致大量的碰撞，例如 hello 和 ehllo 将具有相同的哈希值。 更好的哈希函数可以使用这样的方案：它将第一个字节作为状态，然后转换状态（例如，将它乘以像 31 这样的素数），然后将下一个字节添加到状态，然后再次转换状态并添加下一个字节等。 这样的操作可以显着降低碰撞概率并产生更均匀的分布。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:1:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"二、加密哈希函数 一个好的「加密哈希函数」必须满足抗碰撞（collision-resistant）和不可逆（irreversible）这两个条件。 抗碰撞是指通过统计学方法（彩虹表）很难或几乎不可能猜出哈希值对应的原始数据，而不可逆则是说攻击者很难或几乎不可能从算法层面通过哈希值逆向演算出原始数据。 一个理想的加密哈希函数，应当具有如下属性： 快速：计算速度要足够快 确定性：对同样的输入，应该总是产生同样的输出 难以分析：对输入的任何微小改动，都应该使输出完全发生变化 不可逆：从其哈希值逆向演算出输入值应该是不可行的。这意味着没有比暴力破解更好的破解方法 无碰撞：找到具有相同哈希值的两条不同消息应该非常困难（或几乎不可能） 现代加密哈希函数（如 SHA2 和 SHA3）都具有上述几个属性，并被广泛应用在多个领域，各种现代编程语言和平台的标准库中基本都包含这些常用的哈希函数。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:2:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"量子安全性 现代密码学哈希函数（如 SHA2, SHA3, BLAKE2）都被认为是量子安全的，无惧量子计算机的发展。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:2:1","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"加密哈希函数的应用 1. 数据完整性校验 加密哈希函数被广泛用于文件完整性校验。如果你从网上下载的文件计算出的 SHA256 校验和（checksum）跟官方公布的一致，那就说明文件没有损坏。 但是哈希函数自身不能保证文件的真实性，目前来讲，真实性通常是 TLS 协议要保证的，它确保你在 openssl 网站上看到的「SHA256 校验和」真实无误（未被篡改）。 现代网络基本都很难遇到文件损坏的情况了，但是在古早的低速网络中，即使 TCP 跟底层协议已经有多种数据纠错手段，下载完成的文件仍然是有可能损坏的。 这也是以前 rar 压缩格式很流行的原因之一—— rar 压缩文件拥有一定程度上的自我修复能力，传输过程中损坏少量数据，仍然能正常解压。 2. 保存密码 加密哈希函数还被用于密码的安全存储，现代系统使用专门设计的安全哈希算法计算用户密码的哈希摘要，保存到数据库中，这样能确保密码的安全性。除了用户自己，没有人清楚该密码的原始数据，即使数据库管理员也只能看到一个哈希摘要。 3. 生成唯一 ID 加密哈希函数也被用于为文档或消息生成（绝大多数情况下）唯一的 ID，因此哈希值也被称为数字指纹。 注意这里说的是数字指纹，而非数字签名。 数字签名是与下一篇文章介绍的「MAC」码比较类似的，用于验证消息的真实、完整、作者身份的一段数据。 加密哈希函数计算出的哈希值理论上确实有碰撞的概率，但是这个概率实在太小了，因此绝大多数系统（如 Git）都假设哈希函数是无碰撞的（collistion free）。 文档的哈希值可以被用于证明该文档的存在性，或者被当成一个索引，用于从存储系统中提取文档。 使用哈希值作为唯一 ID 的典型例子，Git 版本控制系统（如 3c3be25bc1757ca99aba55d4157596a8ea217698）肯定算一个，比特币地址（如 1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2）也算。 4. 伪随机数生成 哈希值可以被当作一个随机数看待，生成一个伪随机数的简单流程如下： 通过随机事件得到一个熵（例如键盘点击或鼠标移动），将它作为最初的随机数种子（random seed）。 添加一个 1 到熵中，进行哈希计算得到第一个随机数 再添加一个 2，进行哈希计算得到第二个随机数 以此类推 当然为了确保安全性，实际的加密随机数生成器会比这再复杂一些，我们会在后面的「随机数生成器」一节学习其中细节。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:2:2","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"安全的加密哈希算法 1. SHA-2, SHA-256, SHA-512 SHA-2，即 Secure Hash Algorithm 2，是一组强密码哈希函数：SHA-256（256位哈希）、SHA-384（384位哈希）、SHA-512（512位哈希）等。基于密码概念「Merkle–Damgård construction」，目前被认为是高度安全。 SHA-2 是 SHA-1 的继任者，于 2001 年在美国作为官方加密标准发布。 SHA-2 在软件开发和密码学中被广泛使用，它被认为在密码学上足够强大，可用于现代商业应用。 SHA-256 被广泛用于比特币区块链，例如用于识别交易哈希和矿工执行的工作证明挖掘。 Python 代码示例： import hashlib, binascii text = 'hello' data = text.encode(\"utf8\") sha256hash = hashlib.sha256(data).digest() print(f\"SHA-256({text}) = \", binascii.hexlify(sha256hash).decode(\"utf8\")) sha384hash = hashlib.sha384(data).digest() print(f\"SHA-384({text}) = \", binascii.hexlify(sha384hash).decode(\"utf8\")) sha512hash = hashlib.sha512(data).digest() print(f\"SHA-512({text}) = \", binascii.hexlify(sha512hash).decode(\"utf8\")) 输出如下： SHA-256('hello') = 2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824 SHA-384('hello') = 59e1748777448c69de6b800d7a33bbfb9ff1b463e44354c3553bcdb9c666fa90125a3c79f90397bdf5f6a13de828684f SHA-512('hello') = 9b71d224bd62f3785d96d46ad3ea3d73319bfbc2890caadae2dff72519673ca72323c3d99ba5c11d7c7acc6e14b8c5da0c4663475c2e5c3adef46f73bcdec043 2. 更长的哈希值 == 更高的抗碰撞能力 按照设计，哈希函数的输出越长，就有望实现更高的安全性和抗碰撞能力（但也有一些例外）。 一般来说，128 位哈希算法比 256 位哈希算法弱，256 位哈希算法比 512 位哈希算法弱。 因此显然 SHA-512 比 SHA-256 更强。我们可以预期，SHA-512 的碰撞概率要比 SHA-256 更低。 3. SHA-3, SHA3-256, SHA3-512, Keccak-256 在输出的哈希长度相同时，SHA-3（及其变体 SHA3-224、SHA3-256、SHA3-384、SHA3-512）被认为拥有比 SHA-2（SHA-224、SHA-256、SHA-384、SHA-512）更高的加密强度。 例如，对于相同的哈希长度（256 位），SHA3-256 提供比 SHA-256 更高的加密强度。 SHA-3 系列函数是 Keccak 哈希家族的代表，它基于密码学概念海绵函数。Keccak 是SHA3 NIST 比赛的冠军。 与 SHA-2 不同，SHA-3 系列加密哈希函数不易受到长度拓展攻击 Length extension attack. SHA-3 被认为是高度安全的，并于 2015 年作为美国官方推荐的加密标准发布。 以太坊（Ethereum）区块链中使用的哈希函数 Keccak-256 是 SHA3-256 的变体，在代码中更改了一些常量。 哈希函数 SHAKE128(msg, length) 和 SHAKE256(msg, length) 是 SHA3-256 和 SHA3-512 算法的变体，它们输出消息的长度可以变化。 SHA3 的 Python 代码示例： import hashlib, binascii text = 'hello' data = text.encode(\"utf8\") sha3_256hash = hashlib.sha3_256(data).digest() print(f\"SHA3-256({text}) = \", binascii.hexlify(sha3_256hash).decode(\"utf8\")) sha3_512hash = hashlib.sha3_512(data).digest() print(f\"SHA3-512({text}) = \", binascii.hexlify(sha3_512hash).decode(\"utf8\")) 输出： SHA3-256('hello') = 3338be694f50c5f338814986cdf0686453a888b84f424d792af4b9202398f392 Keccak-256('hello') = 1c8aff950685c2ed4bc3174f3472287b56d9517b9c948127319a09a7a36deac8 SHA3-512('hello') = 75d527c368f2efe848ecf6b073a36767800805e9eef2b1857d5f984f036eb6df891d75f72d9b154518c1cd58835286d1da9a38deba3de98b5a53e5ed78a84976 SHAKE-128('hello', 256) = 4a361de3a0e980a55388df742e9b314bd69d918260d9247768d0221df5262380 SHAKE-256('hello', 160) = 1234075ae4a1e77316cf2d8000974581a343b9eb 4. BLAKE2 / BLAKE2s / BLAKE2b BLAKE / BLAKE2 / BLAKE2s / BLAKE2b 是一系列快速、高度安全的密码学哈希函数，提供 160 位、224 位、256 位、384 位和 512 位摘要大小的计算，在现代密码学中被广泛应用。BLAKE 进入了SHA3 NIST 比赛的决赛。 BLAKE2 函数是 BLAKE 的改进版本。 BLAKE2s（通常为 256 位）是 BLAKE2 实现，针对 32 位微处理器进行了性能优化。 BLAKE2b（通常为 512 位）是 BLAKE2 实现，针对 64 位微处理器进行了性能优化。 BLAKE2 哈希函数具有与 SHA-3 类似的安全强度，但开发人员目前仍然更倾向于使用 SHA2 和 SHA3。 BLAKE 哈希值的 Python 示例： import hashlib, binascii text = 'hello' data = text.encode(\"utf8\") blake2s = hashlib.new('blake2s', data).digest() print(\"BLAKE2s({text}) = \", binascii.hexlify(blake2s).decode(\"utf-8\")) blake2b = hashlib.new('blake2b', data).digest() print(\"BLAKE2b({text}) = \", binascii.hexlify(blake2b).decode(\"utf-8\")) 输出如下： BLAKE2s('hello') = 19213bacc58dee6dbde3ceb9a47cbb330b3d86f8cca8997eb00be456f140ca25 BLAKE2b('hello') = e4cfa39a3d37be31c59609e807970799caa68a19bfaa15135f165085e01d41a65ba1e1b146aeb6bd0092b49eac214c103ccfa3a365954bbbe52f74a2b3620c94 5. RIPEMD-160 RIPEMD-160, RIPE Message Digest 是一种安全哈希函数，发布于 1996 年，目前主要被应用在 PGP 和比特币中。 RIPEMD 的 160 位变体在实践中被广泛使用，而 RIPEMD-128、RIPEMD-256 和 RIPEMD-320 等其他变体并不流行，并且它们的安全优势具有争议。 建议优先使用 SHA-2 和 SHA-3 而不是 RIPEMD，因为它们输出的哈希值更长，抗碰撞能力更强。 Python 示例： import hashlib, binascii text = 'hello' data = text.encode(\"utf8\") ripemd160 = hashlib.new('ripemd160', data).digest() print(\"RIPEMD-160({text}) = \", binascii.hexlify(ripemd160).decode(\"utf-8\")) # =\u003e RIPEMD-160({text}) = 108f07b8","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:2:3","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"不安全的加密哈希算法 一些老一代的加密哈希算法，如 MD5, SHA-0 和 SHA-1 被认为是不安全的，并且由于加密漏洞（发现碰撞）而被撤回。不要使用 MD5、SHA-0 和 SHA-1！这些哈希函数都被证明在密码学上是不安全的。 使用这些不安全的哈希算法，可能会导致数字签名被伪造、密码泄漏等严重问题！ 另外也请避免使用以下被认为不安全或安全性有争议的哈希算法： MD2, MD4, MD5, SHA-0, SHA-1, Panama, HAVAL（有争议的安全性，在 HAVAL-128 上发现了碰撞），Tiger（有争议，已发现其弱点），SipHash（它属于非加密哈希函数）。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:2:4","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"PoW 工作量证明哈希函数 区块链中的 Proof-of-Work 工作量证明挖矿算法使用了一类特殊的哈希函数，这些函数是计算密集型和内存密集型的。 这些哈希函数被设计成需要消耗大量计算资源和大量内存，并且很难在硬件设备（例如集成电路或矿机）中实现，也就难以设计专用硬件来加速计算。这种哈希函数被称为抗 ASIC，英文是 ASIC-resistant. 大部分工作量证明（Proof-of-Work）算法，都是要求计算出一个比特定值（称为挖掘难度）更大的哈希值。 因为哈希值是不可预测的，为了找出符合条件的哈希值，矿工需要计算数十亿个不同的哈希值，再从中找出最大的那个。 比如，一个工作量证明问题可能会被定义成这样：已有常数 x，要求找到一个数 p，使 hash(x + p) 的前十个比特都为 0. 有许多哈希函数是专为工作量证明挖掘算法设计的，例如 ETHash、Equihash、CryptoNight 和 Cookoo Cycle. 这些哈希函数的计算速度很慢，通常使用 GPU 硬件（如 NVIDIA GTX 1080 等显卡）或强大的 CPU 硬件（如 Intel Core i7-8700K）和大量快速 RAM 内存（如 DDR4 芯片）来执行这类算法。 这些挖矿算法的目标是通过刺激小型矿工（家庭用户和小型矿场）来最大限度地减少挖矿的集中化，并限制挖矿行业中高级玩家们（他们有能力建造巨型挖矿设施和数据中心）的力量。 与少数的高玩相比，大量小玩家意味着更好的去中心化。 目前大型虚拟货币挖矿公司手中的主要武器是 ASIC 矿机，因此，现代加密货币通常会要求使用「抗 ASIC 哈希算法」或「权益证明（proof-of-stake）共识协议」进行「工作量证明挖矿」，以限制这部分高级玩家，达成更好的去中心化。 1. ETHash 这里简要说明下以太坊区块链中使用的 ETHash 工作量证明挖掘哈希函数背后的思想。 ETHash 是以太坊区块链中的工作量证明哈希函数。它是内存密集型哈希函数（需要大量 RAM 才能快速计算），因此它被认为是抗 ASIC 的。 ETHash 的工作流程： 基于直到当前区块的整个链，为每个区块计算一个「种子」 从种子中计算出一个 16 MB 的伪随机缓存 从缓存中提取 1 GB 数据集以用于挖掘 挖掘涉及将数据集的随机切片一起进行哈希 更多信息参见 eth.wiki - ethash 2. Equihash 简要解释一下 Zcash、Bitcoin Gold 和其他一些区块链中使用的 Equihash 工作量证明挖掘哈希函数背后的思想。 Equihash 是 Zcash 和 Bitcoin Gold 区块链中的工作量证明哈希函数。它是内存密集型哈希函数（需要大量 RAM 才能进行快速计算），因此它被认为是抗 ASIC 的。 Equihash 的工作流程： 基于直到当前区块的整个链，使用 BLAKE2b 计算出 50 MB 哈希数据集 在生成的哈希数据集上解决「广义生日问题」（从 2097152 中挑选 512 个不同的字符串，使得它们的二进制 XOR 为零）。已知最佳的解决方案（瓦格纳算法）在指数时间内运行，因此它需要大量的内存密集型和计算密集型计算 对前面得到的结果，进行双 SHA256 计算得到最终结果，即 SHA256(SHA256(solution)) 更多信息参见 https://github.com/tromp/equihash ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:2:5","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"三、非加密哈希函数 加密哈希函数非常看重「加密」，为了实现更高的安全强度，费了非常多的心思、也付出了很多代价。 但是实际应用中很多场景是不需要这么高的安全性的，相反可能会对速度、随机均匀性等有更高的要求。 这就催生出了很多「非加密哈希函数」。 非加密哈希函数的应用场景有很多： 哈希表 Hash Table: 在很多语言中也被称为 map/dict，它使用的算法很简单，通常就是把对象的各种属性不断乘个质数（比如 31）再相加，哈希空间会随着表的变化而变化。这里最希望的是数据的分布足够均匀。 一致性哈希：目的是解决分布式缓存的问题。在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。 高性能哈希算法：SipHash MurMurHash3 等，使用它们的目的可能是对数据进行快速去重，要求就是足够快。 有时我们甚至可能不太在意哈希碰撞的概率。 也有的场景输入是有限的，这时我们可能会希望哈希函数具有可逆性。 总之非加密哈希函数也有非常多的应用，但是不是本文的主题。 这里就不详细介绍了，有兴趣的朋友们可以自行寻找其他资源。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:3:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":"参考 Practical-Cryptography-for-Developers-Book 漫谈非加密哈希算法 开发中常见的一些Hash函数（一） ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-2-hash/:4:0","tags":["Cryptography","Hash","密码学","哈希","散列"],"title":"「译」写给开发人员的实用密码学（二）—— 哈希函数","uri":"/posts/practical-cryptography-basics-2-hash/"},{"categories":["技术"],"content":" 本文主要翻译自 Practical-Cryptography-for-Developers-Book，但是笔者也补充了许多代码示例及算法细节。 《写给开发人员的实用密码学》系列文章目录： 「译」写给开发人员的实用密码学（一）—— 概览 「译」写给开发人员的实用密码学（二）—— 哈希函数 「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF 「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器 「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE 「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法 待续 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:0:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"零、前言 你是软件开发人员吗？有时你会需要在日常工作中使用哈希、加密或数字签名等密码学工具吗？ 你认为密码学很复杂，充满了数学知识，而且只适合书呆子吗？ 不，不是这样滴，每个开发人员都可以学习如何使用加密算法。 从开发人员的角度理解密码学概念不需要你是一个厉害的数学家。 本书将以几乎没有数学内容的方式教你应用密码学的基础知识，而且包含大量循序渐进的代码示例和实践练习——就像你学习 Web 开发、数据库或 APP 一样。 没错，如果你能够学会 Web 开发或 RESTful 服务，那么你也完全可以学会实用密码学。这就像学习一个新的 API 或一个新的 Web 开发框架，只要掌握了概念 + 加密库 API + 工具 + 最佳实践，你就学会了实用密码学~ 从本书中，你将学习如何使用密码算法和密码系统，如哈希、MAC 码和密钥派生函数 (KDF)、随机生成器、密钥交换协议、对称密码算法、加密方案、非对称密码系统、公钥密码学、椭圆曲线、数字签名和量子安全加密算法，以及现代加密工具和库。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:1:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"一、现代密码学概览 密码学已经从第一代广泛应用的密码学算法（比如已经退役的 MD5 跟 DES），发展到现代密码学算法（如 SHA-3, Argon2 以及 ChaCha20）。 让我们首先跟一些基本的密码学概念混个脸熟： 哈希函数，如 SHA-256, SHA3, RIPEMD 等 散列消息认证码 HMAC 密钥派生函数 KDF，如 Scrypt 密钥交换算法，Diffie-Hellman 密钥交换协议 对称密钥加密方案，如 AES-256-CTR-HMAC-SHA-256 使用公私钥的非对称密钥加密方案，如 RSA 和 ECC, secp256k1 曲线跟 Ed25519 密码系统 数字签名算法，如 ECDSA 熵（entropy）与安全随机数生成 量子安全（quantum-safe）密码学 上述这些概念涉及到技术被广泛应用在 IT 领域，如果你有过一些开发经验，可能会很熟悉其中部分名词。 如果不熟也没任何关系，本书的目的就是帮你搞清楚这些概念。 这个系列的文章会按上面给出的顺序，依次介绍这些密码学概念以及如何在日常开发中使用它们。 不过在开始学习之前，我们先来了解一下什么是密码学，以及密码学的几大用途。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:2:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"二、什么是密码学 密码学（Cryptography）是提供信息安全和保护的科学。 它在我们的数字世界中无处不在：当你打开网站、发送电子邮件或连接到 WiFi 网络时。这就是为什么开发人员至少应该对密码学有基本的了解，至少也得知道如何使用密码算法和密码库，了解哈希、对称密码算法、非对称密码算法（cipher）与加密方案这些概念，知晓数字签名及其背后的密码系统和算法。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:3:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"三、密码学的用途 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:4:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"1. 加密与密钥 密码学的一大用途，就是进行数据的安全存储和安全传输。 这可能涉及使用对称或非对称加密方案加密和解密数据，其中一个或多个密钥用于将数据从明文转换为加密形式或者相反。 对称加密（如 AES、Twofish 和 ChaCha20）使用相同的密钥来加密和解密消息， 而非对称加密使用公钥密码系统（如 RSA 或 ECC）和密钥对来进行这两项操作。 单纯使用加密算法是不够的，这是因为有的加密算法只能按块进行加密，而且很多加密算法并不能保证密文的真实性、完整性。 因此现实中我们通常会使用加密方案进行数据的加密解密。加密方案是结合了多种加密算法、消息认证或数字签名算法等多种算法，能同时保证数据的安全性、真实性、完整性的一套方案。 比如 AES-256-CTR-HMAC-SHA-256、ChaCha20-Poly1305 或 ECIES-secp256k1-AES-128-GCM，后面我们会学到，加密方案的名称就是使用到的各种算法名称的组合。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:4:1","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"2. 数字签名与消息认证 密码学提供了保证消息真实性（authenticity）、完整性（integrity）和不可否认性（non-repudiation）的方法：数字签名算法与消息认证（MAC）算法。 大多数数字签名算法（如 DSA、ECDSA 和 EdDSA）使用非对称密钥对（私钥和公钥）干这个活：消息由私钥签名，签名由相应的公钥验证。 在银行系统中，数字签名用于签署和批准付款。 在区块链签名交易中，用户可以将区块链资产从一个地址转移到另一个地址，确保转移操作的真实、完整、不可否认。 消息认证算法（如 HMAC）和消息认证码（MAC 码）也是密码学的一部分。MAC 跟数字签名的功能实际上是一致的，区别在于 MAC 使用哈希算法或者对称加密系统。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:4:2","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"3. 安全随机数 密码学的另一个部分，是熵（entropy，不可预测的随机性）和随机数的安全生成（例如使用 CSPRNG）。 安全随机数理论上是不可预测的，开发人员需要关心的是你使用的随机数生成器是否足够安全。 很多编程语言中被广泛使用的随机数生成器都是不安全的，如果你在对安全有严格要求的场景下使用了这种不安全的随机生成器，可能会黑客被预测到它生成的随机数，导致系统或者 APP 被黑客入侵。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:4:3","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"4. 密钥交换 密码学定义了密钥交换算法（如 Diffie-Hellman 密钥交换和 ECDH）和密钥构建方案，用于在需要安全传输消息的两方之间安全地构建加密密钥。 这种算法通常在两方之间建立新的安全连接时执行，例如当你打开一个现代 HTTPS 网站或连接到 WiFi 网络时。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:4:4","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"5. 加密哈希与 Password 哈希 密码学提供了加密哈希函数（如 SHA-3 和 BLAKE2）将消息转换为消息摘要/数字指纹（固定长度的散列），确保无法逆向出原始消息，并且几乎不可能找到具有相同哈希值的两条不同消息。 例如，在区块链系统中，哈希用于生成区块链地址、交易 ID 以及许多其他算法和协议。在 Git 中，加密哈希用于为文件和提交生成唯一 ID。 而密钥派生函数（如 Scrypt 和 Argon2）通过从基于文本的 Password 安全地派生出哈希值（或密钥），并且这种算法还通过注入随机参数（盐）和使用大量迭代和计算资源使密码破解速度变慢。 密码学也被用于密钥（一个非常大的、保密的数字）的生成。 因为人类只擅长记忆字符形式的 Password/Passphrases，而各种需要加密算法需要的密钥，都是一个非常大的、保密的数字。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:5:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"四、混淆与扩散 在密码学当中，香农提出的混淆（confusion）与扩散（diffusion）是设计安全密码学算法的两个原则。 混淆使密文和对称加密中密钥的映射关系变得尽可能的复杂，使之难以分析。 如果使用了混淆，那么输出密码中的每个位都应该依赖于密钥和输入数据的多个部分，确保两者无法建立直接映射。 混淆常用的方法是「替换」与「排列」。 「扩散」将明文的统计结构扩散到大量密文中，隐藏明文与密文之间的统计学关系。 使单个明文或密钥位的影响尽可能扩大到更多的密文中去，确保改变输入中的任意一位都应该导致输出中大约一半的位发生变化，反过来改变输出密文的任一位，明文中大约一半的位也必须发生变化。 扩散常用的方法是「置换」。 这两个原则被包含在大多数散列函数、MAC 算法、随机数生成器、对称和非对称密码中。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:6:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["技术"],"content":"五、密码库 说了这么多，作为一个程序员，我学习密码学的目的，只是了解如何在编程语言中使用现代密码库，并从中挑选合适的算法、使用合适的参数。 程序员经常会自嘲日常复制粘贴，但是在编写涉及到密码学的代码时，一定要谨慎处理！盲目地从 Internet 复制/粘贴代码或遵循博客中的示例可能会导致不安全的设计和弱安全性，曾经安全的代码、算法或者最佳实践随着时间的推移也可能变得不再安全。 本系列文章的后续部分，会分别介绍上述密码学概念，并使用 Python 演示其用法，其他语言的写法网上也很容易找到。 ","date":"2022-03-01","objectID":"/posts/practical-cryptography-basics-1/:7:0","tags":["Cryptography","Hash","KDF","密码学","哈希","加解密","签名"],"title":"「译」写给开发人员的实用密码学（一）—— 概览","uri":"/posts/practical-cryptography-basics-1/"},{"categories":["随笔"],"content":" 本文转载自朋友写的 写给优秀程序员看的马拉松指南🏃 - Chuanyi，读下来感觉写得超棒超正能量，征得他同意后转载过来分享下嘿嘿~ 文中术语：PB(Personal Best) PW(Personal Worst) BQ(Boston Qualify) 4 月 11 日，气温 16-19 度，东风。前两天看预报，说可能会有雷阵雨，当天看预报，雷阵雨又延后到了下午两点多，真是天公作美啊。早上八点气温非常舒适，我预感到我又要 PB 了。 今年仙马的路线非常平稳，起伏不到三十米。正是农历草长莺飞二月天，沿途春意盎然，令人心情愉悦。只是十公里处的折返点非常恼人，拐弯后跑出几十米就立刻折返再次拐弯，减速到 0 并再次加速浪费了数秒。我知道此举是为了凑距离，但是完全可以取消这个折返点，延长终点。路线上的这个凸起，不禁让我联想到 Ph.D 的使命。 一名博士的使命 仙马四年，声名鹊起，一路摘得铜牌、银牌、金牌，今年又被“世界田径“正式列为标牌赛事，这些年出圈的努力和成果都蕴含在这个尖尖上了，我如此解读，组委会应该没有意见吧。 4 月 11 日早上，东风三级，起步向东，有些逆风，不利。吹面不寒杨柳风，逆风带来了凉爽，一路汗水都被吹干，全身上下始终都保持着干燥舒适。 第一公里计划是五分配，但是太过于兴奋，有些失控，但仍然压着 440；后五公里状态来临，逐渐将配速提到并保持在 430；六公里多迎来一个南北走向的下坡，借着势能的释放，配速拉到 410 以内。由南向北，春风拂面，夹道樱花，落英缤纷，我踩着碳板，好像踏着粉色的云霞。此时手表却一直在耳机里提醒我配速过高，机器终归是无情的，不懂风月，难知我心；七到十六公里折返点终于开始顺风，此时我稳定了 4:25 上下配速，喝了两次水，感觉还不错，并没有什么痛苦。十二公里，为了防止临近终点力量不足，我掏出一个柠檬味能量胶，迅速挤在嘴里，并在后面的水站取了一杯水。到了十三公里外已经能看见折返的第一梯队了；十六公里折返开始一个长达三公里的缓坡，中途听见一位大哥在和同伴谈论后面如何如何难跑。以我的状态看来，我不以为然，缓坡没让我失速太多。十九公里路过我的母校北门，门口有我校传统艺能舞龙舞狮，不过PB 目标不允许我驻足拍一张，有些遗憾；越跑越欢，转眼二十公里，前方是熟悉的校友团服，追上前去看，是张书记，打了招呼后，我便全力冲刺，最终成绩 133，意料之外，情理之中，冬天堆有氧的效果体现了。 青春仙林，大爱仙马。17 年首届，门外汉，门外看；18年入门，陈子豪（2016 年南京市大学生运动会 1500 米冠军田径小霸王2016年南京市运会1500m一骑绝尘！）带我们在仙林校区开始练，一圈刚好就是 5km 的绝佳跑场。19 年终于参加了我的第一次仙马，去年仙马因疫情停办一年，时隔一年后再次回归。故地重游，取得 PB，这段仙马记忆永远不会斑驳。 仙马成绩证书 第七场半程了, 成绩一路提升，156 =\u003e 149 =\u003e 147 =\u003e null =\u003e 157 =\u003e 138 =\u003e 133，每次的进步都会令我无比激动。 生活好似一个湖泊，平水如鉴，岁月静好，固然优雅；但不流动的水是容易腐败的，需要一些外来的扰动，狂风骤雨之下，浊浪翻滚，却也注入了全新的生命力。每次 PB 都是我对这平静生活狂风暴雨一般的拷问，我的生命力不应该只局限在钢筋水泥之间。 ","date":"2022-02-26","objectID":"/posts/likenttt-2021-04-11-xianlin-half-marathon-1_33_12/:0:0","tags":["长跑","马拉松","运动"],"title":"「转」仙马赛记——我又 PB 了","uri":"/posts/likenttt-2021-04-11-xianlin-half-marathon-1_33_12/"},{"categories":["随笔"],"content":" 本文转载自朋友写的 写给优秀程序员看的马拉松指南🏃 - Chuanyi，读下来感觉写得超棒超正能量，征得他同意后转载过来分享下嘿嘿~ 本文所描述的广州马拉松赛事时间为 2020-12-13 文中术语：PB(Personal Best) PW(Personal Worst) BQ(Boston Qualify) ","date":"2022-02-26","objectID":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/:0:0","tags":["长跑","马拉松","运动"],"title":"「转」MIRT出征广马——首次摸到330的边儿","uri":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/"},{"categories":["随笔"],"content":"赛前计划 目标成绩：3:37 平均配速：5:08 前21km 5:13 加减 5s 后21km 5:03 加减 5s 实际：3:30:15 ","date":"2022-02-26","objectID":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/:1:0","tags":["长跑","马拉松","运动"],"title":"「转」MIRT出征广马——首次摸到330的边儿","uri":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/"},{"categories":["随笔"],"content":"补给 能量胶6支 绿灰绿灰黄红 服用时机 颜色 赛前5分钟 绿 10 灰 20 绿 30 灰 35 黄 40 红 ","date":"2022-02-26","objectID":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/:2:0","tags":["长跑","马拉松","运动"],"title":"「转」MIRT出征广马——首次摸到330的边儿","uri":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/"},{"categories":["随笔"],"content":"赛中简记 我和兴勇师兄一起从 C 区出发，按照 500 配速跑，观察状态。 九公里处追上旦哥，旦哥此次担任 345 Pacer ，赛前他向我们许诺，如果能追上他就能摸一摸他的光头。说实话，我对这颗光头是垂涎已久，心想这是罕有的机会，舍我其谁。当我远远地望见飘动的气球时，我就忍不住兴奋的呼喊旦哥，渐渐距离迫近到数米，旦哥心照不宣地兑现承诺，主动伸过他的头，让我摸。紧实的光头满是汗水，很滑，竟没有一丝头发，既不扎手也没有阻滞感，像极了一颗剥了壳的鸡蛋，我一个程序员也不禁为之动容，设计师（旦哥是一名声音设计师）这么伤头发吗，幸亏我没入这行。师兄决意一路跟着旦哥，我遂和他分别，去追赶 330 兔子，配速始终稳定在 450～500。 此后至 38km 之间配速稳定在这个区间里，看看风景，胡思乱想。猎德大桥是一个不小的挑战，迂回冲坡上引桥，下桥减速绕弯弯，起伏之间容易跑崩，但我始终平稳。下了桥是一个超长的折返，双向车道被绿化带切开，木棉（也许是合欢）一字排开，树干跟保龄球一样臃肿粗壮，草地上洒满了粉的花，白的穗，这南国的冬天竟然好似江南的樱花季。去程左前方已经稀稀落落地有人折回，能拉开这么多距离，是精英选手无疑了，他们跑姿大多都很美观，服装、配件、摆臂、踏步令我欣赏了好一阵。但是也有一些跑者，跑姿不那么具有观赏性的，用力过度，姿势僵硬，力量运用地不太经济，近似一种暴力美学了，我认为他们中有一些人只是暂时领先而已。后来我也折返了，此时再往左前方看，人群开始密集了起来，这种视角仿佛和原来的自己打了个照面。目光数次和几个聚集的配速员集团相遇，我试图在人群中分辨出我的队友们，却始终搜索无获，我数度怀疑是不是我已经走神儿错过了他们。21km 附近几个隧道也是不小的挑战，U型隧道起伏大，下坡要适当利用势能但也要避免心率过高，上坡要适当减速增加抓地力，地面湿滑，摩擦系数减小，要防止滑倒。过了半程以后，广州塔近在咫尺，仰之弥高，我的精神还很轻松，决定钻之弥坚。 今天是国家公祭日，十点，脑子里想到南京城此时应该鸣笛的，不禁热泪盈眶，随后心中默哀了一分多钟。昭昭前事，惕惕后人。永矢弗谖，祈愿和平。 天气预报显示今日气温在 21～22 度，但湿度较大，体感温度高于 22 度。好在穿的是背心，体表散热面积大，心率始终控制在 175 以下。每逢水站喝一小杯水，每五公里吃两片盐丸，按着计划吃能量胶。得益于以上种种努力，前 38 公里都还轻松，甚至游刃有余。但是第 39 公里我开始感到疲惫，感到厌倦，看看手表，发现心率已经到达 189，心下想这是终点前跑崩的前兆啊。一个多月前无锡马拉松折戟的经历还令我心有余悸。第 39 和 40 公里分别跑出了 521 和 523 的配速，心里很慌。到达水站后，再度补充盐丸和能量胶，并不断给自己做心里建设工作：这是难得的机遇，跑团南下首秀，集团给了莫大支持，跑团组委会也做了大量筹备；年初 PB(Personal Best)，年尾 PW(Personal Worst)，有点虎头蛇尾，接下来，坚持鏖战，后悔几天，放弃躺倒，懊悔半年。吃完最后一支柠檬味的能量胶，喝饱了水，重新出发。最后两公里跑回 451 配速，安全完赛并 PB。冲过终点，顿时感到一种超然🤯的轻快，广州是一座充满希望的城市！不过差 15 秒就能达到广马的 BQ(Boston Qualify)，仍然有一丝遗憾。但无论如何，取得这样的成绩我已经很满意了。 我很庆幸，从学生时代就培养起来的长跑爱好，可以陪伴我走进职业生涯并顽强保持至今，一路上我收获一群互相砥砺支持的好朋友。易方达基金的 slogan：乐于在长跑中取得胜利，这也是广马重要收获之一。胜利，指挑战并超越过去的自己，beat yesterday。寄予希望，并不断挑战超越，这是一种痛并快乐着的幸福。长跑如此，生活职业亦如是。 ","date":"2022-02-26","objectID":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/:3:0","tags":["长跑","马拉松","运动"],"title":"「转」MIRT出征广马——首次摸到330的边儿","uri":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/"},{"categories":["随笔"],"content":"技术总结 广马当天高达二十多摄氏度，通常来说，这样的温度并不特别友好，无疑，这丰富了我高温作战的经验。及时补给，盐丸和能量胶，如果天热尤其要补水和盐丸。后来和旦哥复盘，我抱怨道中途补充了九次水，后面几乎逢水站必停。旦哥说：如果你不补水，你怎么保证后面不会崩呢？我恍然大悟，吃到第个三馒头饱了，功劳绝不只是第三个馒头的，前两个馒头亦是关键。 预先规划好时间和配速。根据目的估算并严格执行。如果是跑成绩，不要高估，避免过度透支能力，也不要低估，一直躺在舒适的成绩上。 烟雾弹还是要放的，这是赛前乐趣所在，烟雾弹放出去了，进可凡学，退可务实。 训练需要注意提高体能和心理承受阈值。体能耗尽，其后是心有余而力不足；心态崩溃，无心再战，先前努力便俱付东流。 ","date":"2022-02-26","objectID":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/:3:1","tags":["长跑","马拉松","运动"],"title":"「转」MIRT出征广马——首次摸到330的边儿","uri":"/posts/likenttt-2020-12-13-guangzhou-marathon-3_30_15/"},{"categories":["技术"],"content":" 个人笔记，只会列出我自己容易忘掉的命令，方便查阅。 内容比较多，适合当参考手册用。可能不太适合从头读到尾… 本文主要介绍 Linux 命令，顺带介绍下 Windows/MacOSX. ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:0:0","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"一、Linux ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:0","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"1. 后台运行 # 1. 后台运行命令 nohup python xxx.py \u0026 也可以使用 tmux，tmux 提供的 session 功能比 nohup 更好用，后面会介绍 tmux ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:1","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"2. 查找替换 sed/awk sed 常用命令： ## 只在目录中所有的 .py 和 .dart 文件中递归搜索字符\"main()\" grep \"main()\" . -r --include *.{py, dart} ## 1） 全文搜索并替换 ### -i --in-place 原地替换（修改原文件） ### -i=SUFFIX 替换后的文件添加 SUFFIX 这个后缀 ### -r 使用拓展的正则表达式，注意此正则不支持 \\d\\w\\s 等语法，必须使用 [0-9] [a-zA-Z] 等来替换！！！ sed -ri \"s/pattern_str/replace_str/g\" `grep \"key_pattern\" 'path_pattern' -rl` ## 2）文件名搜索，替换文件内容 sed -ri \"s/pattern_str/replace_str/g\" `find . -name \"pattern\"` ## 3）批量转换大小写 # 将当前文件夹内，所有的 gitlab URL 都转换成小写 # \\L 转小写 \\U 转大写 sed -ri 's@http://GITLAB.*.git@\\L\u0026@g' `find . -name pubspec*` ## 4) 拷贝文件，并且保持文件夹结构（--parents 表示保持文件夹结构） cp --parents `find \u003csrc-dir\u003e -name *.py` \u003cdst-dir\u003e awk 用于按列处理文本，它比 sed 更强大更复杂，常用命令： ## 1. 单独选出第 1 列的文本 cat xxx.txt | awk -F '{print $1}' | head ## 2. 可以使用 -F 指定分隔符，打印出多列 awk -F ',' '{print $1,$2}'| head ## 3. 打印出行数 cat log_test | awk '{print NR,$1}' | more ## 4. if 判断语句 cat log_test | awk '{if($11\u003e300) print($1,$11)}' cat log_test | awk '{print $11}' | sort -n | uniq -c # 求和 cat data|awk '{sum+=$1} END {print \"Sum = \", sum}' # 求平均 cat data|awk '{sum+=$1} END {print \"Average = \", sum/NR}' # 求最大值 cat data|awk 'BEGIN {max = 0} {if ($1\u003emax) max=$1 fi} END {print \"Max=\", max}' # 求最小值（min的初始值设置一个超大数即可） awk 'BEGIN {min = 1999999} {if ($1\u003cmin) min=$1 fi} END {print \"Min=\", min}' ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:2","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"3. 压缩相关 # 直接 cat 压缩文件的内容 zcat xxx.gz | more # gzip xzcat xxx.xz | more # xz tar -axvf xxx.tar.* # 通过后缀识别压缩格式，智能解压 更多命令参见 常见压缩格式的区别，及 Linux 下的压缩相关指令 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:3","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"4. 文件拷贝与同步 各种 Linux 发行版都自带 scp/ssh，这两个工具功能简单，一般够用。 另外就是更强大也更复杂的 rsync，部分发行版会自带 rsync。 下面分别介绍下。 1. ssh/scp # 如果使用 ssh 命令进行文件传输，可安装 pv 命令查看传输速度（pipeviewer） ## ubuntu sudo apt-get install pv ## centos sudo yum install epel-release sudo yum install pv ## 1)从本地上传到服务器 ### 使用 ssh 的好处是流式传输不会占用目标机器的存储空间，适合传输可能引起空间不足的大文件，并在目标机器上实时处理该文件。 cat \u003cfilename\u003e | pv | ssh \u003cuser\u003e@\u003chost\u003e -p 22 \"cat - \u003e \u003cnew-filename\u003e\" tar cz \u003cfilename or foldername or glob\u003e | pv | ssh \u003cuser\u003e@\u003chost\u003e -p 22 \"tar xz\" # 压缩传输 ## scp 命令比 ssh 命令更简洁（但是不适合用于传文件夹，它会破坏文件的权限设置，把文件夹弄得一团糟） scp -P 22 \u003cfilename\u003e \u003cuser\u003e@\u003chost\u003e:\u003cfolder-name or filename\u003e # 通过 scp 传输，传文件夹时记得添加 -r 参数（recursive） ## 2) 从服务器下载到本地 ssh \u003cuser\u003e@\u003chost\u003e -p 22 \"tar cz \u003cfilename or foldername or glob\u003e\" | pv | tar xz # 压缩传输 scp -P 22 \u003cuser\u003e@\u003chost\u003e:\u003cfolder-name or filename\u003e \u003cfilename\u003e # 通过 scp 传输，传文件夹时记得添加 -r 参数（recursive） 2. rsync rsync 的功能其实和前面的 scp/(tar+ssh) 是一样的，将文件从一个地方拷贝到另一个地方。 区别在于它只做增量同步，在多次拷贝文件时，只拷贝（同步）修改过的部分，很多场景下可以大大加快拷贝/备份速度。 rsync 的常用命令： # 将一个文件夹归档、压缩，并通过 ssh 协议（默认）同步到另一个地方 # -a, --archive # 归档模式，保留文件的所有元信息，等同于 `-rlptgoD` # -r, --recursive # 递归复制文件夹，`-a` 隐含了这个参数，通常都用 -a。 # -v, --verbose # 输出详细信息 # --progress # 显示传输进度 # -z, --compress # 传输文件时进行压缩 rsync -avz --progress src host:dest rsync -avz --progress -e \"ssh -p225\" /path/src user@host:dest # 使用非默认的 ssh 端口进行传输 rsync -avz --progress -e \"ssh -i id_xxx\" /path/src user@host:dest # 使用指定的私钥连接 ssh 服务端，其他各种 ssh 参数都可以在这里指定 # --exclude 排除掉某些不需要的文件(夹) rsync -avz --progress --exclude \"foor/bar\" src user@host:dest # 有时我们希望在同步数据时修改文件的 user/group # --chown # 设置文件的 user:group，必须与 `-og`/`--owner --group` 同时使用！（`-a` 隐含了 `-og`） rsync -avz --progress --chown=root:root src user@host:dest # 传输时修改 user/group 为 root # 详细说明 src 和 dest 的位置 rsync -avz --progress path/src user@host:/tmp # 将 src 拷贝到远程主机的 /tmp 中（得到 /tmp/src） ## 注意 src 结尾有 / rsync -avz --progress path/src/ user@host:/tmp/src # 将 src 目录中的文件拷贝到远程主机的 /tmp/src 目录中（同样得到 /tmp/src） # 有时候我们在传输文件时不希望保留文件的元信息 # rsync 默认不会删除 dest 中多余的文件，使用 --delete 可让 rsync 删除这部分无关的文件 # 对 src 文件夹进行完全镜像，保证两个文件夹的内容一模一样，不多不少 rsync -avz --progress --delete src user@host:dest # 也可以使用 --ignore-existing 让 rsync 忽略掉 dest 已经存在的文件。就是只同步新增的文件。 rsync -avz --progress --ignore-existing src user@host:dest 另外也有使用双冒号 :: 分隔的传输命令，这种命令使用 rsync 协议进行传输，要求目标主机启用 rsync-daemon。用得会比 ssh 少一些，暂时不做介绍。 rsync 详细文档参见 https://rsync.samba.org/documentation.html，或者 man rsync. ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:4","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"5. Tmux 输入 tmux 启动一个 tmux 会话。（或者用 tmux new -s \u003csession-name\u003e 启动一个命名会话） 输入 python xxx.py，python 进程开始运行。 按快捷键 ctrl+b，然后再按一下 d 脱离(detatch)当前会话。此时 python 进程进入后台运行，关闭当前终端对 python 进程没有影响。 输入 tmux ls 可以查看当前正在后台运行的会话。（命名会话会显示名称，否则只显示 id） 通过 tmux attach -t \u003csession-name/id\u003e 重新接入后台会话。 缩写 tmux a -t \u003csession\u003e 或者通过 tmux kill-session -t \u003csession-name/id\u003e 杀死一个后台会话。 常用快捷键： # prefix 表示 `ctrl`+`b`# pane 的切分与选择prefix \" # 在下方新建一个 paneprefix % # 在右侧新建一个 paneprefix `方向键` # 光标移动到指定方向的 pane 中# 使用方向键滚动窗口内容prefix [ # 进入翻页模式，可使用 page up/down，或者方向键来浏览 pane 的内容# 使用鼠标滚轮来滚动窗口内容（也可以把此命令添加到 `~/.tmux.conf` 中使它永久生效）prefix `:` 然后输入 `set-window-option -g mode-mouse on`# （调整 pane 大小）将当前的 pane 向给定的方向扩容 5 行或者 5 列# 按住 ALT 时快速重复敲击「方向键」，能快速调整，否则就得从 prefix 开始重新输入prefix `Alt` + `方向键`# 将当前窗格全屏显示，第二次使用此命令，会将窗格还原prefix z# 交换 pane 的位置prefix { # 当前窗格与上一个窗格交换位置prefix } # 当前窗格与下一个窗格交换位置# session 相关操作prefix s # 查看 session 列表，并通过方向键选择 sessionprefix `number` # 通过数字标签选择 session# window 相关操作（关系：每个 session 可以包含多个 window，每个 window 里面又可以有多个 pane）prefix c# 新建 windowprefix w# 通过数字标签选择 window 参考文档： https://github.com/tmux/tmux/wiki/Getting-Started https://www.ruanyifeng.com/blog/2019/10/tmux.html ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:5","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"6. Bash Shell 基础 目标：能使用 shell 编写 10 行以内的脚本。更长的脚本可以使用 Python 编写，就没必要折腾 Shell 了。 1. For 循环 单行 for 循环，有时候很有用： # 数字枚举 for i in $(seq 1 5); do echo $i; done # sh/bash 都支持 for i in {1..5}; do echo $i; done # sh 不支持此语法 # 文件枚举，可使用 glob 语法进行文件匹配 for f in *; do echo $f; done for f in /etc/*.py; do echo $f; done # 使用 find 进行文件枚举 for f in $(find . -name *.py); do echo $f; done 单行 for 循环加几个换行就得到多行 for 循环，格式如下：写脚本用得到，不过更建议用 python: for i in $(seq 1 5) do echo $i done # sh/bash 都支持 2. if 语句 # 单行 if 语句 if [ true ]; then \u003ccommand\u003e; fi # if else if [ expression ] then Statement(s) to be executed if expression is true else Statement(s) to be executed if expression is not true fi 3. Shell脚本中的set指令，比如set -x 和 set -e 参见：Shell脚本中的set指令，比如set -x 和 set -e 4. 其他资料 shell_scripts: 实用 shell 小脚本 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:6","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"7. socket 连接查询 - ss/netcat/lsof 查看 socket 信息可以帮我们回答下列问题： 我的程序是不是真的在监听我指定的端口？ 我的程序是在监听 127.0.0.1（本机），还是在监听 0.0.0.0（整个网络） 进程们分别在使用哪些端口？ 我的连接数是否达到了上限？ 现在较新版本的 Ubuntu 和 CentOS 都已经使用 iproute2 替换掉了 net-tools， 如果你还需要使用陈旧的 route netstat 等命令，需要手动安装 net-tools。 我们可以使用 ss(socket statistics) 或者 netstat 命令来查看 socket 信息: # 查看 socket 连接的统计信息 # 主要统计处于各种状态的 tcp sockets 数量，以及其他 sockets 的统计信息 ss --summary ss -s # 缩写 # 查看哪个进程在监听 80 端口 # --listening 列出所有正在被监听的 socket # --processes 显示出每个 socket 对应的 process 名称和 pid # --numeric 直接打印数字端口号（不解析协议名称） ss --listening --processes --numeric | grep 80 ss -nlp | grep 80 # 缩写 ss -lp | grep http # 解析协议名称，然后通过协议名搜索监听 ## 使用过时的 netstat ### -t tcp ### -u udp netstat -tunlp | grep \":80\" # 查看 sshd 当前使用的端口号 ss --listening --processes | grep sshd ## 使用过时的 netstat netstat -tunlp | grep \u003cpid\u003e # pid 通过 ps 命令获得 # 列出所有的 tcp sockets，包括所有的 socket 状态 ss --tcp --all # 只列出正在 listen 的 socket ss --listening # 列出所有 ESTABLISHED 的 socket（默认行为） ss # 统计 TCP 连接数 ss | grep ESTAB | wc -l # 列出所有 ESTABLISHED 的 socket，并且给出连接的计时器 ss --options # 查看所有来自 192.168.5 的 sockets ss dst 192.168.1.5 # 查看本机与服务器 192.168.1.100 建立的 sockets ss src 192.168.1.5 TCP 连接数受 Linux 文件描述符上限控制，可以通过如下方法查看已用文件句柄的数量。 # 已用文件描述符数量 lsof | wc -l # 文件描述符上限 ulimit -n ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:7","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"8. 其他网络相关命令 主要是 iproute2 dhclient lsof 等 # 查看路由表 routel # 旧的 net-tools 包中的命令 ip route ls # iproute2 提供的新命令 # DHCP，先释放旧租约，再建立新租约 sudo dhclient -r eth0 \u0026\u0026 sudo dhclient eth0 # 查看 DHCP 租期 cat /var/lib/dhcp/dhcpd.leases # 清理 DNS 缓存 ## 1. 如果你使用的是 systemd-resolve，使用此命令 sudo systemd-resolve --flush-caches sudo systemd-resolve --statistics # 查看缓存状态 ## 2. 如果使用的是 dnsmasq，使用此命令 sudo systemctl restart dnsmasq sudo killall -HUP dnsmasq # 直接发送 HUP 信号也可以 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:8","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"9. 容器网络诊断 - nsenter Docker 容器有自己的 namespace，直接通过宿主机的 ss 命令是查看不到容器的 socket 信息的。 比较直观的方法是直接通过 docker exec 在容器中通过 ss 命令。但是这要求容器中必须自带 ss 等程序，有的精简镜像可能不会自带它。 通过 nsenter 可以直接进入到容器的指定 namespace 中，这样就能直接查询容器网络相关的信息了。 docker ps | grep xxx echo CONTAINER=xxx # 容器名称或 ID # 1. 查询到容器对应的 pid PID=$(docker inspect --format {{.State.Pid}} $CONTAINER) # 2. nsenter 通过 pid 进入容器的 network namespace，执行 ss 查看 socket 信息 nsenter --target $PID --net ss -s nsenter 这个工具貌似是 docker 自带的或者是系统内置命令，只要装了 docker，ubuntu/centos 都可以直接使用这个命令。 nsenter 是一个进入名字空间的工具，功能不仅仅局限在「网络诊断」，还有更多用法。 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:9","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"10. 用户与群组 ## 查看用户属于哪些群组 groups \u003cuser-name\u003e # 方法一 id \u003cusername\u003e # 方法二，它会额外列出 gid/uid cat /etc/group | grep \u003cuser-name\u003e # 方法三，直接查看配置 ## 查看群组中有哪些用户，第一列是群组，最后一列是用户名 cat /etc/group | grep \u003cgroup-name\u003e ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:1:10","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"二、Powershell Powershell 是微软推出的一款新一代 shell，它的特点之一是，命令都有一致的命名规则：谓词-名词， 谓词表示动作：Get/Set/Stop/Start 等，名词指示操作对象：Service/Member/ChildItem/Command 等。 这样的命名格式使我们可以很容易地猜测到自己需要的命令的名称。 为了使用方便，powershell 还提供了一些常用命令的缩写，并且添加了大量类似 Linux 命令的别名。 还有就是，Windows 默认不区分字母大小写，日常使用可以全部小写。 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:2:0","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"1. 实用命令 # 删除文件/文件夹 remove-item xxx -confirm ri xxx # 别名1 rm xxx # 别名2 rmdir xxx # etc... # 复制 copy-item xxx xx -r cp -r xxx xx # 显示工作目录 get-location gl pwd # 切换工作目录 set-location xxx sl xxx cd xxx # 查看环境变量 get-childitem env: gci env: gci env:PATH # 查看 PATH 变量 $env:XXX=\"value\" # 临时设置环境变量 $env:Path += \";SomeRandomPath\" # 临时在 Path 末尾添加新路径 ## 以下三行命令只对 windows 有效，linux 下无效 [Environment]::SetEnvironmentVariable(\"XXX\", $env:XXX + \";value\", [EnvironmentVariableTarget]::User) # 修改当前用户的环境变量（永久），只对新进程有效 [Environment]::SetEnvironmentVariable(\"XXX\", \"value\", [EnvironmentVariableTarget]::Machine) # 给这台电脑设置环境变量（永久），只对新进程有效，需要管理员权限 [Environment]::SetEnvironmentVariable(\"XXX\", $env:XXX + \";value\", \"User\") # target 也可用字符串指定 # 删除文件/文件夹 rm xxx # 删除文件夹时会进入交互界面，按提示输入就行。 # 查看命名位置（类似 Linux Shell 的 which） get-command xxx gcm xxx # 通过关键字查找 powershell 命令 gcm | select-string \u003ckeyword\u003e # 通过关键字查找 powershell 命令和环境变量中的程序，比较慢 gcm * | select-string \u003ckeyword\u003e # 查看别名对应的真实命令 get-alias # 类似 linux 的 find/ls 命令 get-childitem -Recurse -Include *.py gci -r -i *.py # 清空终端的输出 clear-host clear # 查看文件内容 get-content xx.py | more get-content xx.py | out-host -paging cat xx.py gc xx.py # 字符串搜索，不能对对象使用 # 类似 linux 的 grep 命令 cat xxx.log | select-string \u003cpattern\u003e gci env: | out-string -stream | select-string \u003cpattern\u003e # 需要先使用 out-string 将对象转换成 string gci env: | where-object {$_.Name -like \u003cpattern\u003e} # 计算输出的行数/对象个数 gci env: | measure-object gci env: | measure # 这是缩写 # 关机/重启 stop-computer restart-computer # windows 计算 hash 值 # 功能等同于 linux 下的 sha256sum/sha1sum/sha512sum/md5sum Get-FileHash -Path /path/to/file -Algorithm SHA256 Get-FileHash -Path /path/to/file -Algorithm SHA256 | Format-List # 用 format 修改格式化效果 # base64 编解码 [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes(\"xxx\")) # base64 编码 [Text.Encoding]::UTF8.GetString([Convert]::FromBase64String(\"eHh4\")) # 解码 另外 windows 同样自带 ssh/scp 命令，参数也和 linux 一致 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:2:1","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"2. 进程相关命令 # 查看所有进程 get-process | more ps | more # 别名 # 查找某进程（替代掉 tasklist） get-process -name exp*,power* # 使用正则查找进程 get-process | select-string \u003cpattern\u003e # 效果同上 # 通过 id 杀掉某进程（替代掉 taskkill） # 也可以通过 -Name 用正则匹配进程 stop-process \u003cpid\u003e kill \u003cpid\u003e # 别名 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:2:2","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"3. 网络相关命令 ## 1. dns 相关(dns-client) Clear-DnsClientCache # 清除 dns 缓存（替换掉 `ipconfig /flushdns`） Get-DnsClientCache # 查看 dns 缓存 Resolve-DnsName baidu.com # 解析域名 # 更新 DHCP 租约 ipconfig /renew ## 2. TCP/IP 相关命令 Get-Command Get-Net* # 查看所有 TCP/IP 相关的命令 Get-NetIPAddress # 查看 IP 地址 Get-NetIPInterface # 查看 IP 接口 Get-NetRoute # 查看路由表 Get-NetNeighbor # 获取链路层 MAC 地址缓存 Get-NetTCPConnection # 查看 TCP 连接 ### 也可以对 TCP/IP 的 IP 地址、接口、路由表进行增删改 New-NetRoute Remove-NetNeighbor # 清除 MAC 地址缓存 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:2:3","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"4. socket 信息查询 - netstat Windows 系统和 macOS 一样，也没有 ss，但是自带 netstat，该命令和 Linux 下的 netstat 有一定差别，具体使用方法如下： netstat -? # 查看使用帮助，很清晰易懂 # 查看那个进程在监听 80 端口，最后一列是进程的 Pid netstat -ano | findstr 80 # windows 命令 netstat -ano | select-string 80 # powershell 命令，就是把 findstr 替换成 select-string # 不仅列出 Pid，还给出 Pid 对应的可执行文件名称（需要管理员权限） netstat -ano -b | select-string 80 # powershell 命令 # 列出所有 ESTABLISHED 的 socket（默认行为） netstat # 列出所有正在监听的端口 netstat -ano | findstr LISTENING # 只列出 TCP 连接 netstat -ano -p TCP # 查看路由表 route -? # 查看使用帮助，很清晰易懂 route print # 查看所有路由信息 route print -4 # 仅 ipv4 比如我们遇到端口占用问题时，就可以通过上述命令查找到端口对应的 Pid，然后使用 kill \u003cPid\u003e 命令（powershell stop-process 的别名）杀死对应的进程。 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:2:4","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"三、Mac OS X Mac OS X 系统也是 unix-like 系统，也使用 zsh/bash，因此大部分命令基本都跟 Linux 没啥区别，可以直接参考前面 Linux 一节的内容。 但是要注意一些坑： macos 自带的 tar 并不是 gnutar，命令使用方式不一样！ 解决：brew install gnu-tar，安装好后通过 gtar 调用，参数就跟 linux 一致了。 网络相关的命令区别较大，后面会详细介绍。 MacOSX 使用 launchpad 作为系统服务管理器，跟 systemd 区别很大。 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:3:0","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"1. 查看 socket 信息 Mac OS X 系统目前没有 ss，但是自带 netstat，该命令和 Linux 下的 netstat 有一定差别，而且还很慢，还不能显示 pid. 所以 stackoverflow 上更推荐使用 lsof，几条常用命令记录如下 # -n 表示不显示主机名 # -P 表示不显示端口俗称 # 不加 sudo 只能查看以当前用户运行的程序 # 通用格式： sudo lsof -nP -iTCP:端口号 -sTCP:LISTEN # 查看所有 tcp 连接 lsof -nP -iTCP # 查看所有监听端口相关的信息（command/pid） lsof -nP -iTCP -sTCP:LISTEN ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:3:1","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"2. 其他网络相关命令 清理 DNS 缓存： # macos 10.10+ sudo dscacheutil -flushcache sudo killall -HUP mDNSResponder # 其他版本请自己网上搜... # 查看所有网络接口及相关参数（ip/mac/type...） ifconfig # 查看路由表 netstat -nr ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:3:2","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"四、跨平台程序 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:4:0","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"1. vim 常用技巧 移动： 0/^ 回到行首，$ 去到行末 w 跳到下个单词的首部，e 跳到下个单词末尾 也能使用 2w 2e 这种命令按单词数量跳转 删除 d 或修改 c: dw 删除单词，d2w 删除两个单词 d$ 删除到行末，d0/d^ 删除到行首 d(/d{/d[[ 删除到文件首部，d)/d}/d]] 删除到文件末尾 r 替换一个字符，R 持续往后替换 多行修改 多行插入，主要用于加注释之类的： 光标停留在你需要插入文本的地方 ctrl+v 进入 visual block 模式，选中多行 输入 I，进入编辑模式 输入 # 注释或者其他字符，但是注意不能输入换行符！也不能删除？ 按两下 Esc，依次退出 Insert 和 visual block 模式，就插入成功了 多行删除： v 进入 visual 模式，在第一行，选中你想要删除的文本块 或者也可以先进入 visual block 模式，再通过左右方向键选择文本。 ctrl+v 进入 visual block 模式，选中多行 visual block 的特点是它是垂直选择，而 visual 模式是段落选择 按 d 键就能删除被选中的所有内容。 多行替换（基本和 sed 一致） 多行行首插入注释符号 # :1,6 s/^/#/g :2,$ s/^/#/g 注：此为2行至尾行 :% s/^/#/g 注：此为所有行 这里使用了正则表达式 ^ 匹配行首，改成 $ 就可在行尾进行批量修改。 此外，它的分隔符也不仅限于 \\，也可以用 @ 等符号，方便阅读。比如： :1,6 s@^@#@g :2,$ s@^@#@g 注：此为2行至尾行 :% s@^@#@g 注：此为所有行 使用 vim 的这个正则匹配功能，不仅能进行插入，也能完成删除、替换的功能。 将选中部分写入到文件 首先按 v 进入 visual 模式，选中需要的内容 按 :，应该会显示 :'\u003c,'\u003e，表示对选中部分进行操作 输入内容 w new.txt，此时显示效果应该是 :'\u003c,'\u003ew new.txt 回车就能完成文件写入 问题：在 vim 中粘贴 yaml 时缩进会变得一团糟 解决方法：在命令模式下输入 :set paste 进入粘贴模式，然后再粘贴 yaml 内容。 注意行首可能会丢失几个字符，需要手动补上。 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:4:1","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":"参考 如何在 Linux 中查看进程占用的端口号 github - nsenter 使用 lsof 代替 Mac OS X 中的 netstat 查看占用端口的程序 aws 常用命令 ","date":"2022-02-13","objectID":"/posts/common-commands-for-various-operating-systems/:5:0","tags":["Linux","MacOSX","Windows","CLI","Powershell","Shell","tmux","rsync","vim","awk"],"title":"Linux/Windows/MacOSX 系统常用命令集锦","uri":"/posts/common-commands-for-various-operating-systems/"},{"categories":["技术"],"content":" 个人笔记，不保证正确。 内容比较多，建议参照目录浏览。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:0:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"一、标准库 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"1. 文件路径 - pathlib 提供了 OS 无关的文件路径抽象，可以完全替代旧的 os.path 和 glob. 学会了 pathlib.Path，你就会了 Python 处理文件路径的所有功能。 1. 路径解析与拼接 from pathlib import Path data_folder = Path(\"./source_data/text_files/\") data_file = data_folder / \"raw_data.txt\" # Path 重载了 / 操作符，路径拼接超级方便 # 路径的解析 data_file.parent # 获取父路径，这里的结果就是 data_folder data_foler.parent # 会返回 Path(\"source_data\") data_file.parents[1] # 即获取到 data_file 的上上层目录，结果和上面一样是 Path(\"source_data\") data_file.parents[2] # 上上上层目录，Path(\".\") dara_file.name # 文件名 \"raw_data.txt\" dara_file.suffix # 文件的后缀（最末尾的）\".txt\"，还可用 suffixes 获取所有后缀 data_file.stem # 去除掉最末尾的后缀后（只去除一个），剩下的文件名：raw_data # 替换文件名或者文件后缀 data_file.with_name(\"test.txt\") # 变成 .../test.txt data_file.with_suffix(\".pdf\") # 变成 .../raw_data.pdf # 当前路径与另一路径 的相对路径 data_file.relative_to(data_folder) # PosixPath('raw_data.txt') 2. pathlib 常用函数 if not data_folder.exists(): data_folder.mkdir(parents=True) # 直接创建文件夹，如果父文件夹不存在，也自动创建 if not filename.exists(): # 文件是否存在 filename.touch() # 直接创建空文件，或者用 filename.open() 直接获取文件句柄 # 路径类型判断 if data_file.is_file(): # 是文件 print(data_file, \"is a file\") elif data_file.is_dir(): # 是文件夹 for child in p.iterdir(): # 通过 Path.iterdir() 迭代文件夹中的内容 print(child) # 路径解析 # 获取文件的绝对路径（符号链接也会被解析到真正的文件） filename.resolve() # 在不区分大小写的系统上（Windows），这个函数也会将大小写转换成实际的形式。 # 可以直接获取 Home 路径或者当前路径 Path.home() / \"file.txt\" # 有时需要以 home 为 base path 来构建文件路径 Path.cwd() / \"file.txt\" # 或者基于当前路径构建 还有很多其它的实用函数，可在使用中慢慢探索。 3. glob 通配符 pathlib 也提供了 glob 支持，也就是广泛用在路径匹配上的一种简化正则表达式。 data_file.match(glob_pattern) # 返回 True 或 False，表示文件路径与给出的 glob pattern 是否匹配 for py_file in data_folder.glob(\"*/*.py\"): # 匹配当前路径下的子文件夹中的 py 文件，会返回一个可迭代对象 print(py_file) # 反向匹配，相当于 glob 模式开头添加 \"**/\" for py_file in data_folder.glob(\"**/*.py\"): # 匹配当前路径下的所有 py 文件（所有子文件夹也会被搜索），返回一个可迭代对象 print(py_file) glob 中的 * 表示任意字符，而 ** 则表示任意层目录。（在大型文件树上使用 ** 速度会很慢！） ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:1","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"2. 时间日期处理 python3 在时间日期处理方面，有标准库 datetime 跟 calender，也有流行的第三方库 arrow 跟 maya. 标准库 datetime 有时候不太方便，比如没有提供解析 iso 格式的函数。 另外就是用标准库时，经常需要自定义格式化串。 相比之下，maya 和 arrow 这两个第三方库会方便很多。 不过第三方库并不是任何时候都可用，这里只介绍标准库 datetime 的用法，maya/arrow 请自行查找官方文档学习。 1. 获取当前时间 import time import datetime as dt # 1. 获取当前时间的时间戳 time.time() # 直接调用 c api，因此速度很快: 1582315203.537061 utcnow = dt.datetime.utcnow() # 当前的世界标准时间: datetime.datetime(2020, 2, 22, 4, 0, 3, 537061) utcnow.timestamp() # 将标准时转换成时间戳：datetime =\u003e 1582315203.537061 # 2. UTC 世界标准时间 time.gmtime() #输出为： time.struct_time(tm_year=2019, tm_mon=6, tm_mday=23, # tm_hour=3, tm_min=49, tm_sec=17, # tm_wday=6, tm_yday=174, tm_isdst=0) # 这实际上是一个命名元组 # 3. 构建一个指定的 datetime 实例 time_1997 = dt.datetime(year=1997, month=1, day=1) # =\u003e datetime.datetime(1997, 1, 1, 0, 0) dt.datetime(year=1997, month=1, day=1, minute=11) # =\u003e datetime.datetime(1997, 1, 1, 0, 11) 2. 时间日期的修改与运算 # 0. 日期的修改（修改年月时分秒） utcnow.replace(day=11) # =\u003e datetime.datetime(2020, 2, 11, 4, 0, 3, 537061) 修改 day utcnow.replace(hour=11) # =\u003e datetime.datetime(2020, 2, 22, 11, 0, 3, 537061) 修改 hour # 1. 日期与时间 date_utcnow = utcnow.date() # =\u003e datetime.date(2020, 2, 22) 年月日 time_utcnow = utcnow.time() # =\u003e datetime.time(4, 0, 3, 537061) 时分秒 # 2. 联结时间和日期（date 和 time 不能用加法联结） dt.datetime.combine(date_utcnow, time_utcnow) # =\u003e datetime.datetime(2020, 2, 22, 4, 0, 3, 537061) # 3. 日期的运算 # 3.1 datetime 之间只能计算时间差（减法），不能进行其他运算 utcnow - time_1997 # =\u003e datetime.timedelta(days=8452, seconds=14403, microseconds=537061) # 3.2 使用 timedelta 进行时间的增减 days_step = dt.timedelta(days=1) # 注意参数是复数形式 time_1997 + days_step # =\u003e datetime.datetime(1997, 1, 2, 0, 0) time_1997 - days_step # =\u003e datetime.datetime(1996, 12, 31, 0, 0) # 3.3 timedelta 之间也可以进行加减法 hours_step = dt.timedelta(hours=1) # =\u003e datetime.timedelta(seconds=3600) days_step + hours_step # =\u003e datetime.timedelta(days=1, seconds=3600) days_step - hours_step # =\u003e datetime.timedelta(seconds=82800) hours_step - days_step # =\u003e datetime.timedelta(days=-1, seconds=3600) # 3.4 timedelta 还可以按比例增减（与数字进行乘除法） hours_step * 2 # =\u003e datetime.timedelta(seconds=7200) days_step * -2 # =\u003e datetime.timedelta(days=-2) hours_step * 1.1 # =\u003e datetime.timedelta(seconds=3960) 3. 时间日期的格式化与解析 先介绍下常用的格式化字符串： 普通格式 - ‘%Y-%m-%d %H:%M:%S’ =\u003e ‘2020-02-22 04:00:03’ ISO 格式 - ‘%Y-%m-%dT%H:%M:%S.%fZ’ =\u003e ‘2020-02-22T04:00:03.537061Z’ 带时区的格式 - ‘%Y-%m-%dT%H:%M:%S%Z’ =\u003e 2022-02-10T00:48:52UTC+08:00 需要时间对象自身有时区属性才行！否则格式化时会忽略 %Z 另外再介绍下 Python 两个时间格式化与解析函数的命名： strftime: 即 string formate time strptime: 即 string parse time # 1. 将时间格式化成字符串 # 1.1 将 datetime 格式化为 iso 标准格式 utcnow.isoformat() # =\u003e '2020-02-22T04:00:03.537061' utcnow.strftime('%Y-%m-%dT%H:%M:%S.%fZ') # =\u003e '2020-02-22T04:00:03.537061Z' utcnow.date().strftime('%Y-%m-%dT%H:%M:%S.%fZ') # =\u003e '2020-02-22T00:00:00.000000Z' # 1.2 将 time.struct_time 格式化为日期字符串（貌似不支持 iso，可能是精度不够） time.strftime('%Y-%m-%dT%H:%M:%S', gm) # =\u003e '2020-02-22T04:00:03' # 1.3 将 datetime 格式化成指定格式 utcnow.strftime('%Y-%m-%d%H:%M:%S') # =\u003e '2020-02-22 04:00:03' # 2. 解析时间字符串 # 2.1 解析 iso 格式的时间字符串，手动指定格式（注意 %f 只对应六位小数，对9位小数它无能为力。。） dt.datetime.strptime('2020-02-22T04:00:03.537061Z', '%Y-%m-%dT%H:%M:%S.%fZ') # =\u003e datetime.datetime(2020, 2, 22, 4, 0, 3, 537061) # 2.2 解析 iso 格式的时间字符串(需要 python 3.7+) dt.datetime.fromisoformat('2020-02-22T04:00:03.537061') # =\u003e datetime.datetime(2020, 2, 22, 4, 0, 3, 537061) dt.date.fromisoformat('2020-02-22') # =\u003e datetime.date(2020, 2, 22) dt.time.fromisoformat(\"04:00:03.537061\") # =\u003e datetime.time(4, 0, 3, 537061) # 2.3 解析指定格式的字符串 dt.datetime.strptime('2020-02-22 04:00:03', '%Y-%m-%d%H:%M:%S') # =\u003e datetime.datetime(2020, 2, 22, 4, 0, 3) 4. 时区转换与日期格式化 # 上海时区：东八区 utc+8 tz_shanghai = dt.timezone(dt.timedelta(hours=8)) now_shanghai = dt.datetime.now(tz=tz_shanghai) now_shanghai.strftime('%Y-%m-%dT%H:%M:%S%Z') # =\u003e 2022-02-10T00:48:52UTC+08:00 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:2","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"3. 排序常用库 - operator operator 模块包含四种类型的方法： 1. operator.itemgetter 经常被用于 sorted/max/mix/itertools.groupby 等 使用方法： # itemgetter f = itemgetter(2) f(r) # return r[2] # 还能一次获取多个值，像 numpy 那样索引 f2 = itemgetter(2,4,5) f2(r) # return (r[2], r[4], r[5]) # 或者使用 slice 切片 s = itemgetter(slice(2, None)) s[r] # return r[2:] # dict 索引也能用 d = itemgetter('rank', 'name') d[r] # return d['rank'], d['name'] 用途： # 用于指定用于比较大小的属性 key = itemgetter(1) sorted(iterable, key=key) # 使用 iterable[1] 对 iterable 进行排序 max(iterable, key=key) # 找出最大的元素，使用 iterable[1] 做比较 # 用于高级切片（比如像 numpy 那样的，指定只获取某几列） s = itemgetter(1,3,4) matrix = [[0,1,2,3,4], [1,2,3,4,5]] map(s, matrix) # list 后得到 [(1, 3, 4), (2,4,5)] 2. operator.attrgetter 可用于动态获取对象的属性，与直接用 getattr() 不同的是，它可以嵌套访问属性。 # 嵌套访问属性 att = attrgetter(\"a.b.c\") att(obj) # return obj.a.b.c # 和 itemgetter 一样，也可以一次获取多个属性 att = attrgetter(\"a.b.c\", \"x.y\") att(obj) # return (obj.a.b.c, obj.x.y) # 不嵌套的话，用 getattr 就行 getattr(obj, \"a\") # return obj.a 这里可以回顾一下类的两个魔法函数： __getattr__: 当被访问的属性不存在时，这个方法会被调用，它的返回值会成为对象的该属性。 用于动态生成实例的属性/函数 __getattribute__: 与 __getattr__ 唯一的差别在于，访问对象的任何属性，都会直接调用这个方法，不管属性存不存在。 3. operator.methodcaller 可用于调用函数，它和 attrgetter 很像，差别在于 attrgetter 只是返回指定的属性，而 methodcaller 会直接把指定的属性当成函数调用，然后返回结果。 举例 f = methodcaller('name', 'foo', bar=1) f(b) # returns b.name('foo', bar=1) 4. 各种操作符对应的函数 operator.add、operator.sub、operator.mul、operator.div 等等，函数式编程有时需要用到。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:3","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"4. itertools itertools 提供了许多针对可迭代对象的实用函数 方法很多，基本不可能一次全记住。还是要用到时多查吧。大致记住有提供哪些功能，需要用到时能想起可以查这个模块就行。 1. 无限迭代器 count(start=0, step=1): 从 start 开始，每次迭代时，返回值都加一个 step 默认返回序列为 0 1 2 3… cycle(iterable): 不断循环迭代 iterable repeat(element, times=None): 默认永远返回 element。（如果 times 不为 None，就迭代 times 后结束） 2. 排列组合迭代器 product(p1, p2, …, repeat=1)：p1, p2… 的元素的笛卡尔积，相当于多层 for 循环 repeat 指参数重复次数，比如 \u003e\u003e\u003e from itertools import product \u003e\u003e\u003e r = product([1, 2], [3, 4], [5, 6]) # 重复一次，也就是 (p1, p2, p3) 的笛卡尔积 \u003e\u003e\u003e pprint(list(r)) [(1, 3, 5), (1, 3, 6), (1, 4, 5), (1, 4, 6), (2, 3, 5), (2, 3, 6), (2, 4, 5), (2, 4, 6)] \u003e\u003e\u003e r2 = product([1, 2], [3, 4], [5, 6], repeat=2) # 重复两次，即 (p1, p2, p3, p1, p2, p3) 的笛卡尔积 \u003e\u003e\u003e pprint(list(r2)) [(1, 3, 5, 1, 3, 5), (1, 3, 5, 1, 3, 6), (1, 3, 5, 1, 4, 5), (1, 3, 5, 1, 4, 6), (1, 3, 5, 2, 3, 5), ... permutations(p[, r])：p 中元素，长度为 r 的所有可能的排列。相当于 product 去重后的结果。 combinations(p, r)：既然有排列，当然就有组合了。 3. 其他 zip_longest(*iterables, fillvalue=None)：和 zip 的差别在于，缺失的元素它会用 fillvalue 补全，而不是直接结束。 takewhile() dropwhile() groupby() 等等等，用得到的时候再查了。。。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:4","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"5. collections 提供了一些实用的高级数据结构（容器） defaultdict：这个感觉是最常用的，可以给定 key 的默认值 Counter：方便、快速的计数器。常用于分类统计 deque：一个线程安全的双端队列 OrderedDict：有时候会需要有序字典 namedtuple：命名元组，有时用于参数传递。与 tuple 的差别是它提供了关键字参数和通过名字访问属性的功能 ChainMap：将多个 map 连接（chain）在一起，提供一个统一的视图。因为是视图，所以原来的 map 不会被影响。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:5","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"6. 常用函数装饰器 functools functools 提供了几个有时很有用的函数和装饰器 1. @functools.wraps 这个装饰器用于使装饰器 copy 被装饰的对象的 __module__, __name__, __qualname__, __annotations__ and __doc__ 属性，这样装饰器就显得更加透明。 from functools import wraps def my_decorator(f): @wraps(f) def wrapper(*args, **kwds): print('Calling decorated function') return f(*args, **kwds) return wrapper # 用了 wraps，wrapper 会复制 f 的各种文档属性 @my_decorator def func(xx): \"\"\" this is func's docstring\"\"\" print(\"this is func~\") 如果不用 wraps 的话，因为实际上返回的是 wrapper，被装饰对象的这些文档属性都会丢失。（比如 docstring） 因此在使用 wrapper 装饰器时，添加 @wraps() 装饰器是个好习惯。 2. functools.partial 这个感觉和高等数学的偏函数很像：比如函数 z = f(x, y) 有 x 和 y 两个变量，现在把 x 看作常数，就可以对 y 进行求导运算。 而 python 的 partial 也差不多，不过它不是把 x 看作常数，而是先给定 x 的值。用法如下： from functools import partial basetwo = partial(int, base=2) # 先给定 int 函数的 base 参数为 2 basetwo.__doc__ = 'Convert base 2 string to an int.' # 如果需要文档，可以添加 __doc__ 属性 basetwo('10010') # return 18 此外，还有个 partialmethod 函数，待了解 3. @functools.lru_cache(maxsize=128, typed=False) 如果某方法可能被频繁调用（使用相同的参数），而且它的结果在一定时间内不会改变。可以用 lru_cache 装饰它，减少运算量或 IO 操作。 from functools import lru_cache # 缓存最近的（least recently used，lru） 64 次参数不同的调用结果。 @lru_cache(maxsize=64) def my_sum(x): # 后续的调用中，如果参数能匹配到缓存，就直接返回缓存结果 return sum(x) 比如用递归计算斐波那契数列，数值较低的参数会被频繁使用，于是可以用 lru_cache 来缓存它们。 或者爬取网页，可能会需要频繁爬取一个变化不快的网页，这时完全可以用 cache 缓存。 但是它不能控制缓存失效时间，因此不能用于 Web 系统的缓存。还是得自己写个简单的装饰器，把缓存存到 redis 里并设置 expires。或者直接用 Flask 或 Django 的 caching 插件。 4. @functools.singledispatch 单重派发，即根据函数的第一个参数的类型，来决定调用哪一个同名函数。 @singledispatch def parse(arg): # 首先定义一个默认函数 print('没有合适的类型被调用') # 如果参数类型没有匹配上，就调用这个默认函数 @parse.register(type(None)) # 第一个参数为 None def _(arg): print('出现 None 了') @parse.register(int) # 第一个参数为整数 def _(arg): print('这次输入的是整数') @parse.register def _(arg: list): # python3.7 开始，可以直接用类型注解来标注第一个参数的类型 print('这次输入的是列表') 画外：有单重派发，自然就有多重派发，Julia 语言就支持多重派发，即根据函数所有参数的类型，来决定调用哪一个同名函数。 Julia 语言根本没有类这个定义，类型的所有方法都是通过多重派发来定义的。 其他 @functools.total_ordering：用于自动生成比较函数。 functools.cmp_to_key(func)：用于将老式的比较函数，转换成新式的 key 函数。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:6","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"7. 上下文管理 - contextlib 即实现使用 with 语句进行自定义的上下文管理。 1. 使用 __enter__ 和 __exit__ Java 使用 try 来自动管理资源，只要实现了 AutoCloseable 接口，就可以部分摆脱手动 colse 的地狱了。 而 Python，则是定义了两个 Protocol：__enter__ 和 __exit__. 下面是一个 open 的模拟实现： class OpenContext(object): def __init__(self, filename, mode): # 调用 open(filename, mode) 返回一个实例 self.fp = open(filename, mode) def __enter__(self): # 用 with 管理 __init__ 返回的实例时，with 会自动调用这个方法 return self.fp # 退出 with 代码块时，会自动调用这个方法。 def __exit__(self, exc_type, exc_value, traceback): self.fp.close() # 这里先构造了 OpenContext 实例，然后用 with 管理该实例 with OpenContext('/tmp/a', 'a') as f: f.write('hello world') 这里唯一有点复杂的，就是 __exit__ 方法。和 Java 一样，__exit__ 相当于 try - catch - finally 的 finally 代码块，在发生异常时，它也会被调用。 当没有异常发生时，__exit__ 的三个参数 exc_type, exc_value, traceback 都为 None，而当发生异常时，它们就对应异常的详细信息。 发生异常时， __exit__ 的返回值将被用于决定是否向外层抛出该异常，返回 True 则抛出，返回 False 则抑制（swallow it）。 Note 1：Python 3.6 提供了 async with 异步上下文管理器，它的 Protocol 和同步的 with 完全类似，是 __aenter__ 和 __aexit__ 两个方法。 Note 2：与 Java 相同，with 支持同时管理多个资源，因此可以直接写 with open(x) as a, open(y) as b: 这样的形式。 2. 推荐：contextlib 2.1 @contextlib.contextmanager 对于简单的 with 资源管理，编写一个类可能会显得比较繁琐，为此 contextlib 提供了一个方便的装饰器 @contextlib.contextmanager 用来简化代码。 使用它，上面的 OpenContext 可以改写成这样： from contextlib import contextmanager @contextmanager def make_open_context(filename, mode): fp = open(filename, mode) try: yield fp # 没错，这是一个生成器函数 finally: fp.close() with make_open_context('/tmp/a', 'a') as f: f.write('hello world') 使用 contextmanager 装饰一个生成器函数，yield 之前的代码对应 __enter__，finally 代码块就对应 __exit__. Note：同样，也有异步版本的装饰器 @contextlib.asynccontextmanager 2.2 contextlib.closing(thing) 用于将原本不支持 with 管理的资源，包装成一个 Context 对象。 from contextlib import closing from urllib.request import urlopen with closing(urlopen('http://www.python.org')) as page: for line in page: print(line) # closing 等同于 from contextlib import contextmanager @contextmanager def closing(thing): try: yield thing finally: thing.close() # 就是添加了一个自动 close 的功能 2.3 contextlib.suppress(*exceptions) 使 with 管理器抑制代码块内任何被指定的异常： from contextlib import suppress with suppress(FileNotFoundError): os.remove('somefile.tmp') # 等同于 try: os.remove('somefile.tmp') except FileNotFoundError: pass 2.4 contextlib.redirect_stdout(new_target) 将 with 代码块内的 stdout 重定向到指定的 target（可用于收集 stdout 的输出） f = io.StringIO() with redirect_stdout(f): # 将输出直接写入到 StringIO help(pow) s = f.getvalue() # 或者直接写入到文件 with open('help.txt', 'w') as f: with redirect_stdout(f): help(pow) redirect_stdout 函数返回的 Context 是可重入的（ reentrant），可以重复使用。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:1:7","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"二、实用代码片段 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"1. 元素分组/group 数据处理中一个常见的操作，是将列表中的元素，依次每 k 个分作一组。 下面的函数使用非常简洁的代码实现了元素分组的功能： from itertools import zip_longest def group_each(a, size: int, longest=False): \"\"\" 将一个可迭代对象 a 内的元素, 每 size 个分为一组 group_each([1,2,3,4], 2) -\u003e [(1,2), (3,4)] \"\"\" iterators = [iter(a)] * size # 将新构造的 iterator 复制 size 次（浅复制） func_zip = zip_longest if longest else zip return func_zip(*iterators) # 然后 zip a = \"abcdefghijk\" list(group_each(a, 3)) # =\u003e [('a', 'b', 'c'), ('d', 'e', 'f'), ('g', 'h', 'i')] list(group_each(a, 3, longest=True)) # =\u003e [('a', 'b', 'c'), ('d', 'e', 'f'), ('g', 'h', 'i'), ('j', 'k', None)] 这个函数还可以进一步简化为 zip(*[iter(a)] * 3)，如果没想到浅复制（Shallow Copy）特性的话，会很难理解它的逻辑。 此外，如果某个 size 比较常用（比如 2），还可以用 partial 封装一下： from functools import partial # 每两个分一组 group_each_2 = partial(group_each, size=2) # 等同于 group_each_2 = lambda a: group_each(a, 2) a = \"abcde\" list(group_each_2(a)) # =\u003e [('a', 'b'), ('c', 'd')] list(group_each_2(a, longest=True)) # =\u003e [('a', 'b'), ('c', 'd'), ('e', None)] ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:1","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"2. 扁平版本的 map 稍微接触过函数式应该都知道 flat_map，可 Python 标准库却没有提供。下面是我在 stackoverflow 上找到的实现，其实很简单 from itertools import chain def flat_map(f, items): return chain.from_iterable(map(f, items)) 它和 map 的差别在于是不是扁平(flat) 的（废话。。），举个例子 \u003e\u003e\u003e list(map(list, ['123', '456'])) [['1', '2', '3'], ['4', '5', '6']] \u003e\u003e\u003e list(flat_map(list, ['123', '456'])) ['1', '2', '3', '4', '5', '6'] ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:2","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"3. 轮流迭代多个迭代器 假设我有多个可迭代对象（迭代器、列表等），现在我需要每次从每个对象中取一个值，直到某个对象为空。如果用循环写会比较繁琐，但是用 itertools 可以这样写： from itertools import chain def iter_one_by_one(items): return chain.from_iterable(zip(*items)) a = [1,2,3] b = [4,5,6] c = [7,8,9,10] list(iter_one_by_one([a,b,c])) # =\u003e [1, 4, 7, 2, 5, 8, 3, 6, 9] ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:3","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"4. 多 dict 的去重 假设我们有一个 dict 的列表，里面可能有内容一模一样的 dict，我们需要对它做去重。 容易想到的方法就是使用 set，可是 set 中的元素必须是 hashable 的，而 dict 是 unhashable 的，因此不能直接放进 set 里。 \u003e\u003e\u003e a = [{'a': 1}, {'a': 1}, {'b': 2}] \u003e\u003e\u003e set(a) Traceback (most recent call last): File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File \"\u003cipython-input-5-5b4c643a6feb\u003e\", line 1, in \u003cmodule\u003e set(a) TypeError: unhashable type: 'dict' 难道就必须手写递归了么？未必，我在 stackoverflow 看到这样一个小技巧 import json def unique_dicts(data_list: list): \"\"\"unique a list of dict dict 是 unhashable 的，不能放入 set 中，所以先转换成 str unique_dicts([{'a': 1}, {'a': 1}, {'b': 2}]) -\u003e [{'a': 1}, {'b': 2}] \"\"\" data_json_set = set(json.dumps(item) for item in data_list) return [json.loads(item) for item in data_json_set] ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:4","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"5. str 的 startswith 和 endswith 的参数可以是元组 In[7]: a = \"bb.gif\" In[8]: b = 'a.jpg' In[9]: a.endswith(('.jpg', '.gif')) Out[9]: True In[10]: b.startswith(('bb', 'a')) Out[10]: True ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:5","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"6. 判断两个对象的所有属性都相同 python 和 java 一样，直接用 == 做判断，默认是比较的引用，相当于 is。对自定义的类，你需要重写 __eq__ 函数。 判断值相等的方法很简单，一行代码： class A: ... def __eq__(self, obj): return self.__dict__ == obj.__dict__ # 转成 __dict__ 再比较 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:6","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"7. 案例 7.1 html table 元素的处理 在做爬虫工作时，有时会遇到这样的 table 元素： 对这种 html 元素，我一般会直接把它转换成 list，结果如下： table = [['label1', 'value1', 'label2', 'value2'], ['label3', 'value3'], ['label4', 'value4', 'label5', 'value5'], ... ] 为了方便索引，现在我需要把上面的数据转换成下面这个样子的 dict { 'label1': 'value1', 'label2': 'value2', 'label3': 'value3', 'label4': 'value4', 'label5': 'value5' } 如果是平常，大概需要写循环了。不过如果用刚刚说到的几个函数的话，会变得异常简单 # 1. 分组 groups = flat_map(group_each_2, table) # 1.1 flat_map 返回的是迭代器，list 后内容如下： # [('label1', 'value1'), # ('label2', 'value2'), # ('label3', 'value3'), # ('label4', 'value4'), # ('label5', 'value5')] # 2. 转换成 dict key_values = dict(groups) # 得到的 key_values 与上面需要的 dict 别无二致。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:2:7","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"三、常见错误 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:3:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"1. 浅复制导致错误 利用好浅复制，可以非常简洁的实现前面提到的元素分组/group功能，但是如果不注意，也会导致非常隐晦的错误！ 比如在使用 * 作为重复运算符时，如果目标是一个嵌套的可变对象，就会产生令人费解的问题： \u003e\u003e\u003e a = [1,2,3] \u003e\u003e\u003e b = a * 3 \u003e\u003e\u003e b [1, 2, 3, 1, 2, 3, 1, 2, 3] \u003e\u003e\u003e b = [a] * 3 # nested \u003e\u003e\u003e b [[1, 2, 3], [1, 2, 3], [1, 2, 3]] \u003e\u003e\u003e b[1][1] = 4 \u003e\u003e\u003e b [[1, 4, 3], [1, 4, 3], [1, 4, 3]] 因为 * 并不是深拷贝，它只是简单地复制了 [a] 这个列表，里面的 [1,2,3] 都是同一个对象，所以改了一个，所有的都会改变。 解决方法是不要使用 * 号，改用[a.copy() for i in range(3)] 执行深拷贝。如果不需要修改，请直接使用不可变对象。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:3:1","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"2. 变量作用域 Python 中只有模块，类以及函数才会引入新的作用域，其它的代码块是不会引入新的作用域的。（而在 C/Java 中，任何一个 {} 块就构成一个局部作用域。另外 Julia 中 for/while/try-catch 都是局部作用域，但 if-else 又不是局部作用域。总之这些小差别要注意。） 局部变量可以与外部变量同名，并且在其作用域中，局部变量会覆盖掉外部变量。 不知是出于实现简单或是性能，还是其他的原因，好像所有的语言都是这样的。其实我更希望变量的作用域覆盖会报错。 如果有函数与其他函数或变量（甚至某些保留字）同名，后定义的会覆盖掉先定义的。（这是因为 Python 中函数也是对象。而在 C/Java 中这是会报错的） 此外，还有一个小问题，先看一个例子： \u003e\u003e\u003e i = 4 \u003e\u003e\u003e def f(): # 单纯的从函数作用域访问外部作用域是没问题的 ... print(i) ... \u003e\u003e\u003e f() 4 再看一个问题举例： \u003e\u003e\u003e i = 3 \u003e\u003e\u003e def f(): ... print(i) # 这里应该是访问外部作用域 ... i = 5 # 可这里又定义了一个同名局部变量 i ... \u003e\u003e\u003e f() # 于是就出错了 Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"\u003cstdin\u003e\", line 2, in f UnboundLocalError: local variable 'i' referenced before assignment 如果在内部作用域先访问外部作用域，再定义一个同名的局部变量，解释器就懵逼了。 如果你其实想做的是改变全局变量 i 的值，就应该在开头声明 global i. 而如果 外部变量 i 不是存在于全局作用域，而是在某个闭合作用域内的话，就该用 nonlocal i ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:3:2","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"四、自定义装饰器 装饰器有两种：用函数定义的装饰器，还有用类定义的装饰器。函数装饰器最常用。 装饰器可用于装饰函数，修改函数/类的某些行为，或者将函数注册到别的地方。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:4:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"1. 函数定义装饰器 @decc def gg(xx): ... # 等同于 def gg(xx) gg = decc(gg) 带参的装饰器 @decorator(A, B) def F(arg): ... F(99) # 等同于 def F(arg): ... F = decorator(A, B)(F) # Rebind F to result of decorator's return value F(99) # Essentially calls decorator(A, B)(F)(99) 上面演示的是用函数定义的装饰器，也是最常用的装饰器。 装饰器接收的参数可以是各种各样的，下面是一个带参的装饰器： @on_command(\"info\") def get_info(): return \"这就是你需要的 info\" def on_command(name: str): # 调用此函数获得装饰器，这样就实现了带参装饰器 def deco(func: Callable) -\u003e Callable: # 这个才是真正的装饰器 # 将命令处理器注册到命令列表内 return func # 直接返回原函数，这样的话，多个装饰器就不会相互影响了。 return deco # 上面的等同于： get_info = on_command(\"info\")(get_info) # on_command(\"info\") 返回真正的装饰器 如果你的 on_command 有通用的部分，还可以将通用的部分抽离出来复用： def _deco_maker(event_type: str) -\u003e Callable: # 调用这个，获取 on_xxx 的 deco_deco， def deco_deco(self) -\u003e Callable: # 这个对应 on_xxx def deco(func: Callable) -\u003e Callable: # 这个才是真正的装饰器 # do something return func # 返回原函数 return deco return deco_deco 我们知道 Python 的类实际上是可以很方便的修改的，因此函数装饰器也能用于装饰类，修改类的某些行为。 def log_getattribute(cls): # Get the original implementation orig_getattribute = cls.__getattribute__ # Make a new definition def new_getattribute(self, name): print('getting:', name) return orig_getattribute(self, name) # Attach to the class and return cls.__getattribute__ = new_getattribute # 修改了被装饰类 cls 的 __getattribute__ return cls # Example use @log_getattribute class A: def __init__(self,x): self.x = x def spam(self): pass ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:4:1","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"2. 类定义装饰器 类定义装饰器和函数定义装饰器的使用方式完全一致。它也可以用于装饰函数或者类。 那么为啥还需要类定义装饰器呢？它的优势在于类是可以继承的，这样的话，就能用继承的方式定义装饰器，将通用部分定义成超类。 类定义装饰器的定义方法如下： # PythonDecorators/entry_exit_class.py class entry_exit(object): def __init__(self, f): self.f = f def __call__(self): #关键在于这个函数，它使此类的对象变成 Callable print(\"Entering\", self.f.__name__) self.f() print(\"Exited\", self.f.__name__) @entry_exit def func1(): print(\"inside func1()\") # 上面的装饰器相当于 func1 = entry_exit(func1) # 从这里看的话，装饰器的行为完全一致 # 接下来调用该函数（实际上是调用了 entry_exit 对象的 call 函数） func1() 输出结果如下： Entering func1 inside func1() Exited func1 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:4:2","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"五、OOP 调用超类方法： 直接通过超类名.__init__(self,xx)调用 通过super(__class__, self).__init__()调用。 （Python3 可直接用 super().__init__() 但是要搞清楚，super() 方法返回的是一个代理类。另外被代理的类也不一定是其超类。如果不清楚这些差别，最好还是显式用方法一最好。） 抽象超类：@abstractmethod @staticmethod @classmethod 与 Java 的 static 方法对比 python的类方法、静态方法，与java的静态方法： java 中 constants、utils 这样的静态类，对应的是python的一个模块（文件），类属性对应模块的全局属性，静态方法对应模块的函数 对于 java 中需要访问类属性的静态方法，如果它不属于第一类，应该用 @classmethod 实现它。classmethod最大的特点就是一定有一个 cls 传入。这种方法的主要用途是实现工厂函数。 对于不需要访问任何类属性，也不属于第一类的方法，应该用 @staticmathod 实现。这种方法其实完全不需要放到类里面，它就是一个独立的函数。（仍然放里面，是为了把功能类似的函数组织到一起而已。） __slots__: 属性导出，不在该列表内的属性，若存在则为只读。不存在的话，就不存在。。 6. __getattr__: 拦截对不存在的属性的访问，可用于实现动态分配属性。 __getattribute__: 和上面相同，但是它拦截对所有属性的访问，包括对已存在的属性的访问。 @property: 提供对属性访问的安全检查 descriptor: get set delete 控制对类的访问。（上面的 getattr 等是控制对类的属性的访问） 类构造器 __new__：在 __init__ 之前运行，它接收一个 cls 参数，然后使用它构造并返回类实例 self。 类方法的 cls 即是当前类，是 type 的实例，cls.xxx 和 \u003c类名\u003e.xxx 调用结果是一致的。而 self 由 __new__ 构造，是 cls 的实例。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:5:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"元类 metaclasses 元类，也就是用于创建class 的 class，算是很高级的话题了（If you wonder whether you need metaclasses, you don’t ） 元类的工作流程： 拦截类的创建 修改类 返回修改之后的类 详细直接看 http://blog.jobbole.com/21351/ 吧。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:5:1","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"六、查看 Python 源码 对一般的标准库的模块，要查看其具体的 Python 实现是很简单的：直接通过 __file__ 属性就能看到 .py 文件的位置。 但是 Python 很多功能是 C 写的，对于这类函数/类，__file__ 就没啥用了。 如果是需要查看 builtins 模块 的具体实现，直接查看 Python/bltinmodule.c 就行。 其他 C 模块的源码，待补充具体的查看方法。 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:6:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":["技术"],"content":"七、参考文档 Python中一些不为人知的基础技巧总结 Python3 官方文档 ","date":"2022-02-13","objectID":"/posts/python-tips-and-tricks/:7:0","tags":["Python","Tips","Tricks","常见错误"],"title":"Python 实用技巧与常见错误集锦","uri":"/posts/python-tips-and-tricks/"},{"categories":null,"content":" 更新时间: 2022-03-09T20:09:39UTC+08:00 ","date":"2022-02-07","objectID":"/statistics/:0:0","tags":null,"title":"本站统计数据","uri":"/statistics/"},{"categories":null,"content":"一、全站统计 人均阅读时长 总访客数 UV 总访问量 PV 总阅读时长 01m 34s 10091 23785 11 days, 1h 01s ","date":"2022-02-07","objectID":"/statistics/:1:0","tags":null,"title":"本站统计数据","uri":"/statistics/"},{"categories":null,"content":"二、近 30 天阅读排行 按「人均阅读时长」降序排列 标题 人均阅读时长 访客数 访问量 1 瘾的退却 03m 41s 9 28 2 使用 Istio 进行 JWT 身份验证（充当 API 网关） 03m 07s 16 32 3 iptables 及 docker 容器网络分析 02m 55s 25 54 4 secrets 管理工具 Vault 的介绍、安装及使用 02m 32s 89 116 5 「译」写给开发人员的实用密码学（六）—— 对称密钥加密算法 02m 29s 9 22 6 Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例 02m 17s 8 11 7 2021 年年终总结 02m 10s 95 133 8 云原生流水线 Argo Workflows 的安装、使用以及个人体验 02m 06s 65 98 9 我在创业公司做技术一年多的一点体会 01m 54s 18 28 10 Pulumi 使用体验 - 基础设施代码化 01m 52s 27 35 11 openSUSE 使用指南 01m 43s 9 16 12 「转」MIRT出征广马——首次摸到330的边儿 01m 36s 2 11 13 TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段 01m 34s 57 63 14 「小歌行」-景德镇文艺复兴-2020巡演-深圳 01m 34s 2 2 15 SQL 基础笔记（一） 01m 20s 6 12 16 月宫 01m 19s 14 26 17 Kubernetes 微服务最佳实践 01m 18s 41 60 18 WebSocket、HTTP/2 与 gRPC 01m 16s 18 23 19 学英语啊学英语 01m 14s 5 10 20 我患上了阅读焦虑症 01m 11s 7 41 21 「译」写给开发人员的实用密码学（一）—— 概览 01m 06s 28 48 22 QEMU-KVM 虚拟化环境的搭建与使用 01m 04s 73 96 23 逃离我的大学 01m 03s 17 23 24 「转」且看有思想的年轻人 01m 02s 26 36 25 部署一个 Kubernetes 集群 59s 62 83 26 Linux 中的虚拟网络接口 57s 32 40 27 Python 实用技巧与常见错误集锦 56s 46 51 28 2020 年年终总结 55s 13 14 29 Base64 编码并不唯一 53s 3 5 30 SQL 基础笔记（二）进阶查询 53s 3 6 31 Python 并发编程：PoolExecutor 篇 46s 3 4 32 Manjaro 使用指南 41s 8 8 33 使用 tcpdump 和 Wireshark 进行远程实时抓包分析 37s 23 27 34 SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言 36s 1 2 35 Kubernetes 常见错误、原因及处理方法 35s 7 6 36 此岸弃草，彼岸繁花 30s 6 6 37 进程线程协程与并发并行 30s 2 3 38 Linux 网络工具中的瑞士军刀 - socat \u0026 netcat 29s 17 20 39 忽而假末 29s 7 10 40 「译」写给开发人员的实用密码学（三）—— MAC 与密钥派生函数 KDF 27s 12 18 41 JWT 签名算法 HS256、RS256 及 ES256 及密钥生成 26s 27 28 42 「译」写给开发人员的实用密码学（二）—— 哈希函数 26s 23 38 43 Linux/Windows/MacOSX 系统常用命令集锦 25s 69 115 44 「转」仙马赛记——我又 PB 了 23s 36 50 45 少有人迹的校园 23s 5 6 46 2019 年年终总结 22s 2 2 47 「转」MIRT出征广马——首次摸到330的边儿 17s 21 27 48 「译」写给开发人员的实用密码学（四）—— 安全的随机数生成器 17s 15 21 49 SQLAlchemy 学习笔记（三）：ORM 中的关系构建 14s 1 1 50 「译」写给开发人员的实用密码学（五）—— 密钥交换与 DHKE 13s 18 21 51 《十二国记》 11s 1 2 52 在回声中重历 09s 2 2 53 又一个期末 07s 8 9 54 欧几里得算法求最大公约数(GCD)的数学原理 06s 7 7 ","date":"2022-02-07","objectID":"/statistics/:2:0","tags":null,"title":"本站统计数据","uri":"/statistics/"},{"categories":null,"content":"三、说明 此页面受 极客兔兔 - 博客折腾记(七) - Gitalk Plus 的启发而创建，其核心诉求是「帮助访客发现本站的优质文章」~ 目前我认为文章的「人均阅读时长」，也就是「网页处于浏览器前台的总时长」，应该能在一定程度上反应出文章的价值，供各位参考。 此页面的数据由 Github Action 自动从 Google Analytics 获取，更新间隔为 6 小时。 .animation-wrapper { position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: -100; } .particle, .particle:after { background: transparent; } .particle:after { position: absolute; content: \"\"; top: 2560px; } .particle-1 { -webkit-animation: animParticle 60s linear infinite; animation: animParticle 60s linear infinite; box-shadow: 0px 0px #fff, 1231px 1530px #fff, 336px 2471px #fff, 2385px 128px #fff, 2436px 1283px #fff, 549px 681px #fff, 1775px 1144px #fff, 238px 1396px #fff, 1330px 1558px #fff, 2060px 342px #fff, 1986px 1672px #fff, 1532px 702px #fff, 1313px 1459px #fff, 2406px 1616px #fff, 1529px 802px #fff, 1267px 680px #fff, 2258px 2109px #fff, 1325px 22px #fff, 1578px 1045px #fff, 945px 2256px #fff, 1400px 1441px #fff, 1652px 2152px #fff, 2513px 969px #fff, 2192px 1352px #fff, 793px 334px #fff, 1371px 1086px #fff, 2408px 1898px #fff, 475px 840px #fff, 539px 1108px #fff, 556px 1499px #fff, 643px 122px #fff, 2370px 1975px #fff, 1196px 1786px #fff, 308px 1834px #fff, 1957px 1569px #fff, 875px 339px #fff, 562px 412px #fff, 1187px 2258px #fff, 1406px 1824px #fff, 1172px 1792px #fff, 235px 1489px #fff, 2081px 878px #fff, 925px 176px #fff, 953px 1829px #fff, 38px 48px #fff, 1976px 1994px #fff, 1524px 1567px #fff, 1397px 1141px #fff, 2014px 1773px #fff, 1638px 1832px #fff, 1150px 465px #fff, 1212px 1854px #fff, 122px 20px #fff, 2493px 2361px #fff, 2221px 194px #fff, 480px 2020px #fff, 2340px 403px #fff, 1975px 2507px #fff, 1434px 142px #fff, 963px 871px #fff, 2379px 1765px #fff, 2346px 100px #fff, 1931px 1308px #fff, 527px 814px #fff, 549px 1732px #fff, 943px 886px #fff, 1592px 2277px #fff, 1339px 810px #fff, 871px 2016px #fff, 2121px 763px #fff, 1962px 1114px #fff, 2498px 550px #fff, 107px 586px #fff, 316px 1033px #fff, 2104px 2120px #fff, 1933px 1786px #fff, 1377px 2457px #fff, 2250px 1010px #fff, 1314px 2316px #fff, 1339px 947px #fff, 122px 1014px #fff, 558px 2354px #fff, 1250px 1790px #fff, 1185px 2144px #fff, 2432px 158px #fff, 1911px 2148px #fff, 1177px 804px #fff, 2504px 1254px #fff, 617px 1084px #fff, 1959px 1325px #fff, 2394px 2081px #fff, 395px 735px #fff, 221px 1891px #fff, 652px 2245px #fff, 1225px 1023px #fff, 1542px 2053px #fff, 876px 2178px #fff, 479px 1915px #fff, 2297px 1799px #fff, 2160px 387px #fff, 160px 358px #fff, 1122px 2164px #fff, 2056px 1402px #fff, 2133px 1470px #fff, 1508px 1865px #fff, 250px 2157px #fff, 715px 1452px #fff, 2095px 1539px #fff, 1860px 1450px #fff, 185px 2013px #fff, 1855px 1878px #fff, 690px 2520px #fff, 2250px 838px #fff, 1547px 1752px #fff, 1103px 615px #fff, 151px 262px #fff, 1630px 577px #fff, 769px 2448px #fff, 1938px 2347px #fff, 700px 1634px #fff, 2105px 2053px #fff, 1498px 49px #fff, 799px 512px #fff, 1278px 744px #fff, 2301px 364px #fff, 1059px 2066px #fff, 2116px 2424px #fff, 1884px 1046px #fff, 699px 1101px #fff, 62px 1893px #fff, 370px 161px #fff, 298px 1288px #fff, 1972px 2211px #fff, 1834px 2350px #fff, 1591px 1118px #fff, 1343px 1730px #fff, 706px 850px #fff, 317px 1171px #fff, 1395px 2529px #fff, 1040px 2523px #fff, 793px 2535px #fff, 2180px 142px #fff, 2016px 2511px #fff, 1032px 1204px #fff, 499px 625px #fff, 130px 2064px #fff, 1371px 758px #fff, 1045px 2018px #fff, 1954px 309px #fff, 1445px 2514px #fff, 839px 1523px #fff, 920px 238px #fff, 1421px 1105px #fff, 668px 1517px #fff, 2045px 2344px #fff, 2465px 1619px #fff, 403px 48px #fff, 1142px 1102px #fff, 2066px 1803px #fff, 658px 1744px #fff, 721px 2062px #fff, 2180px 827px #fff, 2310px 111px #fff, 935px 808px #fff, 1121px 1108px #fff, 1424px 1998px #fff, 821px 1317px #fff, 2425px 1354px #fff, 305px 1422px #fff, 169px 1559px #fff, 1850px 425px #fff, 719px 1507px #fff, 1650px 1803px #fff, 275px 402px #fff, 1038px 772px #fff, 404px 105px #fff, 78px 2119px #fff, 133px 110px #fff, 2559px 944px #fff, 688px 212px #fff, 869px 22","date":"2022-02-07","objectID":"/statistics/:3:0","tags":null,"title":"本站统计数据","uri":"/statistics/"},{"categories":["技术"],"content":" 本文由个人笔记 ryan4yin/knowledge 整理而来，不保证正确 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:0:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"本地 Kubernetes 集群安装工具 云上的 Kubernetes 集群，基本上各云厂商都支持一键部署。这里主要关注本地部署，或者叫做裸机(baremetal)部署 本文介绍的方法适合开发测试使用，安全性、稳定性、长期可用性等方案都可能还有问题。 kubernetes 是一个组件化的系统，安装过程有很大的灵活性，很多组件都有多种实现，这些实现各有特点，让初学者眼花缭乱。 而且要把这些组件一个个安装配置好并且能协同工作，也是很不容易的。 因此社区出现了各种各样的安装方案，下面介绍下几种支持裸机（Baremetal）部署的工具： kubeadm: 社区的集群安装工具，目前已经很成熟了。 使用难度：简单 k3s: 轻量级 kubernetes，资源需求小，部署非常简单，适合开发测试用或者边缘环境 支持 airgap 离线部署 使用难度：超级简单 alibaba/sealer: 支持将整个 kubernetes 打包成一个镜像进行交付，而且部署也非常简单。 使用难度：超级简单 这个项目目前还在发展中，不过貌似已经有很多 toB 的公司在使用它进行 k8s 应用的交付了。 kubespray: 适合自建生产级别的集群，是一个大而全的 kubernetes 安装方案，自动安装容器运行时、k8s、网络插件等组件，而且各组件都有很多方案可选，但是感觉有点复杂。 使用难度：中等 支持 airgap 离线部署，但是以前我试用过是有坑，现在不知道咋样了 底层使用了 kubeadm 部署集群 笔者为了学习 Kubernetes，下面采用官方的 kubeadm 进行部署（不要问为啥不二进制部署，问就是懒），容器运行时使用 containerd，网络插件则使用目前最潮的基于 eBPF 的 Cilium. kubernetes 官方介绍了两种高可用集群的拓扑结构：「堆叠 Etcd 拓扑（Stacked Etcd Topology）」和「外部 Etcd 拓扑（External Etcd Topology）」，简单起见，本文使用第一种「堆叠 Etcd 拓扑」结构，创建一个三 master 的高可用集群。 参考： Kubernetes Docs - Installing kubeadm Kubernetes Docs - Creating Highly Available clusters with kubeadm ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:1:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"0. 网络环境的准备 本文行文未考虑国内网络环境，但是 Kubernetes 用到的很多镜像都在 gcr.io 上，在国内访问会有困难。 这里提供两个手段： 在家庭路由器上整个科学代理，实现全局科学上网。（我就是这么干的） 使用 liangyuanpeng 大佬在评论区提供的 gcr 国内镜像地址，这需要进行如下替换： k8s.gcr.io—\u003e lank8s.cn gcr.io—\u003e gcr.lank8s.cn ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:2:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"1. 节点的环境准备 首先准备三台 Linux 虚拟机，系统按需选择，然后调整这三台机器的设置： 节点配置： master：不低于 2c/3g，硬盘 20G 主节点性能也受集群 Pods 个数的影响，上述配置应该可以支撑到每个 Worker 节点跑 100 个 Pod. worker：看需求，建议不低于 2c/4g，硬盘不小于 20G，资源充分的话建议 40G 以上。 处于同一网络内并可互通（通常是同一局域网） 各主机的 hostname 和 mac/ip 地址以及 /sys/class/dmi/id/product_uuid，都必须唯一 这里新手最容易遇到的问题，是 hostname 冲突 必须关闭 swap 交换内存，kubelet 才能正常工作 方便起见，我直接使用 ryan4yin/pulumi-libvirt 自动创建了五个 opensuse leap 15.3 虚拟机，并设置好了 ip/hostname. ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:3:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"1.1 iptables 设置 目前 kubernetes 的容器网络，默认使用的是 bridge 模式，这种模式下，需要使 iptables 能够接管 bridge 上的流量。 配置如下： sudo modprobe br_netfilter cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:3:1","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"1.2 开放节点端口 局域网环境的话，建议直接关闭防火墙。这样所有端口都可用，方便快捷。 通常我们的云上集群，也是关闭防火墙的，只是会通过云服务提供的「安全组」来限制客户端 ip Control-plane 节点，也就是 master，需要开放如下端口： Protocol Direction Port Range Purpose Used By TCP Inbound 6443* Kubernetes API server All TCP Inbound 2379-2380 etcd server client API kube-apiserver, etcd TCP Inbound 10250 kubelet API Self, Control plane TCP Inbound 10251 kube-scheduler Self TCP Inbound 10252 kube-controller-manager Self Worker 节点需要开发如下端口： Protocol Direction Port Range Purpose Used By TCP Inbound 10250 kubelet API Self, Control plane TCP Inbound 30000-32767 NodePort Services† All 另外通常我们本地测试的时候，可能更想直接在 80 443 8080 等端口上使用 NodePort， 就需要修改 kube-apiserver 的 --service-node-port-range 参数来自定义 NodePort 的端口范围，相应的 Worker 节点也得开放这些端口。 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:3:2","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"2. 安装 containerd 首先是环境配置： cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter nf_conntrack EOF sudo modprobe overlay sudo modprobe br_netfilter sudo modprobe nf_conntrack # Setup required sysctl params, these persist across reboots. cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF # Apply sysctl params without reboot sudo sysctl --system 安装 containerd+nerdctl: wget https://github.com/containerd/nerdctl/releases/download/v0.11.1/nerdctl-full-0.11.1-linux-amd64.tar.gz tar -axvf nerdctl-full-0.11.1-linux-amd64.tar.gz # 这里简单起见，rootless 相关的东西也一起装进去了，测试嘛就无所谓了... mv bin/* /usr/local/bin/ mv lib/systemd/system/containerd.service /usr/lib/systemd/system/ systemctl enable containerd systemctl start containerd nerdctl 是一个 containerd 的命令行工具，但是它的容器、镜像与 Kubernetes 的容器、镜像是完全隔离的，不能互通！ 目前只能通过 crictl 来查看、拉取 Kubernetes 的容器、镜像，下一节会介绍 crictl 的安装。 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:4:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"3. 安装 kubelet/kubeadm/kubectl # 一些全局都需要用的变量 CNI_VERSION=\"v0.8.2\" CRICTL_VERSION=\"v1.17.0\" # kubernetes 的版本号 # RELEASE=\"$(curl -sSL https://dl.k8s.io/release/stable.txt)\" RELEASE=\"1.22.1\" # kubelet 配置文件的版本号 RELEASE_VERSION=\"v0.4.0\" # 架构 ARCH=\"amd64\" #　安装目录 DOWNLOAD_DIR=/usr/local/bin # CNI 插件 sudo mkdir -p /opt/cni/bin curl -L \"https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\" | sudo tar -C /opt/cni/bin -xz # crictl 相关工具 curl -L \"https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\" | sudo tar -C $DOWNLOAD_DIR -xz # kubelet/kubeadm/kubectl cd $DOWNLOAD_DIR sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/${ARCH}/{kubeadm,kubelet,kubectl} sudo chmod +x {kubeadm,kubelet,kubectl} # kubelet/kubeadm 配置 curl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\" | sed \"s:/usr/bin:${DOWNLOAD_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service sudo mkdir -p /etc/systemd/system/kubelet.service.d curl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\" | sed \"s:/usr/bin:${DOWNLOAD_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf systemctl enable --now kubelet # 验证 kubelet 启动起来了，但是目前还没有初始化配置，过一阵就会重启一次 systemctl status kubelet 试用 crictl: export CONTAINER_RUNTIME_ENDPOINT='unix:///var/run/containerd/containerd.sock' # 列出所有 pods，现在应该啥也没 crictl pods # 列出所有镜像 crictl images ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:5:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"4. 为 master 的 kube-apiserver 创建负载均衡实现高可用 根据 kubeadm 官方文档 Kubeadm Docs - High Availability Considerations 介绍，要实现 kube-apiserver 的高可用，目前最知名的负载均衡方式是 keepalived+haproxy，另外也可以考虑使用 kube-vip 等更简单的工具。 简单起见，我们直接用 kube-vip 吧，参考了 kube-vip 的官方文档：Kube-vip as a Static Pod with Kubelet. P.S. 我也见过有的安装工具会直接抛弃 keepalived，直接在每个节点上跑一个 nginx 做负载均衡，配置里写死了所有 master 的地址… 首先使用如下命令生成 kube-vip 的配置文件，以 ARP 为例（生产环境建议换成 BGP）： cat \u003c\u003cEOF | sudo tee add-kube-vip.sh # 你的虚拟机网卡，opensuse/centos 等都是 eth0，但是 ubuntu 可能是 ens3 export INTERFACE=eth0 # 用于实现高可用的 vip，需要和前面的网络接口在同一网段内，否则就无法路由了。 export VIP=192.168.122.200 # 生成 static-pod 的配置文件 mkdir -p /etc/kubernetes/manifests nerdctl run --rm --network=host --entrypoint=/kube-vip ghcr.io/kube-vip/kube-vip:v0.3.8 \\ manifest pod \\ --interface $INTERFACE \\ --vip $VIP \\ --controlplane \\ --services \\ --arp \\ --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml EOF bash add-kube-vip.sh 三个 master 节点都需要跑下上面的命令（worker 不需要），创建好 kube-vip 的 static-pod 配置文件。 在完成 kubeadm 初始化后，kubelet 会自动把它们拉起为 static pod. ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:6:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"5. 使用 kubeadm 创建集群 其实需要运行的就是这条命令： # 极简配置： cat \u003c\u003cEOF | sudo tee kubeadm-config.yaml apiVersion: kubeadm.k8s.io/v1beta3 kind: InitConfiguration nodeRegistration: criSocket: \"/var/run/containerd/containerd.sock\" imagePullPolicy: IfNotPresent --- kind: ClusterConfiguration apiVersion: kubeadm.k8s.io/v1beta3 kubernetesVersion: v1.22.1 clusterName: kubernetes certificatesDir: /etc/kubernetes/pki imageRepository: k8s.gcr.io controlPlaneEndpoint: \"192.168.122.200:6443\" # 填 apiserver 的 vip 地址，或者整个域名也行，但是就得加 /etc/hosts 或者内网 DNS 解析 networking: serviceSubnet: \"10.96.0.0/16\" podSubnet: \"10.244.0.0/16\" etcd: local: dataDir: /var/lib/etcd --- apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration cgroupDriver: systemd # 让 kubelet 从 certificates.k8s.io 申请由集群 CA Root 签名的 tls 证书，而非直接使用自签名证书 # 如果不启用这个， 安装 metrics-server 时就会遇到证书报错，后面会详细介绍。 serverTLSBootstrap: true EOF # 查看 kubeadm 默认的完整配置，供参考 kubeadm config print init-defaults \u003e init.default.yaml # 执行集群的初始化，这会直接将当前节点创建为 master # 成功运行的前提：前面该装的东西都装好了，而且 kubelet 已经在后台运行了 # `--upload-certs` 会将生成的集群证书上传到 kubeadm 服务器，在两小时内加入集群的 master 节点会自动拉证书，主要是方便集群创建。 kubeadm init --config kubeadm-config.yaml --upload-certs kubeadm 应该会报错，提示你有些依赖不存在，下面先安装好依赖项。 sudo zypper in -y socat ebtables conntrack-tools 再重新运行前面的 kubeadm 命令，应该就能正常执行了，它做的操作有： 拉取控制面的容器镜像 生成 ca 根证书 使用根证书为 etcd/apiserver 等一票工具生成 tls 证书 为控制面的各个组件生成 kubeconfig 配置 生成 static pod 配置，kubelet 会根据这些配置自动拉起 kube-proxy 以及其他所有的 k8s master 组件 运行完会给出三部分命令： 将 kubeconfig 放到 $HOME/.kube/config 下，kubectl 需要使用该配置文件连接 kube-apiserver control-plane 节点加入集群的命令: 这里由于我们提前添加了 kube-vip 的 static-pod 配置，这里的 preflight-check 会报错，需要添加此参数忽略该报错 - --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests kubeadm join 192.168.122.200:6443 --token \u003ctoken\u003e \\ --discovery-token-ca-cert-hash sha256:\u003chash\u003e \\ --control-plane --certificate-key \u003ckey\u003e \\ --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests worker 节点加入集群的命令: kubeadm join 192.168.122.200:6443 --token \u003ctoken\u003e \\ --discovery-token-ca-cert-hash sha256:\u003chash\u003e 跑完第一部分 kubeconfig 的处理命令后，就可以使用 kubectl 查看集群状况了： k8s-master-0:~/kubeadm # kubectl get no NAME STATUS ROLES AGE VERSION k8s-master-0 NotReady control-plane,master 79s v1.22.1 k8s-master-0:~/kubeadm # kubectl get po --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-78fcd69978-6tlnw 0/1 Pending 0 83s kube-system coredns-78fcd69978-hxtvs 0/1 Pending 0 83s kube-system etcd-k8s-master-0 1/1 Running 6 90s kube-system kube-apiserver-k8s-master-0 1/1 Running 4 90s kube-system kube-controller-manager-k8s-master-0 1/1 Running 4 90s kube-system kube-proxy-6w2bx 1/1 Running 0 83s kube-system kube-scheduler-k8s-master-0 1/1 Running 7 97s 现在在其他节点运行前面打印出的加入集群的命令，就可以搭建好一个高可用的集群了。 所有节点都加入集群后，通过 kubectl 查看，应该是三个控制面 master，两个 worker： k8s-master-0:~/kubeadm # kubectl get node NAME STATUS ROLES AGE VERSION k8s-master-0 NotReady control-plane,master 26m v1.22.1 k8s-master-1 NotReady control-plane,master 7m2s v1.22.1 k8s-master-2 NotReady control-plane,master 2m10s v1.22.1 k8s-worker-0 NotReady \u003cnone\u003e 97s v1.22.1 k8s-worker-1 NotReady \u003cnone\u003e 86s v1.22.1 现在它们都还处于 NotReady 状态，需要等到我们把网络插件安装好，才会 Ready. 现在再看下集群的证书签发状态： ❯ kubectl get csr --sort-by='{.spec.username}' NAME AGE SIGNERNAME REQUESTOR REQUESTEDDURATION CONDITION csr-95hll 6m58s kubernetes.io/kube-apiserver-client-kubelet system:bootstrap:q8ivnz \u003cnone\u003e Approved,Issued csr-tklnr 7m5s kubernetes.io/kube-apiserver-client-kubelet system:bootstrap:q8ivnz \u003cnone\u003e Approved,Issued csr-w92jv 9m15s kubernetes.io/kube-apiserver-client-kubelet system:bootstrap:q8ivnz \u003cnone\u003e Approved,Issued csr-rv7sj 8m11s kubernetes.io/kube-apiserver-client-kubelet system:bootstrap:q8ivnz \u003cnone\u003e Approved,Issued csr-nxkgx 10m kubernetes.io/kube-apiserver-client-kubelet system:node:k8s-master-0 \u003cnone\u003e Approved,Issued csr-cd22c 10m kubernetes.io/kubelet-serving system:node:k8s-master-0 \u003cnone\u003e Pending csr-wjrnr 9m53s kubernetes.io/kubelet-serving system:node:k8s-master-0 \u003cnone\u003e Pending csr-sjq42 9m8s kubernetes.io/kubelet-serv","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:7:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"5.1 常见问题 5.1.1 使用国内镜像源 如果你没有科学环境，kubeadm 默认的镜像仓库在国内是拉不了的。 如果对可靠性要求高，最好是自建私有镜像仓库，把镜像推送到私有仓库。 可以通过如下命令列出所有需要用到的镜像地址： ❯ kubeadm config images list --kubernetes-version v1.22.1 k8s.gcr.io/kube-apiserver:v1.22.1 k8s.gcr.io/kube-controller-manager:v1.22.1 k8s.gcr.io/kube-scheduler:v1.22.1 k8s.gcr.io/kube-proxy:v1.22.1 k8s.gcr.io/pause:3.5 k8s.gcr.io/etcd:3.5.0-0 k8s.gcr.io/coredns/coredns:v1.8.4 使用 skopeo 等工具或脚本将上述镜像拷贝到你的私有仓库，或者图方便（测试环境）也可以考虑网上找找别人同步好的镜像地址。将镜像地址添加到 kubeadm-config.yaml 中再部署。 5.1.2 重置集群配置 创建集群的过程中出现任何问题，都可以通过在所有节点上运行 kubeadm reset 来还原配置，然后重新走 kubeadm 的集群创建流程。 但是要注意几点： kubeadm reset 会清除包含 kube-vip 配置在内的所有 static-pod 配置文件，所以 master 节点需要重新跑下前面给的 kube-vip 命令，生成下 kube-vip 配置。 kubeadm reset 不会重置网络接口的配置，master 节点需要手动清理下 kube-vip 添加的 vip: ip addr del 192.168.122.200/32 dev eth0. 如果你在安装了网络插件之后希望重装集群，顺序如下： 通过 kubectl delete -f xxx.yaml/helm uninstall 删除所有除网络之外的其他应用配置 删除网络插件 先重启一遍所有节点，或者手动重置所有节点的网络配置 建议重启，因为我不知道该怎么手动重置… 试了 systemctl restart network 并不会清理所有虚拟网络接口。 如此操作后，再重新执行集群安装，应该就没啥毛病了。 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:7:1","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"6. 验证集群的高可用性 虽然网络插件还没装导致集群所有节点都还没 ready，但是我们已经可以通过 kubectl 命令来简单验证集群的高可用性了。 首先，我们将前面放置在 k8s-master-0 的认证文件 $HOME/.kube/config 以及 kunbectl 安装在另一台机器上，比如我直接放我的宿主机。 然后在宿主机上跑 kubectl get node 命令验证集群的高可用性： 三个主节点都正常运行时，kubectl 命令也正常 pause 或者 stop 其中一个 master，kubectl 命令仍然能正常运行 再 pause 第二个 master，kubectl 命令应该就会卡住，并且超时，无法使用了 resume 恢复停掉的两个 master 之一，会发现 kubectl 命令又能正常运行了 到这里 kubeadm 的工作就完成了，接下来再安装网络插件，集群就可用了。 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:8:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"7. 安装网络插件 社区有很多种网络插件可选，比较知名且性能也不错的，应该是 Calico 和 Cilium，其中 Cilium 主打基于 eBPF 的高性能与高可观测性。 下面分别介绍这两个插件的安装方法。（注意只能安装其中一个网络插件，不能重复安装。） 需要提前在本机安装好 helm，我这里使用宿主机，因此只需要在宿主机安装: # 一行命令安装，也可以自己手动下载安装包，都行 curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash # 或者 opensuse 直接用包管理器安装 sudo zypper in helm ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:9:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"7.1 安装 Cilium 官方文档：https://docs.cilium.io/en/v1.10/gettingstarted/k8s-install-kubeadm/ cilium 通过 eBPF 提供了高性能与高可观测的 k8s 集群网络， 另外 cilium 还提供了比 kube-proxy 更高效的实现，可以完全替代 kube-proxy. 这里我们还是先使用 kube-proxy 模式，先熟悉下 cilium 的使用： helm repo add cilium https://helm.cilium.io/ helm search repo cilium/cilium -l | head helm install cilium cilium/cilium --version 1.10.4 --namespace kube-system 可以通过 kubectl get pod -A 查看 cilium 的安装进度，当所有 pod 都 ready 后，集群就 ready 了~ cilium 也提供了专用的客户端： curl -L --remote-name-all https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64.tar.gz{,.sha256sum} sha256sum --check cilium-linux-amd64.tar.gz.sha256sum sudo tar xzvfC cilium-linux-amd64.tar.gz /usr/local/bin rm cilium-linux-amd64.tar.gz{,.sha256sum} 然后使用 cilium 客户端检查网络插件的状态： $ cilium status --wait /¯¯\\ /¯¯\\__/¯¯\\ Cilium: OK \\__/¯¯\\__/ Operator: OK /¯¯\\__/¯¯\\ Hubble: disabled \\__/¯¯\\__/ ClusterMesh: disabled \\__/ DaemonSet cilium Desired: 5, Ready: 5/5, Available: 5/5 Deployment cilium-operator Desired: 2, Ready: 2/2, Available: 2/2 Containers: cilium Running: 5 cilium-operator Running: 2 Cluster Pods: 2/2 managed by Cilium Image versions cilium quay.io/cilium/cilium:v1.10.4@sha256:7d354052ccf2a7445101d78cebd14444c7c40129ce7889f2f04b89374dbf8a1d: 5 cilium-operator quay.io/cilium/operator-generic:v1.10.4@sha256:c49a14e34634ff1a494c84b718641f27267fb3a0291ce3d74352b44f8a8d2f93: 2 cilium 还提供了命令，自动创建 pod 进行集群网络的连接性测试： ❯ cilium connectivity test ℹ️ Monitor aggregation detected, will skip some flow validation steps ✨ [kubernetes] Creating namespace for connectivity check... ✨ [kubernetes] Deploying echo-same-node service... ✨ [kubernetes] Deploying same-node deployment... ✨ [kubernetes] Deploying client deployment... ✨ [kubernetes] Deploying client2 deployment... ✨ [kubernetes] Deploying echo-other-node service... ✨ [kubernetes] Deploying other-node deployment... ... ℹ️ Expose Relay locally with: cilium hubble enable cilium status --wait cilium hubble port-forward\u0026 🏃 Running tests... ... --------------------------------------------------------------------------------------------------------------------- ✅ All 11 tests (134 actions) successful, 0 tests skipped, 0 scenarios skipped. 通过 kubectl get po -A 能观察到，这个测试命令会自动创建一个 cilium-test 名字空间，并在启动创建若干 pod 进行详细的测试。 整个测试流程大概会持续 5 分多钟，测试完成后，相关 Pod 不会自动删除，使用如下命令手动删除： kubectl delete namespace cilium-test ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:9:1","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"7.2 安装 Calico 官方文档：https://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises 也就两三行命令。安装确实特别简单，懒得介绍了，看官方文档吧。 但是实际上 calico 的细节还蛮多的，建议通读下它的官方文档，了解下 calico 的架构。 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:9:2","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"8. 查看集群状态 官方的 dashboard 个人感觉不太好用，建议直接在本地装个 k9s 用，特别爽。 sudo zypper in k9s 然后就可以愉快地玩耍了。 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:10:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"9. 安装 metrics-server 这一步可能遇到的问题：Enabling signed kubelet serving certificates 如果需要使用 HPA 以及简单的集群监控，那么 metrics-server 是必须安装的，现在我们安装一下它。 首先，跑 kubectl 的监控命令应该会报错： ❯ kubectl top node error: Metrics API not available k9s 里面应该也看不到任何监控指标。 现在通过 helm 安装它： helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/ helm search repo metrics-server/metrics-server -l | head helm upgrade --install metrics-server metrics-server/metrics-server --version 3.5.0 --namespace kube-system metrics-server 默认只会部署一个实例，如果希望高可用，请参考官方配置：metrics-server - high-availability manifests 等 metrics-server 启动好后，就可以使用 kubectl top 命令啦： ❯ kubectl top node NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-master-0 327m 16% 1465Mi 50% k8s-master-1 263m 13% 1279Mi 44% k8s-master-2 289m 14% 1282Mi 44% k8s-worker-0 62m 3% 518Mi 13% k8s-worker-1 115m 2% 659Mi 8% ❯ kubectl top pod No resources found in default namespace. ❯ kubectl top pod -A NAMESPACE NAME CPU(cores) MEMORY(bytes) kube-system cilium-45nw4 9m 135Mi kube-system cilium-5x7jf 6m 154Mi kube-system cilium-84sr2 7m 160Mi kube-system cilium-operator-78f45675-dp4b6 2m 30Mi kube-system cilium-operator-78f45675-fpm5g 1m 30Mi kube-system cilium-tkhl4 6m 141Mi kube-system cilium-zxbvm 5m 138Mi kube-system coredns-78fcd69978-dpxxk 3m 16Mi kube-system coredns-78fcd69978-ptd9p 1m 18Mi kube-system etcd-k8s-master-0 61m 88Mi kube-system etcd-k8s-master-1 50m 85Mi kube-system etcd-k8s-master-2 55m 83Mi kube-system kube-apiserver-k8s-master-0 98m 462Mi kube-system kube-apiserver-k8s-master-1 85m 468Mi kube-system kube-apiserver-k8s-master-2 85m 423Mi kube-system kube-controller-manager-k8s-master-0 22m 57Mi kube-system kube-controller-manager-k8s-master-1 2m 23Mi kube-system kube-controller-manager-k8s-master-2 2m 23Mi kube-system kube-proxy-j2s76 1m 24Mi kube-system kube-proxy-k6d6z 1m 18Mi kube-system kube-proxy-k85rx 1m 23Mi kube-system kube-proxy-pknsc 1m 20Mi kube-system kube-proxy-xsq4m 1m 15Mi kube-system kube-scheduler-k8s-master-0 3m 25Mi kube-system kube-scheduler-k8s-master-1 4m 21Mi kube-system kube-scheduler-k8s-master-2 5m 21Mi kube-system kube-vip-k8s-master-0 4m 17Mi kube-system kube-vip-k8s-master-1 2m 16Mi kube-system kube-vip-k8s-master-2 2m 17Mi kube-system metrics-server-559f85484-5b6xf 7m 27Mi ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:11:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"10. 为 etcd 添加定期备份能力 请移步 etcd 的备份与恢复 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:12:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":"11. 安装 Volume Provisioner 在我们学习使用 Prometheus/MinIO/Tekton 等有状态应用时，它们默认情况下会通过 PVC 声明需要的数据卷。 为了支持这个能力，我们需要在集群中部署一个 Volume Provisioner. 对于云上环境，直接接入云服务商提供的 Volume Provisioner 就 OK 了，方便省事而且足够可靠。 而对于 bare-metal 环境，比较有名的应该是 rook-ceph，但是这个玩意部署复杂，维护难度又高，不适合用来测试学习，也不适合生产环境。 对于开发、测试环境，或者个人集群，建议使用： local 数据卷，适合数据可丢失，且不要求分布式的场景，如开发测试环境 https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner https://github.com/rancher/local-path-provisioner NFS 数据卷，适合数据可丢失，对性能要求不高，并且要求分布式的场景。比如开发测试环境、或者线上没啥压力的应用 https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner https://github.com/kubernetes-csi/csi-driver-nfs NFS 数据的可靠性依赖于外部 NFS 服务器，企业通常使用群晖等 NAS 来做 NFS 服务器 如果外部 NFS 服务器出问题，应用就会崩。 直接使用云上的对象存储，适合希望数据不丢失、对性能要求不高的场景。 直接使用 https://github.com/rclone/rclone mount 模式来保存数据，或者直接同步文件夹数据到云端（可能会有一定数据丢失）。 ","date":"2022-01-25","objectID":"/posts/kubernetes-deployemnt-using-kubeadm/:13:0","tags":["Kubernetes","云原生"],"title":"部署一个 Kubernetes 集群","uri":"/posts/kubernetes-deployemnt-using-kubeadm/"},{"categories":["技术"],"content":" 本文由个人笔记 ryan4yin/knowledge 整理而来 本文主要介绍我个人在使用 Kubernetes 的过程中，总结出的一套「Kubernetes 配置」，是我个人的「最佳实践」。 其中大部分内容都经历过线上环境的考验，但是也有少部分还只在我脑子里模拟过，请谨慎参考。 阅读前的几个注意事项： 这份文档比较长，囊括了很多内容，建议当成参考手册使用，先参照目录简单读一读，有需要再细读相关内容。 这份文档需要一定的 Kubernetes 基础才能理解，而且如果没有过实践经验的话，看上去可能会比较枯燥。 而有过实践经验的大佬，可能会跟我有不同的见解，欢迎各路大佬评论~ 我会视情况不定期更新这份文档。 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:0:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"零、示例 首先，这里给出一些本文遵守的前提，这些前提只是契合我遇到的场景，可灵活变通： 这里只讨论无状态服务，有状态服务不在讨论范围内 我们不使用 Deployment 的滚动更新能力，而是为每个服务的每个版本，都创建不同的 Deployment + HPA + PodDisruptionBudget，这是为了方便做金丝雀/灰度发布 我们的服务可能会使用 IngressController / Service Mesh 来进行服务的负载均衡、流量切分 下面先给出一个 Deployment + HPA + PodDisruptionBudget 的 demo，后面再拆开详细说下： apiVersion:apps/v1kind:Deploymentmetadata:name:my-app-v3namespace:prodlabels:app:my-appspec:replicas:3strategy:type:RollingUpdate# 因为服务的每个版本都使用各自的 Deployment，服务更新时其实是用不上这里的滚动更新策略的# 这个配置应该只在 SRE 手动修改 Deployment 配置时才会生效（通常不应该发生这种事）rollingUpdate:maxSurge:10% # 滚动更新时，每次最多更新 10% 的 PodsmaxUnavailable:0# 滚动更新时，不允许出现不可用的 Pods，也就是说始终要维持 3 个可用副本selector:matchLabels:app:my-appversion:v3template:metadata:labels:app:my-appversion:v3spec:affinity:podAffinity:preferredDuringSchedulingIgnoredDuringExecution:# 非强制性条件- weight:100# weight 用于为节点评分，会优先选择评分最高的节点（只有一条规则的情况下，这个值没啥意义）podAffinityTerm:labelSelector:matchExpressions:- key:appoperator:Invalues:- my-app- key:versionoperator:Invalues:- v3# pod 尽量使用同一种节点类型，也就是尽量保证节点的性能一致topologyKey:node.kubernetes.io/instance-typepodAntiAffinity:preferredDuringSchedulingIgnoredDuringExecution:# 非强制性条件- weight:100# weight 用于为节点评分，会优先选择评分最高的节点（只有一条规则的情况下，这个值没啥意义）podAffinityTerm:labelSelector:matchExpressions:- key:appoperator:Invalues:- my-app- key:versionoperator:Invalues:- v3# 将 pod 尽量打散在多个可用区topologyKey:topology.kubernetes.io/zonerequiredDuringSchedulingIgnoredDuringExecution:# 强制性要求（这个建议按需添加）# 注意这个没有 weights，必须满足列表中的所有条件- labelSelector:matchExpressions:- key:appoperator:Invalues:- my-app- key:versionoperator:Invalues:- v3# Pod 必须运行在不同的节点上topologyKey:kubernetes.io/hostnamesecurityContext:# runAsUser: 1000 # 设定用户# runAsGroup: 1000 # 设定用户组runAsNonRoot:true# Pod 必须以非 root 用户运行seccompProfile:# security compute modetype:RuntimeDefaultnodeSelector:eks.amazonaws.com/nodegroup:common # 使用专用节点组，如果希望使用多个节点组，可改用节点亲和性volumes:- name:tmp-diremptyDir:{}containers:- name:my-app-v3image:my-app:v3 # 建议使用私有镜像仓库，规避 docker.io 的镜像拉取限制imagePullPolicy:IfNotPresentvolumeMounts:- mountPath:/tmpname:tmp-dirlifecycle:preStop:exec:command:- /bin/sh- -c- \"while [ $(netstat -plunt | grep tcp | wc -l | xargs) -ne 0 ]; do sleep 1; done\"resources:# 资源请求与限制# 对于核心服务，建议设置 requests = limits，避免资源竞争requests:# HPA 会使用 requests 计算资源利用率# 建议将 requests 设为服务正常状态下的 CPU 使用率，HPA 的目前指标设为 80%# 所有容器的 requests 总量不建议为 2c/4G 4c/8G 等常见值，因为节点通常也是这个配置，这会导致 Pod 只能调度到更大的节点上，适当调小 requests 等扩充可用的节点类型，从而扩充节点池。 cpu:1000mmemory:1Gilimits:# limits - requests 为允许超卖的资源量，建议为 requests 的 1 到 2 倍，酌情配置。cpu:1000mmemory:1GisecurityContext:# 将容器层设为只读，防止容器文件被篡改## 如果需要写入临时文件，建议额外挂载 emptyDir 来提供可读写的数据卷readOnlyRootFilesystem:true# 禁止 Pod 做任何权限提升allowPrivilegeEscalation:falsecapabilities:# drop ALL 的权限比较严格，可按需修改drop:- ALLstartupProbe:# 要求 kubernetes 1.18+httpGet:path:/actuator/health # 直接使用健康检查接口即可port:8080periodSeconds:5timeoutSeconds:1failureThreshold:20# 最多提供给服务 5s * 20 的启动时间successThreshold:1livenessProbe:httpGet:path:/actuator/health # spring 的通用健康检查路径port:8080periodSeconds:5timeoutSeconds:1failureThreshold:5successThreshold:1# Readiness probes are very important for a RollingUpdate to work properly,readinessProbe:httpGet:path:/actuator/health # 简单起见可直接使用 livenessProbe 相同的接口，当然也可额外定义port:8080periodSeconds:5timeoutSeconds:1failureThreshold:5successThreshold:1---apiVersion:autoscaling/v2beta2kind:HorizontalPodAutoscalermetadata:labels:app:my-appname:my-app-v3namespace:prodspec:scaleTargetRef:apiVersion:apps/v1kind:Deploymentname:my-app-v3maxReplicas:50minReplicas:3metrics:- type:Resourceresource:name:cputarget:type:UtilizationaverageUtilization:70---apiVersion:policy/v1kind:PodDisruptionBudgetmetadata:name:my-app-v3namespace:prodlabels:app:my-appspec:minAvailable:75%selector:matchLabels:app:my-appversion:v3 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:1:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"一、优雅停止（Gracful Shutdown）与 502/504 报错 如果 Pod 正在处理大量请求（比如 1000 QPS+）时，因为节点故障或「竞价节点」被回收等原因被重新调度， 你可能会观察到在容器被 terminate 的一段时间内出现少量 502/504。 为了搞清楚这个问题，需要先理解清楚 terminate 一个 Pod 的流程： Pod 的状态被设为「Terminating」，（几乎）同时该 Pod 被从所有关联的 Service Endpoints 中移除 preStop 钩子被执行，它可以是一个命令，或者一个对 Pod 中容器的 http 调用 如果你的程序在收到 SIGTERM 信号时，无法优雅退出，就可以考虑使用 preStop 如果让程序本身支持优雅退出比较麻烦的话，用 preStop 实现优雅退出是一个非常好的方式 将 SIGTERM 发送给 Pod 中的所有容器 继续等待，直到超过 spec.terminationGracePeriodSeconds 设定好的时间，这个值默认为 30s 需要注意的是，这个优雅退出的等待计时是与 preStop 同步开始的！而且它也不会等待 preStop 结束！ 如果超过了 spec.terminationGracePeriodSeconds 容器仍然没有停止，k8s 将会发送 SIGKILL 信号给容器 进程全部终止后，整个 Pod 完全被清理掉 注意：1 和 2 两个工作是异步发生的，所以可能会出现「Pod 还在 Service Endpoints 中，但是 preStop 已经执行了」的情况，我们需要考虑到这种状况的发生。 了解了上面的流程后，我们就能分析出两种错误码出现的原因： 502：应用程序在收到 SIGTERM 信号后直接终止了运行，导致部分还没有被处理完的请求直接中断，代理层返回 502 表示这种情况 504：Service Endpoints 移除不够及时，在 Pod 已经被终止后，仍然有个别请求被路由到了该 Pod，得不到响应导致 504 通常的解决方案是，在 Pod 的 preStop 步骤加一个 15s 的等待时间。 其原理是：在 Pod 处理 terminating 状态的时候，就会被从 Service Endpoints 中移除，也就不会再有新的请求过来了。 在 preStop 等待 15s，基本就能保证所有的请求都在容器死掉之前被处理完成（一般来说，绝大部分请求的处理时间都在 300ms 以内吧）。 一个简单的示例如下，它使 Pod 被终止时，总是先等待 15s，再发送 SIGTERM 信号给容器： containers:- name:my-app# 添加下面这部分lifecycle:preStop:exec:command:- /bin/sleep- \"15\" 更好的解决办法，是直接等待所有 tcp 连接都关闭（需要镜像中有 netstat）： containers:- name:my-app# 添加下面这部分lifecycle:preStop:exec:command:- /bin/sh- -c- \"while [ $(netstat -plunt | grep tcp | wc -l | xargs) -ne 0 ]; do sleep 1; done\" ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:2:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"如果我的服务还使用了 Sidecar 代理网络请求，该怎么处理？ 以服务网格 Istio 为例，在 Envoy 代理了 Pod 流量的情况下，502/504 的问题会变得更复杂一点——还需要考虑 Sidecar 与主容器的关闭顺序： 如果在 Envoy 已关闭后，有新的请求再进来，将会导致 504（没人响应这个请求了） 所以 Envoy 最好在 Terminating 至少 3s 后才能关，确保 Istio 网格配置已完全更新 如果在 Envoy 还没停止时，主容器先关闭，然后又有新的请求再进来，Envoy 将因为无法连接到 upstream 导致 503 所以主容器也最好在 Terminating 至少 3s 后，才能关闭。 如果主容器处理还未处理完遗留请求时，Envoy 或者主容器的其中一个停止了，会因为 tcp 连接直接断开连接导致 502 因此 Envoy 必须在主容器处理完遗留请求后（即没有 tcp 连接时），才能关闭 所以总结下：Envoy 及主容器的 preStop 都至少得设成 3s，并且在「没有 tcp 连接」时，才能关闭，避免出现 502/503/504. 主容器的修改方法在前文中已经写过了，下面介绍下 Envoy 的修改方法。 和主容器一样，Envoy 也能直接加 preStop，修改 istio-sidecar-injector 这个 configmap，在 sidecar 里添加 preStop sleep 命令: containers:- name:istio-proxy# 添加下面这部分lifecycle:preStop:exec:command:- /bin/sh- -c- \"while [ $(netstat -plunt | grep tcp | grep -v envoy | wc -l | xargs) -ne 0 ]; do sleep 1; done\" ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:2:1","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"参考 Kubernetes best practices: terminating with grace Graceful shutdown in Kubernetes is not always trivial ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:2:2","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"二、服务的伸缩配置 - HPA Kubernetes 官方主要支持基于 Pod CPU 的伸缩，这是应用最为广泛的伸缩指标，需要部署 metrics-server 才可使用。 先回顾下前面给出的，基于 Pod CPU 使用率进行伸缩的示例： apiVersion:autoscaling/v2beta2 # k8s 1.23+ 此 API 已经 GAkind:HorizontalPodAutoscalermetadata:labels:app:my-appname:my-app-v3namespace:prodspec:scaleTargetRef:apiVersion:apps/v1kind:Deploymentname:my-app-v3maxReplicas:50minReplicas:3metrics:- type:Resourceresource:name:cputarget:type:UtilizationaverageUtilization:70 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:3:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"1. 当前指标值的计算方式 提前总结：每个 Pod 的指标是其中所有容器指标之和，如果计算百分比，就再除以 Pod 的 requests. HPA 默认使用 Pod 的当前指标进行计算，以 CPU 使用率为例，其计算公式为： 「Pod 的 CPU 使用率」= 100% * 「所有 Container 的 CPU 用量之和」/「所有 Container 的 CPU requests 之和」 注意分母是总的 requests 量，而不是 limits. 1.1 存在的问题与解决方法 在 Pod 只有一个容器时这没啥问题，但是当 Pod 注入了 envoy 等 sidecar 时，这就会有问题了。 因为 Istio 的 Sidecar requests 默认为 100m 也就是 0.1 核。 在未 tuning 的情况下，服务负载一高，sidecar 的实际用量很容易就能涨到 0.2-0.4 核。 把这两个值代入前面的公式，会发现 对于 QPS 较高的服务，添加 Sidecar 后，「Pod 的 CPU 利用率」可能会高于「应用容器的 CPU 利用率」，造成不必要的扩容。 即使改用「Pod 的 CPU 用量」而非百分比来进行扩缩容，也解决不了这个问题。 解决方法： 方法一：针对每个服务的 CPU 使用情况，为每个服务的 sidecar 设置不同的 requests/limits. 感觉这个方案太麻烦了 方法二：使用 KEDA 等第三方组件，获取到应用程序的 CPU 利用率（排除掉 Sidecar），使用它进行扩缩容 方法三：使用 k8s 1.20 提供的 alpha 特性：Container Resourse Metrics. ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:3:1","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"2. HPA 的扩缩容算法 HPA 什么时候会扩容，这一点是很好理解的。但是 HPA 的缩容策略，会有些迷惑，下面简单分析下。 HPA 的「目标指标」可以使用两种形式：绝对度量指标和资源利用率。 绝对度量指标：比如 CPU，就是指 CPU 的使用量 资源利用率（资源使用量/资源请求 * 100%）：在 Pod 设置了资源请求时，可以使用资源利用率进行 Pod 伸缩 HPA 的「当前指标」是一段时间内所有 Pods 的平均值，不是峰值。 HPA 的扩缩容算法为： 期望副本数 = ceil[当前副本数 * ( 当前指标 / 目标指标 )] 从上面的参数可以看到： 只要「当前指标」超过了目标指标，就一定会发生扩容。 当前指标 / 目标指标要小到一定的程度，才会触发缩容。 比如双副本的情况下，上述比值要小于等于 1/2，才会缩容到单副本。 三副本的情况下，上述比值的临界点是 2/3。 五副本时临界值是 4/5，100副本时临界值是 99/100，依此类推。 如果 当前指标 / 目标指标 从 1 降到 0.5，副本的数量将会减半。（虽然说副本数越多，发生这么大变化的可能性就越小。） 当前副本数 / 目标指标的值越大，「当前指标」的波动对「期望副本数」的影响就越大。 为了防止扩缩容过于敏感，HPA 有几个相关参数： Hardcoded 参数 HPA Loop 延时：默认 15 秒，每 15 秒钟进行一次 HPA 扫描。 缩容冷却时间：默认 5 分钟。 对于 K8s 1.18+，HPA 通过 spec.behavior 提供了多种控制扩缩容行为的参数，后面会具体介绍。 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:3:2","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"3. HPA 的期望值设成多少合适 这个需要针对每个服务的具体情况，具体分析。 以最常用的按 CPU 值伸缩为例， 核心服务 requests/limits 值: 建议设成相等的，保证服务质量等级为 Guaranteed 需要注意 CPU 跟 Memory 的 limits 限制策略是不同的，CPU 是真正地限制了上限，而 Memory 是用超了就干掉容器（OOMKilled） k8s 一直使用 cgroups v1 (cpu_shares/memory.limit_in_bytes)来限制 cpu/memory，但是对于 Guaranteed 的 Pods 而言，内存并不能完全预留，资源竞争总是有可能发生的。1.22 有 alpha 特性改用 cgroups v2，可以关注下。 HPA: 一般来说，期望值设为 60% 到 70% 可能是比较合适的，最小副本数建议设为 2 - 5. （仅供参考） PodDisruptionBudget: 建议按服务的健壮性与 HPA 期望值，来设置 PDB，后面会详细介绍，这里就先略过了 非核心服务 requests/limits 值: 建议 requests 设为 limits 的 0.6 - 0.9 倍（仅供参考），对应的服务质量等级为 Burstable 也就是超卖了资源，这样做主要的考量点是，很多非核心服务负载都很低，根本跑不到 limits 这么高，降低 requests 可以提高集群资源利用率，也不会损害服务稳定性。 HPA: 因为 requests 降低了，而 HPA 是以 requests 为 100% 计算使用率的，我们可以提高 HPA 的期望值（如果使用百分比为期望值的话），比如 80% ~ 90%，最小副本数建议设为 1 - 3. （仅供参考） PodDisruptionBudget: 非核心服务嘛，保证最少副本数为 1 就行了。 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:3:3","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"4. HPA 的常见问题 4.1. Pod 扩容 - 预热陷阱 预热：Java/C# 这类运行在虚拟机上的语言，第一次使用到某些功能时，往往需要初始化一些资源，例如「JIT 即时编译」。 如果代码里还应用了动态类加载之类的功能，就很可能导致微服务某些 API 第一次被调用时，响应特别慢（要动态编译 class）。 因此 Pod 在提供服务前，需要提前「预热（slow_start）」一次这些接口，将需要用到的资源提前初始化好。 在负载很高的情况下，HPA 会自动扩容。 但是如果扩容的 Pod 需要预热，就可能会遇到「预热陷阱」。 在有大量用户访问的时候，不论使用何种负载均衡策略，只要请求被转发到新建的 Pod 上，这个请求就会「卡住」。 如果请求速度太快，Pod 启动的瞬间「卡住」的请求就越多，这将会导致新建 Pod 因为压力过大而垮掉。 然后 Pod 一重启就被压垮，进入 CrashLoopBackoff 循环。 如果是在使用多线程做负载测试时，效果更明显：50 个线程在不间断地请求， 别的 Pod 响应时间是「毫秒级」，而新建的 Pod 的首次响应是「秒级」。几乎是一瞬间，50 个线程就会全部陷在新建的 Pod 这里。 而新建的 Pod 在启动的瞬间可能特别脆弱，瞬间的 50 个并发请求就可以将它压垮。 然后 Pod 一重启就被压垮，进入 CrashLoopBackoff 循环。 解决方法： 可以在「应用层面」解决： 在启动探针 API 的后端控制器里面，依次调用所有需要预热的接口或者其他方式，提前初始化好所有资源。 启动探针的控制器中，可以通过 localhost 回环地址调用它自身的接口。 使用「AOT 预编译」技术：预热，通常都是因为「JIT 即时编译」导致的问题，在需要用到时它才编译。而 AOT 是预先编译，在使用前完成编译，因此 AOT 能解决预热的问题。 也可以在「基础设施层面」解决： 像 AWS ALB TargetGroup 以及其他云服务商的 ALB 服务，通常都可以设置 slow_start 时长，即对新加入的实例，使用一定时间慢慢地把流量切过去，最终达到预期的负载均衡状态。这个可以解决服务预热问题。 Envoy 也已经支持 slow_start 模式，支持在一个设置好的时间窗口内，把流量慢慢负载到新加入的实例上，达成预热效果。 4.2. HPA 扩缩容过于敏感，导致 Pod 数量震荡 通常来讲，EKS 上绝大部分负载都应该选择使用 CPU 进行扩缩容。因为 CPU 通常能很好的反映服务的负载情况 但是有些服务会存在其他影响 CPU 使用率的因素，导致使用 CPU 扩缩容变得不那么可靠，比如： 有些 Java 服务堆内存设得很大，GC pause 也设得比较长，因此内存 GC 会造成 CPU 间歇性飙升，CPU 监控会有大量的尖峰。 有些服务有定时任务，定时任务一运行 CPU 就涨，但是这跟服务的 QPS 是无关的 有些服务可能一运行 CPU 就会立即处于一个高位状态，它可能希望使用别的业务侧指标来进行扩容，而不是 CPU. 因为上述问题存在，使用 CPU 扩缩容，就可能会造成服务频繁的扩容然后缩容，或者无限扩容。 而有些服务（如我们的「推荐服务」），对「扩容」和「缩容」都是比较敏感的，每次扩缩都会造成服务可用率抖动。 对这类服务而言，HPA 有这几种调整策略： 选择使用 QPS 等相对比较平滑，没有 GC 这类干扰的指标来进行扩缩容，这需要借助 KEDA 等社区组件。 对 kubernetes 1.18+，可以直接使用 HPA 的 behavior.scaleDown 和 behavior.scaleUp 两个参数，控制每次扩缩容的最多 pod 数量或者比例。 示例如下： ---apiVersion:autoscaling/v2beta2kind:HorizontalPodAutoscalermetadata:name:podinfonamespace:defaultspec:scaleTargetRef:apiVersion:apps/v1kind:Deploymentname:podinfominReplicas:3maxReplicas:50metrics:- type:Resourceresource:name:cputarget:type:UtilizationaverageUtilization:50# 期望的 CPU 平均值behavior:scaleUp:stabilizationWindowSeconds:0# 默认为 0，只使用当前值进行扩缩容policies:- periodSeconds:180# 每 3 分钟最多扩容 5% 的 Podstype:Percentvalue:5- periodSeconds:60# 每分钟最多扩容 1 个 Pod，扩的慢一点主要是为了一个个地预热，避免一次扩容太多未预热的 Pods 导致服务可用率剧烈抖动type:Podsvalue:1selectPolicy:Min # 选择最小的策略# 以下的一切配置，都是为了更平滑地缩容scaleDown:stabilizationWindowSeconds:600# 使用过去 10 mins 的最大 cpu 值进行缩容计算，避免过快缩容policies:- type:Percent # 每 3 mins 最多缩容 `ceil[当前副本数 * 5%]` 个 pod（20 个 pod 以内，一次只缩容 1 个 pod）value:5periodSeconds:180- type:Pods # 每 1 mins 最多缩容 1 个 podvalue:1periodSeconds:60selectPolicy:Min # 上面的 policies 列表，只生效其中最小的值作为缩容限制（保证平滑缩容） 而对于扩容不够平滑这个问题，可以考虑提供类似 AWS ALB TargetGroup slow_start 的功能，在扩容时缓慢将流量切到新 Pod 上，以实现预热服务（JVM 预热以及本地缓存预热），这样就能达到比较好的平滑扩容效果。 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:3:4","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"5. HPA 注意事项 注意 kubectl 1.23 以下的版本，默认使用 hpa.v1.autoscaling 来查询 HPA 配置，v2beta2 相关的参数会被编码到 metadata.annotations 中。 比如 behavior 就会被编码到 autoscaling.alpha.kubernetes.io/behavior 这个 key 所对应的值中。 因此如果使用了 v2beta2 的 HPA，一定要明确指定使用 v2beta2 版本的 HPA： kubectl get hpa.v2beta2.autoscaling 否则不小心动到 annotations 中编码的某些参数，可能会产生意料之外的效果，甚至直接把控制面搞崩… 比如这个 issue: Nil pointer dereference in KCM after v1 HPA patch request ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:3:5","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"6. 参考 Pod 水平自动伸缩 - Kubernetes Docs Horizontal Pod Autoscaler演练 - Kubernetes Docs ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:3:6","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"三、节点维护与Pod干扰预算 在我们通过 kubectl drain 将某个节点上的容器驱逐走的时候， kubernetes 会依据 Pod 的「PodDistruptionBuget」来进行 Pod 的驱逐。 如果不设置任何明确的 PodDistruptionBuget，Pod 将会被直接杀死，然后在别的节点重新调度，这可能导致服务中断！ PDB 是一个单独的 CR 自定义资源，示例如下： apiVersion:policy/v1beta1kind:PodDisruptionBudgetmetadata:name:podinfo-pdbspec:# 如果不满足 PDB，Pod 驱逐将会失败！minAvailable:1# 最少也要维持一个 Pod 可用# maxUnavailable: 1 # 最大不可用的 Pod 数，与 minAvailable 不能同时配置！二选一selector:matchLabels:app:podinfo 如果在进行节点维护时(kubectl drain)，Pod 不满足 PDB，drain 将会失败，示例： \u003e kubectl drain node-205 --ignore-daemonsets --delete-local-data node/node-205 cordoned WARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-nfhj7, kube-system/kube-proxy-94dz5 evicting pod default/podinfo-7c84d8c94d-h9brq evicting pod default/podinfo-7c84d8c94d-gw6qf error when evicting pod \"podinfo-7c84d8c94d-h9brq\" (will retry after 5s): Cannot evict pod as it would violate the pod's disruption budget. evicting pod default/podinfo-7c84d8c94d-h9brq error when evicting pod \"podinfo-7c84d8c94d-h9brq\" (will retry after 5s): Cannot evict pod as it would violate the pod's disruption budget. evicting pod default/podinfo-7c84d8c94d-h9brq error when evicting pod \"podinfo-7c84d8c94d-h9brq\" (will retry after 5s): Cannot evict pod as it would violate the pod's disruption budget. evicting pod default/podinfo-7c84d8c94d-h9brq pod/podinfo-7c84d8c94d-gw6qf evicted pod/podinfo-7c84d8c94d-h9brq evicted node/node-205 evicted 上面的示例中，podinfo 一共有两个副本，都运行在 node-205 上面。我给它设置了干扰预算 PDB minAvailable: 1。 然后使用 kubectl drain 驱逐 Pod 时，其中一个 Pod 被立即驱逐走了，而另一个 Pod 大概在 15 秒内一直驱逐失败。 因为第一个 Pod 还没有在新的节点上启动完成，它不满足干扰预算 PDB minAvailable: 1 这个条件。 大约 15 秒后，最先被驱逐走的 Pod 在新节点上启动完成了，另一个 Pod 满足了 PDB 所以终于也被驱逐了。这才完成了一个节点的 drain 操作。 ClusterAutoscaler 等集群节点伸缩组件，在缩容节点时也会考虑 PodDisruptionBudget. 如果你的集群使用了 ClusterAutoscaler 等动态扩缩容节点的组件，强烈建议设置为所有服务设置 PodDisruptionBudget. 在 PDB 中使用百分比的注意事项 在使用百分比时，计算出的实例数都会被向上取整，这会造成两个现象： 如果使用 minAvailable，实例数较少的情况下，可能会导致 ALLOWED DISRUPTIONS 为 0，所有实例都无法被驱逐了。 如果使用 maxUnavailable，因为是向上取整，ALLOWED DISRUPTIONS 的值一定不会低于 1，至少有 1 个实例可以被驱逐。 因此从「便于驱逐」的角度看，如果你的服务至少有 2-3 个实例，建议在 PDB 中使用百分比配置 maxUnavailable，而不是 minAvailable. 相对的从「确保服务稳定性」的角度看，我们则应该使用 minAvailable，确保至少有 1 个实例可用。 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:4:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"最佳实践 Deployment + HPA + PodDisruptionBudget 一般而言，一个服务的每个版本，都应该包含如下三个资源： Deployment: 管理服务自身的 Pods 嘛 HPA: 负责 Pods 的扩缩容，通常使用 CPU 指标进行扩缩容 PodDisruptionBudget(PDB): 建议按照 HPA 的目标值，来设置 PDB. 比如 HPA CPU 目标值为 60%，就可以考虑设置 PDB minAvailable=65%，保证至少有 65% 的 Pod 可用。这样理论上极限情况下 QPS 均摊到剩下 65% 的 Pods 上也不会造成雪崩（这里假设 QPS 和 CPU 是完全的线性关系） ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:4:1","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"四、节点亲和性与节点组 我们一个集群，通常会使用不同的标签为节点组进行分类，比如 kubernetes 自动生成的一些节点标签： kubernetes.io/os: 通常都用 linux kubernetes.io/arch: amd64, arm64 topology.kubernetes.io/region 和 topology.kubernetes.io/zone: 云服务的区域及可用区 我们使用得比较多的，是「节点亲和性」以及「Pod 反亲和性」，另外两个策略视情况使用。 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:5:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"1. 节点亲和性 如果你使用的是 aws，那 aws 有一些自定义的节点标签： eks.amazonaws.com/nodegroup: aws eks 节点组的名称，同一个节点组使用同样的 aws ec2 实例模板 比如 arm64 节点组、amd64/x64 节点组 内存比例高的节点组如 m 系实例，计算性能高的节点组如 c 系列 竞价实例节点组：这个省钱啊，但是动态性很高，随时可能被回收 按量付费节点组：这类实例贵，但是稳定。 假设你希望优先选择竞价实例跑你的 Pod，如果竞价实例暂时跑满了，就选择按量付费实例。 那 nodeSelector 就满足不了你的需求了，你需要使用 nodeAffinity，示例如下: apiVersion:apps/v1kind:Deploymentmetadata:name:xxxnamespace:xxxspec:# ...template:# ...spec:affinity:nodeAffinity:# 优先选择 spot-group-c 的节点preferredDuringSchedulingIgnoredDuringExecution:- preference:matchExpressions:- key:eks.amazonaws.com/nodegroupoperator:Invalues:- spot-group-cweight:80# weight 用于为节点评分，会优先选择评分最高的节点- preference:matchExpressions:# 优先选择 aws c6i 的机器- key:node.kubernetes.io/instance-typeoperator:Invalues:- \"c6i.xlarge\"- \"c6i.2xlarge\"- \"c6i.4xlarge\"- \"c6i.8xlarge\"weight:70- preference:matchExpressions:# 其次选择 aws c5 的机器- key:node.kubernetes.io/instance-typeoperator:Invalues:- \"c5.xlarge\"- \"c5.2xlarge\"- \"c5.4xlarge\"- \"c5.9xlarge\"weight:60# 如果没 spot-group-c 可用，也可选择 ondemand-group-c 的节点跑requiredDuringSchedulingIgnoredDuringExecution:nodeSelectorTerms:- matchExpressions:- key:eks.amazonaws.com/nodegroupoperator:Invalues:- spot-group-c- ondemand-group-ccontainers:# ... ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:5:1","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"2. Pod 反亲和性 通常建议为每个 Deployment 的 template 配置 Pod 反亲和性，把 Pods 打散在所有节点上： apiVersion:apps/v1kind:Deploymentmetadata:name:xxxnamespace:xxxspec:# ...template:# ...spec:replicas:3affinity:podAntiAffinity:preferredDuringSchedulingIgnoredDuringExecution:# 非强制性条件- weight:100# weight 用于为节点评分，会优先选择评分最高的节点podAffinityTerm:labelSelector:matchExpressions:- key:appoperator:Invalues:- xxx- key:versionoperator:Invalues:- v12# 将 pod 尽量打散在多个可用区topologyKey:topology.kubernetes.io/zonerequiredDuringSchedulingIgnoredDuringExecution:# 强制性要求# 注意这个没有 weights，必须满足列表中的所有条件- labelSelector:matchExpressions:- key:appoperator:Invalues:- xxx- key:versionoperator:Invalues:- v12# Pod 必须运行在不同的节点上topologyKey:kubernetes.io/hostname ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:5:2","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"五、Pod 的就绪探针、存活探针与启动探针 Pod 提供如下三种探针，均支持使用 Command、HTTP API、TCP Socket 这三种手段来进行服务可用性探测。 startupProbe 启动探针（Kubernetes v1.18 [beta]）: 此探针通过后，「就绪探针」与「存活探针」才会进行存活性与就绪检查 用于对慢启动容器进行存活性检测，避免它们在启动运行之前就被杀掉 startupProbe 显然比 livenessProbe 的 initialDelaySeconds 参数更灵活。 同时它也能延迟 readinessProbe 的生效时间，这主要是为了避免无意义的探测。容器都还没 startUp，显然是不可能就绪的。 程序将最多有 failureThreshold * periodSeconds 的时间用于启动，比如设置 failureThreshold=20、periodSeconds=5，程序启动时间最长就为 100s，如果超过 100s 仍然未通过「启动探测」，容器会被杀死。 readinessProbe 就绪探针: 就绪探针失败次数超过 failureThreshold 限制（默认三次），服务将被暂时从 Service 的 Endpoints 中踢出，直到服务再次满足 successThreshold. livenessProbe 存活探针: 检测服务是否存活，它可以捕捉到死锁等情况，及时杀死这种容器。 存活探针失败可能的原因： 服务发生死锁，对所有请求均无响应 服务线程全部卡在对外部 redis/mysql 等外部依赖的等待中，导致请求无响应 存活探针失败次数超过 failureThreshold 限制（默认三次），容器将被杀死，随后根据重启策略执行重启。 kubectl describe pod 会显示重启原因为 State.Last State.Reason = Error, Exit Code=137，同时 Events 中会有 Liveness probe failed: ... 这样的描述。 上述三类探测器的参数都是通用的，五个时间相关的参数列举如下： # 下面的值就是 k8s 的默认值initialDelaySeconds:0# 默认没有 delay 时间periodSeconds:10timeoutSeconds:1failureThreshold:3successThreshold:1 示例： apiVersion:apps/v1kind:Deploymentmetadata:name:my-app-v3spec:# ...template:# ...spec:containers:- name:my-app-v3image:xxx.com/app/my-app:v3imagePullPolicy:IfNotPresent # ... 省略若干配置startupProbe:httpGet:path:/actuator/health # 直接使用健康检查接口即可port:8080periodSeconds:5timeoutSeconds:1failureThreshold:20# 最多提供给服务 5s * 20 的启动时间successThreshold:1livenessProbe:httpGet:path:/actuator/health # spring 的通用健康检查路径port:8080periodSeconds:5timeoutSeconds:1failureThreshold:5successThreshold:1# Readiness probes are very important for a RollingUpdate to work properly,readinessProbe:httpGet:path:/actuator/health # 简单起见可直接使用 livenessProbe 相同的接口，当然也可额外定义port:8080periodSeconds:5timeoutSeconds:1failureThreshold:5successThreshold:1 在 Kubernetes 1.18 之前，通用的手段是为「就绪探针」添加较长的 initialDelaySeconds 来实现类似「启动探针」的功能动，避免容器因为启动太慢，存活探针失败导致容器被重启。示例如下： apiVersion:apps/v1kind:Deploymentmetadata:name:my-app-v3spec:# ...template:# ...spec:containers:- name:my-app-v3image:xxx.com/app/my-app:v3imagePullPolicy:IfNotPresent # ... 省略若干配置livenessProbe:httpGet:path:/actuator/health # spring 的通用健康检查路径port:8080initialDelaySeconds:120# 前两分钟，都假设服务健康，避免 livenessProbe 失败导致服务重启periodSeconds:5timeoutSeconds:1failureThreshold:5successThreshold:1# 容器一启动，Readiness probes 就会不断进行检测readinessProbe:httpGet:path:/actuator/healthport:8080initialDelaySeconds:3# readiness probe 不需要设太长时间，使 Pod 尽快加入到 Endpoints.periodSeconds:5timeoutSeconds:1failureThreshold:5successThreshold:1 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:6:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"六、Pod 安全 这里只介绍 Pod 中安全相关的参数，其他诸如集群全局的安全策略，不在这里讨论。 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:7:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"1. Pod SecurityContext 通过设置 Pod 的 SecurityContext，可以为每个 Pod 设置特定的安全策略。 SecurityContext 有两种类型： spec.securityContext: 这是一个 PodSecurityContext 对象 顾名思义，它对 Pod 中的所有 contaienrs 都有效。 spec.containers[*].securityContext: 这是一个 SecurityContext 对象 container 私有的 SecurityContext 这两个 SecurityContext 的参数只有部分重叠，重叠的部分 spec.containers[*].securityContext 优先级更高。 我们比较常遇到的一些提升权限的安全策略： 特权容器：spec.containers[*].securityContext.privileged 添加（Capabilities）可选的系统级能力: spec.containers[*].securityContext.capabilities.add 只有 ntp 同步服务等少数容器，可以开启这项功能。请注意这非常危险。 Sysctls: 系统参数: spec.securityContext.sysctls 权限限制相关的安全策略有（强烈建议在所有 Pod 上按需配置如下安全策略！）： spec.volumes: 所有的数据卷都可以设定读写权限 spec.securityContext.runAsNonRoot: true Pod 必须以非 root 用户运行 spec.containers[*].securityContext.readOnlyRootFileSystem:true 将容器层设为只读，防止容器文件被篡改。 如果微服务需要读写文件，建议额外挂载 emptydir 类型的数据卷。 spec.containers[*].securityContext.allowPrivilegeEscalation: false 不允许 Pod 做任何权限提升！ spec.containers[*].securityContext.capabilities.drop: 移除（Capabilities）可选的系统级能力 还有其他诸如指定容器的运行用户(user)/用户组(group)等功能未列出，请自行查阅 Kubernetes 相关文档。 一个无状态的微服务 Pod 配置举例： apiVersion:v1kind:Podmetadata:name:\u003cPod name\u003espec:containers:- name:\u003ccontainer name\u003eimage:\u003cimage\u003eimagePullPolicy:IfNotPresent # ......此处省略 500 字securityContext:readOnlyRootFilesystem:true# 将容器层设为只读，防止容器文件被篡改。allowPrivilegeEscalation:false# 禁止 Pod 做任何权限提升capabilities:drop:# 禁止容器使用 raw 套接字，通常只有 hacker 才会用到 raw 套接字。# raw_socket 可自定义网络层数据，避开 tcp/udp 协议栈，直接操作底层的 ip/icmp 数据包。可实现 ip 伪装、自定义协议等功能。# 去掉 net_raw 会导致 tcpdump 无法使用，无法进行容器内抓包。需要抓包时可临时去除这项配置- NET_RAW# 更好的选择：直接禁用所有 capabilities# - ALLsecurityContext:# runAsUser: 1000 # 设定用户# runAsGroup: 1000 # 设定用户组runAsNonRoot:true# Pod 必须以非 root 用户运行seccompProfile:# security compute modetype:RuntimeDefault ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:7:1","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"2. seccomp: security compute mode seccomp 和 seccomp-bpf 允许对系统调用进行过滤，可以防止用户的二进制文对主机操作系统件执行通常情况下并不需要的危险操作。它和 Falco 有些类似，不过 Seccomp 没有为容器提供特别的支持。 视频: Seccomp: What Can It Do For You? - Justin Cormack, Docker ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:7:2","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["技术"],"content":"其他问题 不同节点类型的性能有差距，导致 QPS 均衡的情况下，CPU 负载不均衡 解决办法（未验证）： 尽量使用性能相同的实例类型：通过 podAffinity 及 nodeAffinity 添加节点类型的亲和性 ","date":"2022-01-25","objectID":"/posts/kubernetes-best-practices/:8:0","tags":["Kubernetes","最佳实践","云原生"],"title":"Kubernetes 微服务最佳实践","uri":"/posts/kubernetes-best-practices/"},{"categories":["随笔","技术"],"content":" 更新：2022/1/22 ","date":"2022-01-03","objectID":"/posts/2021-summary/:0:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"闲言碎语 一晃一年又是过去了，这个新年，全球疫情再创新高，圣诞节后美国单日新增更是直接突破 50 万直逼 60 万大关❌ 100 万✅，国内也有西安管理不力导致民众忍饥挨饿。 新冠已经两年多了啊。 言归正传，我今年年初从 W 公司离职后，非常幸运地进了现在的公司——大宇无限，在融入大宇的过程中也是五味杂陈。 不过总体结果还是挺满意的，目前工作已经步入正轨，也发现了非常多的机会，大宇的基础设施领域仍然大有可为。 一些重要事情还是没怎么想通，不过毕竟风口上的猪都能飞，今年小小努力了一把，大部分时间仍然随波逐流，却也渐入佳境。 ","date":"2022-01-03","objectID":"/posts/2021-summary/:1:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"生活 1 月的时候从博客园迁移到这个独立博客，还认识了 @芝士，芝士帮我调整好了博客「友链」页面的样式，超级感谢~ 2 月的时候从 W 公司离职，然后怎么说呢，瞬间感觉海阔天空，心态 180 度转变，好得不得了，但是其实也很担心自己各方面的不足。总之心里有好多的想法，跟 @是格子啊、@芝士 以及前同事聊了好多，非常感谢这几位朋友跟同事帮我梳理思路，给我肯定。也是这个时间点，我被 @芝士 拉进了中文 twitter 的圈子。 过年响应号召没回家（其实是嫌核酸检测麻烦，家里也建议先别回），每天爬爬山看看风景，买了个吊床去公园午睡，练习口琴竹笛，就这样玩了一个月。 到了 3 月份的时候我开始找工作，面了几家公司后，非常幸运地进入了大宇无限，成为了一名 SRE 萌新。在大宇一年的感受，就放在后面的「工作」部分写了，这里先略过。 加入大宇后，全年都有定期的团建，跟 SRE 小伙伴公款吃喝，我 2021 年下馆子次数估计是上一年的七八倍 3 月底，看了电影——《寻龙传说》（2021 年看的唯一一部电影），片尾曲超好听。 4 月份，各种巧合下，意外发现初中同学住得离我 1km 不到，在他家吃了顿家乡菜，还有杨梅酒，味道非常棒！还有回甘强烈的城步青钱柳茶，让我念念不忘。 8 月份，堂弟来深圳暑期实习，跟两个堂弟一起穿越深圳东西冲海岸线，风景非常棒，不过路上也是又热又渴 10 月份 加入了大宇的冲浪小分队，第一次冲浪、海边烧烤 买了双轮滑鞋，学会了倒滑、压步转向，复习了大学时学过的若干基础技巧 12 月，买了台云米泉先净饮机后，有了随时随地的矿物质热水，就想起了 4 月份在初中同学家喝过的青钱柳，然后就喝茶上瘾了，一桌子的滇红、祁门红茶、安吉白茶、黄山毛峰、青钱柳、莓茶、梅子菁…目前感觉滇红跟祁门红茶最好喝，安吉白茶跟黄山毛峰都非常清香，青钱柳回甘最强烈，莓茶怎么说呢味道感觉不太好（也可能是泡的手法不对？） 我的云米净饮机\" 我的云米净饮机 桌面上的各种茶叶\" 桌面上的各种茶叶 2022 年 1 月，第一次买动漫手办，妆点后感觉房间都增色不少~ 我的房间-挂画-手办\" 我的房间-挂画-手办 ","date":"2022-01-03","objectID":"/posts/2021-summary/:2:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"读书 年初辞职后游山玩水，心思稍微安定了些，看了大半本《走出荒野》。 6 月份社区组织打新冠疫苗时，在等候室看了本《青春驿站——深圳打工妹写真》，讲述八九十年代打工妹的生活。很真实，感情很细腻。 年末二爷爷去世，参加完葬礼后，心态有些变化，看完了大一时买下的《月宫 Moon Palace》，讲述主角的悲剧人生。 其余大部分业余时间，无聊，又不想学点东西，也不想运动，于是看了非常多的网络小说打发时间。 ","date":"2022-01-03","objectID":"/posts/2021-summary/:3:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"音乐 年初辞职后，练了一段时间的竹笛跟蓝调口琴，但后来找到工作后就基本沉寂了。 总的来说还是原地踏步吧。 ","date":"2022-01-03","objectID":"/posts/2021-summary/:4:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"工作 - 我在大宇无限的这一年 3 月份刚进大宇的我充满好奇，但也小心谨慎，甚至有点不敢相信自己能进到一家这么棒的公司，感觉自己运气爆棚。 毕竟大宇无论是同事水平还是工作氛围，亦或是用户体量，相比我上家公司都是质的差别。 我在大宇的第一个工位\" 我在大宇的第一个工位 之后慢慢熟悉工作的内容与方法，leader 尽力把最匹配我兴趣的工作安排给我，帮我排疑解难，同时又给我极大的自主性，真的是棒极了。 然而自主性高带来的也是更高的工作难度，遇到困难时也曾手忙脚乱、迷茫、甚至自我怀疑，很担心是不是隔天就得跑路了… 但好在我终究还是能调节好心态，负起责任，一步步把工作完成。 中间有几次工作有延误时，leader 还陪我加班，事情干完后又带我去吃大餐犒劳自己，真的超级感谢他的帮助与支持。 换座位后的新工位，落地窗风景很棒\" 换座位后的新工位，落地窗风景很棒 这样经历了几个项目的洗礼后，现在我终于能说自己是脚踏实地了，心态从「明天是不是得提桶跑路」转变成了「哇还有这个可以搞，那个 ROI 也很高，有好多有趣的事可以做啊」，我终于能说自己真正融入了大宇无限这家公司，成为了它的一员。 回看下了 2020 年的总结与展望，今年实际的进步，跟去年期望的差别很大。最初的目标大概只实现了 10%，但是接触到了许多意料之外的东西，总体还是满意的： 熟悉了新公司的文化与工作方式，这感觉是个很大的收获，我的工作方式有了很大的改善 接触并且熟悉了新公司的 AWS 线上环境 负责维护线上 Kubernetes 管理平台，第一次接触到的线上集群峰值 QPS 就有好几万。从一开始的小心翼翼，到现在也转变成了老手，这算是意义重大吧 使用 python 写了几个 Kubernetes 管理平台的服务，这也是我第一次写线上服务，很有些成就感 下半年在 AWS 成本的分析与管控上花了很多精力，也有了一些不错的成果，受益匪浅 学会了 Nginx 的简单使用，刚好够用于维护公司先有的 Nginx 代理配置 主导完成了「新建 K8s 集群，将服务迁移到新集群」。虽然并不是一件很难的事，但这应该算是我 2021 年最大的成就了。 升级过程中也是遇到了各种问题，第一次升级迁移时我准备了好久，慌的不行，结果升级时部分服务还是出了问题，当时脑子真的是个懵的，跟 leader 搞到半夜 1 点多后还是没解决，回退到了旧集群，升级失败。之后通过各种测试分析，确认到是某个服务扩缩容震荡导致可用率无法恢复，尝试通过 HPA 的 behavior 来控制扩缩容速率，又意外触发了 K8s HPA 的 bug 把集群控制面搞崩了… 再之后把问题都确认了，第二次尝试升级，又是有个别服务可用率抖动，调试了好几天。那几天神经一直紧绷，每天早上都是被服务可用率的告警吵醒的。跨年的那天晚上业务量上涨，我就在观察服务可用率的过程中跨年了。这样才终于完成了 K8s 集群的升级，期间各位同事也有参与帮忙分析排查各种问题，非常感谢他们，还有努力的我自己。 随便写了几个 go 的 demo，基本没啥进步 学了一个星期的 rust 语言，快速看完了 the book，用 rust 重写了个 video2chars 学习了 Linux 容器的底层原理：cgroups/namespace 技术，并且用 go/rust 实现了个 demo 学习了 Linux 的各种网络接口、Iptables 熟悉了 PromQL/Grafana，现在也能拷贝些 PromQL 查各种数据了 如果要给自己打分的话，那就是「良好」吧。因为并没有很强的进取心，所以出来的结果也并不能称之为「优秀」。 顺便公司的新办公区真的超赞，详情见我的 twitter： 新办公区真好呐～ 值此良辰美景，好想整个榻榻米坐垫，坐在角落的落地窗边工作🤣 那种使用公共设施工（mo）作（yu）的乐趣，以及平常工位见不到的景色交相辉映，是不太好表述的奇妙体验 pic.twitter.com/FASffzw8N3 — ryan4yin | 於清樂 (@ryan4yin) January 17, 2022 ","date":"2022-01-03","objectID":"/posts/2021-summary/:5:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"技术方面的感受 Istio 服务网格：体会到了它有点重，而且它的发展跟我们的需求不一定匹配 Sidecar 模式的成本比较高，在未调优的情况下，它会给服务带来 1/3 到 1/4 的成本提升，以及延迟上升 比如切量权重固定为 100（新版本将会放宽限制），不支持 pod 的 warm up（社区已经有 PR，持续观望吧） 而它重点发展的虚拟机支持我们却完全不需要 一直在思考是持续往 Istio 投入，还是换其他的方案 服务网格仍然在快速发展，未来的趋势应该是 eBPF + Envoy + WASM Cilium 推出的基于 eBPF 的 Service Mesh 是一个新趋势（它使用高级特性时会退化成 Per Node Proxy 模式），成本、延迟方面都有望吊打 Sidecar 模式的其他服务网格，是今年服务网格领域的大新闻。 我们曾尝试使用中心化网关来替代 Sidecar 以降低成本。但是跨区流量成本、HTTP/gRPC 多协议共存，这些都是挑战。而且这也并不是社区的最佳实践，现在我觉得维持 Sidecar 其实反而能提升资源利用率，我们的集群资源利用率目前很低。如果能把控好，这部分成本或许是可以接受的。 K8s 集群的日志方面，我们目前是使用自研的基于 gelf 协议的系统，但是问题挺多的 从提升系统的可维护性、易用性等角度来说，loki 是值得探索下的 K8s 集群管理方面，觉得集群的升级迭代，可以做得更自动化、更可靠。明年可以在多集群管理这个方向上多探索下。 Pod 服务质量：对非核心服务，可以适当调低 requests 的资源量，而不是完全预留(Guaranteed)，以提升资源利用率。 官方的 HPA 能力是不够用的，业务侧可能会需要基于 QPS/Queue 或者业务侧的其他参数来进行扩缩容 推广基于 KEDA 的扩缩容能力 关注 Container resource metrics 的进展 成本控制方面，体会到了 ARM 架构以及 Spot 竞价实例的好处 2022-02-17 更新：数据库等中间件可以切换到 ARM。EKS 服务目前都是 Spot 实例，它的 ARM 化 ROI 并不高。 跨区流量成本有很大的潜在优化空间 跨区流量成本是在两边都会收费，而且不仅涉及 Kubernetes 集群内服务间的调用，还会涉及对 RDS/ES/ElastiCache/EC2 等其他资源的调用。 今年各云厂商故障频发，没有跨 region 的服务迁移就会很难受，需要持续关注下 karmada 这类多集群管理方案。 Google 账号系统宕机 Fastly CDN 故障 Facebook 故障 AWS 更是各种可用区故障，12/7 的故障导致 AWS 大部分服务都崩了。因此我们 SRE 今年经常是救各种大火小火… Rust/Go/WASM 蓬勃发展，未来可期。 AI 落地到各个领域，影响到了我们日常使用的语音导航、歌声合成、语音合成等多个领域，当然也包括与 SRE 工作相关的场景：AIOps ","date":"2022-01-03","objectID":"/posts/2021-summary/:6:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"2022 年的展望 ","date":"2022-01-03","objectID":"/posts/2021-summary/:7:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"技术侧 今年的展望写得更聚焦一些，争取能实现 50%，就是很大的突破了。 重点仍然是网络技术与 Kubernetes 技术，Redis/Search/Database 等技术还得靠后排，或许明年吧哈哈。 熟练掌握 Go 语言，并分别用于至少两个项目中 打铁还需自身硬，编码能力是基础中的基础 Kubernetes 相关 以 kubebuilder 为代表的 k8s 开发、拓展技术 阅读 k8s 及相关生态的源码，了解其实现逻辑 网络技术 服务网格 Istio 代理工具 Envoy/APISIX 网络插件 Cilium + eBPF AWS K8s 成本与服务稳定性优化 通过拓扑感知的请求转发，节约跨可用区/跨域的流量成本 K8s 新特性：Topology Aware Hints Istio: Locality Load Balancing 推广 gRPC 协议 通过亲和性与反亲和性，实现合理调度 Pods 减少跨域流量、也提升服务容灾能力 提升本地开发效率： nocalhost 多集群的应用部署、容灾 karmada 探索新技术与可能性（优先级低） 基于 Kubernetes 的服务平台，未来的发展方向 kubevela buildpack 是否应该推进 gitops openkruise Serverless 平台的进展 Knative OpenFunction 机器学习、深度学习技术：想尝试下将 AI 应用在音乐、语音、SRE 等我感兴趣的领域，即使是调包也行啊，总之想出点成果… 可以预料到明年 SRE 团队有超多的机会，这其中我具体能负责哪些部分，又能做出怎样的成果，真的相当期待~ ","date":"2022-01-03","objectID":"/posts/2021-summary/:7:1","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"生活侧 运动： 把轮滑练好，学会点花样吧，每个月至少两次。 进行三次以上的次短途旅行，东西冲穿越可以再来一次。 音乐： 再一次学习乐理… midi 键盘买了一直吃灰，多多练习吧 买了个 Synthesizer V Stduio Pro + 「青溯 AI」，新的一年想学下调教，翻唱些自己喜欢的歌。 阅读：清单如下，一个月至少读完其中一本。 文学类： 《人间失格》：久仰大名的一本书，曾经有同学力荐，但是一直没看。 《生命最后的读书会》：或许曾经看过，但是一点印象都没了 《百年孤独》：高中的时候读过一遍，但是都忘差不多了 《霍乱时期的爱情》 《苏菲的世界》：据说是哲学启蒙读物，曾经看过，但是对内容完全没印象了。 《你一生的故事》：我也曾是个科幻迷 《沈从文的后半生》 《我与地坛》 《将饮茶》 《吾国与吾民 - 林语堂》 《房思琪的初恋乐园》 人文社科 《在生命的尽头拥抱你-临终关怀医生手记》：今年想更多地了解下「死亡」 《怎样征服美丽少女》：哈哈 《爱的艺术》 《社会心理学》 《被讨厌的勇气》 《人体简史》 《科学革命的结构》 《邓小平时代》 《论中国》 《刘擎西方现代思想讲义》 《时间的秩序》 《极简宇宙史》 《圆圈正义-作为自由前提的信念》 《人生脚本》 技术类 《复杂》 《SRE - Google 运维解密》 《凤凰项目：一个 IT 运维的传奇故事》 《人月神话》 《绩效使能：超越 OKR》 《奈飞文化手册》 《幕后产品-打造突破式思维》 《深入 Linux 内核架构》 《Linux/UNIX 系统编程手册》 《重构 - 改善既有代码的设计》 《网络是怎样连接的》：曾经学习过《计算机网络：自顶向下方法》，不过只学到网络层。就从这本书开始重新学习吧。 ","date":"2022-01-03","objectID":"/posts/2021-summary/:7:2","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔","技术"],"content":"结语 2021 年初朋友与我给自己的期许是「拆破玉笼飞彩凤，顿开金锁走蛟龙」，感觉确实应验了。 今年我希望不论是在生活上还是在工作上，都能「更上一层楼」~ 更多有趣的、有深度的 2021 年度总结：https://github.com/saveweb/review-2021 ","date":"2022-01-03","objectID":"/posts/2021-summary/:8:0","tags":["总结"],"title":"2021 年年终总结","uri":"/posts/2021-summary/"},{"categories":["随笔"],"content":"大雪，沙雪。 到晴岚桥等送葬队伍时，非常冷。 转头一望，发现抬棺的几位师傅在渠渡庙门口就地取材生起了火堆取暖，这样寒冷的天气下，很有种惊喜的感觉。 送葬路上又是风又是雪，像是老天也在哀伤。辉辉说这还是他第一次在风雪天里送葬，我也有同感。 到了山上，雨伞上已经结了薄薄一层冰，老爸跟老妈衣服也冻上了冰晶，辉辉更是头发都冻上了。 风雪之中，二爷爷被葬在我家后山。我们就这样送走了二爷爷。 这次的送葬，对我而言也像是一个仪式，我在弥补曾经缺席奶奶、外婆过世的遗憾。 事情都办完后，我到洞口赶高铁，结果不论是高铁还是火车都晚点，就连只隔一个站的 K809 都晚点 99 分钟。 等车的时间，我又看起了《月宫》这本小说。这是大一时买的书，因为看到说主角想把自己逼到极限，这引起了当时苦行僧般的我的共鸣。 但是我始终没有看完它，读不下去。 今天很奇怪的，居然又能读的下去了。 在记起是 Kitty 救了自我放逐中的 Fogg，并且重新获得希望之后，我发觉自己目前的状态可能有些问题。 业余时间沉迷在自我中心的网络小说中，其他时间只关注技术，人就渐渐变得跟人脱节。 高铁上我同样用《月宫》打发时间，在晚点两个半小时后，一点半，到达了深圳北。这时候我刚好看到 Kitty 对 Fogg 说：「已经太晚了，我不能再一次冒险。再见，请你好好对自己。」 心里突然就空落落的，我意识到这是一个彻头彻尾的悲剧，我居然想在悲剧中期许一个美好的转折，真的是有些妄想了。 下了车，站在站台上，眼泪就涌了出来。为书中的悲剧哭泣，也再一次意识到，那些记忆中满脸皱纹的身影，是真的永别了。 从 2015 年 11 月到 2021 年 12 月 27 日的凌晨，二爷爷下葬的翌日，我借着火车站路边昏黄的灯光，看完了保罗·奥斯特的《月宫》。 ","date":"2021-12-27","objectID":"/posts/moon-palace/:0:0","tags":["生死"],"title":"月宫","uri":"/posts/moon-palace/"},{"categories":["音乐","随笔"],"content":" 「此岸弃草，彼岸繁花。」取自前永动机主唱「河津樱/白金」的个人简介 今天想推几首歌 emmmm ","date":"2021-08-28","objectID":"/posts/weeds-on-this-side-flowers-on-the-other/:0:0","tags":["后摇"],"title":"此岸弃草，彼岸繁花","uri":"/posts/weeds-on-this-side-flowers-on-the-other/"},{"categories":["技术"],"content":" 本文仅针对 ipv4 网络 本文先介绍 iptables 的基本概念及常用命令，然后分析 docker/podman 是如何利用 iptables 和 Linux 虚拟网络接口实现的单机容器网络。 ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:0:0","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"一、iptables iptables 提供了包过滤、NAT 以及其他的包处理能力，iptables 应用最多的两个场景是 firewall 和 NAT iptables 及新的 nftables 都是基于 netfilter 开发的，是 netfilter 的子项目。 但是 eBPF 社区目前正在开发旨在取代 netfilter 的新项目 bpfilter，他们的目标之一是兼容 iptables/nftables 规则，让我们拭目以待吧。 ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:1:0","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"1. iptables 基础概念 - 四表五链 实际上还有张 SELinux 相关的 security 表（应该是较新的内核新增的，但是不清楚是哪个版本加的），但是我基本没接触过，就略过了。 这里只对 iptables 做简短介绍，详细的教程参见 iptables详解（1）：iptables概念 - 朱双印，这篇文章写得非常棒！把 iptables 讲清楚了。 默认情况下，iptables 提供了四张表（不考虑 security 的话）和五条链，数据在这四表五链中的处理流程如下图所示： 在这里的介绍中，可以先忽略掉图中 link layer 层的链路，它属于 ebtables 的范畴。另外 conntrack 也暂时忽略，在下一小节会详细介绍 conntrack 的功能。 netfilter 数据包处理流程，来自 wikipedia\" netfilter 数据包处理流程，来自 wikipedia 对照上图，对于发送到某个用户层程序的数据而言，流量顺序如下： 首先进入 PREROUTING 链，依次经过这三个表： raw -\u003e mangle -\u003e nat 然后进入 INPUT 链，这个链上也有三个表，处理顺序是：mangle -\u003e nat -\u003e filter 过了 INPUT 链后，数据才会进入内核协议栈，最终到达用户层程序。 用户层程序发出的报文，则依次经过这几个表：OUTPUT -\u003e POSTROUTING 从图中也很容易看出，如果数据 dst ip 不是本机任一接口的 ip，那它通过的几个链依次是：PREROUTEING -\u003e FORWARD -\u003e POSTROUTING 五链的功能和名称完全一致，应该很容易理解。下面按优先级分别介绍下链中的四个表： raw: 对收到的数据包在连接跟踪前进行处理。一般用不到，可以忽略 一旦用户使用了 raw 表，raw 表处理完后，将跳过 nat 表和 ip_conntrack 处理，即不再做地址转换和数据包的链接跟踪处理了 mangle: 用于修改报文、给报文打标签 nat: 主要用于做网络地址转换，SNAT 或者 DNAT filter: 主要用于过滤数据包 数据在按优先级经过四个表的处理时，一旦在某个表中匹配到一条规则 A,下一条处理规则就由规则 A 的 target 参数指定，后续的所有表都会被忽略。target 有如下几种类型： ACCEPT: 直接允许数据包通过 DROP: 直接丢弃数据包，对程序而言就是 100% 丢包 REJECT: 丢弃数据包，但是会给程序返回 RESET。这个对程序更友好，但是存在安全隐患，通常不使用。 MASQUERADE: （伪装）将 src ip 改写为网卡 ip，和 SNAT 的区别是它会自动读取网卡 ip。路由设备必备。 SNAT/DNAT: 顾名思义，做网络地址转换 REDIRECT: 在本机做端口映射 LOG: 在 /var/log/messages 文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。 只有这个 target 特殊一些，匹配它的数据仍然可以匹配后续规则，不会直接跳过。 其他类型，可以用到的时候再查 理解了上面这张图，以及四个表的用途，就很容易理解 iptables 的命令了。 ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:1:1","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"2. 常用命令 注意: 下面提供的 iptables 命令做的修改是未持久化的，重启就会丢失！在下一节会简单介绍持久化配置的方法。 命令格式： iptables [-t table] {-A|-C|-D} chain [-m matchname [per-match-options]] -j targetname [per-target-options] 其中 table 默认为 filter 表，其中系统管理员实际使用最多的是 INPUT 链，用于设置防火墙。 以下简单介绍在 INPUT 链上添加、修改规则，来设置防火墙： # --add 允许 80 端口通过 iptables -A INPUT -p tcp --dport 80 -j ACCEPT # --list-rules 查看所有规则 iptables -S # --list-rules 查看 INPUT 表中的所有规则 iptables -S INPUT # 查看 iptables 中的所有规则（比 -L 更详细） # ---delete 通过编号删除规则 iptables -D 1 # 或者通过完整的规则参数来删除规则 iptables -D INPUT -p tcp --dport 80 -j ACCEPT # --replace 通过编号来替换规则内容 iptables -R INPUT 1 -s 192.168.0.1 -j DROP # --insert 在指定的位置插入规则，可类比链表的插入 iptables -I INPUT 1 -p tcp --dport 80 -j ACCEPT # 在匹配条件前面使用感叹号表示取反 # 如下规则表示接受所有来自 docker0，但是目标接口不是 docker0 的流量 iptables -A FORWARD -i docker0 ! -o docker0 -j ACCEPT # --policy 设置某个链的默认规则 # 很多系统管理员会习惯将连接公网的服务器，默认规则设为 DROP，提升安全性，避免错误地开放了端口。 # 但是也要注意，默认规则设为 DROP 前，一定要先把允许 ssh 端口的规则加上，否则就尴尬了。 iptables -P INPUT DROP # --flush 清空 INPUT 表上的所有规则 iptables -F INPUT 本文后续分析时，假设用户已经清楚 linux bridge、veth 等虚拟网络接口相关知识。 如果你还缺少这些前置知识，请先阅读文章 Linux 中的虚拟网络接口。 ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:1:2","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"3. conntrack 连接跟踪与 NAT 在讲 conntrack 之间，我们再回顾下前面给出过的 netfilter 数据处理流程图： netfilter 数据包处理流程，来自 wikipedia\" netfilter 数据包处理流程，来自 wikipedia 上一节中我们忽略了图中的 conntrack，它就是本节的主角——netfilter 的连接跟踪（connection tracking）模块。 netfilter/conntrack 是 iptables 实现 SNAT/DNAT/MASQUERADE 的前提条件，上面的流程图显示， conntrack 在 PREROUTEING 和 OUTPUT 链的 raw 表之后生效。 下面以 docker 默认的 bridge 网络为例详细介绍下 conntrack 的功能。 首先，这是我在「Linux 的虚拟网络接口」文中给出过的 docker0 网络架构图: +-----------------------------------------------+-----------------------------------+-----------------------------------+ | Host | Container A | Container B | | | | | | +---------------------------------------+ | +-------------------------+ | +-------------------------+ | | | Network Protocol Stack | | | Network Protocol Stack | | | Network Protocol Stack | | | +----+-------------+--------------------+ | +-----------+-------------+ | +------------+------------+ | | ^ ^ | ^ | ^ | |........|.............|........................|................|..................|.................|.................| | v v ↓ | v | v | | +----+----+ +-----+------+ | +-----+-------+ | +-----+-------+ | | | .31.101 | | 172.17.0.1 | +------+ | | 172.17.0.2 | | | 172.17.0.3 | | | +---------+ +-------------\u003c----\u003e+ veth | | +-------------+ | +-------------+ | | | eth0 | | docker0 | +--+---+ | | eth0(veth) | | | eth0(veth) | | | +----+----+ +-----+------+ ^ | +-----+-------+ | +-----+-------+ | | ^ ^ | | ^ | ^ | | | | +------------------------+ | | | | | v | | | | | | +--+---+ | | | | | | | veth | | | | | | | +--+---+ | | | | | | ^ | | | | | | +------------------------------------------------------------------------------+ | | | | | | | | | | | +-----------------------------------------------+-----------------------------------+-----------------------------------+ v Physical Network (192.168.31.0/24) docker 会在 iptables 中为 docker0 网桥添加如下规则： -t nat -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE -t filter -P DROP -t filter -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT 这几行规则使 docker 容器能正常访问外部网络。MASQUERADE 在请求出网时，会自动做 SNAT，将 src ip 替换成出口网卡的 ip. 这样数据包能正常出网，而且对端返回的数据包现在也能正常回到出口网卡。 现在问题就来了：出口网卡收到返回的数据包后，还能否将数据包转发到数据的初始来源端——某个 docker 容器？难道 docker 还额外添加了与 MASQUERADE 对应的 dst ip 反向转换规则？ 实际上这一步依赖的是本节的主角——iptables 提供的 conntrack 连接跟踪功能（在「参考」中有一篇文章详细介绍了此功能）。 连接跟踪对 NAT 的贡献是：在做 NAT 转换时，无需手动添加额外的规则来执行反向转换以实现数据的双向传输。netfilter/conntrack 系统会记录 NAT 的连接状态，NAT 地址的反向转换是根据这个状态自动完成的。 比如上图中的 Container A 通过 bridge 网络向 baidu.com 发起了 N 个连接，这时数据的处理流程如下： 首先 Container A 发出的数据包被 MASQUERADE 规则处理，将 src ip 替换成 eth0 的 ip，然后发送到物理网络 192.168.31.0/24。 conntrack 系统记录此连接被 NAT 处理前后的状态信息，并将其状态设置为 NEW，表示这是新发起的一个连接 对端 baidu.com 返回数据包后，会首先到达 eth0 网卡 conntrack 查表，发现返回数据包的连接已经记录在表中并且状态为 NEW，于是它将连接的状态修改为 ESTABLISHED，并且将 dst_ip 改为 172.17.0.2 然后发送出去 注意，这个和 tcp 的 ESTABLISHED 没任何关系 经过路由匹配，数据包会进入到 docker0，然后匹配上 iptables 规则：-t filter -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT，数据直接被放行 数据经过 veth 后，最终进入到 Container A 中，交由容器的内核协议栈处理。 数据被 Container A 的内核协议栈发送到「发起连接的应用程序」。 1. 支持哪些协议 conntrack 连接跟踪模块目前只支持以下六种协议：TCP、UDP、ICMP、DCCP、SCTP、GRE 要注意的一点是，conntrack 跟踪的「连接」，跟「TCP 连接」不是一个层面的概念，可以看到 conntrack 也支持 UDP 这种无连接通讯协议。 2. 实际测试 conntrack 现在我们来实际测试一下，看看是不是这么回事： # 使用 tcpdump 分别在出口网卡 wlp4s0 （相当于 eth0）和 dcoker0 网桥上抓包，后面会用来分析 ❯ sudo tcpdump -i wlp4s0 -n \u003e wlp4s0.dump # 窗口一，抓 wlp4s0 的包 ❯ sudo tcpdump -i docker0 -n \u003e docker0.dump # 窗口二，抓 docker0 的包 现在新建窗口三，启动一个容器，通过 curl 命令低速下载一个视频文件： ❯ docker run --rm --name curl -it curlimages/curl \"https://media.w3.org/2010/05/sintel/trailer.mp4\" -o /tmp/video.mp4 --limit-rate 100k 然后新建窗口四，在宿主机查看 conntrack 状态 ❯ sudo zypper in conntrack-tools # 这个记得先提前安装好 ❯ sudo conntrack -L | grep 172.17 # curl 通过 NAT 网络发起了一个 dns 查询请求，DNS 服务器是网关上的 192.168.31.1 udp 17 22 src=172.17.0.4 dst=192.168.31.1 sport=59423 dport=53 src=192.168.31.1 dst=192.168.31.228 sport=53 dport=59423 [ASSURED] mark=0 use=1 # curl 通过 NAT 网络向 media.w3.org 发起了 tcp 连接 tcp 6 298 ESTABLISHED src=172.17.0.4 dst=198.18.5.130 sport=54636 dport=443 src=198.18.5.130","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:1:3","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"4. 如何持久化 iptables 配置 首先需要注意的是，centos7/opensuse 15 都已经切换到了 firewalld 作为防火墙配置软件， 而 ubuntu18.04 lts 也换成了 ufw 来配置防火墙。 包括 docker 应该也是在启动的时候动态添加 iptables 配置。 对于上述新系统，还是建议直接使用 firewalld/ufw 配置防火墙吧，或者网上搜下关闭 ufw/firewalld、启用 iptables 持久化的解决方案。 本文主要目的在于理解 docker 容器网络的原理，以及为后面理解 kubernetes 网络插件 calico/flannel 打好基础，因此就不多介绍持久化了。 ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:1:4","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"二、容器网络实现原理 - iptables + bridge + veth Docker/Podman 默认使用的都是 bridge 网络，它们的底层实现完全类似。下面以 docker 为例进行分析（Podman 的分析流程也基本一样）。 首先，使用 docker run 运行几个容器，检查下网络状况： # 运行一个 debian 容器和一个 nginx ❯ docker run -dit --name debian --rm debian:buster sleep 1000000 ❯ docker run -dit --name nginx --rm nginx:1.19-alpine #　查看网络接口，有两个 veth 接口（而且都没设 ip 地址），分别连接到两个容器的 eth0（dcoker0 网络架构图前面给过了，可以往前面翻翻对照下） ❯ ip addr ls ... 5: docker0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default link/ether 02:42:42:c7:12:ba brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:42ff:fec7:12ba/64 scope link valid_lft forever preferred_lft forever 100: veth16b37ea@if99: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 42:af:34:ae:74:ae brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::40af:34ff:feae:74ae/64 scope link valid_lft forever preferred_lft forever 102: veth4b4dada@if101: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 9e:f1:58:1a:cf:ae brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::9cf1:58ff:fe1a:cfae/64 scope link valid_lft forever preferred_lft forever # 两个 veth 接口都连接到了 docker0 上面，说明两个容器都使用了 docker 默认的 bridge 网络 ❯ sudo brctl show bridge name bridge id STP enabled interfaces docker0 8000.024242c712ba no veth16b37ea veth4b4dada # 查看路由规则 ❯ ip route ls default via 192.168.31.1 dev wlp4s0 proto dhcp metric 600 #下列路由规则将 `172.17.0.0/16` 网段的所有流量转发到 docker0 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 192.168.31.0/24 dev wlp4s0 proto kernel scope link src 192.168.31.228 metric 600 # 查看　iptables 规则 # NAT 表 ❯ sudo iptables -t nat -S -P PREROUTING ACCEPT -P INPUT ACCEPT -P OUTPUT ACCEPT -P POSTROUTING ACCEPT -N DOCKER # 所有目的地址在本机的，都先交给 DOCKER 链处理一波 -A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER # （容器访问外部网络）所有出口不为 docker0 的流量，都做下 SNAT，把 src ip 换成出口接口的 ip 地址 -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE -A DOCKER -i docker0 -j RETURN # filter 表 ❯ sudo iptables -t filter -S -P INPUT ACCEPT -P FORWARD DROP -P OUTPUT ACCEPT -N DOCKER -N DOCKER-ISOLATION-STAGE-1 -N DOCKER-ISOLATION-STAGE-2 -N DOCKER-USER # 所有流量都必须先经过如下两个链的处理，没问题才能继续往下走 -A FORWARD -j DOCKER-ISOLATION-STAGE-1 -A FORWARD -j DOCKER-USER # （容器访问外部网络）出去的流量走了 MASQUERADE，回来的流量会被 conntrack 识别并转发回来，这里允许返回的数据包通过。 # 这里直接 ACCEPT 被 conntrack 识别到的流量 -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT # 将所有访问 docker0 的流量都转给自定义链 DOCKER 处理 -A FORWARD -o docker0 -j DOCKER # 允许所有来自 docker0 的流量通过，不论下一跳是否是 docker0 -A FORWARD -i docker0 ! -o docker0 -j ACCEPT -A FORWARD -i docker0 -o docker0 -j ACCEPT # 下面三个链目前啥规则也没有，就是简单的 RETURN，交给后面的表继续处理 -A DOCKER-ISOLATION-STAGE-1 -j RETURN -A DOCKER-ISOLATION-STAGE-2 -j RETURN -A DOCKER-USER -j RETURN 接下来使用如下 docker-compose 配置启动一个 caddy　容器，添加自定义 network 和端口映射，待会就能验证 docker 是如何实现这两种网络的了。 docker-compose.yml 内容： version:\"3.3\"services:caddy:image:\"caddy:2.2.1-alpine\"container_name:\"caddy\"restart:alwayscommand:caddy file-server --browse --root /data/staticports:- \"8081:80\"volumes:- \"/home/ryan/Downloads:/data/static\"networks:- caddy-1networks:caddy-1: 现在先用上面的配置启动 caddy 容器，然后再查看网络状况： # 启动 caddy ❯ docker-compose up -d # 查下 caddy 容器的 ip \u003e docker inspect caddy | grep IPAddress ... \"IPAddress\": \"172.18.0.2\", # 查看网络接口，可以看到多了一个网桥，它就是上一行命令创建的 caddy-1 网络 # 还多了一个 veth，它连接到了 caddy 容器的 eth0(veth) 接口 ❯ ip addr ls ... 5: docker0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default link/ether 02:42:42:c7:12:ba brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:42ff:fec7:12ba/64 scope link valid_lft forever preferred_lft forever 100: veth16b37ea@if99: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue master docker0 state UP group default li","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:2:0","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"三、Docker/Podman 的 macvlan/ipvlan 模式 注意：macvlan 和 wifi 好像不兼容，测试时不要使用无线网络的接口！ 我在前面介绍 Linux 虚拟网络接口的文章中，有介绍过 macvlan 和 ipvlan 两种新的虚拟接口。 目前 Podman/Docker 都支持使用 macvlan 来构建容器网络，这种模式下创建的容器直连外部网络，容器可以拥有独立的外部 IP，不需要端口映射，也不需要借助 iptables. 这和虚拟机的 Bridge 模式就很类似，主要适用于希望容器拥有独立外部 IP 的情况。 下面详细分析下 Docker 的 macvlan 网络（Podman 应该也完全类似）。 # 首先创建一个 macvlan 网络 # subnet/gateway 的参数需要和物理网络一致 # 通过 -o parent 设定父接口，我本机的以太网口名称为 eno1 $ docker network create -d macvlan \\ --subnet=192.168.31.0/24 \\ --gateway=192.168.31.1 \\ -o parent=eno1 \\ macnet0 # 现在使用 macvlan 启动一个容器试试 # 建议和我一样，通过 --ip 手动配置静态 ip 地址，当然不配也可以，DHCP 会自动分配 IP $ docker run --network macnet0 --ip=192.168.31.233 --rm -it buildpack-deps:buster-curl /bin/bash # 在容器中查看网络接口状况，能看到 eth0 是一个 macvlan 接口 root@4319488cb5e7:/# ip -d addr ls 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0 minmtu 0 maxmtu 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 8: eth0@if2: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default link/ether 02:42:c0:a8:1f:e9 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 9194 macvlan mode bridge numtxqueues 1 numrxqueues 1 gso_max_size 64000 gso_max_segs 64 inet 192.168.31.233/24 brd 192.168.31.255 scope global eth0 valid_lft forever preferred_lft forever # 路由表，默认 gateway 被自动配置进来了 root@4319488cb5e7:/# ip route ls default via 192.168.31.1 dev eth0 192.168.31.0/24 dev eth0 proto kernel scope link src 192.168.31.233 # 可以正常访问 baidu root@4319488cb5e7:/# curl baidu.com \u003chtml\u003e \u003cmeta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\"\u003e \u003c/html\u003e Docker 支持的另一种网络模式是 ipvlan（ipvlan 和 macvlan 的区别我在前一篇文章中已经介绍过，不再赘言），创建命令和 macvlan 几乎一样： # 首先创建一个 macvlan 网络 # subnet/gateway 的参数需要和物理网络一致 # 通过 -o parent 设定父接口，我本机的以太网口名称为 eno1 # ipvlan_mode 默认为 l2，表示工作在数据链路层。 $ docker network create -d ipvlan \\ --subnet=192.168.31.0/24 \\ --gateway=192.168.31.1 \\ -o parent=eno1 \\ -o ipvlan_mode=l2 \\ ipvnet0 # 现在使用 macvlan 启动一个容器试试 # 建议和我一样，通过 --ip 手动配置静态 ip 地址，当然不配也可以，DHCP 会自动分配 IP $ docker run --network ipvnet0 --ip=192.168.31.234 --rm -it buildpack-deps:buster-curl /bin/bash # 在容器中查看网络接口状况，能看到 eth0 是一个 ipvlan 接口 root@d0764ebbbf42:/# ip -d addr ls 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0 minmtu 0 maxmtu 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 12: eth0@if2: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UNKNOWN group default link/ether 38:f3:ab:a3:e6:71 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 65535 ipvlan mode l2 bridge numtxqueues 1 numrxqueues 1 gso_max_size 64000 gso_max_segs 64 inet 192.168.31.234/24 brd 192.168.31.255 scope global eth0 valid_lft forever preferred_lft forever # 路由表，默认 gateway 被自动配置进来了 root@d0764ebbbf42:/# ip route ls default via 192.168.31.1 dev eth0 192.168.31.0/24 dev eth0 proto kernel scope link src 192.168.31.234 # 可以正常访问 baidu root@d0764ebbbf42:/# curl baidu.com \u003chtml\u003e \u003cmeta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\"\u003e \u003c/html\u003e ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:3:0","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"四、Rootless 容器的网络实现 如果容器运行时也在 Rootless 模式下运行，那它就没有权限在宿主机添加 bridge/veth 等虚拟网络接口，这种情况下，我们前面描述的容器网络就无法设置了。 那么 podman/containerd(nerdctl) 目前是如何在 Rootless 模式下构建容器网络的呢？ 查看文档，发现它们都用到了 rootlesskit 相关的东西，而 rootlesskit 提供了 rootless 网络的几个实现，文档参见 rootlesskit/docs/network.md 其中目前推荐使用，而且 podman/containerd(nerdctl) 都默认使用的方案，是 rootless-containers/slirp4netns 以 containerd(nerdctl) 为例，按官方文档安装好后，随便启动几个容器，然后在宿主机查 iptables/ip addr ls，会发现啥也没有。 这显然是因为 rootless 模式下 containerd 改不了宿主机的 iptables 配置和虚拟网络接口。但是可以查看到宿主机 slirp4netns 在后台运行： ❯ ps aux | grep tap ryan 11644 0.0 0.0 5288 3312 ? S 00:01 0:02 slirp4netns --mtu 65520 -r 3 --disable-host-loopback --enable-sandbox --enable-seccomp 11625 tap0 但是我看半天文档，只看到怎么使用 rootlesskit/slirp4netns 创建新的名字空间，没看到有介绍如何进入一个已存在的 slirp4netns 名字空间… 使用 nsenter -a -t 11644 也一直报错，任何程序都是 no such binary… 以后有空再重新研究一波… 总之能确定的是，它通过在虚拟的名字空间中创建了一个 tap 虚拟接口来实现容器网络，性能相比前面介绍的网络多少是要差一点的。 ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:4:0","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"五、nftables 前面介绍了 iptables 以及其在 docker 和防火墙上的应用。但是实际上目前各大 Linux 发行版都已经不建议使用 iptables 了，甚至把 iptables 重命名为了 iptables-leagacy. 目前 opensuse/debian/opensuse 都已经预装了并且推荐使用 nftables，而且 firewalld 已经默认使用 nftables 作为它的后端了。 我在 opensuse tumbleweed 上实测，firewalld 添加的是 nftables 配置，而 docker 仍然在用旧的 iptables，也就是说我现在的机器上有两套 netfilter 工具并存： # 查看 iptables 数据 \u003e iptables -S -P INPUT ACCEPT -P FORWARD DROP -P OUTPUT ACCEPT -N DOCKER -N DOCKER-ISOLATION-STAGE-1 -N DOCKER-ISOLATION-STAGE-2 -N DOCKER-USER -A FORWARD -j DOCKER-ISOLATION-STAGE-1 -A FORWARD -o br-e3fbbb7a1b3a -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT -A FORWARD -o br-e3fbbb7a1b3a -j DOCKER ... # 确认下是否使用了 nftables 的兼容层，结果提示请我使用 iptables-legacy \u003e iptables-nft -S # Warning: iptables-legacy tables present, use iptables-legacy to see them -P INPUT ACCEPT -P FORWARD ACCEPT -P OUTPUT ACCEPT # 查看 nftables 规则，能看到三张 firewalld 生成的 table \u003e nft list ruleset table inet firewalld { ... } table ip firewalld { ... } table ip6 firewalld { ... } 但是现在 kubernetes/docker 都还是用的 iptables，nftables 我学了用处不大，以后有空再补充。 ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:5:0","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":"参考 iptables详解（1）：iptables概念 连接跟踪（conntrack）：原理、应用及 Linux 内核实现 网络地址转换（NAT）之报文跟踪 容器安全拾遗 - Rootless Container初探 netfilter - wikipedia ","date":"2021-08-15","objectID":"/posts/iptables-and-container-networks/:6:0","tags":["Linux","网络","虚拟化","容器","iptables","conntrack"],"title":"iptables 及 docker 容器网络分析","uri":"/posts/iptables-and-container-networks/"},{"categories":["技术"],"content":" 本文用到的字符画工具：vscode-asciiflow2 注意: 本文中使用 ip 命令创建或修改的任何网络配置，都是未持久化的，主机重启即消失。 Linux 具有强大的虚拟网络能力，这也是 openstack 网络、docker 容器网络以及 kubernetes 网络等虚拟网络的基础。 这里介绍 Linux 常用的虚拟网络接口类型：TUN/TAP、bridge、veth、ipvlan/macvlan、vlan 以及 vxlan/geneve. ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:0:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"一、tun/tap 虚拟网络接口 tun/tap 是操作系统内核中的虚拟网络设备，他们为用户层程序提供数据的接收与传输。 普通的物理网络接口如 eth0，它的两端分别是内核协议栈和外面的物理网络。 而对于 TUN/TAP 虚拟接口如 tun0，它的一端一定是连接的用户层程序，另一端则视配置方式的不同而变化，可以直连内核协议栈，也可以是某个 bridge（后面会介绍）。 Linux 通过内核模块 TUN 提供 tun/tap 功能，该模块提供了一个设备接口 /dev/net/tun 供用户层程序读写，用户层程序通过 /dev/net/tun 读写主机内核协议栈的数据。 \u003e modinfo tun filename: /lib/modules/5.13.6-1-default/kernel/drivers/net/tun.ko.xz alias: devname:net/tun alias: char-major-10-200 license: GPL author: (C) 1999-2004 Max Krasnyansky \u003cmaxk@qualcomm.com\u003e description: Universal TUN/TAP device driver ... \u003e ls /dev/net/tun /dev/net/tun 一个 TUN 设备的示例图如下： +----------------------------------------------------------------------+ | | | +--------------------+ +--------------------+ | | | User Application A | | User Application B +\u003c-----+ | | +------------+-------+ +-------+------------+ | | | | 1 | 5 | | |...............+......................+...................|...........| | ↓ ↓ | | | +----------+ +----------+ | | | | socket A | | socket B | | | | +-------+--+ +--+-------+ | | | | 2 | 6 | | |.................+.................+......................|...........| | ↓ ↓ | | | +------------------------+ +--------+-------+ | | | Network Protocol Stack | | /dev/net/tun | | | +--+-------------------+-+ +--------+-------+ | | | 7 | 3 ^ | |................+...................+.....................|...........| | ↓ ↓ | | | +----------------+ +----------------+ 4 | | | | eth0 | | tun0 | | | | +-------+--------+ +-----+----------+ | | | 10.32.0.11 | | 192.168.3.11 | | | | 8 +---------------------+ | | | | +----------------+-----------------------------------------------------+ ↓ Physical Network 因为 TUN/TAP 设备的一端是内核协议栈，显然流入 tun0 的数据包是先经过本地的路由规则匹配的。 路由匹配成功，数据包被发送到 tun0 后，tun0 发现另一端是通过 /dev/net/tun 连接到应用程序 B，就会将数据丢给应用程序 B。 应用程序对数据包进行处理后，可能会构造新的数据包，通过物理网卡发送出去。比如常见的 VPN 程序就是把原来的数据包封装/加密一遍，再发送给 VPN 服务器。 ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:1:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"C 语言编程测试 TUN 设备 为了使用 tun/tap 设备，用户层程序需要通过系统调用打开 /dev/net/tun 获得一个读写该设备的文件描述符(FD)，并且调用 ioctl() 向内核注册一个 TUN 或 TAP 类型的虚拟网卡(实例化一个 tun/tap 设备)，其名称可能是 tun0/tap0 等。 此后，用户程序可以通过该 TUN/TAP 虚拟网卡与主机内核协议栈（或者其他网络设备）交互。当用户层程序关闭后，其注册的 TUN/TAP 虚拟网卡以及自动生成的路由表相关条目都会被内核释放。 可以把用户层程序看做是网络上另一台主机，他们通过 tun/tap 虚拟网卡相连。 一个简单的 C 程序示例如下，它每次收到数据后，都只单纯地打印一下收到的字节数： #include \u003clinux/if.h\u003e#include \u003clinux/if_tun.h\u003e #include \u003csys/ioctl.h\u003e #include \u003cfcntl.h\u003e#include \u003cstring.h\u003e #include \u003cunistd.h\u003e#include\u003cstdlib.h\u003e#include\u003cstdio.h\u003e int tun_alloc(int flags) { struct ifreq ifr; int fd, err; char *clonedev = \"/dev/net/tun\"; // 打开 tun 文件，获得 fd if ((fd = open(clonedev, O_RDWR)) \u003c 0) { return fd; } memset(\u0026ifr, 0, sizeof(ifr)); ifr.ifr_flags = flags; // 向内核注册一个 TUN 网卡，并与前面拿到的 fd 关联起来 // 程序关闭时，注册的 tun 网卡及自动生成的相关路由策略，会被自动释放 if ((err = ioctl(fd, TUNSETIFF, (void *) \u0026ifr)) \u003c 0) { close(fd); return err; } printf(\"Open tun/tap device: %s for reading...\\n\", ifr.ifr_name); return fd; } int main() { int tun_fd, nread; char buffer[1500]; /* Flags: IFF_TUN - TUN device (no Ethernet headers) * IFF_TAP - TAP device * IFF_NO_PI - Do not provide packet information */ tun_fd = tun_alloc(IFF_TUN | IFF_NO_PI); if (tun_fd \u003c 0) { perror(\"Allocating interface\"); exit(1); } while (1) { nread = read(tun_fd, buffer, sizeof(buffer)); if (nread \u003c 0) { perror(\"Reading from interface\"); close(tun_fd); exit(1); } printf(\"Read %d bytes from tun/tap device\\n\", nread); } return 0; } 接下来开启三个终端窗口来测试上述程序，分别运行上面的 tun 程序、tcpdump 和 iproute2 指令。 首先通过编译运行上述 c 程序，程序会阻塞住，等待数据到达： # 编译，请忽略部分 warning \u003e gcc mytun.c -o mytun # 创建并监听 tun 设备需要 root 权限 \u003e sudo mytun Open tun/tap device: tun0 for reading... 现在使用 iproute2 查看下链路层设备： # 能发现最后面有列出名为 tun0 的接口，但是状态为 down ❯ ip addr ls ...... 3: wlp4s0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether c0:3c:59:36:a4:16 brd ff:ff:ff:ff:ff:ff inet 192.168.31.228/24 brd 192.168.31.255 scope global dynamic noprefixroute wlp4s0 valid_lft 41010sec preferred_lft 41010sec inet6 fe80::4ab0:130f:423b:5d37/64 scope link noprefixroute valid_lft forever preferred_lft forever 7: tun0: \u003cPOINTOPOINT,MULTICAST,NOARP\u003e mtu 1500 qdisc noop state DOWN group default qlen 500 link/none # 为 tun0 设置 ip 地址，注意不要和其他接口在同一网段，会导致路由冲突 \u003e sudo ip addr add 172.21.22.23/24 dev tun0 # 启动 tun0 这个接口，这一步会自动向路由表中添加将 172.21.22.23/24 路由到 tun0 的策略 \u003e sudo ip link set tun0 up #确认上一步添加的路由策略是否存在 ❯ ip route ls default via 192.168.31.1 dev wlp4s0 proto dhcp metric 600 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 172.21.22.0/24 dev tun0 proto kernel scope link src 172.21.22.23 192.168.31.0/24 dev wlp4s0 proto kernel scope link src 192.168.31.228 metric 600 # 此时再查看接口，发现 tun0 状态为 unknown \u003e ip addr ls ...... 8: tun0: \u003cPOINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500 link/none inet 172.21.22.23/24 scope global tun0 valid_lft forever preferred_lft forever inet6 fe80::3d52:49b5:1cf3:38fd/64 scope link stable-privacy valid_lft forever preferred_lft forever # 使用 tcpdump 尝试抓下 tun0 的数据，会阻塞在这里，等待数据到达 \u003e tcpdump -i tun0 现在再启动第三个窗口发点数据给 tun0，持续观察前面 tcpdump 和 mytun 的日志: # 直接 ping tun0 的地址，貌似有问题，数据没进 mytun 程序，而且还有响应 ❯ ping -c 4 172.21.22.23 PING 172.21.22.23 (172.21.22.23) 56(84) bytes of data. 64 bytes from 172.21.22.23: icmp_seq=1 ttl=64 time=0.167 ms 64 bytes from 172.21.22.23: icmp_seq=2 ttl=64 time=0.180 ms 64 bytes from 172.21.22.23: icmp_seq=3 ttl=64 time=0.126 ms 64 bytes from 172.21.22.23: icmp_seq=4 ttl=64 time=0.141 ms --- 172.21.22.23 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3060ms rtt min/avg/max/mdev = 0.126/0.153/0.180/0.021 ms # 但是 ping 该网段下的其他地址，流量就会被转发给 mytun 程序，因为 mytun 啥数据也没回，自然丢包率 100% # tcpdump 和 mytun 都会打印出相关日志 ❯ ping -c 4 172.21.22.26 PING 172.21.22.26 (172.21.22.26) 56(84) bytes of data. --- 172.21.22.26 ping statistics --- 4 packets transmitted, 0 received, 100% packet loss, time 3055ms 下面给出 mytun 的输出： Read 84 bytes from tun/tap device Read 84 bytes fro","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:1:1","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"TUN 与 TAP 的区别 TUN 和 TAP 的区别在于工作的网络层次不同，用户程序通过 TUN 设备只能读写网络层的 IP 数据包，而 TAP 设备则支持读写链路层的数据包（通常是以太网数据包，带有 Ethernet headers）。 TUN 与 TAP 的关系，就类似于 socket 和 raw socket. TUN/TAP 应用最多的场景是 VPN 代理，比如: clash: 一个支持各种规则的隧道，也支持 TUN 模式 tun2socks: 一个全局透明代理，和 VPN 的工作模式一样，它通过创建虚拟网卡+修改路由表，在第三层网络层代理系统流量。 ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:1:2","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"二、veth veth 接口总是成对出现，一对 veth 接口就类似一根网线，从一端进来的数据会从另一端出去。 同时 veth 又是一个虚拟网络接口，因此它和 TUN/TAP 或者其他物理网络接口一样，也都能配置 mac/ip 地址（但是并不是一定得配 mac/ip 地址）。 其主要作用就是连接不同的网络，比如在容器网络中，用于将容器的 namespace 与 root namespace 的网桥 br0 相连。 容器网络中，容器侧的 veth 自身设置了 ip/mac 地址并被重命名为 eth0，作为容器的网络接口使用，而主机侧的 veth 则直接连接在 docker0/br0 上面。 使用 veth 实现容器网络，需要结合下一小节介绍的 bridge，在下一小节将给出容器网络结构图。 ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:2:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"三、bridge Linux Bridge 是工作在链路层的网络交换机，由 Linux 内核模块 brige 提供，它负责在所有连接到它的接口之间转发链路层数据包。 添加到 Bridge 上的设备被设置为只接受二层数据帧并且转发所有收到的数据包到 Bridge 中。 在 Bridge 中会进行一个类似物理交换机的查MAC端口映射表、转发、更新MAC端口映射表这样的处理逻辑，从而数据包可以被转发到另一个接口/丢弃/广播/发往上层协议栈，由此 Bridge 实现了数据转发的功能。 如果使用 tcpdump 在 Bridge 接口上抓包，可以抓到网桥上所有接口进出的包，因为这些数据包都要通过网桥进行转发。 与物理交换机不同的是，Bridge 本身可以设置 IP 地址，可以认为当使用 brctl addbr br0 新建一个 br0 网桥时，系统自动创建了一个同名的隐藏 br0 网络接口。br0 一旦设置 IP 地址，就意味着这个隐藏的 br0 接口可以作为路由接口设备，参与 IP 层的路由选择(可以使用 route -n 查看最后一列 Iface)。因此只有当 br0 设置 IP 地址时，Bridge 才有可能将数据包发往上层协议栈。 但被添加到 Bridge 上的网卡是不能配置 IP 地址的，他们工作在数据链路层，对路由系统不可见。 它常被用于在虚拟机、主机上不同的 namepsaces 之间转发数据。 ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:3:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"虚拟机场景（桥接模式） 以 qemu-kvm 为例，在虚拟机的桥接模式下，qemu-kvm 会为每个虚拟机创建一个 tun/tap 虚拟网卡并连接到 br0 网桥。 虚拟机内部的网络接口 eth0 是 qemu-kvm 软件模拟的，实际上虚拟机内网络数据的收发都会被 qemu-kvm 转换成对 /dev/net/tun 的读写。 以发送数据为例，整个流程如下： 虚拟机发出去的数据包先到达 qemu-kvm 程序 数据被用户层程序 qemu-kvm 写入到 /dev/net/tun，到达 tap 设备 tap 设备把数据传送到 br0 网桥 br0 把数据交给 eth0 发送出去 整个流程跑完，数据包都不需要经过宿主机的协议栈，效率高。 +------------------------------------------------+-----------------------------------+-----------------------------------+ | Host | VirtualMachine1 | VirtualMachine2 | | | | | | +--------------------------------------+ | +-------------------------+ | +-------------------------+ | | | Network Protocol Stack | | | Network Protocol Stack | | | Network Protocol Stack | | | +--------------------------------------+ | +-------------------------+ | +-------------------------+ | | ↑ | ↑ | ↑ | |.......................|........................|................|..................|.................|.................| | ↓ | ↓ | ↓ | | +--------+ | +-------+ | +-------+ | | | .3.101 | | | .3.102| | | .3.103| | | +------+ +--------+ +-------+ | +-------+ | +-------+ | | | eth0 |\u003c---\u003e| br0 |\u003c---\u003e|tun/tap| | | eth0 | | | eth0 | | | +------+ +--------+ +-------+ | +-------+ | +-------+ | | ↑ ↑ ↑ +--------+ ↑ | ↑ | | | | +------|qemu-kvm|-----------+ | | | | | ↓ +--------+ | | | | | +-------+ | | | | | | |tun/tap| | | | | | | +-------+ | | | | | | ↑ | +--------+ | | | | | +-------------------------------------|qemu-kvm|-------------|-----------------+ | | | | +--------+ | | | | | | | +---------|--------------------------------------+-----------------------------------+-----------------------------------+ ↓ Physical Network (192.168.3.0/24) ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:3:1","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"跨 namespace 通信场景（容器网络，NAT 模式） docker/podman 提供的 bridge 网络模式，就是使用 veth+bridge+iptalbes 实现的。我会在下一篇文章详细介绍「容器网络」。 由于容器运行在自己单独的 network namespace 里面，所以和虚拟机一样，它们也都有自己单独的协议栈。 容器网络的结构和虚拟机差不多，但是它改用了 NAT 网络，并把 tun/tap 换成了 veth，导致 docker0 过来的数据，要先经过宿主机协议栈，然后才进入 veth 接口。 多了一层 NAT，以及多走了一层宿主机协议栈，都会导致性能下降。 示意图如下： +-----------------------------------------------+-----------------------------------+-----------------------------------+ | Host | Container 1 | Container 2 | | | | | | +---------------------------------------+ | +-------------------------+ | +-------------------------+ | | | Network Protocol Stack | | | Network Protocol Stack | | | Network Protocol Stack | | | +----+-------------+--------------------+ | +-----------+-------------+ | +------------+------------+ | | ^ ^ | ^ | ^ | |........|.............|........................|................|..................|.................|.................| | v v ↓ | v | v | | +----+----+ +-----+------+ | +-----+-------+ | +-----+-------+ | | | .31.101 | | 172.17.0.1 | +------+ | | 172.17.0.2 | | | 172.17.0.3 | | | +---------+ +-------------\u003c----\u003e+ veth | | +-------------+ | +-------------+ | | | eth0 | | docker0 | +--+---+ | | eth0(veth) | | | eth0(veth) | | | +----+----+ +-----+------+ ^ | +-----+-------+ | +-----+-------+ | | ^ ^ | | ^ | ^ | | | | +------------------------+ | | | | | v | | | | | | +--+---+ | | | | | | | veth | | | | | | | +--+---+ | | | | | | ^ | | | | | | +------------------------------------------------------------------------------+ | | | | | | | | | | | +-----------------------------------------------+-----------------------------------+-----------------------------------+ v Physical Network (192.168.31.0/24) 每创建一个新容器，都会在容器的 namespace 里新建一个 veth 接口并命令为 eth0，同时在主 namespace 创建一个 veth，将容器的 eth0 与 docker0 连接。 可以在容器中通过 iproute2 查看到， eth0 的接口类型为 veth： ❯ docker run -it --rm debian:buster bash root@5facbe4ddc1e:/# ip --details addr ls 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0 minmtu 0 maxmtu 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 20: eth0@if21: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 65535 veth numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 同时在宿主机中能看到对应的 veth 设备是绑定到了 docker0 网桥的： ❯ sudo brctl show bridge name bridge id STP enabled interfaces docker0 8000.0242fce99ef5 no vethea4171a ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:3:2","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"四、macvlan 目前 docker/podman 都支持创建基于 macvlan 的 Linux 容器网络。 注意 macvlan 和 WiFi 存在兼容问题，如果使用笔记本测试，可能会遇到麻烦。 参考文档：linux 网络虚拟化： macvlan macvlan 是比较新的 Linux 特性，需要内核版本 \u003e= 3.9，它被用于在主机的网络接口（父接口）上配置多个虚拟子接口，这些子接口都拥有各自独立的 mac 地址，也可以配上 ip 地址进行通讯。 macvlan 下的虚拟机或者容器网络和主机在同一个网段中，共享同一个广播域。macvlan 和 bridge 比较相似，但因为它省去了 bridge 的存在，所以配置和调试起来比较简单，而且效率也相对高。除此之外，macvlan 自身也完美支持 VLAN。 如果希望容器或者虚拟机放在主机相同的网络中，享受已经存在网络栈的各种优势，可以考虑 macvlan。 我会在下一篇文章对 docker 的 macvlan/ipvlan 做个分析，这里先略过了… ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:4:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"五、ipvlan linux 网络虚拟化： ipvlan cilium 1.9 已经提供了基于 ipvlan 的网络（beta 特性），用于替换传统的 veth+bridge 容器网络。详见 IPVLAN based Networking (beta) - Cilium 1.9 Docs ipvlan 和 macvlan 的功能很类似，也是用于在主机的网络接口（父接口）上配置出多个虚拟的子接口。但不同的是，ipvlan 的各子接口没有独立的 mac 地址，它们和主机的父接口共享 mac 地址。 因为 mac 地址共享，所以如果使用 DHCP，就要注意不能使用 mac 地址做 DHCP，需要额外配置唯一的 clientID. 如果你遇到以下的情况，请考虑使用 ipvlan： 父接口对 mac 地址数目有限制，或者在 mac 地址过多的情况下会造成严重的性能损失 工作在 802.11(wireless)无线网络中（macvlan 无法和无线网络共同工作） 希望搭建比较复杂的网络拓扑（不是简单的二层网络和 VLAN），比如要和 BGP 网络一起工作 基于 ipvlan/macvlan 的容器网络，比 veth+bridge+iptables 的性能要更高。 我会在下一篇文章对 docker 的 macvlan/ipvlan 做个分析，这里先略过了… ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:5:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"六、vlan vlan 即虚拟局域网，是一个链路层的广播域隔离技术，可以用于切分局域网，解决广播泛滥和安全性问题。被隔离的广播域之间需要上升到第三层才能完成通讯。 常用的企业路由器如 ER-X 基本都可以设置 vlan，Linux 也直接支持了 vlan. 以太网数据包有一个专门的字段提供给 vlan 使用，vlan 数据包会在该位置记录它的 VLAN ID，交换机通过该 ID 来区分不同的 VLAN，只将该以太网报文广播到该 ID 对应的 VLAN 中。 ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:6:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"七、vxlan/geneve rfc8926 - Geneve: Generic Network Virtualization Encapsulation rfc7348 - Virtual eXtensible Local Area Network (VXLAN) linux 上实现 vxlan 网络 在介绍 vxlan 前，先说明下两个名词的含义： underlay 网络：即物理网络 overlay 网络：指在现有的物理网络之上构建的虚拟网络。其实就是一种隧道技术，将原生态的二层数据帧报文进行封装后通过隧道进行传输。 vxlan 与 geneve 都是 overlay 网络协议，它俩都是使用 UDP 包来封装链路层的以太网帧。 vxlan 在 2014 年标准化，而 geneve 在 2020 年底才通过草案阶段，目前尚未形成最终标准。但是目前 linux/cilium 都已经支持了 geneve. geneve 相对 vxlan 最大的变化，是它更灵活——它的 header 长度是可变的。 目前所有 overlay 的跨主机容器网络方案，几乎都是基于 vxlan 实现的（例外：cilium 也支持 geneve）。 我们在学习单机的容器网络时，不需要接触到 vxlan，但是在学习跨主机容器网络方案如 flannel/calico/cilium 时，那 vxlan(overlay) 及 BGP(underlay) 就不可避免地要接触了。 先介绍下 vxlan 的数据包结构： VXLAN 栈帧结构\" VXLAN 栈帧结构 在创建 vxlan 的 vtep 虚拟设备时，我们需要手动设置图中的如下属性： VXLAN 目标端口：即接收方 vtep 使用的端口，这里 IANA 定义的端口是 4789，但是只有 calico 的 vxlan 模式默认使用该端口 calico，而 cilium/flannel 的默认端口都是 Linux 默认的 8472. VNID: 每个 VXLAN 网络接口都会被分配一个独立的 VNID 一个点对点的 vxlan 网络架构图如下: VXLAN 点对点网络架构\" VXLAN 点对点网络架构 可以看到每台虚拟机 VM 都会被分配一个唯一的 VNID，然后两台物理机之间通过 VTEP 虚拟网络设备建立了 VXLAN 隧道，所有 VXLAN 网络中的虚拟机，都通过 VTEP 来互相通信。 有了上面这些知识，我们就可以通过如下命令在两台 Linux 机器间建立一个点对点的 VXLAN 隧道： # 在主机 A 上创建 VTEP 设备 vxlan0 # 与另一个 vtep 接口 B（192.168.8.101）建立隧道 # 将 vxlan0 自身的 IP 地址设为 192.168.8.100 # 使用的 VXLAN 目标端口为 4789(IANA 标准) ip link add vxlan0 type vxlan \\ id 42 \\ dstport 4789 \\ remote 192.168.8.101 \\ local 192.168.8.100 \\ dev enp0s8 # 为我们的 VXLAN 网络设置虚拟网段，vxlan0 就是默认网关 ip addr add 10.20.1.2/24 dev vxlan0 # 启用我们的 vxlan0 设备，这会自动生成路由规则 ip link set vxlan0 up # 现在在主机 B 上运行如下命令，同样创建一个 VTEP 设备 vxlan0，remote 和 local 的 ip 与前面用的命令刚好相反。 # 注意 VNID 和 dstport 必须和前面完全一致 ip link add vxlan0 type vxlan \\ id 42 \\ dstport 4789 \\ remote 192.168.8.100 \\ local 192.168.8.101 \\ dev enp0s8 # 为我们的 VXLAN 网络设置虚拟网段，vxlan0 就是默认网关 ip addr add 10.20.1.3/24 dev vxlan0 ip link set vxlan0 up # 到这里，两台机器就完成连接，可以通信了。可以在主机 B 上 ping 10.20.1.2 试试，应该能收到主机 A 的回应。 ping 10.20.1.2 点对点的 vxlan 隧道实际用处不大，如果集群中的每个节点都互相建 vxlan 隧道，代价太高了。 一种更好的方式，是使用 「组播模式」的 vxlan 隧道，这种模式下一个 vtep 可以一次与组内的所有 vtep 建立隧道。 示例命令如下（这里略过了如何设置组播地址 239.1.1.1 的信息）： ip link add vxlan0 type vxlan \\ id 42 \\ dstport 4789 \\ group 239.1.1.1 \\ dev enp0s8 ip addr add 10.20.1.2/24 dev vxlan0 ip link set vxlan0 up 可以看到，只需要简单地把 local_ip/remote_ip 替换成一个组播地址就行。组播功能会将收到的数据包发送给组里的所有 vtep 接口，但是只有 VNID 能对上的 vtep 会处理该报文，其他 vtep 会直接丢弃数据。 接下来，为了能让所有的虚拟机/容器，都通过 vtep 通信，我们再添加一个 bridge 网络，充当 vtep 与容器间的交换机。架构如下： VXLAN 多播网络架构\" VXLAN 多播网络架构 使用 ip 命令创建网桥、网络名字空间、veth pairs 组成上图中的容器网络： # 创建 br0 并将 vxlan0 绑定上去 ip link add br0 type bridge ip link set vxlan0 master bridge ip link set vxlan0 up ip link set br0 up # 模拟将容器加入到网桥中的操作 ip netns add container1 ## 创建 veth pair，并把一端加到网桥上 ip link add veth0 type veth peer name veth1 ip link set dev veth0 master br0 ip link set dev veth0 up ## 配置容器内部的网络和 IP ip link set dev veth1 netns container1 ip netns exec container1 ip link set lo up ip netns exec container1 ip link set veth1 name eth0 ip netns exec container1 ip addr add 10.20.1.11/24 dev eth0 ip netns exec container1 ip link set eth0 up 然后在另一台机器上做同样的操作，并创建新容器，两个容器就能通过 vxlan 通信啦~ ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:7:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"比组播更高效的 vxlan 实现 组播最大的问题在于，因为它不知道数据的目的地，所以每个 vtep 都发了一份。如果每次发数据时，如果能够精确到对应的 vtep，就能节约大量资源。 另一个问题是 ARP 查询也会被组播，要知道 vxlan 本身就是个 overlay 网络，ARP 的成本也很高。 上述问题都可以通过一个中心化的注册中心（如 etcd）来解决，所有容器、网络的注册与变更，都写入到这个注册中心，然后由程序自动维护 vtep 之间的隧道、fdb 表及 ARP 表. ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:7:1","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"八、虚拟网络接口的速率 Loopback 和本章讲到的其他虚拟网络接口一样，都是一种软件模拟的网络设备。 他们的速率是不是也像物理链路一样，存在链路层（比如以太网）的带宽限制呢？ 比如目前很多老旧的网络设备，都是只支持到百兆以太网，这就决定了它的带宽上限。 即使是较新的设备，目前基本也都只支持到千兆，也就是 1GbE 以太网标准，那本文提到的虚拟网络接口单纯在本机内部通信，是否也存在这样的制约呢？是否也只能跑到 1GbE? 使用 ethtool 检查： # docker 容器的 veth 接口速率 \u003e ethtool vethe899841 | grep Speed Speed: 10000Mb/s # 网桥看起来没有固定的速率 \u003e ethtool docker0 | grep Speed Speed: Unknown! # tun0 设备的默认速率貌似是 10Mb/s ? \u003e ethtool tun0 | grep Speed Speed: 10Mb/s # 此外 ethtool 无法检查 lo 以及 wifi 的速率 ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:8:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"网络性能实测 接下来实际测试一下，先给出机器参数： ❯ cat /etc/os-release NAME=\"openSUSE Tumbleweed\" # VERSION=\"20210810\" ... ❯ uname -a Linux legion-book 5.13.8-1-default #1 SMP Thu Aug 5 08:56:22 UTC 2021 (967c6a8) x86_64 x86_64 x86_64 GNU/Linux ❯ lscpu Architecture: x86_64 CPU(s): 16 Model name: AMD Ryzen 7 5800H with Radeon Graphics ... # 内存，单位 MB ❯ free -m total used free shared buff/cache available Mem: 27929 4482 17324 249 6122 22797 Swap: 2048 0 2048 使用 iperf3 测试： # 启动服务端 iperf3 -s ------------- # 新窗口启动客户端，通过 loopback 接口访问 iperf3-server，大概 49Gb/s ❯ iperf3 -c 127.0.0.1 Connecting to host 127.0.0.1, port 5201 [ 5] local 127.0.0.1 port 48656 connected to 127.0.0.1 port 5201 [ ID] Interval Transfer Bitrate Retr Cwnd [ 5] 0.00-1.00 sec 4.46 GBytes 38.3 Gbits/sec 0 1.62 MBytes [ 5] 1.00-2.00 sec 4.61 GBytes 39.6 Gbits/sec 0 1.62 MBytes [ 5] 2.00-3.00 sec 5.69 GBytes 48.9 Gbits/sec 0 1.62 MBytes [ 5] 3.00-4.00 sec 6.11 GBytes 52.5 Gbits/sec 0 1.62 MBytes [ 5] 4.00-5.00 sec 6.04 GBytes 51.9 Gbits/sec 0 1.62 MBytes [ 5] 5.00-6.00 sec 6.05 GBytes 52.0 Gbits/sec 0 1.62 MBytes [ 5] 6.00-7.00 sec 6.01 GBytes 51.6 Gbits/sec 0 1.62 MBytes [ 5] 7.00-8.00 sec 6.05 GBytes 52.0 Gbits/sec 0 1.62 MBytes [ 5] 8.00-9.00 sec 6.34 GBytes 54.5 Gbits/sec 0 1.62 MBytes [ 5] 9.00-10.00 sec 5.91 GBytes 50.8 Gbits/sec 0 1.62 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 5] 0.00-10.00 sec 57.3 GBytes 49.2 Gbits/sec 0 sender [ 5] 0.00-10.00 sec 57.3 GBytes 49.2 Gbits/sec receiver # 客户端通过 wlp4s0 wifi 网卡(192.168.31.228)访问 iperf3-server，实际还是走的本机，但是速度要比 loopback 快一点，可能是默认设置的问题 ❯ iperf3 -c 192.168.31.228 Connecting to host 192.168.31.228, port 5201 [ 5] local 192.168.31.228 port 43430 connected to 192.168.31.228 port 5201 [ ID] Interval Transfer Bitrate Retr Cwnd [ 5] 0.00-1.00 sec 5.12 GBytes 43.9 Gbits/sec 0 1.25 MBytes [ 5] 1.00-2.00 sec 5.29 GBytes 45.5 Gbits/sec 0 1.25 MBytes [ 5] 2.00-3.00 sec 5.92 GBytes 50.9 Gbits/sec 0 1.25 MBytes [ 5] 3.00-4.00 sec 6.00 GBytes 51.5 Gbits/sec 0 1.25 MBytes [ 5] 4.00-5.00 sec 5.98 GBytes 51.4 Gbits/sec 0 1.25 MBytes [ 5] 5.00-6.00 sec 6.05 GBytes 52.0 Gbits/sec 0 1.25 MBytes [ 5] 6.00-7.00 sec 6.16 GBytes 52.9 Gbits/sec 0 1.25 MBytes [ 5] 7.00-8.00 sec 6.08 GBytes 52.2 Gbits/sec 0 1.25 MBytes [ 5] 8.00-9.00 sec 6.00 GBytes 51.6 Gbits/sec 0 1.25 MBytes [ 5] 9.00-10.00 sec 6.01 GBytes 51.6 Gbits/sec 0 1.25 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 5] 0.00-10.00 sec 58.6 GBytes 50.3 Gbits/sec 0 sender [ 5] 0.00-10.00 sec 58.6 GBytes 50.3 Gbits/sec receiver # 从容器中访问宿主机的 iperf3-server，速度几乎没区别 ❯ docker run -it --rm --name=iperf3-server networkstatic/iperf3 -c 192.168.31.228 Connecting to host 192.168.31.228, port 5201 [ 5] local 172.17.0.2 port 43436 connected to 192.168.31.228 port 5201 [ ID] Interval Transfer Bitrate Retr Cwnd [ 5] 0.00-1.00 sec 4.49 GBytes 38.5 Gbits/sec 0 403 KBytes [ 5] 1.00-2.00 sec 5.31 GBytes 45.6 Gbits/sec 0 544 KBytes [ 5] 2.00-3.00 sec 6.14 GBytes 52.8 Gbits/sec 0 544 KBytes [ 5] 3.00-4.00 sec 5.85 GBytes 50.3 Gbits/sec 0 544 KBytes [ 5] 4.00-5.00 sec 6.14 GBytes 52.7 Gbits/sec 0 544 KBytes [ 5] 5.00-6.00 sec 5.99 GBytes 51.5 Gbits/sec 0 544 KBytes [ 5] 6.00-7.00 sec 5.86 GBytes 50.4 Gbits/sec 0 544 KBytes [ 5] 7.00-8.00 sec 6.05 GBytes 52.0 Gbits/sec 0 544 KBytes [ 5] 8.00-9.00 sec 5.99 GBytes 51.5 Gbits/sec 0 544 KBytes [ 5] 9.00-10.00 sec 6.12 GBytes 52.5 Gbits/sec 0 544 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 5] 0.00-10.00 sec 58.0 GBytes 49.8 Gbits/sec 0 sender [ 5] 0.00-10.00 sec 58.0 GBytes 49.8 Gbits/sec receiver 把 iperf3-server 跑在容器里再测一遍： # 在容器中启动 iperf3-server，并映射到宿主机端口 6201 \u003e docker run -it --rm --name=iperf3-server -p 6201:5201 networkstatic/iperf3 -s \u003e docker inspect --format \"{{ .NetworkSettings.IPAddress }}\" iperf3-server 172.17.0.2 ----------------------------- # 测试容器之间互访的速度，ip 为 iperf3-server 的容器 ip，速度要慢一些。 # 毕竟过了 veth -\u003e veth -\u003e docker0 -\u003e veth","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:8:1","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":"参考 Linux虚拟网络设备之tun/tap Linux虚拟网络设备之veth 云计算底层技术-虚拟网络设备(Bridge,VLAN) 云计算底层技术-虚拟网络设备(tun/tap,veth) Universal TUN/TAP device driver - Kernel Docs Tun/Tap interface tutorial Linux Loopback performance with TCP_NODELAY enabled ","date":"2021-08-14","objectID":"/posts/linux-virtual-network-interfaces/:9:0","tags":["Linux","网络","虚拟化","容器"],"title":"Linux 中的虚拟网络接口","uri":"/posts/linux-virtual-network-interfaces/"},{"categories":["技术"],"content":" 文中的命令均在 macOS Big Sur 和 Opensuse Tumbleweed 上测试通过 ","date":"2021-04-11","objectID":"/posts/socat-netcat/:0:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"socat \u0026 netcat netcat(network cat) 是一个历史悠久的网络工具包，被称作 TCP/IP 的瑞士军刀，各大 Linux 发行版都有默认安装 openbsd 版本的 netcat，它的命令行名称为 nc. 而 socat(socket cat)，官方文档描述它是 \"netcat++\" (extended design, new implementation)，项目比较活跃，kubernetes-client(kubectl) 底层就是使用的它做各种流量转发。 在不方便安装 socat 的环境中，我们可以使用系统自带的 netcat. 而在其他环境，可以考虑优先使用 socat. ","date":"2021-04-11","objectID":"/posts/socat-netcat/:1:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"一、简介 socat 的基本命令格式： socat [参数] 地址1 地址2 给 socat 提供两个地址，socat 干的活就是把两个地址的流对接起来。左边地址的输出传给右边，同时又把右边地址的输出传给左边，也就是一个双向的数据管道。 听起来好像没啥特别的，但是实际上计算机网络干的活也就是数据传输而已，却影响了整个世界，不可小觑它的功能。 socat 支持非常多的地址类型：-/stdio，TCP, TCP-LISTEN, UDP, UDP-LISTEN, OPEN, EXEC, SOCKS, PROXY 等等，可用于端口监听、链接，文件和进程读写，代理桥接等等。 socat 的功能就是这么简单，命令行参数也很简洁，唯一需要花点精力学习的就是它各种地址的定义和搭配写法。 而 netcat 定义貌似没这么严谨，可以简单的理解为网络版的 cat 命令 2333 ","date":"2021-04-11","objectID":"/posts/socat-netcat/:2:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"二、安装方法 各发行版都自带 netcat，包名通常为 nc-openbsd，因此这里只介绍 socat 的安装方法： # Debian/Ubuntu sudo apt install socat # CentOS/RedHat sudo yum install socat # macOS brew install socat 其他发行版基本也都可以使用包管理器安装 socat ","date":"2021-04-11","objectID":"/posts/socat-netcat/:3:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"三、常用命令 ","date":"2021-04-11","objectID":"/posts/socat-netcat/:4:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"1. 网络调试 1.1 检测远程端口的可连接性（确认防火墙没问题） 以前你可能学过如何用 telnet 来做这项测试，不过现在很多发行版基本都不自带 telnet 了，还需要额外安装。 telnet 差不多已经快寿终正寝了，还是建议使用更专业的 socat/netcat 使用 socat/netcat 检测远程端口的可连接性： # -d[ddd] 增加日志详细程度，-dd Prints fatal, error, warning, and notice messages. socat -dd - TCP:192.168.1.252:3306 # -v 显示详细信息 # -z 不发送数据，效果为立即关闭连接，快速得出结果 nc -vz 192.168.1.2 8080 # -vv 显示更详细的内容 # -w2 超时时间设为 2 秒 # 使用 nc 做简单的端口扫描 nc -vv -w2 -z 192.168.1.2 20-500 1.2 测试本机端口是否能正常被外部访问（检测防火墙、路由） 在本机监听一个 TCP 端口，接收到的内容传到 stdout，同时将 stdin 的输入传给客户端： # 服务端启动命令，socat/nc 二选一 socat TCP-LISTEN:7000 - # -l --listening nc -l 7000 # 客户端连接命令，socat/nc 二选一 socat TCP:192.168.31.123:7000 - nc 192.168.11.123 7000 UDP 协议的测试也非常类似，使用 netcat 的示例如下： # 服务端，只监听 ipv4 nc -u -l 8080 # 客户端 nc -u 192.168.31.123 8080 # 客户端本机测试，注意 localhost 会被优先解析为 ipv6! 这会导致服务端(ipv4)的 nc 接收不到数据！ nc -u localhost 8080 使用 socat 的 UDP 测试示例如下： socat UDP-LISTEN:7000 - socat UDP:192.168.31.123:7000 - 1.3 调试 TLS 协议 参考 socat 官方文档：Securing Traffic Between two Socat Instances Using SSL 测试证书及私钥的生成参见 TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段 模拟一个 mTLS 服务器，监听 4433 端口，接收到的数据同样输出到 stdout： # socat 需要使用同时包含证书和私钥的 pem 文件，生成方法如下 cat server.key server.crt \u003e server.pem cat client.key client.crt \u003e client.pem # 服务端启动命令 socat openssl-listen:4433,reuseaddr,cert=server.pem,cafile=client.crt - # 客户端连接命令 socat - openssl-connect:192.168.31.123:4433,cert=client.pem,cafile=server.crt # 或者使用 curl 连接(我们知道 ca.crt 和 server.crt 都能被用做 cacert/cafile) curl -v --cacert ca.crt --cert client.crt --key client.key --tls-max 1.2 https://192.168.31.123:4433 上面的命令使用了 mTLS 双向认证的协议，可通过设定 verify=0 来关掉客户端认证，示例如下： # socat 需要使用同时包含证书和私钥的 pem 文件，生成方法如下 cat server.key server.crt \u003e server.pem # 服务端启动命令 socat openssl-listen:4433,reuseaddr,cert=server.pem,verify=0 - # 客户端连接命令，如果 ip/域名不受证书保护，就也需要添加 verify=0 socat - openssl-connect:192.168.31.123:4433,cafile=server.crt # 或者使用 curl 连接，证书无效请添加 -k 跳过证书验证 curl -v --cacert server.crt https://192.168.31.123:4433 ","date":"2021-04-11","objectID":"/posts/socat-netcat/:4:1","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"2. 数据传输 通常传输文件时，我都习惯使用 scp/ssh/rsync，但是 socat 其实也可以传输文件。 以将 demo.tar.gz 从主机 A 发送到主机 B 为例， 首先在数据发送方 A 执行如下命令： # -u 表示数据只从左边的地址单向传输给右边（socat 默认是一个双向管道） # -U 和 -u 相反，数据只从右边单向传输给左边 socat -u open:demo.tar.gz tcp-listen:2000,reuseaddr 然后在数据接收方 B 执行如下命令，就能把文件接收到： socat -u tcp:192.168.1.252:2000 open:demo.tar.gz,create # 如果觉得太繁琐，也可以直接通过 stdout 重定向 socat -u tcp:192.168.1.252:2000 - \u003e demo.tar.gz 使用 netcat 也可以实现数据传输： # 先在接收方启动服务端 nc -l -p 8080 \u003e demo.tar.gz # 再在发送方启动客户端发送数据 nc 192.168.1.2 8080 \u003c demo.tar.gz ","date":"2021-04-11","objectID":"/posts/socat-netcat/:5:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"3. 担当临时的 web 服务器 使用 fork reuseaddr SYSTEM 三个命令，再用 systemd/supervisor 管理一下，就可以用几行命令实现一个简单的后台服务器。 下面的命令将监听 8080 端口，并将数据流和 web.py 的 stdio 连接起来，可以直接使用浏览器访问 http://\u003cip\u003e:8080 来查看效果。 socat TCP-LISTEN:8080,reuseaddr,fork SYSTEM:\"python3 web.py\" 假设 web.py 的内容为： print(\"hello world\") 那 curl localhost:8080 就应该会输出 hello world ","date":"2021-04-11","objectID":"/posts/socat-netcat/:6:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"4. 端口转发 监听 8080 端口，建立该端口与 baidu.com:80 之间的双向管道: socat TCP-LISTEN:8080,fork,reuseaddr TCP:baidu.com:80 拿 curl 命令测试一下，应该能正常访问到百度： # 注意指定 Host curl -v -H 'Host: baidu.com' localhost:8080 ","date":"2021-04-11","objectID":"/posts/socat-netcat/:7:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["技术"],"content":"参考 新版瑞士军刀：socat - 韦易笑 - 知乎 用好你的瑞士军刀/netcat - 韦易笑 - 知乎 socat - Multipurpose relay ","date":"2021-04-11","objectID":"/posts/socat-netcat/:8:0","tags":["网络","Linux","网络调试"],"title":"Linux 网络工具中的瑞士军刀 - socat \u0026 netcat","uri":"/posts/socat-netcat/"},{"categories":["随笔"],"content":" 2022-02-09 更新：2022 年再回看这篇文章，明显感觉到我的进步很大很大，不论是工作文化与环境、薪资、吃喝玩乐、还是接触到的线上环境规模都有了质的变化，详情见 2021 年总结。 目前对自己的认知更清晰了，期待 2022 年我能「更上一层楼」哈哈~ 2021-09-04 更新：在新公司认识到了自己技术、方法论、思维模式等多方面的不足。 这篇文章的部分内容让我觉得有点羞耻…不过就这样吧，毕竟这确实是我当时的所思所想… ","date":"2021-02-06","objectID":"/posts/end-of-the-first-round/:0:0","tags":["总结","心得"],"title":"我在创业公司做技术一年多的一点体会","uri":"/posts/end-of-the-first-round/"},{"categories":["随笔"],"content":"人有悲欢离合，月有阴晴圆缺 今年年底的时候，自己心思摇摆不定，这影响到了我的工作，顺势就向公司提出了离职。 这两三天和老板、技术经理，还包括公司比较强的同事们，都做了一番沟通。 这一是公司希望我能够认同公司的路线和理念，跟着一条道往前走。二呢我也很想知道，老板、技术经理、还有技术骨干们，为什么能这么坚定不疑？为什么这么拼？ 结果是我和公司都发现，我们不是一路人，观念存在冲突。公司的技术骨干们都是创业思维，他们或者乐在其中，或者愿意为了老板描述的未来忍一时痛苦。他们都愿意为了产品付出更多。 但是我发现对公司，我不愿意付出太多。在这里，我一直就是个普通上班族的想法，高点工资，多点个人时间，做着自己喜欢的事情。 于是我火速离职。当天办完交接，签完离职协议，拿着离职协议和离职证明，光速撤退。 这是我毕业后的第一份工作，2019 年 6 月底入职，在公司呆了一年多，学到了很多东西，绝不仅仅只是技术。因此我觉得自己有必要做一个技术以外的总结。 任何一家公司都有好有坏，但是按照惯例，这篇文章会避而不谈公司不好的东西。公司的名称呢，这里就用 W 来代替吧。 因为有前辈在博客园评论里为 W 公司感到可惜，在开始正题之前，还是先说下离职原因。 其实说来也简单，基本都能猜到：工资超低、画饼充饥、鼓励无意义加班、技术能力到了瓶颈，以及技术能力提升使我信心膨胀。 ","date":"2021-02-06","objectID":"/posts/end-of-the-first-round/:1:0","tags":["总结","心得"],"title":"我在创业公司做技术一年多的一点体会","uri":"/posts/end-of-the-first-round/"},{"categories":["随笔"],"content":"自我认识 我刚进 W 公司时，是一个刚毕业的小白，只是兴趣使然喜欢技术。因为专业不同，周围也接触不到多少搞技术的，就比较「独」。 在 W 公司我获得了和一群有上进心的人们互相协作的机会，大家在一步一步往前走的感觉，让我在职期间一直非常快乐。 我们的技术经理也给了 DevOps 团队足够的自由，甚至是鼓励我们去探索、尝试新技术。这是我这一年多 DevOps 这个方向进步这么快的最大原因。 然后在和技术经理、同事们坦诚沟通的时候，我也了解到了自己的能力，不仅仅在技术。我对公司的价值，也绝不仅仅在技术。 这是我以前从来没有想过的，我喜欢技术，而且找工作发现职位要求也都是写的技术，我真的就一直以为技术就是一切。 这里我尤其要感谢技术经理，是他帮我把自己对公司的价值和不足分析得如此透彻。 下面是我结合经理和同事对我的评价，对我个人能力做个评估（三人行必有我师，仅供参考）： 理解能力、洞察能力：在公司，我这方面的能力是拔尖的。和人交流，我经常能很快地把握住核心。 表达能力：我的表达能力也是公司里拔尖的。同事跟我讲，听我描述一条鱼，他能清晰地看到鱼的骨头。 其实我日常写博客时，经常觉得自己表达地不够好，很多人的文章就比我写得更好。不同的角度看到的东西真的区别很大，感谢我的同事们。 探索能力：我日常喜欢逛 github，翻 CNCF Landscape，我的兴趣驱动着自己去探索各种新技术，思考它们的优劣。 但是我的大部分同事们都不是这样的，很多同事只读中文文档和博客，英文也必须依赖不怎么靠谱的翻译。 另外他们工期紧业务多，也没我们 DevOps 这边这么多的时间去探索试用新技术。 因此，我的探索能力要强于大多数同事。 全局思考能力: 放眼全局、思考未来，在众多选择中能够并且敢于做出决策。我目前还很缺乏这样的能力。 说到底我目前还是个普通人的思路，没有把自己放在决策者的位置上去思考。 其次呢，我的知识面还太窄，导致我根本看不清好坏，很多时候就无法独立做出决策。我需要扩大自己的知识面。 技术能力：我的技术能力在公司里能评到 80 分吧。我技术不算好，基础薄弱，但是在我们一个小创业公司内部比较，能到 80 分。 管理能力：DevOps 就两三人，因为我具有上面这些能力，矮个子里拔高的，理所当然地我成了领头的。但是性格使然，我管理能力是公司最差的… 创业思维：公司是创业公司，技术骨干们都是创业思维。但是说实话我从来没想过要去创业，不愿意投入太多。这也是我离职的原因。 因此，技术经理认为，我可能更适合当讲师哈哈。 在公司也确实给同事们讲过几次课，能够看到同事们高兴地鼓掌，告诉我「讲得可以」，我就很开心。这种心情就和有人在我博客里评论「感谢，很有帮助」是一样的。 ","date":"2021-02-06","objectID":"/posts/end-of-the-first-round/:2:0","tags":["总结","心得"],"title":"我在创业公司做技术一年多的一点体会","uri":"/posts/end-of-the-first-round/"},{"categories":["随笔"],"content":"我的收获 首先技术就不用说了，从我这一年多的博客文章就能看到，我的技术进步相当大。 还有就是提升了对自我的认识，这一点前面也已经阐述过了。 那其他方面我收获了啥呢？大概有下面这些： 我发现，技术经理几十年的技术经验和生活经历，能让他不了解的技术领域中，也能快速找出真正有价值的东西。——经验和阅历给了他强大的洞察能力。 技术产品中最有价值的东西，也最难看透的东西，并不是技术本身，而是理念、抽象。比如 DevOps、基础设施即代码、云计算、开源。 这很难，但是能领先所有人，最先发现这些宏观概念的价值，并押注的人，就能获得巨大的先手优势。 但是「世人大都愚昧」，或者说「太过聪明」，导致这类创业团队可能和社会格格不入。不论成功失败，这类永远是少数人。 理性的沟通是好的，但是有时候情绪化的沟通反而更有效果。 我们技术经理是一个超级理性的人，但是我和他沟通，他的想法并不能很好的传达给我。反而情绪化的老板跟我沟通，我更能感同身受。 我认识了形形色色的人，公司的同事、领导，很多都有值得我学习的地方。有些感悟 富二代不在意钱，没普通人这么斤斤计较，只在意公司氛围，以及自己能做什么。反而更愿意付出更多，能够乐在其中，也更容易成功。创业公司大概很喜欢这类人。 世界上大部分人都是普通人。大众认同的观点，不一定就是正确的观点。大众观点的变化也能体现出社会的变迁。 比如当年大跃进全民的狂热，和现在公司倡导 996，社会舆论则积极反抗。公司和民众站在了对立面。 除了上面这些虚的，还有更实在的： 快乐：经理为人相当好，同事之间合作大都也很愉快，人事小姐姐超级专业，无微不至地照顾我们。在职期间我收获了相当多的快乐。 自信心：我进公司之前，作为一个跨专业的小白，非常没有底气，而且在学校的时候整个人非常颓废。但是在 W 公司，我学到了技术，工作乐在其中，还收获了同事和领导的肯定。我建立起了自信心。 Money: 虽然不多，但是我好歹也是个有些闲钱了的人hhh ","date":"2021-02-06","objectID":"/posts/end-of-the-first-round/:3:0","tags":["总结","心得"],"title":"我在创业公司做技术一年多的一点体会","uri":"/posts/end-of-the-first-round/"},{"categories":["随笔"],"content":"未来 毕业后，第一份工作就这样结束了。有点仓促，因为很出乎意料，但细想下来也是情理之中。 下面就是过年了，过年呢，就照着既有的计划来吧，继续提升下技术能力。至少对目前的我而言，技术还是我的能力基础和找工作的最大依仗，其他能力目前还是在围绕技术成长。 年后准备找下一份工作。这一次，我希望能多走一走，看一看，不着急做决定。 我觉得自己的眼界还太狭窄了，我对世界还很缺乏了解。以至于很多东西，我根本无法作出评判。 既然现在跳出了一座我的「围城」，自然要去多看看，外面的世界是个啥样子。 或许也没什么区别？那也得看过才能下结论啊（笑 ","date":"2021-02-06","objectID":"/posts/end-of-the-first-round/:4:0","tags":["总结","心得"],"title":"我在创业公司做技术一年多的一点体会","uri":"/posts/end-of-the-first-round/"},{"categories":["随笔"],"content":"文末 文章的最后，祝大家、也祝我自己在 2021 年里—— 拆破玉笼飞彩凤，顿开金锁走蛟龙。 ","date":"2021-02-06","objectID":"/posts/end-of-the-first-round/:5:0","tags":["总结","心得"],"title":"我在创业公司做技术一年多的一点体会","uri":"/posts/end-of-the-first-round/"},{"categories":null,"content":"一、我的学习清单 技术上，目前的重点仍然是网络技术与 Kubernetes 技术，Redis/Search/Database 等技术还得靠后排，或许明年吧哈哈。 生活上呢，就完全看个人兴趣安排了。 ","date":"2021-02-01","objectID":"/now/:1:0","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"最高优先级 技术： go web 编程: 完成 xhup-club-api-go 这个项目 kubebuilder: 使用 kubebuilder 完成一个实用 operator. 服务网格 跟进 istio 的 warm_up/slow_start PR 进展 - 目前已 Merge，有望在下个版本见到 生活： 娱乐+运动： 轮滑：倒滑后压步 阅读（一二三月份，就读这两本吧）： 《人间失格》 Practical Cryptography for Developers - 70% 《在生命的尽头拥抱你-临终关怀医生手记》 - 10% ","date":"2021-02-01","objectID":"/now/:1:1","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"高优先级 服务网格 Cilium Service Mesh - 使用 eBPF + per-node proxy 实现 的服务网格，很有前景。 Zone Aware Load Balancing - 减少跨区流量 如何调优数据面，降低 CPU 使用率及延迟 学习与测试各种负载均衡策略: 需要持续更新这份文档 - 50% 研究 istio 的限流限并发能力 日志方案调研：grafana loki 配置管理：研究如何使用 vault 实现跨集群的动态配置支持，如何落地此项能力 阅读（四五六月份的书单）： 《生命最后的读书会》 《房思琪的初恋乐园》 《圆圈正义-作为自由前提的信念》 《网络是怎样连接的》 生活： 音乐：Synthesizer V, 练习键盘 k8s 网络插件 - Cilium Kubernetes：阅读源码，熟悉底层细节 计算机网络： Computer Networking: A Top-Down Approach, 7th Edition BGP 路由协议 vxlan 数据库: SQL进阶教程 ","date":"2021-02-01","objectID":"/now/:1:2","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"中优先级 rust 语言 容器底层原理 容器镜像的文件系统：overlayfs 镜像的结构分析 镜像的构建流程 写几个小项目（使用 rust/go） 实现一个文本编辑器 https://viewsourcecode.org/snaptoken/kilo/ 实现一个简单的 Linux 容器 https://blog.lizzie.io/linux-containers-in-500-loc.html 网络代理（不到 2000 行的 TUN 库） https://github.com/songgao/water 实现简单的键值数据库： https://github.com/tidb-incubator/tinykv 实现简单的关系数据库： https://github.com/tidb-incubator/tinysql 学习搜索引擎技术： 这就是搜索引擎 https://github.com/huichen/wukong 操作系统： The Linux Programming Interface Computer Systems: A Programmer’s Perspective, 3/E (CS:APP3e) 编译原理 自制编译器 Programming Language Pragmatics, Fourth Edition 学习英语，目标是能流利地读写交流。 主要是可以扩宽工作的选择面，外企很多职位会要求英文读写流利。 区块链技术 Web3.0 非同质化代币 (NFT)、去中心化自治组织 (DAO) 智能合约 以太坊开发者文档 ","date":"2021-02-01","objectID":"/now/:1:3","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"低优先级 操作系统： Systems Performance: Enterprise and the Cloud, 2nd Edition (2020) 编译原理（如何实现一个编程语言） 编译器设计（第2版） 编程语言实现模式 Openresty 技术栈：（暂时感觉兴趣不大） 阅读《Lua 程序设计》 阅读 APISIX 源码 + Openresty 深入学习 Nginx 及 epoll [进阶]数据库、数据结构与算法 MIT 6.824：Designing Data-Intensive Applications redis 底层 mysql/postgresql 底层 Readings in Database Systems ","date":"2021-02-01","objectID":"/now/:1:4","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"其他暂时排不上号的兴趣点 值得了解的数据库 OLAP ClickHouse Snowflake Druid ElasticSearch HTAP TiDB PostgreSQL 键值数据库 Redis Etcd 底层数据库：boltdb/rocksdb/leveldb 文档数据库 MongoDB 时序数据库 VictoriaMetrics Prometheus 特征向量搜索 / 相似度搜索 / 视频搜索 / 语义搜索 图数据库 https://github.com/dgraph-io/dgraph 机器学习、深度学习 编程语言 Elixir Kotlin 编程语言理论（如何设计一个编程语言） Essentials of Programming Languages, 3rd Edition The Little Schemer - 4th Edition 微积分、线代、概率论、数学物理方法 信号与系统、数字信号处理、音视频处理 《声学基础》、《理论声学》、《空间声学》：虽然大学学的一塌糊涂，现在居然又有些兴趣想学来玩玩，写些声学仿真工具试试。 语音合成、歌声合成 声学模拟：揉搓声模拟 ","date":"2021-02-01","objectID":"/now/:1:5","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"三、此时此刻的我 主要记录下业余时间我都在干些啥。 ","date":"2021-02-01","objectID":"/now/:2:0","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"now 目前想做的： 研究使用 aws/karpenter 实现集群弹性扩缩容 继续学习与翻译《写给开发人员的实用密码学》系列文章 kubebuilder: 使用 kubebuilder 完成一个实用 operator. go web 编程: 完成 xhup-club-api-go 这个项目 ","date":"2021-02-01","objectID":"/now/:2:1","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2022-03-07 - 2022-03-08 跟推荐系统大佬一起将服务从 HTTP 切换到 gRPC，效果立竿见影，服务流量下降 50% ~ 60%，延迟下降 30% ~ 50% 提升了服务性能，降低了 AWS 跨区流量成本 ","date":"2021-02-01","objectID":"/now/:2:2","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2022-03-05 - 2022-03-06 发布《写给开发人员的实用密码学》系列的第六篇：对称加密算法 ","date":"2021-02-01","objectID":"/now/:2:3","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2022-03-01 深圳疫情形式严峻，开始居家办公 整理润色后，发布《写给开发人员的实用密码学》前五篇的内容 ","date":"2021-02-01","objectID":"/now/:2:4","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2022-02-19 - 2022-02-25 阅读 Practical Cryptography for Developers，同时完成我的密码学笔记 完成了《写给开发人员的实用密码学》前五篇的草稿。 研究 istio 的 gRPC 支持与监控指标 ","date":"2021-02-01","objectID":"/now/:2:5","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2022-02-17 发现我们的 EKS 集群主使用的是 AWS Spot 实例，这类实例的 c6i/c6g 性能与价格差距并不高，做 ARM 化的 ROI 貌似并不高 发现对 aws 的 RDS/EC2-Volume/Redis 等资源进行全面评估，删掉闲置资源、缩小实例/集群规格，可以轻易节省大量成本（说明以前申请资源时风格比较豪放 2333） 继续迭代个人博客 ","date":"2021-02-01","objectID":"/now/:2:6","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2022-02-07 - 2022-02-16 迭代我的独立博客 https://thiscute.world 添加「阅读排行」页，定期从 Google Analytics 同步数据 从博客园迁移部分有价值的文章到独立博客 ","date":"2021-02-01","objectID":"/now/:2:7","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2022-01-01 了解 APISIX/Nginx/Envoy 中的各种负载均衡算法，及其适用场景、局限性。 ","date":"2021-02-01","objectID":"/now/:2:8","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-12-12 练习二个半小时轮滑，学会了压步转弯技术 无聊，但是又啥都不想干，耽于网络小说… 感觉有点现充了，感觉需要找个更明确的、能给人动力的目标 做个三年的职业规划以及生活规划？ ","date":"2021-02-01","objectID":"/now/:2:9","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-11-21 轮滑：复习前双鱼、前剪、前蛇，尝试侧压步、倒滑 ","date":"2021-02-01","objectID":"/now/:2:10","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-11-08 - 2021-11-12 将上次 EKS 升级过程中，有问题的服务迁移到 1.21 的 EKS 集群，直接切线上流量测试。 复现了问题，通过 JFR + pods 数量监控，确认到是服务链路上的个别服务频繁扩缩容导致的，这些服务比较重，对扩缩容比较敏感。 测试在 HPA 中添加 behavior 降低缩容速率，同时添加上 PodDisruptionBudget 以避免节点回收导致大量 Pod 被回收，经测试问题基本解决。 遭遇 AWS EKS 托管的控制平面故障，controller-manager 挂了一整天。现象非常奇怪，又是第一次遇到，导致长时间未排查到问题。 确认问题来自 HPA behavior 的 Bug 储存于 etcd 中的 object 仅会有一个版本，透过 apiserver 读取时会转换成请求的 autoscaling API 版本。 autoscaling/v2beta2 scaleUp 及 scaleDown 对象不能为 null，并在其 Kubernetse 代码可以查看到相应的检查机制。 当使用 autoscaling/v1 时，v2beta2 版本中的相关对象字段将作为 annotation 保留，apiserver 不会检查 ScaleUp/ScaleDown 的 annotation是否为 non-null，而导致 kube-controller-manager panic 问题。 我们可以使用 v1 或 v2beta2 创建一个 HPA 对象，然后使用 v1 或 v2beta2 读取、更新或删除该对象。 etcd 中存储的对象只有一个版本，每当您使用 v1 或 v2beta2 获取 HPA 对象时，apiserver 从 etcd 读取它，然后将其转换为您请求的版本。 在使用 kubectl 时，客户端将默认使用 v1(kubectl get hpa)，因此我们必须明确请求 v2beta2 才能使用这些功能(kubectl get hpa.v2beta2.autoscaling) 如果在更新 v1 版本的 HPA 时（kubectl 默认用 v1），手动修改了 v2beta2 功能相关的 annotation 将 scaleUp/scaleDown 设为 null，会导致 controller-manager 挂掉. ","date":"2021-02-01","objectID":"/now/:2:11","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-10-23 跟公司冲浪小分队，第一次玩冲浪，最佳成绩是在板上站了大概 6s… ","date":"2021-02-01","objectID":"/now/:2:12","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-10/11 - 2021-10-19 将 EKS 集群从 1.17 升级到 1.21（新建集群切量的方式），但是遇到部分服务迁移后可用率抖动。 未定位到原因，升级失败，回滚了流量。 ","date":"2021-02-01","objectID":"/now/:2:13","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-09-13 - 2021-09-17 学习极客时间《10X程序员工作法》 以终推始 识别关键问题 ownership ","date":"2021-02-01","objectID":"/now/:2:14","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-09-02 - 2021-09-11 EKS 集群升级 了解 EKS 集群的原地升级的细节 输出 EKS 集群原地升级的测试方案，以及生产环境的 EKS 集群升级方案 学习使用 kubeadm+containerd 部署 k8s 测试集群 涉及到的组件：Kuberntes 控制面、网络插件 Cilium、kube-proxy、coredns、containerd ","date":"2021-02-01","objectID":"/now/:2:15","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-08-31 - 2021-09-01 思考我在工作中遇到的一些非技术问题，寻找解法 效率：如何在没人 push 的情况下（没有外部压力），维持住高效率的工作状态（早早干完活下班它不香么？）。 建立有效的「自检」与「纠错」机制 自检： 列出目前已知的「异常」和「健康」两类工作状态，每日做一个对比。 每日都列一下详细的工作计划，精确到小时（预留 1 小时 buffer 应对临时需求）。 沟通：遇到问题（各种意义上的问题）时，及时沟通清楚再继续推进，是一件 ROI 非常高的事。否则几乎肯定会在后面的某个节点，被这个问题坑一把。 目前的关键目标是啥？存在哪些关键问题（实现关键目标最大的阻碍）？我最近做的主要工作，是不是在为关键目标服务？ 如何把安排到手上的事情做好？ 思考这件事情真正的目标的什么？ 比如任务是排查下某服务状态码有无问题，真正的目的应该是想知道服务有没有异常 达成真正的目标，需要做哪些事？ 不仅仅状态码需要排查，还有服务负载、内存、延迟的分位值，或许都可以看看。 跟需求方沟通，询问是否真正需要做的，是前面分析得出的事情。 这些问题都是有解法的，关键是思路的转换。 ","date":"2021-02-01","objectID":"/now/:2:16","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-08-28 =\u003e 2021-08-29 容器底层原理： linux namespace 与 cgroups linux 虚拟网络接口 macvlan/ipvlan、vlan、vxlan ","date":"2021-02-01","objectID":"/now/:2:17","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-08-19 =\u003e 2021-08-23 阅读 rust 语言的官方文档：the book 边读文档边做 rustlings 的小习题 目前完成了除 macros 之外的所有题 遇到的最难的题：conversions/{try_from_into, from_str} 使用 rust 重写了一版 video2chars ","date":"2021-02-01","objectID":"/now/:2:18","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-08-12 =\u003e 2021-08-16 Linux 的虚拟网络接口 Linux 的 netfilter 网络处理框架，以及其子项目 iptables/conntrack ","date":"2021-02-01","objectID":"/now/:2:19","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":null,"content":"2021-03-11 =\u003e 2021-08-09 学习 nginx - openresty - apisix 工作中，在自己负责的领域，建立起 ownership 学习新公司的工作模式：OKR 工作法 学习新公司的思维模式（识别关键问题） 如何从公司的角度去思考问题，找到我们目前最应该做的事情 从以下角度去评价一件事情的重要性 这件事情对我们目前的目标有多大帮助？ 需要投入多少资源和人力？ 在推进过程中，有哪些阶段性成果或者 check point？ ","date":"2021-02-01","objectID":"/now/:2:20","tags":null,"title":"此时此刻的我","uri":"/now/"},{"categories":["技术"],"content":" 注意：这篇文章并不是一篇入门教程，学习 Argo Workflows 请移步官方文档 Argo Documentation Argo Workflows 是一个云原生工作流引擎，专注于编排并行任务。它的特点如下： 使用 Kubernetes 自定义资源(CR)定义工作流，其中工作流中的每个步骤都是一个容器。 将多步骤工作流建模为一系列任务，或者使用有向无环图（DAG）描述任务之间的依赖关系。 可以在短时间内轻松运行用于机器学习或数据处理的计算密集型作业。 Argo Workflows 可以看作 Tekton 的加强版，因此显然也可以通过 Argo Workflows 运行 CI/CD 流水线(Pipielines)。 阿里云是 Argo Workflows 的深度使用者和贡献者，另外 Kubeflow 底层的工作流引擎也是 Argo Workflows. ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:0:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"一、Argo Workflows 对比 Jenkins 我们在切换到 Argo Workflows 之前，使用的 CI/CD 工具是 Jenkins，下面对 Argo Workflows 和 Jenkins 做一个比较详细的对比， 以了解 Argo Workflows 的优缺点。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"1. Workflow 的定义 Workflow 使用 kubernetes CR 进行定义，因此显然是一份 yaml 配置。 一个 Workflow，就是一个运行在 Kubernetes 上的流水线，对应 Jenkins 的一次 Build. 而 WorkflowTemplate 则是一个可重用的 Workflow 模板，对应 Jenkins 的一个 Job. WorkflowTemplate 的 yaml 定义和 Workflow 完全一致，只有 Kind 不同！ WorkflowTemplate 可以被其他 Workflow 引用并触发，也可以手动传参以生成一个 Workflow 工作流。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:1","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"2. Workflow 的编排 Argo Workflows 相比其他流水线项目(Jenkins/Tekton/Drone/Gitlab-CI)而言，最大的特点，就是它强大的流水线编排能力。 其他流水线项目，对流水线之间的关联性考虑得很少，基本都假设流水线都是互相独立的。 而 Argo Workflows 则假设「任务」之间是有依赖关系的，针对这个依赖关系，它提供了两种协调编排「任务」的方法：Steps 和 DAG 再借助 templateRef 或者 Workflow of Workflows，就能实现 Workflows 的编排了。 我们之所以选择 Argo Workflows 而不是 Tekton，主要就是因为 Argo 的流水线编排能力比 Tekton 强大得多。（也许是因为我们的后端中台结构比较特殊，导致我们的 CI 流水线需要具备复杂的编排能力） 一个复杂工作流的示例如下： https://github.com/argoproj/argo/issues/1088#issuecomment-445884543\" https://github.com/argoproj/argo/issues/1088#issuecomment-445884543 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:2","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"3. Workflow 的声明式配置 Argo 使用 Kubernetes 自定义资源(CR)来定义 Workflow，熟悉 Kubernetes Yaml 的同学上手应该都很快。 下面对 Workflow 定义文件和 Jenkinsfile 做个对比： argo 完全使用 yaml 来定义流水线，学习成本比 Jenkinsfile 的 groovy 低。对熟悉 Kubernetes 的同学尤其如此。 将 jenkinsfile 用 argo 重写后，代码量出现了明显的膨胀。一个 20 行的 Jenkinsfile，用 Argo 重写可能就变成了 60 行。 配置出现了膨胀是个问题，但是考虑到它的可读性还算不错， 而且 Argo 的 Workflow 编排功能，能替代掉我们目前维护的部分 Python 构建代码，以及一些其他优点，配置膨胀这个问题也就可以接受了。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:3","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"4. Web UI Argo Workflows 的 Web UI 感觉还很原始。确实该支持的功能都有，但是它貌似不是面向「用户」的，功能比较底层。 它不像 Jenkins 一样，有很友好的使用界面(虽然说 Jenkins 的 UI 也很显老…) 另外它所有的 Workflow 都是相互独立的，没办法直观地找到一个 WorkflowTemplate 的所有构建记录，只能通过 label/namespace 进行分类，通过任务名称进行搜索。 而 Jenkins 可以很方便地看到同一个 Job 的所有构建历史。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:4","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"5. Workflow 的分类 为何需要对 Workflow 做细致的分类 常见的微服务项目，往往会拆分成众多 Git 仓库（微服务）进行开发，众多的 Git 仓库会使我们创建众多的 CI/CD 流水线。 如果没有任何的分类，这一大堆的流水线如何管理，就成了一个难题。 最显见的需求：前端和后端的流水线最好能区分一下，往下细分，前端的 Web 端和客户端最好也能区分，后端的业务层和中台最好也区分开来。 另外我们还希望将运维、自动化测试相关的任务也集成到这个系统中来（目前我们就是使用 Jenkins 完成运维、自动化测试任务的）， 如果没有任何分类，这一大堆流水线将混乱无比。 Argo Workflows 的分类能力 当 Workflow 越来越多的时候，如果不做分类，一堆 WorkflowTemplate 堆在一起就会显得特别混乱。（没错，我觉得 Drone 就有这个问题…） Argo 是完全基于 Kubernetes 的，因此目前它也只能通过 namespace/labels 进行分类。 这样的分类结构和 Jenkins 的视图-文件夹体系大相径庭，目前感觉不是很好用（也可能纯粹是 Web UI 的锅）。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:5","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"6. 触发构建的方式 Argo Workflows 的流水线有多种触发方式： 手动触发：手动提交一个 Workflow，就能触发一次构建。可以通过 workflowTemplateRef 直接引用一个现成的流水线模板。 定时触发：CronWorkflow 通过 Git 仓库变更触发：借助 argo-events 可以实现此功能，详见其文档。 另外目前也不清楚 WebHook 的可靠程度如何，会不会因为宕机、断网等故障，导致 Git 仓库变更了，而 Workflow 却没触发，而且还没有任何显眼的错误通知？如果这个错误就这样藏起来了，就可能会导致很严重的问题！ ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:6","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"7. secrets 管理 Argo Workflows 的流水线，可以从 kubernetes secrets/configmap 中获取信息，将信息注入到环境变量中、或者以文件形式挂载到 Pod 中。 Git 私钥、Harbor 仓库凭据、CD 需要的 kubeconfig，都可以直接从 secrets/configmap 中获取到。 另外因为 Vault 很流行，也可以将 secrets 保存在 Vault 中，再通过 vault agent 将配置注入进 Pod。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:7","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"8. Artifacts Argo 支持接入对象存储，做全局的 Artifact 仓库，本地可以使用 MinIO. 使用对象存储存储 Artifact，最大的好处就是可以在 Pod 之间随意传数据，Pod 可以完全分布式地运行在 Kubernetes 集群的任何节点上。 另外也可以考虑借助 Artifact 仓库实现跨流水线的缓存复用（未测试），提升构建速度。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:8","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"9. 容器镜像的构建 借助 Buildkit 等容器镜像构建工具，可以实现容器镜像的分布式构建。 Buildkit 对构建缓存的支持也很好，可以直接将缓存存储在容器镜像仓库中。 不建议使用 Google 的 Kaniko，它对缓存复用的支持不咋地，社区也不活跃。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:9","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"10. 客户端/SDK Argo 有提供一个命令行客户端，也有 HTTP API 可供使用。 如下项目值得试用： argo-client-python: Argo Workflows 的 Python 客户端 说实话，感觉和 kubernetes-client/python 一样难用，毕竟都是 openapi-generator 生成出来的… argo-python-dsl: 使用 Python DSL 编写 Argo Workflows 感觉使用难度比 yaml 高，也不太好用。 couler: 为 Argo/Tekton/Airflow 提供统一的构建与管理接口 理念倒是很好，待研究 感觉 couler 挺不错的，可以直接用 Python 写 WorkflowTemplate，这样就一步到位，所有 CI/CD 代码全部是 Python 了。 此外，因为 Argo Workflows 是 kubernetes 自定义资源 CR，也可以使用 helm/kustomize 来做 workflow 的生成。 目前我们一些步骤非常多，但是重复度也很高的 Argo 流水线配置，就是使用 helm 生成的——关键数据抽取到 values.yaml 中，使用 helm 模板 + range 循环来生成 workflow 配置。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:1:10","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"二、安装 Argo Workflows 参考官方文档：https://argoproj.github.io/argo-workflows/installation/ 安装一个集群版(cluster wide)的 Argo Workflows，使用 MinIO 做 artifacts 存储： kubectl apply -f https://raw.githubusercontent.com/argoproj/argo/stable/manifests/install.yaml 部署 MinIO: helm repo add minio https://helm.min.io/ # official minio Helm charts # 查看历史版本 helm search repo minio/minio -l | head # 下载并解压 chart helm pull minio/minio --untar --version 8.0.9 # 编写 custom-values.yaml，然后部署 minio kubectl create namespace minio helm install minio ./minio -n argo -f custom-values.yaml minio 部署好后，它会将默认的 accesskey 和 secretkey 保存在名为 minio 的 secret 中。 我们需要修改 argo 的配置，将 minio 作为它的默认 artifact 仓库。 在 configmap workflow-controller-configmap 的 data 中添加如下字段： artifactRepository: | # 是否将 main 容器的日志保存为 artifact，这样 pod 被删除后，仍然可以在 artifact 中找到日志 archiveLogs: true s3: bucket: argo-bucket # bucket 名称，这个 bucket 需要先手动创建好！ endpoint: minio:9000 # minio 地址 insecure: true # 从 minio 这个 secret 中获取 key/secret accessKeySecret: name: minio key: accesskey secretKeySecret: name: minio key: secretkey 现在还差最后一步：手动进入 minio 的 Web UI，创建好 argo-bucket 这个 bucket. 直接访问 minio 的 9000 端口（需要使用 nodeport/ingress 等方式暴露此端口）就能进入 Web UI，使用前面提到的 secret minio 中的 key/secret 登录，就能创建 bucket. ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:2:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"ServiceAccount 配置 https://argoproj.github.io/argo-workflows/service-accounts/ Argo Workflows 依赖于 ServiceAccount 进行验证与授权，而且默认情况下，它使用所在 namespace 的 default ServiceAccount 运行 workflow. 可 default 这个 ServiceAccount 默认根本没有任何权限！所以 Argo 的 artifacts, outputs, access to secrets 等功能全都会因为权限不足而无法使用！ 为此，Argo 的官方文档提供了两个解决方法。 方法一，直接给 default 绑定 cluster-admin ClusterRole，给它集群管理员的权限，只要一行命令（但是显然安全性堪忧）： kubectl create rolebinding default-admin --clusterrole=admin --serviceaccount=\u003cnamespace\u003e:default -n \u003cnamespace\u003e 方法二，官方给出了Argo Workflows 需要的最小权限的 Role 定义，方便起见我将它改成一个 ClusterRole: apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:name:argo-workflow-rolerules:# pod get/watch is used to identify the container IDs of the current pod# pod patch is used to annotate the step's outputs back to controller (e.g. artifact location)- apiGroups:- \"\"resources:- podsverbs:- get- watch- patch# logs get/watch are used to get the pods logs for script outputs, and for log archival- apiGroups:- \"\"resources:- pods/logverbs:- get- watch 创建好上面这个最小的 ClusterRole，然后为每个名字空间，跑一下如下命令，给 default 账号绑定这个 clusterrole: kubectl create rolebinding default-argo-workflow --clusterrole=argo-workflow-role --serviceaccount=\u003cnamespace\u003e:default -n \u003cnamespace\u003e 这样就能给 default 账号提供最小的 workflow 运行权限。 或者如果你希望使用别的 ServiceAccount 来运行 workflow，也可以自行创建 ServiceAccount，然后再走上面方法二的流程，但是最后，要记得在 workflow 的 spec.serviceAccountName 中设定好 ServiceAccount 名称。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:2:1","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"Workflow Executors https://argoproj.github.io/argo-workflows/workflow-executors/ Workflow Executor 是符合特定接口的一个进程(Process)，Argo 可以通过它执行一些动作，如监控 Pod 日志、收集 Artifacts、管理容器生命周期等等… Workflow Executor 有多种实现，可以通过前面提到的 configmap workflow-controller-configmap 来选择。 可选项如下： docker(默认): 目前使用范围最广，但是安全性最差。它要求一定要挂载访问 docker.sock，因此一定要 root 权限！ kubelet: 应用非常少，目前功能也有些欠缺，目前也必须提供 root 权限 Kubernetes API (k8sapi): 直接通过调用 k8sapi 实现日志监控、Artifacts 手机等功能，非常安全，但是性能欠佳。 Process Namespace Sharing (pns): 安全性比 k8sapi 差一点，因为 Process 对其他所有容器都可见了。但是相对的性能好很多。 在 docker 被 kubernetes 抛弃的当下，如果你已经改用 containerd 做为 kubernetes 运行时，那 argo 将会无法工作，因为它默认使用 docker 作为运行时！ 我们建议将 workflow executore 改为 pns，兼顾安全性与性能，workflow-controller-configmap 按照如下方式修改： apiVersion:v1kind:ConfigMapmetadata:name:workflow-controller-configmapdata:config:|# ...省略若干配置... # Specifies the container runtime interface to use (default: docker) # must be one of: docker, kubelet, k8sapi, pns containerRuntimeExecutor: pns # ... ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:2:2","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"三、使用 Argo Workflows 做 CI 工具 官方的 Reference 还算详细，也有提供非常多的 examples 供我们参考，这里提供我们几个常用的 workflow 定义。 使用 buildkit 构建镜像：https://github.com/argoproj/argo-workflows/blob/master/examples/buildkit-template.yaml buildkit 支持缓存，可以在这个 example 的基础上自定义参数 注意使用 PVC 来跨 step 共享存储空间这种手段，速度会比通过 artifacts 高很多。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:3:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"四、常见问题 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"1. workflow 默认使用 root 账号？ workflow 的流程默认使用 root 账号，如果你的镜像默认使用非 root 账号，而且要修改文件，就很可能遇到 Permission Denined 的问题。 解决方法：通过 Pod Security Context 手动设定容器的 user/group: Workflow Pod Security Context 安全起见，我建议所有的 workflow 都手动设定 securityContext，示例： apiVersion:argoproj.io/v1alpha1kind:WorkflowTemplatemetadata:name:xxxspec:securityContext:runAsNonRoot:truerunAsUser:1000 或者也可以通过 workflow-controller-configmap 的 workflowDefaults 设定默认的 workflow 配置。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:1","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"2. 如何从 hashicorp vault 中读取 secrets? 参考 Support to get secrets from Vault hashicorp vault 目前可以说是云原生领域最受欢迎的 secrets 管理工具。 我们在生产环境用它做为分布式配置中心，同时在本地 CI/CD 中，也使用它存储相关的敏感信息。 现在迁移到 argo，我们当然希望能够有一个好的方法从 vault 中读取配置。 目前最推荐的方法，是使用 vault 的 vault-agent，将 secrets 以文件的形式注入到 pod 中。 通过 valut-policy - vault-role - k8s-serviceaccount 一系列认证授权配置，可以制定非常细粒度的 secrets 权限规则，而且配置信息阅后即焚，安全性很高。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:2","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"3. 如何在多个名字空间中使用同一个 secrets? 使用 Namespace 对 workflow 进行分类时，遇到的一个常见问题就是，如何在多个名字空间使用 private-git-creds/docker-config/minio/vault 等 workflow 必要的 secrets. 常见的方法是把 secrets 在所有名字空间 create 一次。 但是也有更方便的 secrets 同步工具： 比如，使用 kyverno 进行 secrets 同步的配置： apiVersion:kyverno.io/v1kind:ClusterPolicymetadata:name:sync-secretsspec:background:falserules:# 将 secret vault 从 argo Namespace 同步到其他所有 Namespace- name:sync-vault-secretmatch:resources:kinds:- Namespacegenerate:kind:Secretname:regcrednamespace:\"{{request.object.metadata.name}}\"synchronize:trueclone:namespace:argoname:vault# 可以配置多个 rules，每个 rules 同步一个 secret 上面提供的 kyverno 配置，会实时地监控所有 Namespace 变更，一但有新 Namespace 被创建，它就会立即将 vault secret 同步到该 Namespace. 或者，使用专门的 secrets/configmap 复制工具：kubernetes-replicator ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:3","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"4. Argo 对 CR 资源的验证不够严谨，写错了 key 都不报错 待研究 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:4","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"5. 如何归档历史数据？ Argo 用的时间长了，跑过的 Workflows/Pods 全都保存在 Kubernetes/Argo Server 中，导致 Argo 越用越慢。 为了解决这个问题，Argo 提供了一些配置来限制 Workflows 和 Pods 的数量，详见：Limit The Total Number Of Workflows And Pods 这些限制都是 Workflow 的参数，如果希望设置一个全局默认的限制，可以按照如下示例修改 argo 的 workflow-controller-configmap 这个 configmap: apiVersion:v1kind:ConfigMapmetadata:name:workflow-controller-configmapdata:config:|# Default values that will apply to all Workflows from this controller, unless overridden on the Workflow-level # See more: docs/default-workflow-specs.md workflowDefaults: spec: # must complete in 8h (28,800 seconds) activeDeadlineSeconds: 28800 # keep workflows for 1d (86,400 seconds) ttlStrategy: secondsAfterCompletion: 86400 # secondsAfterSuccess: 5 # secondsAfterFailure: 500 # delete all pods as soon as they complete podGC: # 可选项：\"OnPodCompletion\", \"OnPodSuccess\", \"OnWorkflowCompletion\", \"OnWorkflowSuccess\" strategy: OnPodCompletion ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:5","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"6. Argo 的其他进阶配置 Argo Workflows 的配置，都保存在 workflow-controller-configmap 这个 configmap 中，我们前面已经接触到了它的部分内容。 这里给出此配置文件的完整 examples: https://github.com/argoproj/argo-workflows/blob/master/docs/workflow-controller-configmap.yaml 其中一些可能需要自定义的参数如下： parallelism: workflow 的最大并行数量 persistence: 将完成的 workflows 保存到 postgresql/mysql 中，这样即使 k8s 中的 workflow 被删除了，还能查看 workflow 记录 也支持配置过期时间 sso: 启用单点登录 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:6","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"7. 是否应该尽量使用 CI/CD 工具提供的功能？ 我从同事以及网络上，了解到部分 DevOps 人员主张尽量自己使用 Python/Go 来实现 CI/CD 流水线，CI/CD 工具提供的功能能不使用就不要使用。 因此有此一问。下面做下详细的分析： 尽量使用 CI/CD 工具提供的插件/功能，好处是不需要自己去实现，可以降低维护成本。 但是相对的运维人员就需要深入学习这个 CI/CD 工具的使用，另外还会和 CI/CD 工具绑定，会增加迁移难度。 而尽量自己用 Python 等代码去实现流水线，让 CI/CD 工具只负责调度与运行这些 Python 代码， 那 CI/CD 就可以很方便地随便换，运维人员也不需要去深入学习 CI/CD 工具的使用。 缺点是可能会增加 CI/CD 代码的复杂性。 我观察到 argo/drone 的一些 examples，发现它们的特征是： 所有 CI/CD 相关的逻辑，全都实现在流水线中，不需要其他构建代码 每一个 step 都使用专用镜像：golang/nodejs/python 比如先使用 golang 镜像进行测试、构建，再使用 kaniko 将打包成容器镜像 那是否应该尽量使用 CI/CD 工具提供的功能呢？ 其实这就是有多种方法实现同一件事，该用哪种方法的问题。这个问题在各个领域都很常见。 以我目前的经验来看，需要具体问题具体分析，以 Argo Workflows 为例： 流水线本身非常简单，那完全可以直接使用 argo 来实现，没必要自己再搞个 python 脚本 简单的流水线，迁移起来往往也非常简单。没必要为了可迁移性，非要用 argo 去调用 python 脚本。 流水线的步骤之间包含很多逻辑判断/数据传递，那很可能是你的流水线设计有问题！ 流水线的步骤之间传递的数据应该尽可能少！复杂的逻辑判断应该尽量封装在其中一个步骤中！ 这种情况下，就应该使用 python 脚本来封装复杂的逻辑，而不应该将这些逻辑暴露到 Argo Workflows 中！ 我需要批量运行很多的流水线，而且它们之间还有复杂的依赖关系：那显然应该利用上 argo wrokflow 的高级特性。 argo 的 dag/steps 和 workflow of workflows 这两个功能结合，可以简单地实现上述功能。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:4:7","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"8. 如何提升 Argo Workflows 的创建和销毁速度？ 我们发现 workflow 的 pod，创建和销毁消耗了大量时间，尤其是销毁。 这导致我们单个流水线在 argo 上跑，还没在 jenkins 上跑更快。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:5:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"使用体验 目前已经使用 Argo Workflows 一个月多了，总的来说，最难用的就是 Web UI。 其他的都是小问题，只有 Web UI 是真的超难用，感觉根本就没有好好做过设计… 急需一个第三方 Web UI… ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:6:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"画外 - 如何处理其他 Kubernetes 资源之间的依赖关系 Argo 相比其他 CI 工具，最大的特点，是它假设「任务」之间是有依赖关系的，因此它提供了多种协调编排「任务」的方法。 但是貌似 Argo CD 并没有继承这个理念，Argo CD 部署时，并不能在 kubernetes 资源之间，通过 DAG 等方法定义依赖关系。 微服务之间存在依赖关系，希望能按依赖关系进行部署，而 ArgoCD/FluxCD 部署 kubernetes yaml 时都是不考虑任何依赖关系的。这里就存在一些矛盾。 解决这个矛盾的方法有很多，我查阅了很多资料，也自己做了一些思考，得到的最佳实践来自解决服务依赖 - 阿里云 ACK 容器服务，它给出了两种方案： 应用端服务依赖检查: 即在微服务的入口添加依赖检查逻辑，确保所有依赖的微服务/数据库都可访问了，就续探针才能返回 200. 如果超时就直接 Crash 独立的服务依赖检查逻辑: 部分遗留代码使用方法一改造起来或许会很困难，这时可以考虑使用 pod initContainer 或者容器的启动脚本中，加入依赖检查逻辑。 但是这两个方案也还是存在一些问题，在说明问题前，我先说明一下我们「按序部署」的应用场景。 我们是一个很小的团队，后端做 RPC 接口升级时，通常是直接在开发环境做全量升级+测试。 因此运维这边也是，每次都是做全量升级。 因为没有协议协商机制，新的微服务的「RPC 服务端」将兼容 v1 v2 新旧两种协议，而新的「RPC 客户端」将直接使用 v2 协议去请求其他微服务。 这就导致我们必须先升级「RPC 服务端」，然后才能升级「RPC 客户端」。 为此，在进行微服务的全量升级时，就需要沿着 RPC 调用链路按序升级，这里就涉及到了 Kubernetes 资源之间的依赖关系。 我目前获知的关键问题在于：我们使用的并不是真正的微服务开发模式，而是在把整个微服务系统当成一个「单体服务」在看待，所以引申出了这样的依赖关键的问题。 我进入的新公司完全没有这样的问题，所有的服务之间在 CI/CD 这个阶段都是解耦的，CI/CD 不需要考虑服务之间的依赖关系，也没有自动按照依赖关系进行微服务批量发布的功能，这些都由开发人员自行维护。 或许这才是正确的使用姿势，如果动不动就要批量更新一大批服务，那微服务体系的设计、拆分肯定是有问题了，生产环境也不会允许这么轻率的更新。 前面讲了，阿里云提供的「应用端服务依赖检查」和「独立的服务依赖检查逻辑」是最佳实践。它们的优点有： 简化部署逻辑，每次直接做全量部署就 OK。 提升部署速度，具体体现在：GitOps 部署流程只需要走一次（按序部署要很多次）、所有镜像都提前拉取好了、所有 Pod 也都提前启动了。 但是这里有个问题是「灰度发布」或者「滚动更新」，这两种情况下都存在新旧版本共存的问题。 如果出现了 RPC 接口升级，那就必须先完成「RPC 服务端」的「灰度发布」或者「滚动更新」，再去更新「RPC 客户端」。 否则如果直接对所有微服务做灰度更新，只依靠「服务依赖检查」，就会出现这样的问题——「RPC 服务端」处于「薛定谔」状态，你调用到的服务端版本是新还是旧，取决于负载均衡的策略和概率。 **因此在做 RPC 接口的全量升级时，只依靠「服务依赖检查」是行不通的。**我目前想到的方案，有如下几种： 我们当前的使用方案：直接在 yaml 部署这一步实现按序部署，每次部署后就轮询 kube-apiserver，确认全部灰度完成，再进行下一阶段的 yaml 部署。 让后端加个参数来控制客户端使用的 RPC 协议版本，或者搞一个协议协商。这样就不需要控制微服务发布顺序了。 社区很多有状态应用的部署都涉及到部署顺序等复杂操作，目前流行的解决方案是使用 Operator+CRD 来实现这类应用的部署。Operator 会自行处理好各个组件的部署顺序。 ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:7:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"参考文档 Argo加入CNCF孵化器，一文解析Kubernetes原生工作流 视频: How to Multiply the Power of Argo Projects By Using Them Together - Hong Wang ","date":"2021-01-27","objectID":"/posts/expirence-of-argo-workflow/:8:0","tags":["云原生","CI","持续集成","流水线"],"title":"云原生流水线 Argo Workflows 的安装、使用以及个人体验","uri":"/posts/expirence-of-argo-workflow/"},{"categories":["技术"],"content":"Vault 是 hashicorp 推出的 secrets 管理、加密即服务与权限管理工具。它的功能简介如下： secrets 管理：支持保存各种自定义信息、自动生成各类密钥，vault 自动生成的密钥还能自动轮转(rotate) 认证方式：支持接入各大云厂商的账号体系（比如阿里云RAM子账号体系）或者 LDAP 等进行身份验证，不需要创建额外的账号体系。 权限管理：通过 policy，可以设定非常细致的 ACL 权限。 密钥引擎：也支持接管各大云厂商的账号体系（比如阿里云RAM子账号体系），实现 API Key 的自动轮转。 支持接入 kubernetes rbac 权限体系，通过 serviceaccount+role 为每个 Pod 单独配置权限。 支持通过 sidecar/init-container 将 secrets 注入到 pod 中，或者通过 k8s operator 将 vault 数据同步到 k8s secrets 中 在使用 Vault 之前，我们是以携程开源的 Apollo 作为微服务的分布式配置中心。 Apollo 在国内非常流行。它功能强大，支持配置的继承，也有提供 HTTP API 方便自动化。 缺点是权限管理和 secrets 管理比较弱，也不支持信息加密，不适合直接存储敏感信息。因此我们现在切换到了 Vault. 目前我们本地的 CI/CD 流水线和云上的微服务体系，都是使用的 Vault 做 secrets 管理. ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:0:0","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"一、Vault 基础概念 「基本概念」这一节，基本都翻译自官方文档: https://www.vaultproject.io/docs/internals/architecture 首先看一下 Vault 的架构图： vault layers\" vault layers 可以看到，几乎所有的 Vault 组件都被统称为「屏障（Barrier）」， Vault 可以简单地被划分为存储后端（Storage Backend）、屏障（Barrier 和 HTTP/S API 三个部分。 类比银行金库，「屏障」就是 Vault(金库) 周围的「钢铁」和「混凝土」，存储后端和客户端之间的所有数据流动都需要经过它。 「屏障」确保只有加密数据会被写入存储后端，加密数据在经过「屏障」被读出的过程中被验证与解密。 和银行金库的大门非常类似，Barrier 也必须先解封，才能解密存储后端中的数据。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:1:0","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"1. 数据存储及加密解密 存储后端（Storage Backend）: Vault 自身不存储数据，因此需要为它配置一个「存储后端」。 「存储后端」是不受信任的，只用于存储加密数据。 Initialization(初始化): Vault 在首次启动时需要初始化，这一步生成一个「加密密钥(Encryption Key)」用于加密数据，加密完成的数据才能被保存到「存储后端」。 Unseal(解封): Vault 启动后，因为不知道「加密密钥」，它会进入「封印（Sealed）」状态，在「解封」前无法进行任何操作。 「加密密钥」被「master key」保护，我们必须提供「master key」才能完成解封操作。 默认情况下，Vault 使用沙米尔密钥共享算法 将「master key」分割成五个「Key Shares(分享密钥)」，必须要提供其中任意三个「Key Shares」才能重建出「master key」从而完成解封。 vault-shamir-secret-sharing\" vault-shamir-secret-sharing 「Key Shares」的数量，以及重建「master key」最少需要的 key shares 数量，都是可以调整的。 沙米尔密钥共享算法也可以关闭，这样 master key 将被直接用于 Unseal. ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:1:1","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"2. 认证系统及权限系统 在解封完成后，Vault 就可以开始处理请求了。 HTTP 请求进入后的整个处理流程都由 vault core 管理，core 会强制进行 ACL 检查，并确保审计日志(audit logging)完成记录。 客户端首次连接 vault 时，需要先完成身份认证，vault 的「auth methods」模块有很多身份认证方法可选： 用户友好的认证方法，适合管理员使用：username/password、云服务商、ldap 在创建 user 的时候，需要为 user 绑定 policy，给予合适的权限。 应用友好的方法，适合应用程序使用：public/private keys、tokens、kubernetes、jwt 身份验证请求流经 Core 并进入 auth methods，auth methods 确定请求是否有效并返回「关联策略(policies)」的列表。 ACL Policies 由 policy store 负责管理与存储，由 core 进行 ACL 检查。 ACL 的默认行为是拒绝，这意味着除非明确配置 Policy 允许某项操作，否则该操作将被拒绝。 在通过 auth methods 完成了身份认证，并且返回的「关联策略」也没毛病之后，「token store」将会生成并管理一个新的 token， 这个 token 会被返回给客户端，用于进行后续请求。 类似 web 网站的 cookie，token 也都存在一个 lease 租期或者说有效期，这加强了安全性。 token 关联了相关的策略 policies，这些策略将被用于验证请求的权限。 请求经过验证后，将被路由到 secret engine。如果 secret engine 返回了一个 secret（由 vault 自动生成的 secret）， Core 会将其注册到 expiration manager，并给它附加一个 lease ID。lease ID 被客户端用于更新(renew)或吊销(revoke)它得到的 secret. 如果客户端允许租约(lease)到期，expiration manager 将自动吊销这个 secret. Core 负责处理审核代理(audit broker)的请求及响应日志，将请求发送到所有已配置的审核设备(audit devices)。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:1:2","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"3. Secret Engine Secret Engine 是保存、生成或者加密数据的组件，它非常灵活。 有的 Secret Engines 只是单纯地存储与读取数据，比如 kv 就可以看作一个加密的 Redis。 而其他的 Secret Engines 则连接到其他的服务并按需生成动态凭证。 还有些 Secret Engines 提供「加密即服务(encryption as a service)」的能力，如 transit、证书管理等。 常用的 engine 举例： AliCloud Secrets Engine: 基于 RAM 策略动态生成 AliCloud Access Token，或基于 RAM 角色动态生成 AliCloud STS 凭据 Access Token 会自动更新(Renew)，而 STS 凭据是临时使用的，过期后就失效了。 kv: 键值存储，可用于存储一些静态的配置。它一定程度上能替代掉携程的 Apollo 配置中心。 Transit Secrets Engine: 提供加密即服务的功能，它只负责加密和解密，不负责存储。主要应用场景是帮 app 加解密数据，但是数据仍旧存储在 MySQL 等数据库中。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:1:3","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"二、部署 Vault 官方建议通过 Helm 部署 vault，大概流程： 使用 helm/docker 部署运行 vault. 初始化/解封 vault: vault 安全措施，每次重启必须解封(可设置自动解封). ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:2:0","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"0. 如何选择存储后端？ 首先，我们肯定需要 HA，至少要保留能升级到 HA 的能力，所以不建议选择不支持 HA 的后端。 而具体的选择，就因团队经验而异了，人们往往倾向于使用自己熟悉的、知根知底的后端，或者选用云服务。 比如我们对 MySQL/PostgreSQL 比较熟悉，而且使用云服务提供的数据库不需要考虑太多的维护问题，MySQL/PostgreSQL 作为一个通用协议也不会被云厂商绑架，那我们就倾向于使用这两者之一。 而如果你们是本地自建，那你可能更倾向于使用 Etcd/Consul/Raft 做后端存储。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:2:1","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"1. docker-compose 部署（非 HA） 推荐用于本地开发测试环境，或者其他不需要高可用的环境。 docker-compose.yml 示例如下： version:'3.3'services:vault:# 文档：https://hub.docker.com/_/vaultimage:vault:1.6.0container_name:vaultports:# rootless 容器，内部不能使用标准端口 443- \"443:8200\"restart:alwaysvolumes:# 审计日志存储目录（`file` audit backend）- ./logs:/vault/logs# 当使用 file data storage 插件时，数据被存储在这里。默认不往这写任何数据。- ./file:/vault/file# vault 配置- ./config.hcl:/vault/config/config.hcl# TLS 证书- ./certs:/certs# vault 需要锁定内存以防止敏感值信息被交换(swapped)到磁盘中# 为此需要添加如下 capabilitycap_add:- IPC_LOCK# 必须设定 entrypoint，否则 vault 容器默认以 development 模式运行entrypoint:vault server -config /vault/config/config.hcl config.hcl 内容如下： ui = true // 使用文件做数据存储（单节点） storage \"file\" { path = \"/vault/file\" } listener \"tcp\" { address = \"[::]:8200\" tls_disable = false tls_cert_file = \"/certs/server.crt\" tls_key_file = \"/certs/server.key\" } 将如上两份配置保存在同一文件夹内，同时在 ./certs 中提供 TLS 证书 server.crt 和私钥 server.key。 然后 docker-compose up -d 就能启动运行一个 vault 实例。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:2:2","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"2. 通过 helm 部署高可用的 vault 推荐用于生产环境 通过 helm 部署： # 添加 valut 仓库 helm repo add hashicorp https://helm.releases.hashicorp.com # 查看 vault 版本号 helm search repo hashicorp/vault -l | head # 下载某个版本号的 vault helm pull hashicorp/vault --version 0.11.0 --untar 参照下载下来的 ./vault/values.yaml 编写 custom-values.yaml， 部署一个以 mysql 为后端存储的 HA vault，配置示例如下: 配置内容虽然多，但是大都是直接拷贝自 ./vault/values.yaml，改动很少。 测试 Vault 时可以忽略掉其中大多数的配置项。 global:# enabled is the master enabled switch. Setting this to true or false# will enable or disable all the components within this chart by default.enabled:true# TLS for end-to-end encrypted transporttlsDisable:falseinjector:# True if you want to enable vault agent injection.enabled:truereplicas:1# If true, will enable a node exporter metrics endpoint at /metrics.metrics:enabled:false# Mount Path of the Vault Kubernetes Auth Method.authPath:\"auth/kubernetes\"certs:# secretName is the name of the secret that has the TLS certificate and# private key to serve the injector webhook. If this is null, then the# injector will default to its automatic management mode that will assign# a service account to the injector to generate its own certificates.secretName:null# caBundle is a base64-encoded PEM-encoded certificate bundle for the# CA that signed the TLS certificate that the webhook serves. This must# be set if secretName is non-null.caBundle:\"\"# certName and keyName are the names of the files within the secret for# the TLS cert and private key, respectively. These have reasonable# defaults but can be customized if necessary.certName:tls.crtkeyName:tls.keyserver:# Resource requests, limits, etc. for the server cluster placement. This# should map directly to the value of the resources field for a PodSpec.# By default no direct resource request is made.# Enables a headless service to be used by the Vault Statefulsetservice:enabled:true# Port on which Vault server is listeningport:8200# Target port to which the service should be mapped totargetPort:8200# This configures the Vault Statefulset to create a PVC for audit# logs. Once Vault is deployed, initialized and unseal, Vault must# be configured to use this for audit logs. This will be mounted to# /vault/audit# See https://www.vaultproject.io/docs/audit/index.html to know moreauditStorage:enabled:false# Run Vault in \"HA\" mode. There are no storage requirements unless audit log# persistence is required. In HA mode Vault will configure itself to use Consul# for its storage backend. The default configuration provided will work the Consul# Helm project by default. It is possible to manually configure Vault to use a# different HA backend.ha:enabled:truereplicas:3# Set the api_addr configuration for Vault HA# See https://www.vaultproject.io/docs/configuration#api_addr# If set to null, this will be set to the Pod IP AddressapiAddr:null# config is a raw string of default configuration when using a Stateful# deployment. Default is to use a Consul for its HA storage backend.# This should be HCL.# Note: Configuration files are stored in ConfigMaps so sensitive data # such as passwords should be either mounted through extraSecretEnvironmentVars# or through a Kube secret. For more information see: # https://www.vaultproject.io/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurationsconfig:|ui = true listener \"tcp\" { address = \"[::]:8200\" cluster_address = \"[::]:8201\" # 注意，这个值要和 helm 的参数 global.tlsDisable 一致 tls_disable = false tls_cert_file = \"/etc/certs/vault.crt\" tls_key_file = \"/etc/certs/vault.key\" } # storage \"postgresql\" { # connection_url = \"postgres://username:password@\u003chost\u003e:5432/vault?sslmode=disable\" # ha_enabled = true # } service_registration \"kubernetes\" {} # Example configuration for using auto-unseal, using AWS KMS. # the cluster must have a service account that is authorized to access AWS KMS, throught an IAM Role. # seal \"awskms\" { # region = \"us-east-1\" # kms_key_id = \"\u003csome-key-id\u003e\" # 默认情况下插件会使用 awskms 的公网 enpoint，但是也可以使用如下参数，改用自行创建的 vpc 内网 endpoint # endpoint = \"https:/","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:2:3","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"3. 初始化并解封 vault 官方文档：Initialize and unseal Vault - Vault on Kubernetes Deployment Guide 通过 helm 部署 vault，默认会部署一个三副本的 StatefulSet，但是这三个副本都会处于 NotReady 状态（docker 方式部署的也一样）。 接下来还需要手动初始化并解封 vault，才能 Ready: 第一步：从三个副本中随便选择一个，运行 vault 的初始化命令：kubectl exec -ti vault-0 -- vault operator init 初始化操作会返回 5 个 unseal keys，以及一个 Initial Root Token，这些数据非常敏感非常重要，一定要保存到安全的地方！ 第二步：在每个副本上，使用任意三个 unseal keys 进行解封操作。 一共有三个副本，也就是说要解封 3*3 次，才能完成 vault 的完整解封！ # 每个实例都需要解封三次！ ## Unseal the first vault server until it reaches the key threshold $ kubectl exec -ti vault-0 -- vault operator unseal # ... Unseal Key 1 $ kubectl exec -ti vault-0 -- vault operator unseal # ... Unseal Key 2 $ kubectl exec -ti vault-0 -- vault operator unseal # ... Unseal Key 3 这样就完成了部署，但是要注意，vault 实例每次重启后，都需要重新解封！也就是重新进行第二步操作！ ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:2:4","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"4. 初始化并设置自动解封 在未设置 auto unseal 的情况下，vault 每次重启都要手动解封所有 vault 实例，实在是很麻烦，在云上自动扩缩容的情况下，vault 实例会被自动调度，这种情况就更麻烦了。 为了简化这个流程，可以考虑配置 auto unseal 让 vault 自动解封。 自动解封目前有两种方法： 使用阿里云/AWS/Azure 等云服务提供的密钥库来管理 encryption key AWS: awskms Seal 如果是 k8s 集群，vault 使用的 ServiceAccount 需要有权限使用 AWS KMS，它可替代掉 config.hcl 中的 access_key/secret_key 两个属性 阿里云：alicloudkms Seal 如果你不想用云服务，那可以考虑 autounseal-transit，这种方法使用另一个 vault 实例提供的 transit 引擎来实现 auto-unseal. 简单粗暴：直接写个 crontab 或者在 CI 平台上加个定时任务去执行解封命令，以实现自动解封。不过这样安全性就不好说了。 以使用 awskms 为例，首先创建 aws IAM 的 policy 内容如下: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VaultKMSUnseal\", \"Effect\": \"Allow\", \"Action\": [ \"kms:Decrypt\", \"kms:Encrypt\", \"kms:DescribeKey\" ], \"Resource\": \"*\" } ] } 然后创建 IAM Role 绑定上面的 policy，并为 vault 的 k8s serviceaccount 创建一个 IAM Role，绑定上这个 policy. 这样 vault 使用的 serviceaccount 自身就拥有了访问 awskms 的权限，也就不需要额外通过 access_key/secret_key 来访问 awskms. 关于 IAM Role 和 k8s serviceaccount 如何绑定，参见官方文档：IAM roles for EKS service accounts 完事后再修改好前面提供的 helm 配置，部署它，最后使用如下命令初始化一下： # 初始化命令和普通模式并无不同 kubectl exec -ti vault-0 -- vault operator init # 会打印出一个 root token，以及五个 Recovery Key（而不是 Unseal Key） # Recover Key 不再用于解封，但是重新生成 root token 等操作仍然会需要用到它. 然后就大功告成了，可以尝试下删除 vault 的 pod，新建的 Pod 应该会自动解封。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:2:5","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"三、Vault 自身的配置管理 Vault 本身是一个复杂的 secrets 工具，它提供了 Web UI 和 CLI 用于手动管理与查看 Vault 的内容。 但是作为一名 DevOps，我们当然更喜欢自动化的方法，这有两种选择: 使用 vault 的 sdk: python-hvac 使用 terraform-provider-vault 或者 pulumi-vault 实现 vault 配置的自动化管理。 Web UI 适合手工操作，而 sdk/terraform-provider-vault 则适合用于自动化管理 vault. 我们的测试环境就是使用 pulumi-vault 完成的自动化配置 vault policy 和 kubernetes role，然后自动化注入所有测试用的 secrets. ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:3:0","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"1. 使用 pulumi 自动化配置 vault 使用 pulumi 管理 vault 配置的优势是很大的，因为云上资源的敏感信息（数据库账号密码、资源 ID、RAM子账号）都是 pulumi 创建的。 再结合使用 pulumi_valut，就能实现敏感信息自动生成后，立即保存到 vault 中，实现完全自动化。 后续微服务就可以通过 kubernetes 认证，直接从 vault 读取敏感信息。 或者是写入到本地的 vault 中留做备份，在需要的时候，管理员能登入进去查看相关敏感信息。 1.1 Token 的生成 pulumi_vault 本身挺简单的，声明式的配置嘛，直接用就是了。 但是它一定要求提供 VAULT_TOKEN 作为身份认证的凭证（实测 userpass/approle 都不能直接使用，会报错 no vault token found），而且 pulumi 还会先生成临时用的 child token，然后用这个 child token 进行后续的操作。 首先安全起见，肯定不应该直接提供 root token！root token 应该封存，除了紧急情况不应该启用。 那么应该如何生成一个权限有限的 token 给 vault 使用呢？ 我的方法是创建一个 userpass 账号，通过 policy 给予它有限的权限。 然后先手动(或者自动)登录获取到 token，再将 token 提供给 pulumi_vault 使用。 这里面有个坑，就是必须给 userpass 账号创建 child token 的权限： path \"local/*\" { capabilities = [\"read\", \"list\"] } // 允许创建 child token path \"auth/token/create\" { capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\"] } 不给这个权限，pulumi_vault 就会一直报错。。 然后还得给它「自动化配置」需要的权限，比如自动创建/更新 policy/secrets/kubernetes 等等，示例如下: # To list policies - Step 3 path \"sys/policy\" { capabilities = [\"read\"] }# Create and manage ACL policies broadly across Vault path \"sys/policy/*\" { capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\", \"sudo\"] }# List, create, update, and delete key/value secrets path \"secret/*\" { capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\", \"sudo\"] } path \"auth/kubernetes/role/*\" { capabilities = [\"create\", \"read\", \"update\", \"list\"] } ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:3:1","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"四、在 Kubernetes 中使用 vault 注入 secrets vault-k8s-auth-workflow\" vault-k8s-auth-workflow 前面提到过 vault 支持通过 Kubernetes 的 ServiceAccount 为每个 Pod 单独分配权限。 应用程序有两种方式去读取 vault 中的配置： 借助 Vault Sidecar，将 secrets 以文件的形式自动注入到 Pod 中，比如 /vault/secrets/config.json vault sidecar 在常驻模式下每 15 秒更新一次配置，应用程序可以使用 watchdog 实时监控 secrets 文件的变更。 应用程序自己使用 SDK 直接访问 vault api 获取 secrets 上述两种方式，都可以借助 Kubernetes ServiceAccount 进行身份验证和权限分配。 下面以 Sidecar 模式为例，介绍如何将 secrets 以文件形式注入到 Pod 中。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:4:0","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"1. 部署并配置 vault agent 首先启用 Vault 的 Kubernetes 身份验证: # 配置身份认证需要在 vault pod 中执行，启动 vault-0 的交互式会话 kubectl exec -n vault -it vault-0 -- /bin/sh export VAULT_TOKEN='\u003cyour-root-token\u003e' export VAULT_ADDR='http://localhost:8200' # 启用 Kubernetes 身份验证 vault auth enable kubernetes # kube-apiserver API 配置，vault 需要通过 kube-apiserver 完成对 serviceAccount 的身份验证 vault write auth/kubernetes/config \\ token_reviewer_jwt=\"$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)\" \\ kubernetes_host=\"https://$KUBERNETES_PORT_443_TCP_ADDR:443\" \\ kubernetes_ca_cert=@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt 1.1 使用集群外部的 valut 实例 如果你没这个需求，请跳过这一节。 详见 Install the Vault Helm chart configured to address an external Vault kubernetes 也可以和外部的 vault 实例集成，集群中只部署 vault-agent. 这适用于多个 kubernetes 集群以及其他 APP 共用一个 vault 实例的情况，比如我们本地的多个开发测试集群，就都共用着同一个 vault 实例，方便统一管理应用的 secrets. 首先，使用 helm chart 部署 vault-agent，接入外部的 vault 实例。使用的 custom-values.yaml 示例如下： global:# enabled is the master enabled switch. Setting this to true or false# will enable or disable all the components within this chart by default.enabled:true# TLS for end-to-end encrypted transporttlsDisable:falseinjector:# True if you want to enable vault agent injection.enabled:truereplicas:1# If multiple replicas are specified, by default a leader-elector side-car# will be created so that only one injector attempts to create TLS certificates.leaderElector:enabled:trueimage:repository:\"gcr.io/google_containers/leader-elector\"tag:\"0.4\"ttl:60s# If true, will enable a node exporter metrics endpoint at /metrics.metrics:enabled:false# External vault server address for the injector to use. Setting this will# disable deployment of a vault server along with the injector.# TODO 这里的 https ca.crt 要怎么设置？mTLS 又该如何配置？externalVaultAddr:\"https://\u003cexternal-vault-url\u003e\"# Mount Path of the Vault Kubernetes Auth Method.authPath:\"auth/kubernetes\"certs:# secretName is the name of the secret that has the TLS certificate and# private key to serve the injector webhook. If this is null, then the# injector will default to its automatic management mode that will assign# a service account to the injector to generate its own certificates.secretName:null# caBundle is a base64-encoded PEM-encoded certificate bundle for the# CA that signed the TLS certificate that the webhook serves. This must# be set if secretName is non-null.caBundle:\"\"# certName and keyName are the names of the files within the secret for# the TLS cert and private key, respectively. These have reasonable# defaults but can be customized if necessary.certName:tls.crtkeyName:tls.key 部署命令和 通过 helm 部署 vault 一致，只要更换 custom-values.yaml 就行。 vault-agent 部署完成后，第二步是为 vault 创建 serviceAccount、secret 和 ClusterRoleBinding，以允许 vault 审查 kubernetes 的 token, 完成对 pod 的身份验证. yaml 配置如下： ---apiVersion:v1kind:ServiceAccountmetadata:name:vault-authnamespace:vault---apiVersion:v1kind:Secretmetadata:name:vault-authnamespace:vaultannotations:kubernetes.io/service-account.name:vault-authtype:kubernetes.io/service-account-token---apiVersion:rbac.authorization.k8s.io/v1beta1kind:ClusterRoleBindingmetadata:name:role-tokenreview-bindingroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:system:auth-delegatorsubjects:- kind:ServiceAccountname:vault-authnamespace:vault 现在在 vault 实例这边，启用 kubernetes 身份验证，在 vault 实例内，执行如下命令： vault 实例内显然没有 kubectl 和 kubeconfig，简便起见，下列的 vault 命令也可以通过 Web UI 完成。 export VAULT_TOKEN='\u003cyour-root-token\u003e' export VAULT_ADDR='http://localhost:8200' # 启用 Kubernetes 身份验证 vault auth enable kubernetes # kube-apiserver API 配置，vault 需要通过 kube-apiserver 完成对 serviceAccount 的身份验证 # TOKEN_REVIEW_JWT: 就是我们前面创建的 secret `vault-auth` TOKEN_REVIEW_JWT=$(kubectl -n vault get secret vault-auth -o go-template='{{ .data.token }}' | base64 --decode) # kube-apiserver 的 ca 证书 KUBE_CA_CERT=$(kubectl -n vault config view --raw --minify --flatten -o jsonpath='{.clusters[].cluster.certificate-authority-data}' | base64 --decode) # kube-apiserver 的 url KUBE_HOST=$(kubectl config view --raw --minify","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:4:1","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"2. 关联 k8s rbac 权限系统和 vault 接下来需要做的事： 通过 vault policy 定义好每个 role（微服务）能访问哪些资源。 为每个微服务生成一个 role，这个 role 需要绑定对应的 vault policy 及 kubernetes serviceaccount 这个 role 是 vault 的 kubernetes 插件自身的属性，它和 kubernetes role 没有半毛钱关系。 创建一个 ServiceAccount，并使用这个 使用这个 ServiceAccount 部署微服务 其中第一步和第二步都可以通过 vault api 自动化完成. 第三步可以通过 kubectl 部署时完成。 方便起见，vault policy / role / k8s serviceaccount 这三个配置，都建议和微服务使用相同的名称。 上述配置中，role 起到一个承上启下的作用，它关联了 k8s serviceaccount 和 vault policy 两个配置。 比如创建一个名为 my-app-policy 的 vault policy，内容为: # 允许读取数据 path \"my-app/data/*\" { capabilities = [\"read\", \"list\"] } // 允许列出 myapp 中的所有数据(kv v2) path \"myapp/metadata/*\" { capabilities = [\"read\", \"list\"] } 然后在 vault 的 kuberntes 插件配置中，创建 role my-app-role，配置如下: 关联 k8s default 名字空间中的 serviceaccount my-app-account，并创建好这个 serviceaccount. 关联 vault token policy，这就是前面创建的 my-app-policy 设置 token period（有效期） 这之后，每个微服务就能通过 serviceaccount 从 vault 中读取 my-app 中的所有信息了。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:4:2","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"3. 部署 Pod 参考文档：https://www.vaultproject.io/docs/platform/k8s/injector 下一步就是将配置注入到微服务容器中，这需要使用到 Agent Sidecar Injector。 vault 通过 sidecar 实现配置的自动注入与动态更新。 具体而言就是在 Pod 上加上一堆 Agent Sidecar Injector 的注解，如果配置比较多，也可以使用 configmap 保存，在注解中引用。 需要注意的是 vault-inject-agent 有两种运行模式： init 模式: 仅在 Pod 启动前初始化一次，跑完就退出（Completed） 常驻模式: 容器不退出，持续监控 vault 的配置更新，维持 Pod 配置和 vualt 配置的同步。 示例： apiVersion:apps/v1kind:Deploymentmetadata:labels:app:my-appname:my-appnamespace:defaultspec:minReadySeconds:3progressDeadlineSeconds:60revisionHistoryLimit:3selector:matchLabels:app:my-appstrategy:rollingUpdate:maxUnavailable:1type:RollingUpdatetemplate:metadata:annotations:vault.hashicorp.com/agent-init-first:'true'# 是否使用 initContainer 提前初始化配置文件vault.hashicorp.com/agent-inject:'true'vault.hashicorp.com/secret-volume-path:vaultvault.hashicorp.com/role:\"my-app-role\"# vault kubernetes 插件的 role 名称vault.hashicorp.com/agent-inject-template-config.json:|# 渲染模板的语法在后面介绍vault.hashicorp.com/agent-limits-cpu:250mvault.hashicorp.com/agent-requests-cpu:100m# 包含 vault 配置的 configmap，可以做更精细的控制# vault.hashicorp.com/agent-configmap: my-app-vault-configlabels:app:my-appspec:containers:- image:registry.svc.local/xx/my-app:latestimagePullPolicy:IfNotPresent# 此处省略若干配置...serviceAccountName:my-app-account 常见错误： vault-agent(sidecar) 报错: namespace not authorized auth/kubernetes/config 中的 role 没有绑定 Pod 的 namespace vault-agent(sidecar) 报错: permission denied 检查 vault 实例的日志，应该有对应的错误日志，很可能是 auth/kubernetes/config 没配对，vault 无法验证 kube-apiserver 的 tls 证书，或者使用的 kubernetes token 没有权限。 vault-agent(sidecar) 报错: service account not authorized auth/kubernetes/config 中的 role 没有绑定 Pod 使用的 serviceAccount ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:4:3","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"4. vault agent 配置 vault-agent 的配置，需要注意的有： 如果使用 configmap 提供完整的 config.hcl 配置，注意 agent-init vautl-agent 的 template 说明： 目前来说最流行的配置文件格式应该是 json/yaml，以 json 为例， 对每个微服务的 kv 数据，可以考虑将它所有的个性化配置都保存在 \u003cengine-name\u003e/\u003cservice-name\u003e/ 下面，然后使用如下 template 注入配置： { {{ range secrets \"\u003cengine-name\u003e/metadata/\u003cservice-name\u003e/\" }} \"{{ printf \"%s\" . }}\": {{ with secret (printf \"\u003cengine-name\u003e/\u003cservice-name\u003e/%s\" .) }} {{ .Data.data | toJSONPretty }}, {{ end }} {{ end }} } template 的详细语法参见: https://github.com/hashicorp/consul-template#secret 注意：v2 版本的 kv secrets，它的 list 接口有变更，因此在遍历 v2 kv secrets 时， 必须要写成 range secrets \"\u003cengine-name\u003e/metadata/\u003cservice-name\u003e/\"，也就是中间要插入 metadata，而且 policy 中必须开放 \u003cengine-name\u003e/metadata/\u003cservice-name\u003e/ 的 read/list 权限！ 官方文档完全没提到这一点，我通过 wireshark 抓包调试，对照官方的 KV Secrets Engine - Version 2 (API) 才搞明白这个。 这样生成出来的内容将是 json 格式，不过有个不兼容的地方：最后一个 secrets 的末尾有逗号 , 渲染出的效果示例： { \"secret-a\": { \"a\": \"b\", \"c\": \"d\" }, \"secret-b\": { \"v\": \"g\", \"r\": \"c\" }, } 因为存在尾部逗号(trailing comma)，直接使用 json 标准库解析它会报错。 那该如何去解析它呢？我在万能的 stackoverflow 上找到了解决方案：yaml 完全兼容 json 语法，并且支持尾部逗号！ 以 python 为例，直接 yaml.safe_load() 就能完美解析 vault 生成出的 json 内容。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:4:4","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"5. 拓展：在 kubernetes 中使用 vault 的其他姿势 除了使用官方提供的 sidecar 模式进行 secrets 注入，社区也提供了一些别的方案，可以参考： hashicorp/vault-csi-provider: 官方的 Beta 项目，通过 Secrets Store CSI 驱动将 vault secrets 以数据卷的形式挂载到 pod 中 kubernetes-external-secrets: 提供 CRD 定义，根据定义将 secret 从 vault 中同步到 kubernetes secrets 官方的 sidecar/init-container 模式仍然是最推荐使用的。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:4:5","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":"五、使用 vault 实现 AWS IAM Credentials 的自动轮转 待续。。。 ","date":"2021-01-24","objectID":"/posts/expirence-of-vault/:5:0","tags":["Vault","云原生","Secrets","配置","配置管理"],"title":"secrets 管理工具 Vault 的介绍、安装及使用","uri":"/posts/expirence-of-vault/"},{"categories":["技术"],"content":" 个人笔记，并非教程！只适合当成参考手册，按目录选读。 如果希望深入学习，建议阅读 Practical Cryptography for Developers ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:0:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"更新记录 补充 TLS 协议的详细流程 完成 TLS 证书的详细介绍 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:1:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"一、TLS 协议 我们需要加密网络数据以实现安全通信，但是有一个现实的问题： 非对称加密算法（RSA/ECC 等）可以方便地对数据进行签名/验证，但是计算速度慢。 对称加密算法（ChaCha20/AES 等）计算速度快，强度高，但是无法安全地生成与保管密钥。 TLS 协议巧妙地解决了这个问题：它在握手阶段使用「非对称算法」验证服务端，并使用 ECDHE 密钥交换算法（Elliptic Curve Diffie-Hellman key exchange）安全地生成一个临时的对称密钥，然后使用「对称算法」进行加密通信。 在后续的每次数据交换过程中，TLS 协议都会使用 ECDHE 算法生成新的对称密钥，再使用新密钥加密解密数据。 perfect-forward-secrecy-diagram\" perfect-forward-secrecy-diagram TLS 协议通过上述的流程，提供了「完美前向保密（Perfect Forward Secrecy）」特性，也就是说它能够保护过去进行的通讯不受密钥在未来暴露的威胁。 即使攻击者破解出了一个「对称密钥」，也只能获取到一次事务中的数据，黑客必须破解出整个 TLS 连接中所有事务的对称密钥，才能得到完整的数据。 早期的 tls1.1/tls1.2 使用的不少算法，都不是前向安全的，从安全角度上讲建议使用 tls1.3，或者 tls1.2 + 前向安全的算法。 本文主要介绍 TLS 协议的使用、TLS 证书的生成，不涉及具体算法实现及协议细节。 接下来讲下证书，TLS 协议通过两个证书来实现服务端身份验证，以及对称密钥的安全生成： CA 证书：浏览器/操作系统自带，用于验证服务端 TLS 证书的签名。保证服务端证书可信。 TLS 证书（服务端证书）：浏览器验证了服务端 TLS 证书可信后，将使用这个 TLS 证书与服务端进行协议/算法协商，以安全地生成一个对称密钥。 CA 证书和 TLS 证书，都只在 TLS 握手阶段有用到，之后的通信就与它们无关了。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:2:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"二、TLS 证书介绍 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:3:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"1. 证书是什么？ 证书是一个文件，目前主流的证书规范为 X.509，由 RFC5280 定义。 简单的说，证书其实就是非对称加密中的公钥，加上一些别的信息组成的一个文件。 比如 CA 证书，就是「CA 公钥 + CA 机构相关信息」构成的一个文件。 而 TLS 证书，则主要包含「公钥 + 申请者信息(你) + 颁发者(CA)的信息 + 签名(使用 CA 私钥加密的证书 Hash)」，以及一些其他相关信息。 因为 TLS 证书的签名是使用 CA 证书生成的，因此使用 CA 证书的公钥就能验证 TLS 证书签名的正确性，也就能判断该证书是否可信。 现实中的 CA 证书实际上还要复杂些，通常证书颁发机构的权威证书的私钥是受到严格保护的，根证书会签发许多中间证书，形成一个 CA 证书链。TLS 证书 由 CA 证书链最末端的证书对 TLS 证书进行签名。 另外还有复杂的证书吊销机制，这里就不详细介绍了。 你可以尝试使用浏览器查看 Google 的证书详情，我使用 Firefox 查看到的内容如下： cert-content\" cert-content ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:3:1","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"2. TLS 证书支持保护的域名类型 TLS 证书支持配置多个域名，并且支持所谓的通配符（泛）域名。 但是通配符域名证书的匹配规则，和 DNS 解析中的匹配规则并不一致！ 根据证书选型和购买 - 阿里云文档 的解释，通配符证书只支持同级匹配，详细说明如下： 一级通配符域名：可保护该通配符域名（主域名）自身和该域名所有的一级子域名。 例如：一级通配符域名 *.aliyun.com 可以用于保护 aliyun.com、www.aliyun.com 以及其他所有一级子域名。 但是不能用于保护任何二级子域名，如 xx.aa.aliyun.com 二级或二级以上通配符域名：只能保护该域名同级的所有通配域名，不支持保护该通配符域名本身。 例如：*.a.aliyun.com 只支持保护它的所有同级域名，不能用于保护三级子域名。 要想保护多个二三级子域，只能在生成 TLS 证书时，添加多个通配符域名。 因此设计域名规则时，要考虑到这点，尽量不要使用层级太深的域名！有些信息可以通过 - 来拼接以减少域名层级，比如阿里云的 oss 域名： 公网：oss-cn-shenzhen.aliyuncs.com 内网：oss-cn-shenzhen-internal.aliyuncs.com ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:3:2","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"三、TLS 证书的生成 OpenSSL 是目前使用最广泛的网络加密算法库，这里以它为例介绍证书的生成。 另外也可以考虑使用 cfssl. 先回顾下，前面讲了 TLS 协议握手需要使用到两个证书： TLS 证书（服务端证书）：这个是服务端需要配置的数据加密证书。 服务端需要持有这个 TLS 证书本身，以及证书的私钥。 握手时服务端需要将 TLS 证书发送给客户端。 CA 证书：这是受信的根证书，客户端可用于验证所有使用它进行签名的 TLS 证书。 CA 证书的私钥由权威机构持有，客户端（比如浏览器）则保有 CA 证书自身。 在 TLS 连接的建立阶段，客户端（如浏览器）会使用 CA 证书的公钥对服务端的证书签名进行验证，验证成功则说明该证书是受信任的。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:4:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"1. TLS 证书的类型 按照证书的生成方式进行分类，证书有三种类型： 由权威 CA 机构签名的 TLS 证书：这类证书会被浏览器、小程序等第三方应用/服务商信任。申请证书时需要验证你的所有权，也就使证书无法伪造。 如果你的 API 需要提供给第三方应用/服务商/浏览器访问，那就必须向权威 CA 机构申请此类证书。 本地签名证书 - tls_locally_signed_cert：即由本地 CA 证书签名的 TLS 证书 本地 CA 证书，就是自己使用 openssl 等工具生成的 CA 证书。 这类证书不会被浏览器/小程序等第三方应用/服务商信任，证书就可以被伪造。 这类证书的缺点是无法与第三方应用/服务商建立安全的连接。 如果客户端是完全可控的（比如是自家的 APP），那可以自行验证证书的可靠性（公钥锁定、双向 TLS 验证）。这种场景下使用此类证书是安全可靠的。可以不使用权威CA机构颁发的证书。 自签名证书 - tls_self_signed_cert: 和 tls_locally_signed_cert 类似，但使用 TLS 证书自己充当 CA 证书（我签我自己），生成出的证书就叫自签名证书。 注意:更广义地讲，自签名证书，就是「并非由权威 CA 机构签名的 TLS 证书」，也就是同时指代了 tls_self_signed_cert 和 tls_locally_signed_cert。这也是「自签名证书」应用最广泛的一种含义。 总的来说，权威CA机构颁发的证书，可以被第三方的应用信任，但是自己生成的不行。 而越贵的权威证书，安全性与可信度就越高，或者可以保护更多的域名。 在客户端可控的情况下，可以考虑使用「本地签名证书」（方便、省钱），将这个证书预先埋入客户端中用于验证。 而「自签名证书」主要是方便，能不用还是尽量不要使用。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:4:1","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"2. 向权威CA机构申请「受信 TLS 证书」 免费的 TLS 证书有两种方式获取： 部分 TLS 提供商有提供免费证书的申请，有效期为一年，但是不支持泛域名。 申请 Let’s Encrypt 免费证书 很多代理工具都有提供 Let’s Encrypt 证书的 Auto Renewal，比如: Traefik Caddy docker-letsencrypt-nginx-proxy-companion 网上也有一些 certbot 插件，可以通过 DNS 提供商的 API 进行 Let’s Encrypt 证书的 Auto Renewal，比如： certbot-dns-aliyun terraform 也有相关 provider: terraform-provider-acme 收费证书可以在各 TLS 提供商处购买，比如国内的阿里云腾讯云等。 完整的证书申请流程如下： 证书申请流程\" 证书申请流程 为了方便用户，图中的申请人(Applicant)自行处理的部分，目前很多证书申请网站也可以自动处理，用户只需要提供相关信息即可。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:4:2","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"3. 生成「本地签名证书」或者「自签名证书」 除了被第三方信任的「受信 TLS 证书」，在内网环境，我们需要也使用 TLS 证书保障通信安全，这时我们可能会选择自己生成证书，而不是向权威机构申请证书。 可能的原因如下： 要向权威机构申请证书，那是要给钱的。而在内网环境下，并无必要使用权威证书。 内网环境使用的可能是非公网域名（xxx.local/xxx.lan/xxx.srv 等），权威机构不签发这种域名的证书。（因为没有人唯一地拥有这个域名） 前面介绍过，自己生成的证书有两种方类型： 本地签名证书：生成两个独立的密钥对，一个用于 CA 证书，另一个用于 TLS 证书。使用 CA 证书对 TLS 证书进行签名。 自签名证书（我签我自己）：TLS 证书和 CA 证书都使用同一个密钥对，使用 TLS 证书对它自己进行签名。 测试发现这种方式得到的证书貌似不包含 SAN 属性！因此不支持多域名。 一般来说，直接生成一个泛域名的「自签名证书」就够了，但是它不方便拓展——客户端对每个「自签名证书」，都需要单独添加一次信任。 而「本地签名证书」就没这个问题，one ca.crt rules them all. 总的来说，使用「自签名证书」不方便进行拓展，未来可能会遇到麻烦。因此建议使用「本地签名证书」。 另外介绍下这里涉及到的几种文件类型： xxx.key: 就是一个私钥，一般是一个 RSA 私钥，长度通常指定为 2048 位。 CA 证书和 TLS 证书的私钥都是通过这种方式生成的。 xxx.csr: 即 Certificate Sign Request，证书签名请求。使用 openssl 等工具，通过 TLS 密钥+TLS 证书的相关信息，可生成出一个 CSR 文件。 域名（Common Name, CN）就是在这里指定的，可以使用泛域名。 用户将 csr 文件发送给 CA 机构，进行进一步处理。 xxx.crt: 这就是我们所说的 TLS 证书，CA 证书和服务端 TLS 证书都是这个格式。 使用 CA 证书、CA 密钥对 csr 文件进行签名，就能得到最终的服务端 TLS 证书——一个 crt 文件。 生成一个「自签名证书」或者「本地签名证书」（RSA256 算法），有两个步骤： 编写证书签名请求的配置文件 csr.conf: [ req ] default_bits = 2048 prompt = no default_md = sha256 req_extensions = req_ext distinguished_name = dn [ dn ] C = CN # Contountry ST = \u003cstate\u003e L = \u003ccity\u003e O = \u003corganization\u003e OU = \u003corganization unit\u003e CN = *.svc.local # 泛域名，这个字段已经被 chrome/apple 弃用了。 [ alt_names ] # 备用名称，chrome/apple 目前只信任这里面的域名。 DNS.1 = *.svc.local # 一级泛域名 DNS.2 = *.aaa.svc.local # 二级泛域名 DNS.3 = *.bbb.svc.local # 二级泛域名 [ req_ext ] subjectAltName = @alt_names [ v3_ext ] subjectAltName=@alt_names # Chrome 要求必须要有 subjectAltName(SAN) authorityKeyIdentifier=keyid,issuer:always basicConstraints=CA:FALSE keyUsage=keyEncipherment,dataEncipherment,digitalSignature extendedKeyUsage=serverAuth,clientAuth 此文件的详细文档：OpenSSL file formats and conventions 生成证书： # 1. 生成 2048 位 的 RSA 密钥 openssl genrsa -out server.key 2048 # 2. 通过第一步编写的配置文件，生成证书签名请求（公钥+申请者信息） openssl req -new -key server.key -out server.csr -config csr.conf # 3. 生成最终的证书，这里指定证书有效期 3650 天 ## 3.1 方法一（自签名）：使用 server.key 进行自签名。这种方式得到的证书不包含 SAN！不支持多域名！ openssl req -x509 -sha256 -days 3650 -key server.key -in server.csr -out server.crt ## 3.2 方法二（本地签名）：生成 ca 证书，并且使用 CA 证书、CA 密钥对 `csr` 文件进行签名 ### 3.2.1 ca 私钥 openssl genrsa -out ca.key 2048 ### 3.2.2 ca 证书，ca 证书的有效期尽量设长一点，因为不方便更新换代。 openssl req -x509 -new -nodes -key ca.key -subj \"/CN=MyLocalRootCA\" -days 10000 -out ca.crt ### 3.2.3 签名，得到最终的 TLS 证书，它包含四部分内容：公钥+申请者信息 + 颁发者(CA)的信息+签名(使用 CA 私钥加密) openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \\ -CAcreateserial -out server.crt -days 3650 \\ -extensions v3_ext -extfile csr.conf 上述流程生成一个 x509 证书链，详细的参数说明，参见 RFC5280 - Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:4:3","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"4. 关于证书寿命 对于公开服务，服务端证书的有效期不要超过 825 天（27 个月）！而 2020 年 11 月起，新申请的服务端证书有效期缩短到了 398 天（13 个月）。目前 Apple/Mozilla/Chrome 都发表了相应声明，证书有效期超过上述限制的，将被浏览器/Apple设备禁止使用。 对于其他用途的证书，如果更换起来很麻烦，可以考虑放宽条件。 比如 kubernetes 集群的加密证书，可以考虑有效期设长一些，比如 10 年。 据云原生安全破局｜如何管理周期越来越短的数字证书？所述，大量知名企业如 特斯拉/微软/领英/爱立信 都曾因未及时更换 TLS 证书导致服务暂时不可用。 因此 TLS 证书最好是设置自动轮转！人工维护不可靠！ 目前很多 Web 服务器/代理，都支持自动轮转 Let’s Encrypt 证书。 另外 Vault 等安全工具，也支持自动轮转私有证书。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:4:4","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"5. 拓展1：基于 ECC 算法的 TLS 证书 Let’s Encrypt 目前也已经支持了 ECC 证书。 ECC(Elliptic Curve Cryptography) 算法被认为是比 RSA 更优秀的算法。与 RSA 算法相比，ECC 算法使用更小的密钥大小，但可提供同样的安全性，这使计算更快，降低了能耗，并节省了内存和带宽。 对于 RSA 密钥，可以提供不同的密钥大小（密钥大小越大，加密效果越好）。 而对于 ECC 密钥，您应选择要用哪种曲线生成密钥对。各个组织（ANSI X9.62、NIST、SECG）命名了多种曲线，可通过如下命名查看 openssl 支持的所有椭圆曲线名称： openssl ecparam -list_curves 生成一个自签名的 ECC 证书的命令示例如下： # 生成 ec 算法的私钥，使用 prime256v1 算法，密钥长度 256 位。（强度大于 2048 位的 RSA 密钥） openssl ecparam -genkey -name prime256v1 -out key.pem # 生成证书签名请求，需要输入域名(Common Name, CN)等相关信息 openssl req -new -sha256 -key key.pem -out csr.csr -config csr.conf # 生成最终的证书，这里指定证书有效期 10 年 ## 方法一：自签名证书 openssl req -x509 -sha256 -days 3650 -key key.pem -in csr.csr -out certificate.pem ## 方法二：使用 ca 进行签名，方法参考前面 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:4:5","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"6. 拓展2：使用 OpenSSL 生成 SSH/JWT 密钥对 RSA/ECC 这两类非对称加密算法被广泛的应用在各类加密通讯中。 SSH/JWT 都支持 RSA-SHA256 及 ECDSA-SHA256 等基于 RSA/ECDSA 的签名/加密算法，因此使用 OpenSSL 生成的密钥对，也应该能用于 SSH 协议加密、JWT 签名等场景。 目前有两种基于 ECC 和 DSA 的椭圆曲线签名算法：ECDSA 和 EdDSA(ed25519)，其中 ECDSA 的文档在曲线选择方面语焉不详，被认为可能存在安全隐患（政治和技术两方面带来的）。 既然 SSH/TLS/JWT 使用的是相同的密钥对，那理所当然地，SSH/JWT 密钥对应该也可以通过 OpenSSL 生成出来。 生成 RSA 密钥对的命令如下： # 1. 生成 2048 位（不是 256 位）的 RSA 密钥 openssl genrsa -out rsa-private-key.pem 2048 # 2. 通过密钥生成公钥，JWT 使用此公钥验证签名 openssl rsa -in rsa-private-key.pem -pubout -out rsa-public-key.pem # 3. SSH 使用专用的公钥格式，需要使用 ssh-keygen 转换下格式 ssh-keygen -i -mPKCS8 -f rsa-public-key.pem -y \u003e rsa-public.pub 生成 ECC 密钥对的命令如下： # 1. 生成 ec 算法的私钥，使用 prime256v1 算法，密钥长度 256 位。（强度大于 2048 位的 RSA 密钥） openssl ecparam -genkey -name prime256v1 -out ecc-private-key.pem # 2. 通过密钥生成公钥 openssl ec -in ecc-private-key.pem -pubout -out ecc-public-key.pem # 3. SSH 使用专用的公钥格式，需要使用 ssh-keygen 转换下格式 ssh-keygen -i -mPKCS8 -f ecc-public-key.pem -y \u003e ecc-public.pub JWT 签名及验证只需要使用标准的私钥-公钥对，即 ecc-private-key.pem/ecc-public-key.pem. 而 SSH 需要使用专用的公钥格式，因此它的使用的密钥对应该是 ecc-private-key.pem/ecc-public.pub 注：SSH 目前推荐使用 ed25519 算法，而 JWT 目前推荐使用 ECDSA 算法。 6.1 加密与签名 加密与解密：公钥用于对数据进行加密，私钥用于对数据进行解密 签名与验证：私钥用于对数据进行签名，公钥用于对签名进行验证 加密与签名的公私钥，用途刚好相反！ ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:4:6","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"四、服务端与客户端的证书配置 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:5:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"1. 服务端的 TLS 证书配置 要支持 HTTPS 协议，服务端需要两个文件： TLS 证书私钥(RSA 私钥或 EC 私钥)：server.key TLS 证书（包含公钥）：server.crt 一般如 Nginx 等服务端应用，都可以通过配置文件指定这两个文件的位置。修改配置后重新启动，就有 TLS 了，可以通过 https 协议访问测试。 1.1 完美前向保密 旧版本的 TLS 协议并不一定能保证前向保密，为了保证前向安全，需要在服务端配置中进行一定设置。 具体的设置方法参见 ssl-config - mozilla，该网站提供三个安全等级的配置： 「Intermediate」：查看生成出的 ssl-cipher 属性，发现它只支持 ECDHE/DHE 开头的算法。因此它保证前向保密。 对于需要通过浏览器访问的 API，推荐选择这个等级。 「Mordern」：只支持 TLSv1.3，该协议废弃掉了过往所有不安全的算法，保证前向保密，安全性极高，性能也更好。 对于不需要通过浏览器等旧终端访问的 API，请直接选择这个等级。 「Old」：除非你的用户使用非常老的终端进行访问，否则请不要考虑这个选项！ 另外阿里云负载均衡器配置前向保密的方法参见：管理TLS安全策略 - 负载均衡 - 阿里云文档 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:5:1","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"2. 客户端的 TLS 证书配置（针对本地签名的证书） 如果你在证书不是权威 CA 机构颁发的（比如是一个自签名证书），那就需要在客户端将这个 TLS 证书添加到受信证书列表中。 这个步骤可以在 OS 层面进行——添加到 OS 的默认证书列表中，也可以在代码层面完成——指定使用某个证书进行 TLS 验证。 Linux: 使用如下命令安装证书 sudo cp ca.crt /usr/local/share/ca-certificates/server.crt sudo update-ca-certificates Windows: 通过证书管理器 certmgr.msc 将证书安装到 受信任的根证书颁发机构，Chrome 的小锁就能变绿了。 编程：使用 HTTPS 客户端的 api 指定使用的 TLS 证书 Docker-Client: 参见 Use self-signed certificates - Docker Docs 2.1 证书锁定(Certifacte Pining)技术 即使使用了 TLS 协议对流量进行加密，并且保证了前向保密，也无法保证流量不被代理！ 这是因为客户端大多是直接依靠了操作系统内置的证书链进行 TLS 证书验证，而 Fiddler 等代理工具可以将自己的 TLS 证书添加到该证书链中。 为了防止流量被 Fiddler 等工具使用上述方式监听流量，出现了「证书锁定」技术。 方法是在客户端中硬编码证书的指纹（Hash值，或者直接保存整个证书的内容也行），在建立 TLS 连接前，先计算使用的证书的指纹是否匹配，否则就中断连接。 这种锁定方式需要以下几个前提才能确保流量不被监听： 客户端中硬编码的证书指纹不会被篡改。 指纹验证不能被绕过。 目前有公开技术（XPosed+JustTrustMe）能破解 Android 上常见的 HTTPS 请求库，直接绕过证书检查。 针对上述问题，可以考虑加大绕过的难度。或者 App 检测自己是否运行在 Xposed 等虚拟环境下。 用于 TLS 协议的证书不会频繁更换。（如果更换了，指纹就对不上了。） 而对于第三方的 API，因为我们不知道它们会不会更换 TLS 证书，就不能直接将证书指纹硬编码在客户端中。 这时可以考虑从服务端获取这些 API 的证书指纹（附带私钥签名用于防伪造）。 为了实现证书的轮转(rotation)，可以在新版本的客户端中包含多个证书指纹，这样能保证同时有多个可信证书，达成证书的轮转。（类比 JWT 的公钥轮转机制） 证书锁定技术几乎等同于 SSH 协议的 StrictHostKeyChecking 选项，客户端会验证服务端的公钥指纹（key fingerprint），验证不通过则断开连接。 2.2 公钥锁定(Public Key Pining) 前面提到过，TLS 证书其实就是公钥+申请者(你)和颁发者(CA)的信息+签名(使用 CA 私钥加密)，因此我们也可以考虑只锁定其中的公钥。 「公钥锁定」比「证书锁定」更灵活，这样证书本身其实就可以直接轮转了（证书有过期时间），而不需要一个旧证书和新证书共存的中间时期。 如果不考虑实现难度的话，「公钥锁定」是更推荐的技术。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:5:2","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"五、TLS 双向认证(Mutual TLS authentication, mTLS) TLS 协议（tls1.0+，RFC: TLS1.2 - RFC5246）中，定义了服务端请求验证客户端证书的方法。这 个方法是可选的。如果使用上这个方法，那客户端和服务端就会在 TLS 协议的握手阶段进行互相认证。这种验证方式被称为双向 TLS 认证(mTLS, mutual TLS)。 传统的「TLS 单向认证」技术，只在客户端去验证服务端是否可信。 而「TLS 双向认证（mTLS）」，则添加了服务端验证客户端是否可信的步骤（第三步）： 客户端发起请求 「验证服务端是否可信」：服务端将自己的 TLS 证书发送给客户端，客户端通过自己的 CA 证书链验证这个服务端证书。 「验证客户端是否可信」：客户端将自己的 TLS 证书发送给服务端，服务端使用它的 CA 证书链验证该客户端证书。 协商对称加密算法及密钥 使用对称加密进行后续通信。 因为相比传统的 TLS，mTLS 只是添加了「验证客户端」这样一个步骤，所以这项技术也被称为「Client Authetication」. mTLS 需要用到两套 TLS 证书： 服务端证书：这个证书签名已经介绍过了。 客户端证书：客户端证书貌似对证书信息（如 CN/SAN 域名）没有任何要求，只要证书能通过 CA 签名验证就行。 使用 openssl 生成 TLS 客户端证书（ca 和 csr.conf 可以直接使用前面生成服务端证书用到的，也可以另外生成）： # 1. 生成 2048 位 的 RSA 密钥 openssl genrsa -out client.key 2048 # 2. 通过第一步编写的配置文件，生成证书签名请求 openssl req -new -key client.key -out client.csr -config csr.conf # 3. 生成最终的证书，这里指定证书有效期 3650 天 ### 使用前面生成的 ca 证书对客户端证书进行签名（客户端和服务端共用 ca 证书） openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key \\ -CAcreateserial -out client.crt -days 3650 \\ -extensions v3_ext -extfile csr.conf mTLS 的应用场景主要在「零信任网络架构」，或者叫「无边界网络」中。 比如微服务之间的互相访问，就可以使用 mTLS。 这样就能保证每个 RPC 调用的客户端，都是其他微服务（或者别的可信方），防止黑客入侵后为所欲为。 目前查到如下几个Web服务器/代理支持 mTLS: Traefik: Docs - Client Authentication (mTLS) Nginx: Using NGINX Reverse Proxy for client certificate authentication 主要参数是两个：ssl_client_certificate /etc/nginx/client-ca.pem 和 ssl_verify_client on ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:6:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"mTLS 的安全性 如果将 mTLS 用在 App 安全上，存在的风险是： 客户端中隐藏的证书是否可以被提取出来，或者黑客能否 Hook 进 App 中，直接使用证书发送信息。 如果客户端私钥设置了「密码（passphrase）」，那这个密码是否能很容易被逆向出来？ mTLS 和「公钥锁定/证书锁定」对比： 公钥锁定/证书锁定：只在客户端进行验证。 但是在服务端没有进行验证。这样就无法鉴别并拒绝第三方应用（爬虫）的请求。 加强安全的方法，是通过某种算法生成动态的签名。爬虫生成不出来这个签名，请求就被拒绝。 mTLS: 服务端和客户端都要验证对方。 保证双边可信，在客户端证书不被破解的情况下，就能 Ban 掉所有的爬虫或代理技术。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:6:1","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"六 TLS 协议的破解手段 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:7:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"1. 客户端逆向/破解手段总结 要获取一个应用的数据，有两个方向： 服务端入侵：现代应用的服务端突破难度通常都比较客户端高，注入等漏洞底层框架就有处理。 客户端逆向+爬虫：客户端是离用户最近的地方，也是最容易被突破的地方。 mTLS 常见的破解手段，是找到老版本的安装包，发现很容易就能提取出客户端证书。。 待续 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:7:1","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"七、通过 OpenSSL 对 TLS 证书进行 CURD（增删查改） ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:8:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"1. 查询与验证 # 查看证书(crt)信息 openssl x509 -noout -text -in server.crt # 查看证书请求(csr)信息 openssl req -noout -text -in server.csr # 查看 RSA 私钥(key)信息 openssl rsa -noout -text -in server.key # 验证证书是否可信 ## 1. 使用系统的证书链进行验证。因为是自签名证书，会验证失败 openssl verify server.crt ## 2. 使用 ca.crt 进行验证。验证成功。 openssl verify -CAfile ca.crt server.crt ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:8:1","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"2. 证书格式转换 openssl 模式使用 PEM 格式的证书，这个证书格式将证书编码为 base64 格式进行保存。 另外一类使用广泛的证书，是 PKCS#12、PKCS#8，以及 Windows 上常用的 DER 格式。 # pem 格式转 pkcs12，公钥和私钥都放里面 openssl pkcs12 -export -in client.crt -inkey client.key -out client.p12 # 按提示输入保护密码 或者 p12 转 pem: openssl pkcs12 -in xxx.p12 -out xxx.crt -clcerts -nokeys openssl pkcs12 -in xxx.p12 -out xxx.key -nocerts -nodes 微信/支付宝等支付相关的数字证书，通常就使用 pkcs12 格式，使用商户号做加密密码，然后编码为 base64 再提供给用户。 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:8:2","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"参考 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:9:0","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"TLS 协议 HTTPS 温故知新（三） —— 直观感受 TLS 握手流程(上) HTTPS 温故知新（五） —— TLS 中的密钥计算 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:9:1","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"TLS 证书 Certificates - Kubernetes Docs TLS/HTTPS 证书生成与验证 ECC作为SSL/TLS证书加密算法的优势 ECC证书的生成和验签 前向保密(Forward Secrecy) - WikiPedia 证书选型和购买 - 阿里云文档 云原生安全破局｜如何管理周期越来越短的数字证书？ 另外两个关于 CN(Common Name) 和 SAN(Subject Altnative Name) 的问答： Can not get rid of net::ERR_CERT_COMMON_NAME_INVALID error in chrome with self-signed certificates SSL - How do Common Names (CN) and Subject Alternative Names (SAN) work together? 关于证书锁定/公钥锁定技术： Certificate and Public Key Pinning - OWASP Difference between certificate pinning and public key pinning 加密/签名算法相关： RSA算法原理（二） 其他： OpenSSL ManPage openssl 查看证书 ","date":"2021-01-17","objectID":"/posts/about-tls-cert/:9:2","tags":["HTTPS","TLS","OpenSSL","加密","破解"],"title":"TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段","uri":"/posts/about-tls-cert/"},{"categories":["技术"],"content":"QEMU/KVM 虚拟化 QEMU/KVM 是目前最流行的虚拟化技术，它基于 Linux 内核提供的 kvm 模块，结构精简，性能损失小，而且开源免费（对比收费的 vmware），因此成了大部分企业的首选虚拟化方案。 目前各大云厂商的虚拟化方案，新的服务器实例基本都是用的 KVM 技术。即使是起步最早，一直重度使用 Xen 的 AWS，从 EC2 C5 开始就改用了基于 KVM 定制的 Nitro 虚拟化技术。 但是 KVM 作为一个企业级的底层虚拟化技术，却没有对桌面使用做深入的优化，因此如果想把它当成桌面虚拟化软件来使用，替代掉 VirtualBox/VMware，有一定难度。 本文是我个人学习 KVM 的一个总结性文档，其目标是使用 KVM 作为桌面虚拟化软件。 ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:1:0","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"一、安装 QUEU/KVM QEMU/KVM 环境需要安装很多的组件，它们各司其职： qemu: 模拟各类输入输出设备（网卡、磁盘、USB端口等） qemu 底层使用 kvm 模拟 CPU 和 RAM，比软件模拟的方式快很多。 libvirt: 提供简单且统一的工具和 API，用于管理虚拟机，屏蔽了底层的复杂结构。（支持 qemu-kvm/virtualbox/vmware） ovmf: 为虚拟机启用 UEFI 支持 virt-manager: 用于管理虚拟机的 GUI 界面（可以管理远程 kvm 主机）。 virt-viewer: 通过 GUI 界面直接与虚拟机交互（可以管理远程 kvm 主机）。 dnsmasq vde2 bridge-utils openbsd-netcat: 网络相关组件，提供了以太网虚拟化、网络桥接、NAT网络等虚拟网络功能。 dnsmasq 提供了 NAT 虚拟网络的 DHCP 及 DNS 解析功能。 vde2: 以太网虚拟化 bridge-utils: 顾名思义，提供网络桥接相关的工具。 openbsd-netcat: TCP/IP 的瑞士军刀，详见 socat \u0026 netcat，这里不清楚是哪个网络组件会用到它。 安装命令： # archlinux/manjaro sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat # ubuntu,参考了官方文档，但未测试 sudo apt install qemu-kvm libvirt-daemon-system virt-manager virt-viewer virtinst bridge-utils # centos,参考了官方文档，但未测试 sudo yum groupinstall \"Virtualization Host\" sudo yum install virt-manager virt-viewer virt-install # opensuse # see: https://doc.opensuse.org/documentation/leap/virtualization/html/book-virt/cha-vt-installation.html sudo yast2 virtualization # enter to terminal ui, select kvm + kvm tools, and then install it. 安装完成后，还不能直接使用，需要做些额外的工作。请继续往下走。 ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:2:0","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"1. libguestfs - 虚拟机磁盘映像处理工具 libguestfs 是一个虚拟机磁盘映像处理工具，可用于直接修改/查看/虚拟机映像、转换映像格式等。 它提供的命令列表如下： virt-df centos.img: 查看硬盘使用情况 virt-ls centos.img /: 列出目录文件 virt-copy-out -d domain /etc/passwd /tmp：在虚拟映像中执行文件复制 virt-list-filesystems /file/xx.img：查看文件系统信息 virt-list-partitions /file/xx.img：查看分区信息 guestmount -a /file/xx.qcow2(raw/qcow2都支持) -m /dev/VolGroup/lv_root --rw /mnt：直接将分区挂载到宿主机 guestfish: 交互式 shell，可运行上述所有命令。 virt-v2v: 将其他格式的虚拟机(比如 ova) 转换成 kvm 虚拟机。 virt-p2v: 将一台物理机转换成虚拟机。 学习过程中可能会使用到上述命令，提前安装好总不会有错，安装命令如下： # opensuse sudo zypper install libguestfs # archlinux/manjaro，目前缺少 virt-v2v/virt-p2v 组件 sudo pacman -S libguestfs # ubuntu sudo apt install libguestfs-tools # centos sudo yum install libguestfs-tools ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:2:1","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"2. 启动 QEMU/KVM 通过 systemd 启动 libvirtd 后台服务： sudo systemctl enable libvirtd.service sudo systemctl start libvirtd.service ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:2:2","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"3. 让非 root 用户能正常使用 kvm qumu/kvm 装好后，默认情况下需要 root 权限才能正常使用它。 为了方便使用，首先编辑文件 /etc/libvirt/libvirtd.conf: unix_sock_group = \"libvirt\"，取消这一行的注释，使 libvirt 用户组能使用 unix 套接字。 unix_sock_rw_perms = \"0770\"，取消这一行的注释，使用户能读写 unix 套接字。 然后新建 libvirt 用户组，将当前用户加入该组： newgrp libvirt sudo usermod -aG libvirt $USER 最后重启 libvirtd 服务，应该就能正常使用了： sudo systemctl restart libvirtd.service ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:2:3","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"3. 启用嵌套虚拟化 如果你需要在虚拟机中运行虚拟机（比如在虚拟机里测试 katacontainers 等安全容器技术），那就需要启用内核模块 kvm_intel 实现嵌套虚拟化。 # 临时启用 kvm_intel 嵌套虚拟化 sudo modprobe -r kvm_intel sudo modprobe kvm_intel nested=1 # 修改配置，永久启用嵌套虚拟化 echo \"options kvm-intel nested=1\" | sudo tee /etc/modprobe.d/kvm-intel.conf 验证嵌套虚拟化已经启用： $ cat /sys/module/kvm_intel/parameters/nested Y 至此，KVM 的安装就大功告成啦，现在应该可以在系统中找到 virt-manager 的图标，进去就可以使用了。 virt-manager 的使用方法和 virtualbox/vmware workstation 大同小异，这里就不详细介绍了，自己摸索摸索应该就会了。 如下内容是进阶篇，主要介绍如何通过命令行来管理虚拟机磁盘，以及 KVM。 如果你还是 kvm 新手，建议先通过图形界面 virt-manager 熟悉熟悉，再往下继续读。 ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:2:4","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"二、虚拟机磁盘映像管理 这需要用到两个工具： libguestfs: 虚拟机磁盘映像管理工具，前面介绍过了 qemu-img: qemu 的磁盘映像管理工具，用于创建磁盘、扩缩容磁盘、生成磁盘快照、查看磁盘信息、转换磁盘格式等等。 # 创建磁盘 qemu-img create -f qcow2 -o cluster_size=128K virt_disk.qcow2 20G # 扩容磁盘 qemu-img resize ubuntu-server-cloudimg-amd64.img 30G # 查看磁盘信息 qemu-img info ubuntu-server-cloudimg-amd64.img # 转换磁盘格式 qemu-img convert -f raw -O qcow2 vm01.img vm01.qcow2 # raw =\u003e qcow2 qemu-img convert -f qcow2 -O raw vm01.qcow2 vm01.img # qcow2 =\u003e raw ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:3:0","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"1. 导入 vmware 镜像 直接从 vmware ova 文件导入 kvm，这种方式转换得到的镜像应该能直接用（网卡需要重新配置）： virt-v2v -i ova centos7-test01.ova -o local -os /vmhost/centos7-01 -of qcow2 也可以先从 ova 中解压出 vmdk 磁盘映像，将 vmware 的 vmdk 文件转换成 qcow2 格式，然后再导入 kvm（网卡需要重新配置）： # 转换映像格式 qemu-img convert -p -f vmdk -O qcow2 centos7-test01-disk1.vmdk centos7-test01.qcow2 # 查看转换后的映像信息 qemu-img info centos7-test01.qcow2 直接转换 vmdk 文件得到的 qcow2 镜像，启会报错，比如「磁盘无法挂载」。 根据 Importing Virtual Machines and disk images - ProxmoxVE Docs 文档所言，需要在网上下载安装 MergeIDE.zip 组件， 另外启动虚拟机前，需要将硬盘类型改为 IDE，才能解决这个问题。 ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:3:1","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"2. 导入 img 镜像 img 镜像文件，就是所谓的 raw 格式镜像，也被称为裸镜像，IO 速度比 qcow2 快，但是体积大，而且不支持快照等高级特性。 如果不追求 IO 性能的话，建议将它转换成 qcow2 再使用。 qemu-img convert -f raw -O qcow2 vm01.img vm01.qcow2 ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:3:2","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"三、虚拟机管理 虚拟机管理可以使用命令行工具 virsh/virt-install，也可以使用 GUI 工具 virt-manager. GUI 很傻瓜式，就不介绍了，这里主要介绍命令行工具 virsh/virt-install 先介绍下 libvirt 中的几个概念： Domain: 指代运行在虚拟机器上的操作系统的实例 - 一个虚拟机，或者用于启动虚拟机的配置。 Guest OS: 运行在 domain 中的虚拟操作系统。 大部分情况下，你都可以把下面命令中涉及到的 domain 理解成虚拟机。 ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:4:0","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"0. 设置默认 URI virsh/virt-install/virt-viewer 等一系列 libvirt 命令，sudo virsh net-list –all 默认情况下会使用 qemu:///session 作为 URI 去连接 QEMU/KVM，只有 root 账号才会默认使用 qemu:///system. 另一方面 virt-manager 这个 GUI 工具，默认也会使用 qemu:///system 去连接 QEMU/KVM（和 root 账号一致） qemu:///system 是系统全局的 qemu 环境，而 qemu:///session 的环境是按用户隔离的。 另外 qemu:///session 没有默认的 network，创建虚拟机时会出毛病。。。 因此，你需要将默认的 URI 改为 qemu:///system，否则绝对会被坑: echo 'export LIBVIRT_DEFAULT_URI=\"qemu:///system\"' \u003e\u003e ~/.bashrc ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:4:1","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"1. 虚拟机网络 qemu-kvm 安装完成后，qemu:///system 环境中默认会创建一个 default 网络，而 qemu:///session 不提供默认的网络，需要手动创建。 我们通常使用 qemu:///system 环境就好，可以使用如下方法查看并启动 default 网络，这样后面创建虚拟机时才有网络可用。 # 列出所有虚拟机网络 $ sudo virsh net-list --all Name State Autostart Persistent ---------------------------------------------- default inactive no yes # 启动默认网络 $ virsh net-start default Network default started # 将 default 网络设为自启动 $ virsh net-autostart --network default Network default marked as autostarted # 再次检查网络状况，已经是 active 了 $ sudo virsh net-list --all Name State Autostart Persistent -------------------------------------------- default active yes yes 也可以创建新的虚拟机网络，这需要手动编写网络的 xml 配置，然后通过 virsh net-define --file my-network.xml 创建，这里就不详细介绍了，因为暂时用不到… ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:4:2","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"2. 创建虚拟机 - virt-intall # 使用 iso 镜像创建全新的 proxmox 虚拟机，自动创建一个 60G 的磁盘。 virt-install --virt-type kvm \\ --name pve-1 \\ --vcpus 4 --memory 8096 \\ --disk size=60 \\ --network network=default,model=virtio \\ --os-type linux \\ --os-variant generic \\ --graphics vnc \\ --cdrom proxmox-ve_6.3-1.iso # 使用已存在的 opensuse cloud 磁盘创建虚拟机 virt-install --virt-type kvm \\ --name opensuse15-2 \\ --vcpus 2 --memory 2048 \\ --disk opensuse15.2-openstack.qcow2,device=disk,bus=virtio \\ --disk seed.iso,device=cdrom \\ --os-type linux \\ --os-variant opensuse15.2 \\ --network network=default,model=virtio \\ --graphics vnc \\ --import 其中的 --os-variant 用于设定 OS 相关的优化配置，官方文档强烈推荐设定，其可选参数可以通过 osinfo-query os 查看。 ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:4:3","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"3. 虚拟机管理 - virsh 虚拟机创建好后，可使用 virsh 管理虚拟机： 查看虚拟机列表： # 查看正在运行的虚拟机 virsh list # 查看所有虚拟机，包括 inactive 的虚拟机 virsh list --all 使用 virt-viewer 以 vnc 协议登入虚拟机终端： # 使用虚拟机 ID 连接 virt-viewer 8 # 使用虚拟机名称连接，并且等待虚拟机启动 virt-viewer --wait opensuse15 启动、关闭、暂停(休眠)、重启虚拟机： virsh start opensuse15 virsh suuspend opensuse15 virsh resume opensuse15 virsh reboot opensuse15 # 优雅关机 virsh shutdown opensuse15 # 强制关机 virsh destroy opensuse15 # 启用自动开机 virsh autostart opensuse15 # 禁用自动开机 virsh autostart --disable opensuse15 虚拟机快照管理： # 列出一个虚拟机的所有快照 virsh snapshot-list --domain opensuse15 # 给某个虚拟机生成一个新快照 virsh snapshot-create \u003cdomain\u003e # 使用快照将虚拟机还原 virsh snapshot-restore \u003cdomain\u003e \u003csnapshotname\u003e # 删除快照 virsh snapshot-delete \u003cdomain\u003e \u003csnapshotname\u003e 删除虚拟机： virsh undefine opensuse15 迁移虚拟机： # 使用默认参数进行离线迁移，将已关机的服务器迁移到另一个 qemu 实例 virsh migrate 37 qemu+ssh://tux@jupiter.example.com/system # 还支持在线实时迁移，待续 cpu/内存修改： # 改成 4 核 virsh setvcpus opensuse15 4 # 改成 4G virsh setmem opensuse15 4096 虚拟机监控： # 待续 修改磁盘、网络及其他设备： # 添加新设备 virsh attach-device virsh attach-disk virsh attach-interface # 删除设备 virsh detach-disk virsh detach-device virsh detach-interface ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:4:4","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":["技术"],"content":"参考 Virtualization Guide - OpenSUSE Complete Installation of KVM, QEMU and Virt Manager on Arch Linux and Manjaro virtualization-libvirt - ubuntu docs RedHat Docs - KVM ","date":"2021-01-17","objectID":"/posts/qemu-kvm-usage/:5:0","tags":["虚拟化","KVM","libvirt","QEMU"],"title":"QEMU-KVM 虚拟化环境的搭建与使用","uri":"/posts/qemu-kvm-usage/"},{"categories":null,"content":"关于我 有很多的绝望，但也有美的时刻，只不过在美的时刻，时间是不同于以往的。 ──《刺猬的优雅》 昵称：中文昵称「於清樂」「二花」，英文 ID「ryan4yin」「ryan_yin」 音乐： 喜欢听后摇、蓝草、民谣、器乐 有在断断续续地学习竹笛跟口琴，另外也有在学习使用 Synthesizer V 跟 Reaper 其他爱好： 运动：喜欢轮滑以及游泳，哦还有 VR 游戏《Beat Saber》《Pistol Whip》，但是目前都是半吊子哈哈~ 茶：2021 年在朋友家喝过一次青钱柳后就一直念念不忘，年底就入坑了凤牌滇红、天之红祁门红茶、极白安吉白茶，目前比较喜欢喝红茶。 书籍：读得最多的正经书是 IT 技术书籍，另外也喜欢看科幻，以及戒不掉的网文/轻小说 影视：看得最多的是动漫，另外就是欧美科幻片、温情片 中文输入方案：小鹤音形 专业：大学学的是声学，没错就是初中物理课上敲音叉的那个声学。本人专业知识战五渣，学位证都没拿到，就不展开了hhh 自然语言 English: Good at reading technical articles, but weak in writing, listening and speaking 中文：母语，高中语文中等水准。希望能学会用中文写小说，就先从短篇开始吧 编程语言 Python: 目前的主力，也是我最熟悉的语言 Go: 学习中，云原生圈子里最流行的语言 Rust: 学习中，大量函数式的语法糖，贴心的编译器提示，感觉很好用 C: 勉强能看懂代码，荒废比较久了。在学习 Nginx/Linux 的过程中慢慢补吧… 曾经使用过但已经荒废的语言：Java/Julia/Mathematica/Lua 职业：SRE 维护与优化容器计算平台及流量链路，分析与管控云计算成本，稳定高效地支撑快速成长的业务 工具或技术：Linux/Kubernetes/Istio 联系方式 公网聊天：https://github.com/ryan4yin/ryan4yin.space/issues 邮件私聊：eWVzIG15IGVtYWlsIGlzIHhpYW95aW5fY0BxcS5jb20K ","date":"2021-01-16","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 ","date":"2021-01-16","objectID":"/about/:2:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"博客内容 2020 年及之前的技术文章，都搬运自我的博客园 https://www.cnblogs.com/kirito-c/。 2021 年开始的技术内容，大都来自我的个人笔记 ryan4yin/knowledge，我会不定期从这个笔记中找些有意思的内容，整理润色后，拿出来和大家分享，同时查漏补缺。 而另一部分生活类的随笔，则是我的闲言碎语，一般来自我的印象笔记。 ","date":"2021-01-16","objectID":"/about/:2:1","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"我曾用过的标语 何来枷锁 拆破玉笼飞彩凤，顿开金锁走蛟龙。 赞美快乐 双手合十 闭上眼睛 心里什么也不去想 嘴角就高高扬起 笑出声来 赞美快乐~ 错过 我错过花，却看见海 ","date":"2021-01-16","objectID":"/about/:2:2","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"博客时间线 博客时间线 2016-06-17：在博客园 - https://www.cnblogs.com/kirito-c/ 2021-01-16：开设独立博客 https://ryan4yin.space/ 2022-02-07：博客主域名切换为 https://thiscute.world/，另外新增备用域名 https://writefor.fun 2022-02-16：本站通过十年之约审核，正式加入十年之约 博客快照 博客园快照\" 博客园快照 ","date":"2021-01-16","objectID":"/about/:2:3","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"注意事项 本站所有技术内容均为个人观点，不保证正确，另外随着时间变化部分技术内容也可能会失效，请读者自行甄别。 另外本站使用的许多配图都来源于网络，如有侵权，请联系我删除。 ","date":"2021-01-16","objectID":"/about/:3:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"画外 互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-01-16","objectID":"/about/:4:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":" .animation-wrapper { position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: -100; } .particle, .particle:after { background: transparent; } .particle:after { position: absolute; content: \"\"; top: 2560px; } .particle-1 { -webkit-animation: animParticle 60s linear infinite; animation: animParticle 60s linear infinite; box-shadow: 0px 0px #fff, 1231px 1530px #fff, 336px 2471px #fff, 2385px 128px #fff, 2436px 1283px #fff, 549px 681px #fff, 1775px 1144px #fff, 238px 1396px #fff, 1330px 1558px #fff, 2060px 342px #fff, 1986px 1672px #fff, 1532px 702px #fff, 1313px 1459px #fff, 2406px 1616px #fff, 1529px 802px #fff, 1267px 680px #fff, 2258px 2109px #fff, 1325px 22px #fff, 1578px 1045px #fff, 945px 2256px #fff, 1400px 1441px #fff, 1652px 2152px #fff, 2513px 969px #fff, 2192px 1352px #fff, 793px 334px #fff, 1371px 1086px #fff, 2408px 1898px #fff, 475px 840px #fff, 539px 1108px #fff, 556px 1499px #fff, 643px 122px #fff, 2370px 1975px #fff, 1196px 1786px #fff, 308px 1834px #fff, 1957px 1569px #fff, 875px 339px #fff, 562px 412px #fff, 1187px 2258px #fff, 1406px 1824px #fff, 1172px 1792px #fff, 235px 1489px #fff, 2081px 878px #fff, 925px 176px #fff, 953px 1829px #fff, 38px 48px #fff, 1976px 1994px #fff, 1524px 1567px #fff, 1397px 1141px #fff, 2014px 1773px #fff, 1638px 1832px #fff, 1150px 465px #fff, 1212px 1854px #fff, 122px 20px #fff, 2493px 2361px #fff, 2221px 194px #fff, 480px 2020px #fff, 2340px 403px #fff, 1975px 2507px #fff, 1434px 142px #fff, 963px 871px #fff, 2379px 1765px #fff, 2346px 100px #fff, 1931px 1308px #fff, 527px 814px #fff, 549px 1732px #fff, 943px 886px #fff, 1592px 2277px #fff, 1339px 810px #fff, 871px 2016px #fff, 2121px 763px #fff, 1962px 1114px #fff, 2498px 550px #fff, 107px 586px #fff, 316px 1033px #fff, 2104px 2120px #fff, 1933px 1786px #fff, 1377px 2457px #fff, 2250px 1010px #fff, 1314px 2316px #fff, 1339px 947px #fff, 122px 1014px #fff, 558px 2354px #fff, 1250px 1790px #fff, 1185px 2144px #fff, 2432px 158px #fff, 1911px 2148px #fff, 1177px 804px #fff, 2504px 1254px #fff, 617px 1084px #fff, 1959px 1325px #fff, 2394px 2081px #fff, 395px 735px #fff, 221px 1891px #fff, 652px 2245px #fff, 1225px 1023px #fff, 1542px 2053px #fff, 876px 2178px #fff, 479px 1915px #fff, 2297px 1799px #fff, 2160px 387px #fff, 160px 358px #fff, 1122px 2164px #fff, 2056px 1402px #fff, 2133px 1470px #fff, 1508px 1865px #fff, 250px 2157px #fff, 715px 1452px #fff, 2095px 1539px #fff, 1860px 1450px #fff, 185px 2013px #fff, 1855px 1878px #fff, 690px 2520px #fff, 2250px 838px #fff, 1547px 1752px #fff, 1103px 615px #fff, 151px 262px #fff, 1630px 577px #fff, 769px 2448px #fff, 1938px 2347px #fff, 700px 1634px #fff, 2105px 2053px #fff, 1498px 49px #fff, 799px 512px #fff, 1278px 744px #fff, 2301px 364px #fff, 1059px 2066px #fff, 2116px 2424px #fff, 1884px 1046px #fff, 699px 1101px #fff, 62px 1893px #fff, 370px 161px #fff, 298px 1288px #fff, 1972px 2211px #fff, 1834px 2350px #fff, 1591px 1118px #fff, 1343px 1730px #fff, 706px 850px #fff, 317px 1171px #fff, 1395px 2529px #fff, 1040px 2523px #fff, 793px 2535px #fff, 2180px 142px #fff, 2016px 2511px #fff, 1032px 1204px #fff, 499px 625px #fff, 130px 2064px #fff, 1371px 758px #fff, 1045px 2018px #fff, 1954px 309px #fff, 1445px 2514px #fff, 839px 1523px #fff, 920px 238px #fff, 1421px 1105px #fff, 668px 1517px #fff, 2045px 2344px #fff, 2465px 1619px #fff, 403px 48px #fff, 1142px 1102px #fff, 2066px 1803px #fff, 658px 1744px #fff, 721px 2062px #fff, 2180px 827px #fff, 2310px 111px #fff, 935px 808px #fff, 1121px 1108px #fff, 1424px 1998px #fff, 821px 1317px #fff, 2425px 1354px #fff, 305px 1422px #fff, 169px 1559px #fff, 1850px 425px #fff, 719px 1507px #fff, 1650px 1803px #fff, 275px 402px #fff, 1038px 772px #fff, 404px 105px #fff, 78px 2119px #fff, 133px 110px #fff, 2559px 944px #fff, 688px 212px #fff, 869px 2266px #fff, 983px 840px #fff, 1914px 2154px #fff, 1376px 941px #fff, 2064px 739px #fff, 1979px 1255px #fff, 592px 1175px #fff, 283px 253px #fff, 696px 2501px #fff, 1561px 1505px #fff, 745px","date":"2021-01-16","objectID":"/friends/:0:0","tags":null,"title":"我的小伙伴们","uri":"/friends/"},{"categories":null,"content":"交换友链 如果你觉得我的博客有些意思，而且也有自己的博客，并且博客运行时间超过半年，至少有 6 篇自认为有价值的原创文章，欢迎与我交换友链~ 可通过 Issues 或者评论区提交友链申请，格式如下： 站点名称：This Cute World 站点地址：https://thiscute.world/ 个人形象：https://thiscute.world/avatar/myself.jpg 站点描述：赞美快乐~ // 以下为样例内容，按照格式可以随意修改 var myFriends = [ [\"https://chee5e.space\", \"https://chee5e.space/images/avatar.jpg\", \"@芝士部落格\", \"有思想，也有忧伤和理想，芝士就是力量\"], [\"https://sanshiliuxiao.top/\", \"https://cdn.jsdelivr.net/gh/vensing/static@latest/avatar/sanshiliuxiao.jpg\", \"@三十六咲\", \"快走吧，趁风停止之前\"], [\"https://rea.ink/\", \"https://rea.ink/head.png\", \"@倾书\", \"清风皓月，光景常新 0) { var rndNum = Math.floor(Math.random()*myFriends.length); var friendNode = document.createElement(\"li\"); var friend_link = document.createElement(\"a\"), friend_img = document.createElement(\"img\"), friend_name = document.createElement(\"h4\"), friend_about = document.createElement(\"p\") ; friend_link.target = \"_blank\"; friend_link.href = myFriends[rndNum][0]; friend_img.src=myFriends[rndNum][1]; friend_name.innerText = myFriends[rndNum][2]; friend_about.innerText = myFriends[rndNum][3]; friend_link.appendChild(friend_img); friend_link.appendChild(friend_name); friend_link.appendChild(friend_about); friendNode.appendChild(friend_link); targetList.appendChild(friendNode); myFriends.splice(rndNum, 1); } .linkpage ul { color: rgba(255,255,255,.15) } .linkpage ul:after { content: \" \"; clear: both; display: block } .linkpage li { float: left; width: 48%; position: relative; -webkit-transition: .3s ease-out; transition: .3s ease-out; border-radius: 5px; line-height: 1.3; height: 90px; display: block } .linkpage h3 { margin: 15px -25px; padding: 0 25px; border-left: 5px solid #51aded; background-color: #f7f7f7; font-size: 25px; line-height: 40px } .linkpage li:hover { background: rgba(230,244,250,.5); cursor: pointer } .linkpage li a { padding: 0 10px 0 90px } .linkpage li a img { width: 60px; height: 60px; border-radius: 50%; position: absolute; top: 15px; left: 15px; cursor: pointer; margin: auto; border: none } .linkpage li a h4 { color: #333; font-size: 18px; margin: 0 0 7px; padding-left: 90px } .linkpage li a h4:hover { color: #51aded } .linkpage li a h4, .linkpage li a p { cursor: pointer; white-space: nowrap; text-overflow: ellipsis; overflow: hidden; line-height: 1.4; margin: 0 !important; } .linkpage li a p { font-size: 12px; color: #999; padding-left: 90px } @media(max-width: 460px) { .linkpage li { width:97% } .linkpage ul { padding-left: 5px } } ","date":"2021-01-16","objectID":"/friends/:1:0","tags":null,"title":"我的小伙伴们","uri":"/friends/"},{"categories":["技术"],"content":"Pulumi 是一个基础设施的自动管理工具，使用 Python/TypeScript/Go/Dotnet 编写好声明式的资源配置，就能实现一键创建/修改/销毁各类资源，这里的资源可以是： AWS/阿里云等云上的负载均衡、云服务器、TLS 证书、DNS、CDN、OSS、数据库…几乎所有的云上资源 本地自建的 vSphere/Kubernetes/ProxmoxVE/libvirt 环境中的虚拟机、容器等资源 相比直接调用 AWS/阿里云/Kubernetes 的 API，使用 pulumi 的好处有： 声明式配置：你只需要声明你的资源属性就 OK，所有的状态管理、异常处理都由 pulumi 完成。 统一的配置方式：提供统一的配置方法，来声明式的配置所有 AWS/阿里云/Kubernetes 资源。 声明式配置的可读性更好，更便于维护 试想一下，通过传统的手段去从零搭建一个云上测试环境、或者本地开发环境，需要手工做多少繁琐的工作。 而依靠 Pulumi 这类「基础设施即代码」的工具，只需要一行命令就能搭建好一个可复现的云上测试环境或本地开发环境。 比如我们的阿里云测试环境，包括两个 kubernetes 集群、负载均衡、VPC 网络、数据库、云监控告警/日志告警、RAM账号权限体系等等，是一个比较复杂的体系。 人工去配置这么多东西，想要复现是很困难的，非常繁琐而且容易出错。 但是使用 pulumi，只需要一行命令，就能创建并配置好这五花八门一大堆的玩意儿。 销毁整个测试环境也只需要一行命令。 实际使用体验：我们使用 Pulumi 自动化了阿里云测试环境搭建 95%+ 的操作，这个比例随着阿里云的 pulumi provider 的完善，还可以进一步提高！ ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:0:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"Pulumi vs Terraform 有一个「基础设施即代码」的工具比 Pulumi 更流行，它就是 Terraform. 实际上我们一开始使用的也是 Terraform，但是后来使用 Pulumi 完全重写了一遍。 主要原因是，Pulumi 解决了 Terraform 配置的一个痛点：配置语法太过简单，导致配置繁琐。而且还要额外学习一门 DSL - HCL Terraform 虽然应用广泛，但是它默认使用的 HCL 语言太简单，表现力不够强。 这就导致在一些场景下使用 Terraform，会出现大量的重复配置。 一个典型的场景是「批量创建资源，动态生成资源参数」。比如批量创建一批名称类似的 ECS 服务器/VPC交换机。如果使用 terraform，就会出现大量的重复配置。 改用 terraform 提供的 module 能在一定程度上实现配置的复用，但是它还是解决不了问题。 要使用 module，你需要付出时间去学习 module 的概念，为了拼接参数，你还需要学习 HCL 的一些高级用法。 但是付出了这么多，最后写出的 module 还是不够灵活——它被 HCL 局限住了。 为了实现如此的参数化动态化，我们不得不引入 Python 等其他编程语言。于是构建流程就变成了： 借助 Python 等其他语言先生成出 HCL 配置 通过 terraform 命令行进行 plan 与 apply 通过 Python 代码解析 terraform.tfstat，获取 apply 结果，再进行进一步操作。 这显然非常繁琐，主要困难就在于 Python 和 Terraform 之间的交互。 进一步思考，既然其他编程语言如 Python/Go 的引入不可避免，那是不是能使用它们彻底替代掉 HCL 呢？能不能直接使用 Python/Go 编写配置？如果 Terraform 原生就支持 Python/Go 来编写配置，那就不存在交互问题了。 相比于使用领域特定语言 HCL，使用通用编程语言编写配置，好处有： Python/Go/TypeScript 等通用的编程语言，能满足你的一切需求。 作为一个开发人员/DevOps，你应该对 Python/Go 等语言相当熟悉，可以直接利用上已有的经验。 更方便测试：可以使用各编程语言中流行的测试框架来测试 pulumi 配置！ 于是 Pulumi 横空出世。 另一个和 Pulumi 功能类似的工具，是刚出炉没多久的 terraform-cdk，但是目前它还很不成熟。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:1:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"Pulumi 特点介绍 原生支持通过 Python/Go/TypeScript/Dotnet 等语言编写配置，也就完全解决了上述的 terraform 和 python 的交互问题。 pulumi 是目前最流行的 真-IaaS 工具，对各语言的支持都很成熟。 兼容 terraform 的所有 provider，只是需要自行使用 pulumi-tf-provider-boilerplate 重新打包，有些麻烦。 pulumi 官方的 provider 几乎全都是封装的 terraform provider，包括 aws/azure/alicloud，目前只发现 kubernetes 是原生的（独苗啊）。 状态管理和 secrets 管理有如下几种选择： 使用 app.pulumi.com（默认）:免费版提供 stack 历史管理，可以看到所有的历史记录。另外还提供一个资源关系的可视化面板。总之很方便，但是多人合作就需要收费。 本地文件存储：pulumi login file:///app/data 云端对象存储，支持 s3 等对象存储协议，因此可以使用 AWS 或者本地的 MinIO 来做 Backend. pulumi login 's3://\u003cbucket-path\u003e?endpoint=my.minio.local:8080\u0026disableSSL=true\u0026s3ForcePathStyle=true' minio/aws 的 creadential 可以通过 AWS_ACCESS_KEY_ID 和 AWS_SECRET_ACCESS_KEY 两个环境变量设置。另外即使是使用 MinIO，AWS_REGION 这个没啥用的环境变量也必须设置！否则会报错。 gitlab 13 支持 Terraform HTTP State 协议，等这个 pr 合并，pulumi 也能以 gitlab 为 backend 了。 使用 pulumi 企业版（自建服务）：比 app.pulumi.com 提供更多的特性，但是显然是收费的。。 总之，非常香，强烈推荐各位 DevOps 试用。 以下内容是我对 pulumi 的一些思考，以及使用 pulumi 遇到的各种问题+解决方法，适合对 pulumi 有一定了解的同学阅读。 如果你刚接触 Pulumi 而且有兴趣学习，建议先移步 pulumi get started 入个门，再接着看下面的内容。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:2:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"使用建议 建议查看对应的 terraform provider 文档：pulumi 的 provider 基本都是封装的 terraform 版本，而且文档是自动生成的，比（简）较（直）难（一）看（坨）懂（shi），examples 也少。 stack: pulumi 官方提供了两种 stack 用法：「单体」和「微-stack」 单体: one stack rule them all，通过 stack 参数来控制步骤。stack 用来区分环境 dev/pro 等。 微-stack: 每一个 stack 是一个步骤，所有 stack 组成一个完整的项目。 实际使用中，我发现「微-stack」模式需要使用到 pulumi 的 inter-stack dependencies，报一堆的错，而且不够灵活。因此目前更推荐「单体」模式。 我们最近使用 pulumi 完全重写了以前用 terraform 编写的云上配置，简化了很多繁琐的配置，也降低了我们 Python 运维代码和 terraform 之间的交互难度。 另外我们还充分利用上了 Python 的类型检查和语法检查，很多错误 IDE 都能直接给出提示，强化了配置的一致性和可维护性。 不过由于阿里云 provider 暂时还： 不支持管理 ASM 服务网格、DTS 数据传输等资源 OSS 等产品的部分参数也暂时不支持配置（比如 OSS 不支持配置图片样式、ElasticSearch 暂时不支持自动创建 7.x 版本） 不支持创建 ElasticSearch 7.x 这些问题，导致我们仍然有部分配置需要手动处理，另外一些耗时长的资源，需要单独去创建。 因此还不能实现完全的「一键」。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:3:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"常见问题 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"1. Output 的用法 pulumi 通过资源之间的属性引用（Output[str]）来确定依赖关系，如果你通过自定义的属性(str)解耦了资源依赖，会导致资源创建顺序错误而创建失败。 Output[str] 是一个异步属性，类似 Future，不能被用在 pulumi 参数之外的地方！ Output[str] 提供两种方法能直接对 Output[str] 进行一些操作： Output.concat(\"http://\", domain, \"/\", path): 此方法将 str 与 Output[str] 拼接起来，返回一个新的 Output[str] 对象，可用做 pulumi 属性。 domain.apply(lambda it: print(it)): Output[str] 的 apply 方法接收一个函数。在异步获取到数据后，pulumi 会调用这个函数，把具体的数据作为参数传入。 另外 apply 也会将传入函数的返回值包装成 Output 类型返回出来。 可用于：在获取到数据后，将数据打印出来/发送到邮箱/调用某个 API 上传数据等等。 Output.all(output1, output2, ...).apply(lambda it: print(it)) 可用于将多个 output 值，拼接成一个 Output 类型，其内部的 raw 值为一个 tuple 对象 (str1, str2, ...). 官方举例：connection_string = Output.all(sql_server.name, database.name).apply(lambda args: f\"Server=tcp:{args[0]}.database.windows.net;initial catalog={args[1]}...\") ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:1","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"2. 如何使用多个云账号/多个 k8s 集群？ 默认情况下 pulumi 使用默认的 provider，但是 pulumi 所有的资源都有一个额外的 opts 参数，可用于设定其他 provider。 通过这个 opts，我们可以实现在一个 pulumi 项目中，使用多个云账号，或者管理多个 k8s 集群。 示例： from pulumi import get_stack, ResourceOptions, StackReference from pulumi_alicloud import Provider, oss # 自定义 provider，key/secret 通过参数设定，而不是从默认的环境变量读取。 # 可以自定义很多个 providers provider = pulumi_alicloud.Provider( \"custom-alicloud-provider\", region=\"cn-hangzhou\", access_key=\"xxx\", secret_key=\"jjj\", ) # 通过 opts，让 pulumi 使用自定义的 provider（替换掉默认的） bucket = oss.Bucket(..., opts=ResourceOptions(provider=provider)) ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:2","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"3. inter-stack 属性传递 这东西还没搞透，待研究。 多个 stack 之间要互相传递参数，需要通过 pulumi.export 导出属性，通过 stack.require_xxx 获取属性。 从另一个 stack 读取属性的示例： from pulumi import StackReference cfg = pulumi.Config() stack_name = pulumi.get_stack() # stack 名称 project = pulumi.get_project() infra = StackReference(f\"ryan4yin/{project}/{stack_name}\") # 这个属性在上一个 stack 中被 export 出来 vpc_id = infra.require(\"resources.vpc.id\") ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:3","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"4. pulumi up 被中断，或者对资源做了手动修改，会发生什么？ 强行中断 pulumi up，会导致资源进入 pending 状态，必须手动修复。 修复方法：pulumi stack export，删除 pending 资源，再 pulumi stack import 手动删除了云上资源，或者修改了一些对资源管理无影响的参数，对 pulumi 没有影响，它能正确检测到这种情况。 可以通过 pulumi refresh 手动从云上拉取最新的资源状态。 手动更改了资源之间的依赖关系（比如绑定 EIP 之类的），很可能导致 pulumi 无法正确管理资源之间的依赖。 这种情况必须先手动还原依赖关系（或者把相关资源全部手动删除掉），然后才能继续使用 pulumi。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:4","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"5. 如何手动声明资源间的依赖关系？ 有时候因为一些问题（比如 pulumi provider 功能缺失，使用了 restful api 实现部分功能），pulumi 可能无法识别到某些资源之间的依赖关系。 这时可以为资源添加 dependsOn 属性，这个属性能显式地声明依赖关系。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:5","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"6. 如何导入已经存在的资源？ 由于历史原因，我们可能有部分资源是手动创建或者由其他 IaC 工具管理的，该如何将它们纳入 pulumi 管辖呢？ 官方有提供一篇相关文档 Importing Infrastructure. 文档有提到三种资源导入的方法： 使用 pulumi import 命令，这个命令能导入资源同时自动生成对应的代码。 感觉这个命令也很适合用来做资源的配置备份，不需要对照资源手写 pulumi 代码了，好评。 批量导入资源：文档的 Bulk Import Operations 这一节介绍了如何通过 json 列出资源清单，然后使用 pulumi import -f resources.json 自动生成所有导入资源的 pulumi 代码。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:6","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"5. pulumi-kubernetes？ pulumi-kubernetes 是一条龙服务： 在 yaml 配置生成这一步，它能结合/替代掉 helm/kustomize，或者你高度自定义的 Python 脚本。 在 yaml 部署这一步，它能替代掉 argo-cd 这类 gitops 工具。 强大的状态管理，argo-cd 也有状态管理，可以对比看看。 也可以仅通过 kubernetes_pulumi 生成 yaml，再通过 argo-cd 部署，这样 pulumi_kubernetes 就仅用来简化 yaml 的编写，仍然通过 gitops 工具/kubectl 来部署。 使用 pulumi-kubernetes 写配置，要警惕逻辑和数据的混合程度。 因为 kubernetes 的配置复杂度比较高，如果动态配置比较多，很容易就会写出难以维护的 python 代码来。 渲染 yaml 的示例： from pulumi import get_stack, ResourceOptions, StackReference from pulumi_kubernetes import Provider from pulumi_kubernetes.apps.v1 import Deployment, DeploymentSpecArgs from pulumi_kubernetes.core.v1 import ( ContainerArgs, ContainerPortArgs, EnvVarArgs, PodSpecArgs, PodTemplateSpecArgs, ResourceRequirementsArgs, Service, ServicePortArgs, ServiceSpecArgs, ) from pulumi_kubernetes.meta.v1 import LabelSelectorArgs, ObjectMetaArgs provider = Provider( \"render-yaml\", render_yaml_to_directory=\"rendered\", ) deployment = Deployment( \"redis\", spec=DeploymentSpecArgs(...), opts=ResourceOptions(provider=provider), ) 如示例所示，pulumi-kubernetes 的配置是完全结构化的，比 yaml/helm/kustomize 要灵活非常多。 总之它非常灵活，既可以和 helm/kustomize 结合使用，替代掉 argocd/kubectl。 也可以和 argocd/kubectl 使用，替代掉 helm/kustomize。 具体怎么使用好？我也还在研究。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:7","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"6. 阿里云资源 replace 报错？ 阿里云有部分资源，只能创建删除，不允许修改，比如「资源组」。 对这类资源做变更时，pulumi 会直接报错：「Resources aleardy exists」， 这类资源，通常都有一个「force」参数，指示是否强制修改——即先删除再重建。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:8","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"7. 有些资源属性无法使用 pulumi 配置？ 这得看各云服务提供商的支持情况。 比如阿里云很多资源的属性，pulumi 都无法完全配置，因为 alicloud provider 的功能还不够全面。 目前我们生产环境，大概 95%+ 的东西，都可以使用 pulumi 实现自动化配置。 而其他 OSS 的高级参数、新出的 ASM 服务网格、kubernetes 的授权管理、ElasticSearch7 等资源，还是需要手动配置。 这个没办法，只能等阿里云提供支持。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:9","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"8. CI/CD 中如何使 pulumi 将状态保存到文件？ CI/CD 中我们可能会希望 pulumi 将状态保存到本地，避免连接 pulumi 中心服务器。 这一方面能加快速度，另一方面一些临时状态我们可能根本不想存储，可以直接丢弃。 方法： # 指定状态文件路径 pulumi login file://\u003cfile-path\u003e # 保存到默认位置: ~/.pulumi/credentials.json pulumi login --local # 保存到远程 S3 存储（minio/ceph 或者各类云对象存储服务，都兼容 aws 的 s3 协议） pulumi login s3://\u003cbucket-path\u003e 登录完成后，再进行 pulumi up 操作，数据就会直接保存到你设定的路径下。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:4:10","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"缺点 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:5:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"1. 报错信息不直观 pulumi 和 terraform 都有一个缺点，就是封装层次太高了。 封装的层次很高，优点是方便了我们使用，可以使用很统一很简洁的声明式语法编写配置。 而缺点，则是出了 bug，报错信息往往不够直观，导致问题不好排查。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:5:1","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"2. 资源状态被破坏时，修复起来非常麻烦 在很多情况下，都可能发生资源状态被破坏的问题： 在创建资源 A，因为参数是已知的，你直接使用了常量而不是 Output。这会导致 pulumi 无法识别到依赖关系！从而创建失败，或者删除时资源状态被破坏！ 有一个 pulumi stack 一次在三台物理机上创建资源。你白天创建资源晚上删除资源，但是某一台物理机晚上会关机。这将导致 pulumi 无法查询到这台物理机上的资源状态，这个 pulumi stack 在晚上就无法使用，它会一直报错！ ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:5:2","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"常用 Provider pulumi-alicloud: 管理阿里云资源 pulumi-vault: 我这边用它来快速初始化 vault，创建与管理 vault 的所有配置。 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:6:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"我创建维护的 Provider 由于 Pulumi 生态还比较小，有些 provider 只有 terraform 才有。 我为了造(方)福(便)大(自)众(己)，创建并维护了两个本地虚拟机相关的 Providers: ryan4yin/pulumi-proxmox: 目前只用来自动创建 PVE 虚拟机 可以考虑结合 kubespray/kubeadm 快速创建 k8s 集群 ryan4yin/pulumi-libvirt: 快速创建 kvm 虚拟机 可以考虑结合 kubespray/kubeadm 快速创建 k8s 集群 ","date":"2021-01-08","objectID":"/posts/expirence-of-pulumi/:7:0","tags":["基础设施即代码","云原生","Pulumi","Terraform"],"title":"Pulumi 使用体验 - 基础设施代码化","uri":"/posts/expirence-of-pulumi/"},{"categories":["技术"],"content":"openSUSE 是一个基于 RPM 的发行版，这和 RHEL/CentOS 一致。 但是它的官方包管理器是专有的 zypper，挺好用的，软件也很新。 我最近从 Manjaro 切换到了 openSUSE，发现 KDE 桌面确实比 Manjaro 更丝滑，而且社区源 OBS 体验下来比 AUR 更舒服。 尤其是容器/Kubernetes 方面，源里面的东西比 AUR 更丰富，而且是官方维护的。 本文算是对迁移流程做的一个总结。 本文以 openSUSE Tumbleweed 为基础编写，这是一个和 Manjaro/Arch 一样的滚动发行版，软件源都很新。 openSUSE 社区的大部分用户都是使用的 Tumbleweed. 它的硬件兼容性也要比 openSUSE Leap（稳定版）好——实测小米游戏本安装 Leap，休眠后 Touchpad 会失灵。 ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:0:0","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"一、zypper 的基础命令 zypper 的源在国内比较慢，但实际上下载的时候，zypper 会智能选择最快的镜像源下载软件包，比如国内的清华源等。 但是我发现官方的源索引更新太慢，甚至经常失败。因此没办法，还是得手动设置镜像源： # 禁用原有的官方软件源 sudo zypper mr --disable repo-oss repo-non-oss repo-update repo-update-non-oss repo-debug # 添加北外镜像源 sudo zypper ar -fcg https://mirrors.bfsu.edu.cn/opensuse/tumbleweed/repo/oss/ bfsu-oss sudo zypper ar -fcg https://mirrors.bfsu.edu.cn/opensuse/tumbleweed/repo/non-oss/ bfsu-non-oss 然后就是 zypper 的常用命令： sudo zypper refresh # refresh all repos sudo zypper update # update all softwares sudo zypper search --installed-only \u003cpackage-name\u003e # 查找本地安装的程序 sudo zypper search \u003cpackage-name\u003e # 查找本地和软件源中的程序 sudo zypper install \u003cpackage-name\u003e # 安装程序 sudo zypper remove --clean-deps \u003cpackage-name\u003e # 卸载程序，注意添加 --clean-deps 或者 -u，否则不会卸载依赖项！ sudo zypper clean # 清理本地的包缓存 ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:1:0","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"Install Softwares 这里需要用到 OBS(Open Build Service, 类似 arch 的 AUR，但是是预编译的包)，因为 OBS 东西太多了，因此不存在完整的国内镜像，平均速度大概 300kb/s。 建议有条件可以在路由器上加智能代理提速。 安装需要用到的各类软件: # 启用 Packman 仓库，使用北交镜像源 sudo zypper ar -cfp 90 'https://mirror.bjtu.edu.cn/packman/suse/openSUSE_Tumbleweed/' packman-bjtu # install video player and web browser sudo zypper install mpv ffmpeg-4 chromium firefox # install screenshot and other utils # 安装好后可以配个截图快捷键 alt+a =\u003e `flameshot gui` sudo zypper install flameshot peek nomacs # install git clang/make/cmake sudo zypper install git gcc clang make cmake # install wireshark sudo zypper install wireshark sudo gpasswd --add $USER wireshark # 将你添加到 wireshark 用户组中 ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:0","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"IDE + 编程语言 # install vscode: https://en.openSUSE.org/Visual_Studio_Code sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc sudo zypper addrepo https://packages.microsoft.com/yumrepos/vscode vscode sudo zypper refresh sudo zypper install code # 安装 dotnet 5: https://docs.microsoft.com/en-us/dotnet/core/install/linux-openSUSE#openSUSE-15- sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc sudo zypper addrepo https://packages.microsoft.com/openSUSE/15/prod/ microsoft-prod sudo zypper refresh sudo zypper install dotnet-sdk-5.0 # 安装新版本的 go（源中的版本比较低，更建议从 go 官网下载安装） sudo zypper install go 通过 tarball/script 安装： # rustup，rust 环境管理器 curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh # jetbrains toolbox app，用于安装和管理 pycharm/idea/goland/android studio 等 IDE # 参见：https://www.jetbrains.com/toolbox-app/ # 不使用系统 python，改用 miniconda 装 python3.8 # 参考：https://github.com/ContinuumIO/docker-images/blob/master/miniconda3/debian/Dockerfile wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh sudo /bin/bash /tmp/miniconda.sh -b -p /opt/conda rm /tmp/miniconda.sh sudo /opt/conda/bin/conda clean -tipsy sudo ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh echo \". /opt/conda/etc/profile.d/conda.sh\" \u003e\u003e ~/.bashrc echo \"conda activate base\" \u003e\u003e ~/.bashrc # miniconda 的 entrypoint 默认安装在如下目录，添加到 PATH 中 echo \"export PATH=\\$PATH:\\$HOME/.local/bin\" \u003e\u003e ~/.bashrc 接下来安装 VSCode 插件，下列是我的插件列表： 语言： python/go/rust/c#/julia/flutter xml/yaml/toml vscode proto3 ansible/terraform markdown all in one + Markdown Preview Enhanced 美化： community material theme vscode icons glasslt-vsc docker/kubernetes IntelliJ IDEA Keybindings gitlens prettier utils comment translate path intellisense svg visual studio intellicode antlr4 remote ssh + remote containers rest client vscode databases ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:1","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"容器 + Kubernetes # 时髦的新容器套装: https://documentation.suse.com/sles/15-SP2/html/SLES-all/cha-podman-overview.html sudo zypper in podman kompose skopeo buildah katacontainers # 安装 kubernetes 相关工具，tumbleweed 官方仓库的包都非常新！很舒服 sudo zypper in helm k9s kubernetes-client # 本地测试目前还是 docker-compose 最方便，docker 仍有必要安装 sudo zypper in docker sudo gpasswd --add $USER docker sudo systemctl enable docker sudo systemctl start docker # 简单起见，直接用 pip 安装 docker-compose 和 podman-compose sudo pip install docker-compose podman-compose ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:2","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"办公、音乐、聊天 # 添加 openSUSE_zh 源：https://build.opensuse.org/project/show/home:opensuse_zh sudo zypper addrepo 'https://download.opensuse.org/repositories/home:/opensuse_zh/openSUSE_Tumbleweed' openSUSE_zh sudo zypper refresh sudo zypper install wps-office netease-cloud-music # linux qq: https://im.qq.com/linuxqq/download.html # 虽然简陋但也够用，发送文件比 KDE Connect 要方便一些。 sudo rpm -ivh linux_qq.rpm ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:3","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"安装输入法 我用的输入法是小鹤音形，首先安装 fcitx-rime: # 添加 m17n obs 源：https://build.openSUSE.org/repositories/M17N sudo zypper addrepo 'https://download.opensuse.org/repositories/M17N/openSUSE_Tumbleweed' m17n sudo zypper refresh sudo zypper install fcitx5 fcitx5-configtool fcitx5-qt5 fcitx5-rime 然后，从 http://flypy.ys168.com/ 下载最新的鼠须管（MacOS）配置文件，将解压得到的 rime 文件夹拷贝到 ~/.local/share/fcitx5/ 下： mv rime ~/.local/share/fcitx5/ 现在重启系统，在 fcitx5 配置里面添加 rime「中州韵」，就可以正常使用小鹤音形了。 ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:4","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"QEMU/KVM 不得不说，openSUSE 安装 KVM 真的超方便，纯 GUI 操作： # see: https://doc.openSUSE.org/documentation/leap/virtualization/html/book-virt/cha-vt-installation.html sudo yast2 virtualization # enter to terminal ui, select kvm + kvm tools, and then install it. KVM 的详细文档参见 KVM/README.md ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:5","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"KDE Connect KDE Connect 是一个 PC 手机协同工具，可以在电脑和手机之间共享剪切版、远程输入、发送文件、共享文件夹、通知同步等等。 总而言之非常好用，只要手机和 PC 处于同一个局域网就行，不需要什么数据线。 如果安装系统时选择了打开防火墙，KDE Connect 是连不上的，需要手动开放端口号： # see: https://userbase.kde.org/KDEConnect#firewalld # 还可以使用 --add-source=xx.xx.xx.xx/xx 设置 ip 白名单 sudo firewall-cmd --zone=public --permanent --add-port=1714-1764/tcp sudo firewall-cmd --zone=public --permanent --add-port=1714-1764/udp sudo systemctl restart firewalld.service 然后手机（Android）安装好 KDE Connect，就能开始享受了。 目前存在的 Bug: Android 10 禁止了后台应用读取剪切版，这导致 KDE Connect 只能从 PC 同步到手机，而无法反向同步。 如果你有 ROOT 权限，可以参考 Fix clipboard permission on Android 10 的方法，安装 ClipboardWhitelist 来打开权限。 否则，貌似就只能使用手机端的「远程输入」模块来手动传输文本了。 ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:6","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"Qv2ray 代理 Qv2ray 是我用过的比较好用的 GUI 代理工具，通过插件可支持常见的所有代理协议。 # see: https://build.openSUSE.org/repositories/home:zzndb sudo zypper addrepo 'https://download.opensuse.org/repositories/home:/zzndb/openSUSE_Tumbleweed' qv2ray sudo zypper refresh sudo zypper install Qv2ray QvPlugin-Trojan QvPlugin-SS ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:7","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"VPN 连接与防火墙 防火墙默认会禁用 pptp 等 vpn 协议的端口，需要手动打开. 允许使用 PPTP 协议： # 允许 gre 数据包流入网络 sudo firewall-cmd --permanent --zone=public --direct --add-rule ipv4 filter INPUT 0 -p gre -j ACCEPT sudo firewall-cmd --permanent --zone=public --direct --add-rule ipv6 filter INPUT 0 -p gre -j ACCEPT # masquerade: 自动使用 interface 地址伪装所有流量（将主机当作路由器使用，vpn 是虚拟网络，需要这个功能） sudo firewall-cmd --permanent --zone=public --add-masquerade # pptp 客户端使用固定端口 1723/tcp 通信 firewall-cmd --add-port=1723/tcp --permanent sudo firewall-cmd --reload 允许使用 wireguard 协议，此协议只使用 tcp 协议，而且可以端口号可以自定义。不过 wireguard 自身的配置文件 /etc/wireguard/xxx.conf 就能配置 iptables 参数放行相关端口，这里就不赘述了。 ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:2:8","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["技术"],"content":"其他设置 从 Windows 带过来的习惯是单击选中文件，双击才打开，这个可以在「系统设置」-「工作空间行为」-「常规行为」-「点击行为」中修改。 ","date":"2021-01-04","objectID":"/posts/opensuse-instruction/:3:0","tags":["openSUSE","Linux"],"title":"openSUSE 使用指南","uri":"/posts/opensuse-instruction/"},{"categories":["随笔","技术"],"content":"闲言碎语 一晃一年又过去了，今年可真是魔幻的一年，口罩带了一年没能摘下来，美国疫情感染人数 1500 万。 上面这段话要是让去年的我看到了，没准都以为今年真的生化危机了hhh… 言归正传，从去年 6 月底入职，到现在有一年半了，这一年半学到的东西真的非常多，完全重塑了我的技术栈。现在我的整个技术栈，基本都是围绕着云原生这一块发展了。 ","date":"2020-12-12","objectID":"/posts/2020-summary/:1:0","tags":["总结"],"title":"2020 年年终总结","uri":"/posts/2020-summary/"},{"categories":["随笔","技术"],"content":"活动 今年也参加了几个技术沙龙，有些收获，但是没去年那么新奇了，主要是很多东西自己已经懂了hhh。大概有这么几个活动： 2019 年腾讯蓝鲸第5届运维技术沙龙：在深圳腾讯大厦参加的，点心和咖啡很棒，讲的东西里，腾讯自己分享的「研发运维一体化平台」比较有收获，我收藏了那一份 PPT Rancher - 企业云原生的探索与落地：去年参加 Rancher 的沙龙觉得很高大上，因为自己很多东西都不懂。但是今年来听，明显就感觉他们讲的很基础，对我没什么价值了。也侧面说明我确实进步了非常多哈哈。 2020 PyconChina 深圳场：额，也觉得没什么干货，好几个都是在推销自家的产品（Azure AI 平台和一个 Django 写的低代码平台），有个讲 Nix 包管理的大佬但是没讲好，后面我们就直接溜了… 另外就是，今年心血来潮买了四张 Live House 的演出票，体验下来觉得钱花得很值，给我充值了不少正能量。 景德镇文艺复兴《小歌行》：这是我超级喜欢的一个乐队，演出效果超棒！听到了完整的故事，而且见到了九三姑娘本人，太高兴了！ 徐海俏 - 游离片刻：这位歌手我之前其实没接触过，但是听了下她的《空》发现很不错很帅气，就买了。但是整场下来感觉俏俏状态不佳，有点唱不动的感觉。中场问歌迷们有没有带野格酒，末了又问深圳现在能游泳么哈哈，是个很随性的歌手。后面可能还真游泳去了。 夏小虎 - 逝年：这是个民谣歌手，以前上大学的时候听过，只有吉他和人声，其实是有些伤感的歌。因为我最近状态很好，我去之前还担心氛围不适合我。然后夏小虎说开心最重要，带了个乐队来伴奏，架子鼓就是灵魂，整个演出都因鼓点而欢快了起来。效果也非常棒！ 时光胶囊乐队：这也是一个国风后摇乐队，在一个深圳福田一个小酒吧「红糖罐上步店」演出的，比较简陋，人也不多，就四五十人的样子（出乎意料）。但是演出效果很棒，《旅途》《忆长安》《磐石》都非常好听。尤其是在这样的场合唱《我不知道你的名字》，挺有感触的。 ","date":"2020-12-12","objectID":"/posts/2020-summary/:2:0","tags":["总结"],"title":"2020 年年终总结","uri":"/posts/2020-summary/"},{"categories":["随笔","技术"],"content":"技术能力总结 今年我的工作重点有这么几个： 重构及维护 CI/CD 代码，让它能在多个产品线上复用 云上环境管理：今年熟悉了阿里云这一套东西，并且用上了自动化工具对云上环境进行管理。 一开始是使用 terraform，但是 terraform 的 hcl 语法不够灵活，最近切换到了 pulumi+python，不得不说真香。目前云上的资源及配置 95% 都完全用 pulumi 管理了（还剩大概 5% 因为各种原因，需要手动配置）。 kubernetes云原生: 今年我在这个领域的进步最大，熟悉了 k8s/istio/flagger/vault/prometheus/helm/traefik 等等。不过目前这里面大部分工具还停留在「会用」的状态。 服务器虚拟化系统从 vSphere 切换到 PVE VMware 的 vCenter 吃的资源太多，而且还不能自动扩缩容硬盘，Python SDK 也超难用。因此我在公司尝试使用 PVE 替换 vSphere 这一套，效果很不错。 PVE+pulumi/terraform+cloudinit 能实现自动化部署虚拟机，自动配置网络、账号及SSH密钥、自动扩缩容硬盘，非常方便！ 而且 PVE 不收费，去中心化，一套用下来舒服太多了。只是 pve+cloud-init 门槛稍微高一点，需要一定时间去熟悉。 CI/CD 系统：基于 Jenkins 的 CI/CD 在我司各种水土不服，小毛病不断。Jenkins 本身就存在单点故障，不适合云原生，加上 Jenkinsfile 有学习成本，而且不方便复用，我就想把 Jenkins 换掉。我在这一年里调研了大量的开源 CI/CD 工具，都各有不足。主要还是因为我们当下的 Jenkins 承载了太多的功能，已经是一个CI/CD、自动化测试、自动化运维平台了，另一方面公司后端的流水线还存在依赖关系，需要进行复杂的编排。 目前我就找到 Argo Workflows 的功能很符合我们的需求，目前正在尝试迁移一部分功能到 Argo Workflows 试用。 因为 argo 的 UI 和 jenkins 差别过大，暂定仍以 jenkins 为前端，通过 python 将任务分派给 argo 运行。这样 argo 对使用者而言是隐形的，用户体验基本上没区别。 杂事：修水电、修服务器、组装办公电脑、搬机房… ","date":"2020-12-12","objectID":"/posts/2020-summary/:3:0","tags":["总结"],"title":"2020 年年终总结","uri":"/posts/2020-summary/"},{"categories":["随笔","技术"],"content":"今年在技术方面的感受 Podman/Skopeo/Buildah/Kaniko 等技术进一步发展，正在逐渐蚕食 Docker 的地盘. kubernetes 已经弃用 docker-shim，直接对接 containerd，下一步应该是彻底切换到 CRI-O。 Istio 1.5 合并为单体架构效果很明显，各微信公众号三天两头就讲服务网格，服务网格是毋庸置疑的未来 阿里云的 OAM 进一步发展，目前阿里基于 OAM 研发的 Kubevela 致力于封装 Kubernetes 的功能，让小白也能用上 Kubernetes。而这同时还能保留 k8s 完整的能力，值得期待。 云上安全越来越引起重视了，目前 CNCF 社区上容器安全相关的项目在快速发展。包括镜像安全/安全容器(kata containers)等。 使用 Kubernetes 来管理数据库已经是大趋势，毕竟成本优势太明显了。 很多公司已经在使用 docker 运行数据库，毕竟性能没啥损失，就能方便很多。但是仍然手动搭建集群，也不使用分布式存储。 目前好像只有大厂如阿里京东才有这个实力，使用 kubernetes 和分布式存储来跑数据库。容器化的分布式存储系统维护(如 ceph)，其中的难点我目前还不是很清楚，不过无外乎性能、稳定性、故障恢复这些。 ","date":"2020-12-12","objectID":"/posts/2020-summary/:4:0","tags":["总结"],"title":"2020 年年终总结","uri":"/posts/2020-summary/"},{"categories":["随笔","技术"],"content":"明年的展望 Go 语言必须学起来，今年入门了两遍语法，但是没写过啥东西，又忘差不多了。 要进一步熟悉 k8s/istio/flagger/vault/prometheus/helm/traefik/caddy 这些工具，会用还不够，要深入底层。 深入学习计算机网络 + Linux 网络 + Kubernetes 网络！这非常重要。 学习 Podman/Docker 的底层原理，学习 katacontainers 等安全容器技术。 为 kubevela/dapr/knative 等云原生项目做一些贡献，要参与到开源中去。 掌握 Argo Workflows/tekton，将 CI/CD 搬到 k8s 上去。 学习设计模式 有机会的话，熟悉下分布式存储、分布式数据库。这方面我目前还相当欠缺。 学习 KVM 虚拟化 如果学（xian）有（de）余（dan）力（teng）的话，也可以考虑搞搞下面这几个： rust 语言：rust 通过 owner+lifetime 实现内存的智能管理，性能很高，而且编译器提示非常友好，值得一学。 机器学习/深度学习: 这个领域可是当下的大热门，可以用 python/julia 玩一玩，顺便补一补微积分线代概率论。。 《编程语言实现模式》：嗯，希望能自己造轮子，写些简单的 parser。 elixir: ruby 语法+ erlang 并发模型(actor), 如果有时间的话，也可以玩玩，了解下原生分布式的函数式语言的特点。 回看了下去年的总结，发现我 go/c# 都没学多少，设计模式也没动，python 还在原地踏步hhh… 去年的展望很多都没实现。 不过云原生这一块倒是进步很快，总体很满意今年的成果哈哈~ 明年加油！ ","date":"2020-12-12","objectID":"/posts/2020-summary/:5:0","tags":["总结"],"title":"2020 年年终总结","uri":"/posts/2020-summary/"},{"categories":["音乐","随笔"],"content":"前言 2020 年 11 月 28 日，我第一次参加 Live House，演出乐队是「景德镇文艺复兴」。 「景德镇文艺复兴」是我很喜欢的一支后摇乐队，我喜欢上这支乐队，还得从我的昵称「於清樂」说起。 17 年的时候，听了许多后摇，网易云就给我推荐「景德镇文艺复兴」的歌，如此结缘。 其中有一首歌是「满世」，后摇嘛，歌词只有四句： 月下灵鸟吟 花香无处寻 再看破土人 一满又一世 听这首歌的时候，我想起看过韩寒的《长安乱》，里面女主名叫「喜乐」，这名字里寄托着家人对她的期许——平安喜乐。 我心里也升起一个不可能实现的愿望： 希冀能于这尘世之中，享得半世清闲，一生喜乐 这愿望已然不可能实现，过往的岁月里，我有过太多苦恼，做过了太多错事；可遇见的未来，也还没到清闲享乐的时候。 那至少把昵称改成「於清樂」，提醒着自己，你有过这样一个愿望。 ","date":"2020-11-28","objectID":"/posts/jingdezhen-renaissance-band-2020-shenzhen/:1:0","tags":["景德镇文艺复兴","后摇"],"title":"「小歌行」-景德镇文艺复兴-2020巡演-深圳","uri":"/posts/jingdezhen-renaissance-band-2020-shenzhen/"},{"categories":["音乐","随笔"],"content":"演出 演出的内容是《小歌行》这张专辑，乐队通过一个自创的神话故事，将整张专辑串成了一个类似音乐剧的形式，进行演出，效果很棒！ 我用手机录下了几乎全程，因为第一次参加 Live House，又是自己这么喜欢的乐队，想要录下来，留做纪念。 视频已经上传到了 Bilibili: 录到最后手机没电了，为了留点电量刷公交车卡和门禁卡，最后一首《水码头》没有录完。（到家时真的差点刷不了门禁hhh） 好了，下面是演出的照片集锦： Live House 入口的宣传海报\" Live House 入口的宣传海报 老村长1\" 老村长1 老村长2\" 老村长2 老村长3\" 老村长3 拉小提琴的小哥哥\" 拉小提琴的小哥哥 九三舞蹈\" 九三舞蹈 小提琴伴奏\" 小提琴伴奏 九三是朝廷命官\" 九三是朝廷命官 阿弥陀佛\" 阿弥陀佛 唱\" 唱 唱\" 唱 唱\" 唱 唱\" 唱 唱\" 唱 九三最漂亮的一瞬间\" 九三最漂亮的一瞬间 九三超帅气\" 九三超帅气 结束： Live House 后台\" Live House 后台 结束鞠躬\" 结束鞠躬 大合照\" 大合照 签售： 签售\" 签售 ","date":"2020-11-28","objectID":"/posts/jingdezhen-renaissance-band-2020-shenzhen/:2:0","tags":["景德镇文艺复兴","后摇"],"title":"「小歌行」-景德镇文艺复兴-2020巡演-深圳","uri":"/posts/jingdezhen-renaissance-band-2020-shenzhen/"},{"categories":["技术"],"content":" 个人笔记，不保证正确 问题 我以前只知道 Base64 这个编码算法很常用，自己也经常在 JWT 等场景下使用，但是从来没了解过它的原理，一直先入为主地认为它的编码应该是唯一的。 但是今天测试 JWT 时，发现修改 JWT 的最后一个字符（其实不是我发现的。。），居然有可能不影响 JWT 的正确性。比如下这个使用 HS256 算法的 JWT: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c 把它的最后一个字符改成 d e或者 f，都能成功通过 http://jwt.io 的验证。 这让我觉得很奇怪（难道我发现了一个 Bug？），在QQ群里一问，就有大佬找到根本原因：这是 Base64 编码的特性。并且通过 python 进行了实际演示： In [1]: import base64 # 使用 jwt 的 signature 进行验证 In [2]: base64.b64decode(\"SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c==\") Out[2]: b'I\\xf9J\\xc7\\x04IH\\xc7\\x8a(]\\x90O\\x87\\xf0\\xa4\\xc7\\x89\\x7f~\\x8f:N\\xb2%V\\x9dB\\xcb0\\xe5' In [3]: base64.b64decode(\"SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5d==\") Out[3]: b'I\\xf9J\\xc7\\x04IH\\xc7\\x8a(]\\x90O\\x87\\xf0\\xa4\\xc7\\x89\\x7f~\\x8f:N\\xb2%V\\x9dB\\xcb0\\xe5' In [4]: base64.b64decode(\"SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5e==\") Out[4]: b'I\\xf9J\\xc7\\x04IH\\xc7\\x8a(]\\x90O\\x87\\xf0\\xa4\\xc7\\x89\\x7f~\\x8f:N\\xb2%V\\x9dB\\xcb0\\xe5' In [5]: base64.b64decode(\"SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5f==\") Out[5]: b'I\\xf9J\\xc7\\x04IH\\xc7\\x8a(]\\x90O\\x87\\xf0\\xa4\\xc7\\x89\\x7f~\\x8f:N\\xb2%V\\x9dB\\xcb0\\xe5' # 两个等于号之后的任何内容，都会被直接丢弃。这个是实现相关的，有的 base64 处理库对这种情况会报错。 In [6]: base64.b64decode(\"SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5f==fdf=df==dfd=fderwe=r\") Out[6]: b'I\\xf9J\\xc7\\x04IH\\xc7\\x8a(]\\x90O\\x87\\xf0\\xa4\\xc7\\x89\\x7f~\\x8f:N\\xb2%V\\x9dB\\xcb0\\xe5' 可以看到有两个现象： 将同一个 base64 串的最后一个字母分别改成 d e f，解码出来的内容没有任何变化。 在 base64 串末尾 == 后面添加了一堆随机字符，对解码出的内容也没有任何影响。 ","date":"2020-05-31","objectID":"/posts/base64-encoding-is-not-unique/:0:0","tags":["Base64","编码"],"title":"Base64 编码并不唯一","uri":"/posts/base64-encoding-is-not-unique/"},{"categories":["技术"],"content":"原因分析 base64 编码将二进制内容(bytes)从左往右每 6 bits 分为一组，每一组编码为一个可打印字符。 bas64 从 ASCII 字符集中选出了 64 个字符（=号除外）进行编码。因为 $2^6=64$，使用 64 个字符才能保证上述编码的唯一性。 但是被编码的二进制内容(bytes)的 bits 数不一定是 6 的倍数，无法被编码为 6 bits 一组。 为了解决这个问题，就需要在这些二进制内容的末尾填充上 2 或 4 个 bit 位，这样才能使用 base64 进行编码。 关于这些被填充的 bits，在 RFC4648 中定义了规范行为：全部补 0. 但是这并不是一个强制的行为，因此实际上你可以随便补，在进行 base64 解析时，被填补的 bits 会被直接忽略掉。 这就导致了上面描述的行为：修改 JWT 的最后一个字符(6 bits，其中可能包含 2 或 4 个填充比特位)可能并不影响被编码的实际内容！ RFC4684 中对这个 bits 填充的描述如下： 3.5. Canonical Encoding The padding step in base 64 and base 32 encoding can, if improperly implemented, lead to non-significant alterations of the encoded data. For example, if the input is only one octet for a base 64 encoding, then all six bits of the first symbol are used, but only the first two bits of the next symbol are used. These pad bits MUST be set to zero by conforming encoders, which is described in the descriptions on padding below. If this property do not hold, there is no canonical representation of base-encoded data, and multiple base- encoded strings can be decoded to the same binary data. If this property (and others discussed in this document) holds, a canonical encoding is guaranteed. In some environments, the alteration is critical and therefore decoders MAY chose to reject an encoding if the pad bits have not been set to zero. The specification referring to this may mandate a specific behaviour. 它讲到在某些环境下，base64 解析器可能会严格检查被填充的这几个 bits，要求它们全部为 0. 但是我测试发现，Python 标准库和 https://jwt.io 都没有做这样的限制。因此我认为绝大部分环境下，被填充的 bits 都是会被忽略的。 ","date":"2020-05-31","objectID":"/posts/base64-encoding-is-not-unique/:1:0","tags":["Base64","编码"],"title":"Base64 编码并不唯一","uri":"/posts/base64-encoding-is-not-unique/"},{"categories":["技术"],"content":"问题一：为什么只需要填充 2 或 4 个 bit 位？ 这是看到「填充上 2 或 4 个 bit 位」时的第一想法——如果要补足到 6 的倍数，不应该是要填充 1-5 个 bit 位么？ 要解答这个问题，我们得看 base64 的定义。在 RFC4648 的 base64 定义中，有如下这样一段话： The Base 64 encoding is designed to represent arbitrary sequences of octets in a form that allows the use of both upper- and lowercase letters but that need not be human readable. 注意重点：octets—— 和 bytes 同义，表示 8 bits 一组的位序列。这表示 base64 只支持编码 bits 数为 8 的倍数的二进制内容，而 $8x \\bmod 6$ 的结果只可能是 0/2/4 三种情况。 因此只需要填充 2 或 4 个 bit 位。 这样的假设也并没有什么问题，因为现代计算机都是统一使用 8 bits(byte) 为最小的可读单位的。即使是 c 语言的「位域」也是如此。 因为 Byte(8 bits) 现代 CPU 数据读写操作的基本单位，学过汇编的对这个应该都有些印象。 你仔细想想，所有文件的最小计量单位，是不是都是 byte？ ","date":"2020-05-31","objectID":"/posts/base64-encoding-is-not-unique/:2:0","tags":["Base64","编码"],"title":"Base64 编码并不唯一","uri":"/posts/base64-encoding-is-not-unique/"},{"categories":["技术"],"content":"问题二：为什么用 python 测试时可能需要在 JWT signature 的末尾添加多个 =，而 JWT 中不需要？ 前面已经讲过，base64 的编码步骤是是将字节(byte, 8 bits)序列，从左往右每 6 个 bits 转换成一个可打印字符。 查阅 RFC4648 第 4 小节中 baae64 的定义，能看到它实际上是每次处理 24 bits，因为这是 6 和 8 的最小公倍数，可以刚好用 4 个字符表示。 **在被处理的字节序列的比特(bits)数不是 24 的整数时，就需要在序列末尾填充 0 使末尾的 bits 数是 6 的倍数(6-bit groups)。**有可能会出现三种情况： 被处理的字节序列 S 的比特数刚好是 24 的倍数：不需要补比特位，末尾也就不需要加 = S 的比特数是 $24x+8$: 末尾需要补 4 个 bits，这样末尾剩余的 bits 才是 6-bit groups，才能编码成 base64。然后添加两个 == 使编码后的字符数为 4 的倍数。 S 的比特数为 $24x+16$：末尾需要添加 2 个 bits 才能编码成 base64。然后添加一个 = 使编码后的字符数为 4 的倍数。 其实可以看到，添加 = 的目的只是为了使编码后的字符数为 4 的倍数而已，= 这个 padding 其实是冗余信息，完全可以去掉。 在解码完成后，应用程序会自动去除掉末尾这不足 1 byte 的 2 或 4 个填充位。 因此 JWT 就去掉了它以减少传输的数据量。 可以用前面讲到的 JWT signature 进行验证： In [1]: import base64 In [2]: s = base64.b64decode(\"SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c==\") # len(s) * 8 得到 bits 数 In [3]: len(s) * 8 % 24 Out[3]: 8 可以看到这里的被编码内容比特数为 $24x+8$，所以末尾需要添加两个 == 号才符合 RFC4648 的定义。 ","date":"2020-05-31","objectID":"/posts/base64-encoding-is-not-unique/:3:0","tags":["Base64","编码"],"title":"Base64 编码并不唯一","uri":"/posts/base64-encoding-is-not-unique/"},{"categories":["技术"],"content":"参考 Remove trailing “=” when base64 encoding RFC4648 - base64 定义 Difference betweeen RFC 3548 and RFC 4648 Base64隐写原理和提取脚本 ","date":"2020-05-31","objectID":"/posts/base64-encoding-is-not-unique/:4:0","tags":["Base64","编码"],"title":"Base64 编码并不唯一","uri":"/posts/base64-encoding-is-not-unique/"},{"categories":["技术"],"content":"抓包分析 抓包分析工具主要有两种： http/https 网络代理工具：mitmproxy/fiddler 都属于这一类，用于分析 http 非常方便。但是只支持 http/https，有局限性。 tcp/udp/icmp 等网络嗅探工具：tcpdump/tshark 都属于这一类，网络故障分析等场景常用。 这里主要介绍如何使用 tcpdump + wireshark 进行远程实时抓包分析。 而 mitmproxy 抓包和 wireshark 本地抓包都相当简单，就不介绍了。 P.S. tshark 是 wireshark 的命令行版本，用法 tcpdump 非常相似。 ","date":"2020-05-28","objectID":"/posts/tcpdump-and-wireshark/:0:0","tags":["网络","Wireshark","tcpdump","抓包分析"],"title":"使用 tcpdump 和 Wireshark 进行远程实时抓包分析","uri":"/posts/tcpdump-and-wireshark/"},{"categories":["技术"],"content":"一、wireshark 的基本用法 WireShark 的 UI 界面如何使用，网上能搜得到各种类型的 wireshark 演示，多看几篇博客就会了。 搜索 [xxx 协议 wireshark 抓包分析] 就能找到各种各样的演示，比如 「gRPC 协议 wireshark 抓包分析」 「WebSocket 协议 wireshark 抓包分析」 「TCP 协议 wireshark 抓包分析」 等等 主要需要介绍的，应该是 wireshark 的数据包过滤器。 wireshark 中有两种包过滤器： 捕获过滤器：在抓包的时候使用它对数据包进行过滤。 显示过滤器：对抓到的所有数据包进行过滤。 显示过滤器是最有用的，下面简要介绍下显示过滤器的语法。 可以直接通过「协议名称」进行过滤： # 只看 tcp 流量 tcp # 只看 http 流量 http # 使用感叹号（或 not）进行反向过滤 !arp # 过滤掉所有 arp 数据包 也可以通过「协议名称.协议属性」和「比较操作符（比如 ==）」进行更精确的过滤： # 通过 ip 的源地址 src 或 dst 进行过滤 ip.src==192.168.1.33 # 通过 IP 地址（ip.addr）进行过滤（匹配 ip.src 或 ip.dst） ip.addr==192.168.0.5 # 上一条过滤表达式等价于： ip.src==192.168.0.5 or ip.dst==192.168.0.5 # 通过 tcp 端口号进行过滤 tcp.port==80 tcp.port\u003e4000 # 通过 http 的 host 属性进行过滤 http.host != \"xxx.baidu.com\" # 通过 http.referer 属性进行过滤 http.referer == \"xxx.baidu.com\" # 多个过滤器之间用 and、or 进行组合 http.host != \"xxx.baidu.com\" and http.referer == \"xxx.baidu.com\" ","date":"2020-05-28","objectID":"/posts/tcpdump-and-wireshark/:1:0","tags":["网络","Wireshark","tcpdump","抓包分析"],"title":"使用 tcpdump 和 Wireshark 进行远程实时抓包分析","uri":"/posts/tcpdump-and-wireshark/"},{"categories":["技术"],"content":"二、tcpdump + ssh + wireshark 远程实时抓包 在进行远程网络抓包分析时，我们通常的做法是： 使用 tcpdump 在远程主机上抓包，保存为 pcap 文件。 将 pcap 文件拷贝到本地，使用 wireshark 对其进行分析。 但是这样做没有时效性，而且数据拷贝来去也比较麻烦。 考虑使用流的方式，在远程主机上使用 tcpdump 抓包，本地使用 wireshark 进行实时分析。 使用 ssh 协议进行流式传输的示例如下： # eth0 更换成你的机器 interface 名称，虚拟机可能是 ens33 ssh root@some.host \"tcpdump -i eth0 -l -w -\" | wireshark -k -i - 在不方便使用 ssh 协议的情况下（比如容器抓包、Android 抓包），可以考虑使用 nc(netcat) 进行数据流的转发： # 1. 远程主机抓包：将数据流通过 11111 端口暴露出去 tcpdump -i wlan0 -s0 -w - | nc -l -p 11111 # 2. 本地主机从远程主机的 11111 端口读取数据，提供给 wireshark nc \u003cremote-host\u003e 11111 | wireshark -k -S -i - 如果是抓取 Android 手机的数据，方便起见，可以通过 adb 多进行一次数据转发： # 方案一：root 手机后，将 arm 版的 tcpdump 拷贝到手机内进行抓包 # 1. 在 adb shell 里使用 tcpdump 抓 WiFi 的数据包，转发到 11111 端口 ## 需要先获取到 root 权限，将 tcpdump 拷贝到 /system/bin/ 目录下 tcpdump -i wlan0 -s0 -w - | nc -l -p 11111 # 2. 在本机使用 adb forward 将手机的 11111 端口绑定到本机(PC)的 11111 端口 adb forward tcp:11111 tcp:11111 # 3. 直接从本机(PC)的 11111 端口读取数据，提供给 wireshark nc localhost 11111 | wireshark -k -S -i - ## 通过数据转发，本机 11111 端口的数据，就是安卓手机内 tcmpdump 的 stdout 内容。 # 方案二： # 如果手机不方便 root，推荐 PC 开启 WiFi 热点，手机连上这个热点访问网络。 # 这样手机的数据就一定会走 PC，直接在 PC 上通过 wireshark 抓包就行。 # 如果你只需要简单地抓 http/https 包，请使用 fiddler/mitmproxy 如果需要对 Kubernetes 集群中的容器进行抓包，推荐直接使用 ksniff! ","date":"2020-05-28","objectID":"/posts/tcpdump-and-wireshark/:2:0","tags":["网络","Wireshark","tcpdump","抓包分析"],"title":"使用 tcpdump 和 Wireshark 进行远程实时抓包分析","uri":"/posts/tcpdump-and-wireshark/"},{"categories":["技术"],"content":"Windows 系统 另外如果你本机是 Windows 系统，要分 shell 讨论： cmd: 可以直接使用上述命令。 powershell: **PowerShell 管道对 native commands 的支持不是很好，管道两边的命令貌似是串行执行的，这会导致 wireshark 无法启动！**目前没有找到好的解决方法。。 另外如果你使用 wsl，那么可以通过如下命令使 wsl 调用 windows 中的 wireshark 进行抓包分析： # 添加软链接 sudo ln -s \"$(which wireshark.exe)\" /usr/local/bin/wireshark 添加了上述软链接后，就可以正常地在 wsl 中使用前面介绍的所有抓包指令了（包括 ksniff）。 它能正常调用 windows 中的 wireshark，数据流也能正常地通过 shell 管道传输。 ","date":"2020-05-28","objectID":"/posts/tcpdump-and-wireshark/:2:1","tags":["网络","Wireshark","tcpdump","抓包分析"],"title":"使用 tcpdump 和 Wireshark 进行远程实时抓包分析","uri":"/posts/tcpdump-and-wireshark/"},{"categories":["技术"],"content":"2. termshark: 直接通过命令行 UI 进行实时抓包分析 有的时候，远程实时抓包因为某些原因无法实现，而把 pcap 数据拷贝到本地分析又比较麻烦。 这时你可以考虑直接使用命令行版本的 wireshark UI: termshark，直接在命令行进行实时的抓包分析。 kubectl-debug 默认的调试镜像中，就自带 termshark. ","date":"2020-05-28","objectID":"/posts/tcpdump-and-wireshark/:3:0","tags":["网络","Wireshark","tcpdump","抓包分析"],"title":"使用 tcpdump 和 Wireshark 进行远程实时抓包分析","uri":"/posts/tcpdump-and-wireshark/"},{"categories":["技术"],"content":"参考 WireShark使用教程 Tracing network traffic using tcpdump and tshark Android remote sniffing using Tcpdump, nc and Wireshark 聊聊tcpdump与Wireshark抓包分析 ","date":"2020-05-28","objectID":"/posts/tcpdump-and-wireshark/:4:0","tags":["网络","Wireshark","tcpdump","抓包分析"],"title":"使用 tcpdump 和 Wireshark 进行远程实时抓包分析","uri":"/posts/tcpdump-and-wireshark/"},{"categories":["技术"],"content":" 本文基于 Istio1.5 编写测试 Istio 支持使用 JWT 对终端用户进行身份验证（Istio End User Authentication），支持多种 JWT 签名算法。 目前主流的 JWT 算法是 RS256/ES256。（请忽略 HS256，该算法不适合分布式 JWT 验证） 这里以 RSA256 算法为例进行介绍，ES256 的配置方式也是一样的。 ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:0:0","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"1. 介绍 JWK 与 JWKS Istio 要求提供 JWKS 格式的信息，用于 JWT 签名验证。因此这里得先介绍一下 JWK 和 JWKS. JWKS ，也就是 JWK Set，json 结构如下： { \"keys\": [ \u003cjwk-1\u003e, \u003cjwk-2\u003e, ... ]} JWKS 描述一组 JWK 密钥。它能同时描述多个可用的公钥，应用场景之一是密钥的 Rotate. 而 JWK，全称是 Json Web Key，它描述了一个加密密钥（公钥或私钥）的各项属性，包括密钥的值。 Istio 使用 JWK 描述验证 JWT 签名所需要的信息。在使用 RSA 签名算法时，JWK 描述的应该是用于验证的 RSA 公钥。 一个 RSA 公钥的 JWK 描述如下： { \"alg\": \"RS256\", # 算法「可选参数」 \"kty\": \"RSA\", # 密钥类型 \"use\": \"sig\", # 被用于签名「可选参数」 \"kid\": \"NjVBRjY5MDlCMUIwNzU4RTA2QzZFMDQ4QzQ2MDAyQjVDNjk1RTM2Qg\", # key 的唯一 id \"n\": \"yeNlzlub94YgerT030codqEztjfU_S6X4DbDA_iVKkjAWtYfPHDzz_sPCT1Axz6isZdf3lHpq_gYX4Sz-cbe4rjmigxUxr-FgKHQy3HeCdK6hNq9ASQvMK9LBOpXDNn7mei6RZWom4wo3CMvvsY1w8tjtfLb-yQwJPltHxShZq5-ihC9irpLI9xEBTgG12q5lGIFPhTl_7inA1PFK97LuSLnTJzW0bj096v_TMDg7pOWm_zHtF53qbVsI0e3v5nmdKXdFf9BjIARRfVrbxVxiZHjU6zL6jY5QJdh1QCmENoejj_ytspMmGW7yMRxzUqgxcAqOBpVm0b-_mW3HoBdjQ\", \"e\": \"AQAB\" } RSA 是基于大数分解的加密/签名算法，上述参数中，e 是公钥的模数(modulus)，n 是公钥的指数(exponent)，两个参数都是 base64 字符串。 JWK 中 RSA 公钥的具体定义参见 RSA Keys - JSON Web Algorithms (JWA) ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:0:1","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"2. JWK 的生成 要生成 JWK 公钥，需要先生成私钥，生成方法参见 JWT 签名算法 HS256、RS256 及 ES256 及密钥生成。 公钥不需要用上述方法生成，因为我们需要的是 JWK 格式的公钥。后面会通过 python 生成出 JWK 公钥。 上面的命令会将生成出的 RSA 私钥写入 key.pem 中，查看一下私钥内容。 ryan@RYAN-MI-DESKTOP:~/istio$ cat key.pem -----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEAt1cKkQqPh8iOv5BhKh7Rx6A2+1ldpO/jczML/0GBKu4X+lHr Y8YbJrt29jyAXlWM8vHC7tXsqgUG+WziRD0D8nhnh10XC14SeH+3mVuBqph+TqhX TWsh9gtAIbeUHJjEI4I79QK4/wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAy Y35kJZgyJSbrxLsEExL2zujUD/OY+/In2bq/3rFtDGNlgHyC7Gu2zXSXvfOA4O5m 9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4+9q7sc3Dnkc5 EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxwIDAQABAoIBABIKhaaqJF+XM7zU B0uuxrPfJynqrFVbqcUfQ9H1bzF7Rm7CeuhRiUBxeA5Y+8TMpFcPxT/dWzGL1xja RxWx715/zKg8V9Uth6HF55o2r/bKlLtGw3iBz1C34LKwrul1eu+HlEDS6MNoGKco BynE0qvFOedsCu/Pgv7xhQPLow60Ty1uM0AhbcPgi6yJ5ksRB1XjtEnW0t+c8yQS nU3mU8k230SdMhf4Ifud/5TPLjmXdFpyPi9uYiVdJ5oWsmMWEvekXoBnHWDDF/eT VkVMiTBorT4qn+Ax1VjHL2VOMO5ZbXEcpbIc3Uer7eZAaDQ0NPZK37IkIn9TiZ21 cqzgbCkCgYEA5enHZbD5JgfwSNWCaiNrcBhYjpCtvfbT82yGW+J4/Qe/H+bY/hmJ RRTKf0kVPdRwZzq7GphVMWIuezbOk0aFGhk/SzIveW8QpLY0FV/5xFnGNjV9AuNc xrmgVshUsyQvr1TFkbdkC6yuvNgQfXfnbEoaPsXYEMCii2zqdF5lWGUCgYEAzCR2 6g8vEQx0hdRS5d0zD2/9IRYNzfP5oK0+F3KHH2OuwlmQVIo7IhCiUgqserXNBDef hj+GNcU8O/yXLomAXG7VG/cLWRrpY8d9bcRMrwb0/SkNr0yNrkqHiWQ/PvR+2MLk viWFZTTp8YizPA+8pSC/oFd1jkZF0UhKVAREM7sCgYB5+mfxyczFopyW58ADM7uC g0goixXCnTuiAEfgY+0wwXVjJYSme0HaxscQdOOyJA1ml0BBQeShCKgEcvVyKY3g ZNixunR5hrVbzdcgKAVJaR/CDuq+J4ZHYKByqmJVkLND4EPZpWSM1Rb31eIZzw2W 5FG8UBbr/GfAdQ6GorY+CQKBgQCzWQHkBmz6VG/2t6AQ9LIMSP4hWEfOfh78q9dW MDdIO4JomtkzfLIQ7n49B8WalShGITwUbLDTgrG1neeQahsMmg6+X99nbD5JfBTV H9WjG8CWvb+ZF++NhUroSNtLyu+6LhdaeopkbQVvPwMArG62wDu6ebv8v/5MrG8o uwrUSwKBgQCxV43ZqTRnEuDlF7jMN+2JZWhpbrucTG5INoMPOC0ZVatePszZjYm8 LrmqQZHer2nqtFpyslwgKMWgmVLJTH7sVf0hS9po0+iSYY/r8e/c85UdUreb0xyT x8whrOnMMODCAqu4W/Rx1Lgf2vXIx0pZmlt8Df9i2AVg/ePR6jO3Nw== -----END RSA PRIVATE KEY----- 接下来通过 Python 编程生成 RSA Public Key 和 JWK（jwk 其实就是公钥的另一个表述形式而已）: # 需要先安装依赖: pip install jwcrypto from jwcrypto.jwk import JWK from pathlib import Path private_key = Path(\"key.pem\").read_bytes() jwk = JWK.from_pem(private_key) # 导出公钥 RSA Public Key public_key = jwk.public().export_to_pem() print(public_key) print(\"=\"*30) # 导出 JWK jwk_bytes = jwk.public().export() print(jwk_bytes) Istio 需要 JWK 进行 JWT 验证，而我们手动验证 JWT 时一般需要用到 Public Key. 方便起见，上述代码把这两个都打印了出来。内容如下： # Public Key 内容，不包含这行注释 -----BEGIN PUBLIC KEY----- MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAt1cKkQqPh8iOv5BhKh7R x6A2+1ldpO/jczML/0GBKu4X+lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG+WziRD0D 8nhnh10XC14SeH+3mVuBqph+TqhXTWsh9gtAIbeUHJjEI4I79QK4/wquPHHIGZBQ DQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD/OY+/In2bq/ 3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4 KLb6oyvIzoeiprt4+9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ew xwIDAQAB -----END PUBLIC KEY----- # jwk 内容 { 'e': 'AQAB', 'kid': 'oyYwZSLCLVVPHdVp0jXIcLNpGn6dMCumlY-6wSenmFo', 'kty': 'RSA', 'n': 't1cKkQqPh8iOv5BhKh7Rx6A2-1ldpO_jczML_0GBKu4X-lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG-WziRD0D8nhnh10XC14SeH-3mVuBqph-TqhXTWsh9gtAIbeUHJjEI4I79QK4_wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD_OY-_In2bq_3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4-9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxw' } ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:0:2","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"4. 测试密钥可用性 接下来在 jwt.io 中填入测试用的公钥私钥，还有 Header/Payload。一是测试公私钥的可用性，二是生成出 JWT 供后续测试 Istio JWT 验证功能的可用性。 可以看到左下角显示「Signature Verified」，成功地生成出了 JWT。后续可以使用这个 JWT 访问 Istio 网关，测试 Istio JWT 验证功能。 ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:0:3","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"5. 启用 Istio 的身份验证 编写 istio 配置： apiVersion:\"security.istio.io/v1beta1\"kind:\"RequestAuthentication\"metadata:name:\"jwt-example\"namespace:istio-system # istio-system 名字空间中的配置，默认情况下会应用到所有名字空间spec:selector:matchLabels:istio:ingressgatewayjwtRules:# issuer 即签发者，需要和 JWT payload 中的 iss 属性完全一致。- issuer:\"testing@secure.istio.io\"jwks:|{ \"keys\": [ { \"e\": \"AQAB\", \"kid\": \"oyYwZSLCLVVPHdVp0jXIcLNpGn6dMCumlY-6wSenmFo\", # kid 需要与 jwt header 中的 kid 完全一致。 \"kty\": \"RSA\", \"n\": \"t1cKkQqPh8iOv5BhKh7Rx6A2-1ldpO_jczML_0GBKu4X-lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG-WziRD0D8nhnh10XC14SeH-3mVuBqph-TqhXTWsh9gtAIbeUHJjEI4I79QK4_wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD_OY-_In2bq_3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4-9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxw\" } ] } # jwks 或 jwksUri 二选其一 # jwksUri: \"http://nginx.test.local/istio/jwks.json\" 现在 kubectl apply 一下，JWT 验证就添加到全局了。 可以看到 jwtRules 是一个列表，因此可以为每个 issuers 配置不同的 jwtRule. 对同一个 issuers（jwt 签发者），可以通过 jwks 设置多个公钥，以实现JWT签名密钥的轮转。 JWT 的验证规则是： JWT 的 payload 中有 issuer 属性，首先通过 issuer 匹配到对应的 istio 中配置的 jwks。 JWT 的 header 中有 kid 属性，第二步在 jwks 的公钥列表中，中找到 kid 相同的公钥。 使用找到的公钥进行 JWT 签名验证。 ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:0:4","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"6. 启用 Payload 转发/Authorization 转发 默认情况下，Istio 在完成了身份验证之后，会去掉 Authorization 请求头再进行转发。 这将导致我们的后端服务获取不到对应的 Payload，无法判断 End User 的身份。 因此我们需要启用 Istio 的 Authorization 请求头的转发功能，在前述的 RequestAuthentication yaml 配置中添加一个参数就行： apiVersion:\"security.istio.io/v1beta1\"kind:\"RequestAuthentication\"metadata:name:\"jwt-example\"namespace:istio-systemspec:selector:matchLabels:istio:ingressgatewayjwtRules:- issuer:\"testing@secure.istio.io\"jwks:|{ \"keys\": [ { \"e\": \"AQAB\", \"kid\": \"oyYwZSLCLVVPHdVp0jXIcLNpGn6dMCumlY-6wSenmFo\", \"kty\": \"RSA\", \"n\": \"t1cKkQqPh8iOv5BhKh7Rx6A2-1ldpO_jczML_0GBKu4X-lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG-WziRD0D8nhnh10XC14SeH-3mVuBqph-TqhXTWsh9gtAIbeUHJjEI4I79QK4_wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD_OY-_In2bq_3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4-9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxw\" } ] }# ===================== 添加如下参数===========================forwardOriginalToken:true# 转发 Authorization 请求头 加了转发后，流程图如下（需要 mermaid 渲染）： ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:0:5","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"其他问题 ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:1:0","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"1. AuthorizationPolicy Istio 的 JWT 验证规则，默认情况下会直接忽略不带 Authorization 请求头的流量，因此这类流量能直接进入网格内部。如果需要禁止不带 Authorization 头的流量，需要额外配置 AuthorizationPolicy 策略。 RequestsAuthentication 验证失败的请求，Istio 会返回 401 状态码。 AuthorizationPolicy 验证失败的请求，Istio 会返回 403 状态码。 这会导致在使用 AuthorizationPolicy 禁止了不带 Authorization 头的流量后，这类请求会直接被返回 403。。。在使用 RESTful API 时，这种情况可能会造成一定的问题。 ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:1:1","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"2. Response Headers RequestsAuthentication 不支持自定义响应头信息，这导致对于前后端分离的 Web API 而言， 一旦 JWT 失效，Istio 会直接将 401 返回给前端 Web 页面。 因为响应头中不包含 Access-Crontrol-Allow-Origin，响应将被浏览器拦截！ 这可能需要通过 EnvoyFilter 自定义响应头，添加跨域信息。 ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:1:2","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":"参考 JSON Web Key Set Properties - Auth0 JWK - RFC7517 Sample JWT and JWKS data for demo - Istio Security End User Authentication - Istio JWTRule - Istio jwt.io - 动态生成 jwt ","date":"2020-04-06","objectID":"/posts/use-istio-for-jwt-auth/:2:0","tags":["Kubernetes","Istio","服务网格"],"title":"使用 Istio 进行 JWT 身份验证（充当 API 网关）","uri":"/posts/use-istio-for-jwt-auth/"},{"categories":["技术"],"content":" 个人笔记，观点不一定正确. 适合对 Kubernetes 有一定了解的同学。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:0:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"前言 最近一直在学习 Kubernetes，但是手头没有个自有域名，要测试 ingress 就比较麻烦，每次都是手动改 hosts 文件。。 今天突然想到——K8s 内部就是用 DNS 做的服务发现，我为啥不自己弄一个 DNS 服务器呢？然后所有节点的 DNS 都配成它，这样有需要时直接改这个 DNS 服务器的配置就行， 一劳永逸。 我首先想到的是 群晖/Windows Server 自带的那种自带图形化界面的 DNS 服务器，但是这俩都是平台特定的。 网上搜一圈没找到类似带 UI 的 DNS 工具，搜到的 powerdns/bind 相比 coredns 也没看出啥优势来，所以决定就用 CoreDNS，刚好熟悉一下它的具体使用。 不过讲 CoreDNS 前，我们还是先来熟悉一下 DNS 的基础概念吧。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:1:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"一、DNS 是个啥？ 没有写得很清楚，不适合初学。建议先通过别的资料熟悉下 DNS 基础。 DNS，即域名系统（Domain Name System），是一项负责将一个 human readable 的所谓域名，转换成一个 ip 地址的协议。 而域名的好处，有如下几项： 域名对人类更友好，可读的字符串比一串 ip 数字可好记多了。 一个域名可以对应多个 ip，可实现所谓的负载均衡。 多个域名可以对应同一个 ip，以不同的域名访问该 ip，能访问不同的应用。（通过 nginx 做代理实现） DNS 协议是一个基于 UDP 的应用层协议，它默认使用 53 端口进行通信。 应用程序通常将 DNS 解析委派给操作系统的 DNS Resolver 来执行，程序员对它几乎无感知。 DNS 虽然说一般只用来查个 ip 地址，但是它提供的记录类型还蛮多的，主要有如下几种： A 记录：它记录域名与 IPv4 地址的对应关系。目前用的最多的 DNS 记录就是这个。 AAAA 记录：它对应的是 IPv6，可以理解成新一代的 A 记录。以后会用的越来越多的。 NS 记录：记录 DNS 域对应的权威服务器域名，权威服务器域名必须要有对应的 A 记录。 通过这个记录，可以将子域名的解析分配给别的 DNS 服务器。 CNAME 记录: 记录域名与另一个域名的对应关系，用于给域名起别名。这个用得也挺多的。 MX 记录：记录域名对应的邮件服务器域名，邮件服务器的域名必须要有对应的 A 记录。 SRV 记录：SRV 记录用于提供服务发现，看名字也能知道它和 SERVICE 有关。 SRV 记录的内容有固定格式：优先级 权重 端口 目标地址，例如 0 5 5060 sipserver.example.com 主要用于企业域控(AD)、微服务发现（Kubernetes） 上述的所有 DNS 记录，都是属于将域名解析为 IP 地址，或者另一个域名，这被称做** DNS 正向解析**。 除了这个正向解析外，还有个非常冷门的反向解析，基本上只在设置邮件服务器时才会用到。（Kubernetes 可能也有用到） 反向解析主要的记录类型是：PTR 记录，它提供将 IP 地址反向解析为域名的功能。 而且因为域名是从右往左读的（最右侧是根, www.baidu.com.），而 IP 的网段（如 192.168.0.0/16）刚好相反，是左边优先。 因此 PTR 记录的“域名”必须将 IP 地址反着写，末尾再加上 .in-addr.arpa. 表示这是一个反向解析的域名。（ipv6 使用 ip6.arpa.） 拿 baidu.com 的邮件服务器测试一下： PTR 记录查询\" PTR 记录查询 其他还有些 TXT、CAA 等奇奇怪怪的记录，就用到的时候自己再查了。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:2:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"二、域名的分层结构 国际域名系统被分成四层： 根域（Root Zone）：所有域名的根。 根域名服务器负责解析顶级域名，给出顶级域名的 DNS 服务器地址。 全世界仅有十三组根域名服务器，这些服务器的 ip 地址基本不会变动。 它的域名是 “\"，空字符串。而它的**全限定域名（FQDN）**是 .，因为 FQDN 总是以 . 结尾。（FQDN 在后面解释，可暂时忽略） 顶级域（Top Level Domains, TLD）：.com .cn 等国际、国家级的域名 顶级域名服务器负责解析次级域名，给出次级域名的 DNS 服务器地址。 每个顶级域名都对应各自的服务器，它们之间是完全独立的。.cn 的域名解析仅由 .cn 顶级域名服务器提供。 目前国际 DNS 系统中已有上千个 TLD，包括中文「.我爱你」甚至藏文域名，详细列表参见 IANA TLD 数据库 除了国际可用的 TLD，还有一类类似「内网 IP 地址」的“私有 TLD”，最常见的比如 xxx.local xxx.lan，被广泛用在集群通信中。后面详细介绍 次级域（Second Level Domains）：这个才是个人/企业能够买到的域名，比如 baidu.com 每个次级域名都有一到多个权威 DNS 服务器，这些 DNS 服务器会以 NS 记录的形式保存在对应的顶级域名（TLD）服务器中。 权威域名服务器则负责给出最终的解析结果：ip 地址(A 记录 )，另一个域名（CNAME 记录）、另一个 DNS 服务器（NS 记录）等。 子域（Sub Domians）：*.baidu.com 统统都是 baidu.com 的子域。 每一个子域都可以有自己独立的权威 DNS 服务器，这通过在子域中添加 NS 记录实现。 普通用户通常是通过域名提供商如阿里云购买的次级域名，接下来我们以 rea.ink 为例介绍域名的购买到可用的整个流程。 域名的购买与使用流程： 你在某域名提供商处购买了一个域名 rea.ink 域名提供商向 .ink 对应的顶级域名服务器中插入一条以上的 NS 记录，指向它自己的次级 DNS 服务器，如 dns25.hichina.com. 阿里云会向 TLD 中插入几条 NS 记录，指向阿里云的次级 DNS 服务器（如 vip1.alidns.com）。 你在该域名提供商的 DNS 管理界面中添加 A 记录，值为你的服务器 IP。 OK 现在 ping 一下 rea.ink，就会发现它已经解析到你自己的服务器了。 上述流程中忽略了我大天朝的特殊国情——备案，勿介意。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:3:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"三、DNS 递归解析器：在浏览器中输入域名后发生了什么？ 下面的图片拷贝自 Amazon Aws 文档，它展示了在不考虑任何 DNS 缓存的情况下，一次 Web 请求的经过，详细描绘了 DNS 解析的部分。 DNS 解析流程\" DNS 解析流程 其中的第 3 4 5 步按顺序向前面讲过的根域名服务器、顶级域名服务器、权威域名服务器发起请求，以获得下一个 DNS 服务器的信息。这很清晰。 图中当前还没介绍的部分，是紫色的 DNS Resolver(域名解析器)，也叫 Recursive DNS resolver（DNS 递归解析器）。 它本身只负责递归地请求 3 4 5 步中的上游服务器，然后把获取的最终结果返回给客户端，同时将记录缓存到本地以加快解析速度。 这个 DNS 解析器，其实就是所谓的公共 DNS 服务器：Google 的 8.8.8.8，国内著名的 114.114.114.114。 这些公共 DNS 用户量大，缓存了大量的 DNS 记录，有效地降低了上游 DNS 服务器的压力，也加快了网络上的 DNS 查询速度。 接下来使用 dig +trace baidu.com 复现一下上述的查询流程（这种情况下 dig 自己就是一个 DNS 递归解析器）： dig +trace baidu.com\" dig +trace baidu.com 另外前面有讲过 DNS 的反向解析，也是同样的层级结构，是从根服务器开始往下查询的，下面拿 baidu 的一个邮件服务器进行测试： 反向解析\" 反向解析 dig 工具未来可能会被 drill 取代。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:4:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"DNS 泛解析通配符 * DNS 记录允许使用通配符 *，并且该通配符可匹配任意级数的子域！！！比如 *.example.com 就可以匹配所有的一二三四级域名等等，但是无法匹配 example.com 本身！ ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:4:1","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"TTL（Time To Live） 上面讲了公共 DNS 服务器通过缓存技术，降低了上游 DNS 服务器的压力，也加快了网络上的 DNS 查询速度。 可缓存总得有个过期时间吧！为了精确地控制 DNS 记录的过期时间，每条 DNS 记录都要求设置一个时间属性——TTL，单位为秒。这个时间可以自定义。 任何一条 DNS 缓存，在超过过期时间后都必须丢弃！ 另外在没超时的时候，DNS 缓存也可以被主动或者被动地刷新。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:4:2","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"四、本地 DNS 服务器与私有 DNS 域 这类服务器只在当前局域网内有效，是一个私有的 DNS 服务器，企业常用。一般通过 DHCP 或者手动配置的方式，使内网的服务器都默认使用局域网 DNS 服务器进行解析。该服务器可以只解析自己的私有 DNS 域，而将其他 DNS 域的解析 forward 到公网 DNS 解析器去。 这个私有 DNS 域，会覆盖掉公网的同名域(如果公网上有这个域的话)。 私有 dns 域也可使用公网不存在的 TLD，比如 xxx.local xxx.lan 等。vmware vcenter 就默认使用 vsphere.local 作为它的 sso (单点登录)系统的域名。kubernetes 默认使用 svc.cluster.local 作为集群内部域名。 私有 DNS 域的选择，参见 DNS 私有域的选择：internal.xxx.com xxx.local 还是 xxx.zone？ 局域网 DNS 服务器的规模与层级，视局域网的大小而定。一般小公司一个就行，要容灾设三个副本也够了。 以 CoreDNS 为例，局域网 DNS 服务器也可以被设置成一个 DNS Resolver，可以设置只转发特定域名的 DNS 解析。这叫将某个域设为「转发区域」。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:5:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"五、操作系统的 DNS 解析器 应用程序实际上都是调用的操作系统的 DNS Resolver 进行域名解析的。在 Linux 中 DNS Resolver 由 glibc/musl 提供，配置文件为 /etc/resolv.conf。 比如 Python 的 DNS 解析，就来自于标准库的 socket 包，这个包只是对底层 c 语言库的一个简单封装。 基本上只有专门用于网络诊断的 DNS 工具包，才会自己实现 DNS 协议。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:6:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"1. hosts 文件 操作系统中还有一个特殊文件：Linux 中的 /etc/hosts 和 Windows 中的 C:\\Windows\\System32\\drivers\\etc\\hosts 系统中的 DNS resolver 会首先查看这个 hosts 文件中有没有该域名的记录，如果有就直接返回了。没找到才会去查找本地 DNS 缓存、别的 DNS 服务器。 只有部分专门用于网络诊断的应用程序（e.g. dig）不会依赖 OS 的 DNS 解析器，因此这个 hosts 会失效。hosts 对于绝大部分程序都有效。 移动设备上 hosts 可能会失效，部分 app 会绕过系统，使用新兴的 HTTPDNS 协议进行 DNS 解析。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:6:1","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"2. HTTPDNS 传统的 DNS 协议因为使用了明文的 UDP 协议，很容易被劫持。顺应移动互联网的兴起，目前一种新型的 DNS 协议——HTTPDNS 应用越来越广泛，国内的阿里云腾讯云都提供了这项功能。 HTTPDNS 通过 HTTP 协议直接向权威 DNS 服务器发起请求，绕过了一堆中间的 DNS 递归解析器。好处有二： 权威 DNS 服务器能直接获取到客户端的真实 IP（而不是某个中间 DNS 递归解析器的 IP），能实现就近调度。 因为是直接与权威 DNS 服务器连接，避免了 DNS 缓存污染的问题。 HTTPDNS 协议需要程序自己引入 SDK，或者直接请求 HTTP API。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:6:2","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"3. 默认 DNS 服务器 操作系统的 DNS 解析器通常会允许我们配置多个上游 Name Servers，比如 Linux 就是通过 /etc/resolv.conf 配置 DNS 服务器的。 $ cat /etc/resolv.conf nameserver 8.8.8.8 nameserver 8.8.4.4 search lan 不过现在这个文件基本不会手动修改了，各 Linux 发行版都推出了自己的网络配置工具，由这些工具自动生成 Linux 的各种网络配置，更方便。 比如 Ubuntu 就推荐使用 netplan 工具进行网络设置。 Kubernetes 就是通过使用容器卷映射的功能，修改 /etc/resolv.conf，使集群的所有容器都使用集群 DNS 服务器（CoreDNS）进行 DNS 解析。 通过重复使用 nameserver 字段，可以指定多个 DNS 服务器（Linux 最多三个）。DNS 查询会按配置中的顺序选用 DNS 服务器。 **仅在靠前的 DNS 服务器没有响应（timeout）时，才会使用后续的 DNS 服务器！所以指定的服务器中的 DNS 记录最好完全一致！！！**不要把第一个配内网 DNS，第二个配外网！！！ ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:6:3","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"4. DNS 搜索域 上一小节给出的 /etc/resolv.conf 文件内容的末尾，有这样一行: search lan，它指定的，是所谓的 DNS 搜索域。 讲到 DNS 搜索域，就不得不提到一个名词：全限定域名（Full Qulified Domain Name, FQDN），即一个域名的完整名称，www.baidu.com。 一个普通的域名，有下列四种可能： www.baidu.com.: 末尾的 . 表示根域，说明 www.baidu.com 是一个 FQDN，因此不会使用搜索域！ www.baidu.com: 末尾没 .，但是域名包含不止一个 .。首先当作 FQDN 进行查询，没查找再按顺序在各搜索域中查询。 /etc/resolv.conf 的 options 参数中，可以指定域名中包含 . 的临界个数，默认是 1. local: 不包含 .，被当作 host 名称，非 FQDN。首先在 /etc/hosts 中查找，没找到的话，再按顺序在各搜索域中查找。 上述搜索顺序可以通过 host -v \u003cdomain-name\u003e 进行测试，该命令会输出它尝试过的所有 FQDN。 修改 /etc/resolv.conf 中的 search 属性并测试，然后查看输出。 就如上面说例举的，在没有 DNS 搜索域 这个东西的条件下，我们访问任何域名，都必须输入一个全限定域名 FQDN。 有了搜索域我们就可以稍微偷点懒，省略掉域名的一部分后缀，让 DNS Resolver 自己去在各搜索域中搜索。 在 Kubernetes 中就使用到了搜索域，k8s 中默认的域名 FQDN 是 service.namespace.svc.cluster.local， 但是对于 default namespace 中的 service，我们可以直接通过 service 名称查询到它的 IP。 对于其他名字空间中的 service，也可以通过 service.namespace 查询到它们的 IP，不需要给出 FQDN。 Kubernetes 中 /etc/resolv.conf 的示例如下： nameserver 10.43.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5 可以看到 k8s 设置了一系列的搜索域，并且将 . 的临界值设为了 5。 也就是少于 5 个 dots 的域名，都首先当作非 FQDN 看待，优先在搜索域里面查找。 该配置文件的详细描述参见 manpage - resolv.conf，或者在 Linux 中使用 man resolv.conf 命令查看。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:6:4","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"六、DNS 诊断的命令行工具 dig +trace baidu.com # 诊断 dns 的主要工具，非常强大 host -a baidu.com # host 基本就是 dig 的弱化版，不过 host 有个有点就是能打印出它测试过的所有 FQDN nslookup baidu.com # 和 host 没啥大差别，多个交互式查询不过一般用不到 whois baidu.com # 查询域名注册信息，内网诊断用不到 详细的使用请 man dig ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:7:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"七、CoreDNS 的使用 主流的本地 DNS 服务器中，提供 UI 界面的有 Windows DNS Server 和群晖 DNS Server，很方便，不过这两个都是操作系统绑定的。 开源的 DNS 服务器里边儿，BIND 好像是最有名的，各大 Linux 发行版自带的 dig/host/nslookup，最初都是 Bind 提供的命令行工具。 不过为了一举两得（DNS+K8s），咱还是直接学习 CoreDNS 的使用。 CoreDNS 最大的特点是灵活，可以很方便地给它编写插件以提供新功能。功能非常强大，相比传统 DNS 服务器，它非常“现代化”。在 K8s 中它被用于提供服务发现功能。 接下来以 CoreDNS 为例，讲述如何配置一个 DNS 服务器，添加私有的 DNS 记录，并设置转发规则以解析公网域名。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:8:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"1. 配置文件：Corefile CoreDNS 因为是 Go 语言写的，编译结果是单个可执行文件，它默认以当前文件夹下的 Corefile 为配置文件。以 kubernetes 中的 Corefile 为例： .:53 { errors # 启用错误日志 health # 启用健康检查 api ready # 启用 readiness 就绪 api # 启用 kubernetes 集群支持，详见 https://coredns.io/plugins/kubernetes/ # 此插件只处理 cluster.local 域，以及 PTR 解析 kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream # fallthrough in-addr.arpa ip6.arpa # 向下传递 DNS 反向查询 ttl 30 # 过期时间 } prometheus :9153 # 启用 prometheus metrics 支持 forward . 114.114.114.114 19.29.29.29 # 将非集群域名的 DNS 请求，转发给公网 DNS 服务器。 cache 30 # 启用前端缓存，缓存的 TTL 设为 30 loop # 检测并停止死循环解析 reload # 支持动态更新 Corefile # 随机化 A/AAAA/MX 记录的顺序以实现负载均衡。 # 因为 DNS resolver 通常使用第一条记录，而第一条记录是随机的。这样客户端的请求就能被随机分配到多个后端。 loadbalance } Corefile 首先定义 DNS 域，域后的代码块内定义需要使用的各种插件。**注意这里的插件顺序是没有任何意义的！**插件的调用链是在 CoreDNS 编译时就定义好的，不能在运行时更改。 通过上述配置启动的 CoreDNS 是无状态的，它以 Kubernetes ApiServer 为数据源，CoreDNS 本身只相当于一个查询器/缓存，因此它可以很方便地扩缩容。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:8:1","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"2. 将 CoreDNS 设置成一个私有 DNS 服务器 现在清楚了 Corefile 的结构，让我们来设计一个通过文件配置 DNS 条目的 Corefile 配置： # 定义可复用 Block (common) { log errors cache loop # 检测并停止死循环解析 } # 本地开发环境的 DNS 解析 dev-env.local:53 { import common # 导入 Block file dev-env.local { # 从文件 `dev-env.local` 中读取 DNS 数据 reload 30s # 每 30s 检查一次配置的 Serial，若该值有变更则重载整个 Zone 的配置。 } } # 本地测试环境 test-env.local:53 { import common file test-env.local { reload 30s } } # 其他 .:53 { forward . 114.114.114.114 # 解析公网域名 log errors cache } 上面的 Corefile 定义了两个本地域名 dev-env.local 和 test-env.local，它们的 DNS 数据分别保存在 file 指定的文件中。 这个 file 指定的文件和 bind9 一样，都是使用在 rfc1035 中定义的 Master File 格式，dig 命令输出的就是这种格式的内容。示例如下： ;; 與整個領域相關性較高的設定包括 NS, A, MX, SOA 等標誌的設定處！ $TTL 30 @ IN SOA dev-env.local. devops.dev-env.local. ( 20200202 ; SERIAL，每次修改此文件，都应该同步修改这个“版本号”，可将它设为修改时间。 7200 ; REFRESH 600 ; RETRY 3600000 ; EXPIRE 60) ; MINIMUM @ IN NS dns1.dev-env.local. ; DNS 伺服器名稱 dns1.dev-env.local. IN A 192.168.23.2 ; DNS 伺服器 IP redis.dev-env.local. IN A 192.168.23.21 mysql.dev-env.local. IN A 192.168.23.22 elasticsearch.dev-env.local. IN A 192.168.23.23 ftp IN A 192.168.23.25 ; 這是簡化的寫法！ 详细的格式说明参见 鳥哥的 Linux 私房菜 - DNS 正解資料庫檔案的設定 test-env.local 也是一样的格式，根据上面的模板修改就行。这两个配置文件和 Corefile 放在同一个目录下： root@test-ubuntu:~/dns-server# tree . ├── coredns # coredns binary ├── Corefile ├── dev-env.local └── test-env.local 然后通过 ./coredns 启动 coredns。通过 dig 检验： DNS 测试\" DNS 测试 可以看到 ftp.dev-env.local 已经被成功解析了。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:8:2","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"3. 可选插件（External Plugins） CoreDNS 提供的预编译版本，不包含 External Plugins 中列出的部分，如果你需要，可以自行修改 plugin.cfg，然后手动编译。 不得不说 Go 语言的编译，比 C 语言是方便太多了。自动拉取依赖，一行命令编译！只要配好 GOPROXY，启用可选插件其实相当简单。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:8:3","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"4. 设置 DNS 集群 单台 DNS 服务器的性能是有限的，而且存在单点故障问题。因此在要求高可用或者高性能的情况下，就需要设置 DNS 集群。 虽然说 CoreDNS 本身也支持各种 DNS Zone 传输，主从 DNS 服务器等功能，不过我想最简单的，可能还是直接用 K8s。 直接用 ConfigMap 存配置，通过 Deployment 扩容就行，多方便。 要修改起来更方便，还可以启用可选插件：redis，直接把配置以 json 的形式存在 redis 里，通过 redis-desktop-manager 进行查看与修改。 ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:8:4","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"参考 DNS 原理入门 What Is DNS? | How DNS Works - Cloudflare What is DNS? - Amazon AWS 鸟哥的 Linux 私房菜——主機名稱控制者： DNS 伺服器 CoreDNS - Manual Kubernetes - DNS for Services and Pods Kubernetes - Customizing DNS Service ","date":"2020-03-29","objectID":"/posts/about-dns-protocol/:9:0","tags":["DNS","CoreDNS","网络"],"title":"Linux网络学习笔记（二）：域名解析(DNS)——以 CoreDNS 为例","uri":"/posts/about-dns-protocol/"},{"categories":["技术"],"content":"签名算法 介绍具体的 JWT 签名算法前，先解释一下签名、摘要/指纹、加密这几个名词的含义： 数字签名(Digital Signature):就和我们日常办理各种手续时需要在文件上签上自己的名字一样，数字签名的主要用途也是防止伪造签名。 数字摘要(digest)/数字指纹(fingerprint): 指的都是数据的 Hash 值。 加密算法：这个应该不需要解释，就是对数据进行加密。。 数字签名的具体实现，通常是先对数据进行一次 Hash 摘要(SHA1/SHA256/SHA512 等)，然后再使用非对称加密算法(RSA/ECDSA 等)的私钥对这个摘要进行加密，这样得到的结果就是原始数据的一个签名。 用户在验证数据时，只需要使用公钥解密出 Hash 摘要，然后自己再对数据进行一次同样的摘要，对比两个摘要是否相同即可。 注意：签名算法是使用私钥加密，确保得到的签名无法被伪造，同时所有人都可以使用公钥解密来验证签名。这和正常的数据加密算法是相反的。 因为数字签名多了非对称加密这一步，就能保证只有拥有私钥的人才能生成出正确的数字签名，达到了防止伪造签名的目的。 而数字摘要（Hash）则谁都可以计算出来，通常由可信方公布数据的 Hash 值，用户下载数据后，可通过 Hash 值对比来判断数据是否损坏，或者被人调包。 重点在于，Hash 摘要必须由可信方公布出来，否则不能保证安全性。而数字签名可以随数据一起提供，不需要担心被伪造。 JWT 是签名和数据一起提供的，因此必须使用签名才能保证安全性。 P.S. 在 Android/IOS 开发中，经常会遇到各类 API 或者 APP 商店要求提供 APP 的签名，还指明需要的是 MD5/SHA1 值。 这个地方需要填的 MD5/SHA1 值，实际上只是你「签名证书(=公钥+证书拥有者信息)」的「数字指纹/摘要」，和 JWT 的签名不是一回事。 前言 JWT 规范的详细说明请见「参考」部分的链接。这里主要说明一下 JWT 最常见的几种签名算法(JWA)：HS256(HMAC-SHA256) 、RS256(RSA-SHA256) 还有 ES256(ECDSA-SHA256)。 这三种算法都是一种消息签名算法，得到的都只是一段无法还原的签名。区别在于消息签名与签名验证需要的 「key」不同。 HS256 使用同一个「secret_key」进行签名与验证（对称加密）。一旦 secret_key 泄漏，就毫无安全性可言了。 因此 HS256 只适合集中式认证，签名和验证都必须由可信方进行。 传统的单体应用广泛使用这种算法，但是请不要在任何分布式的架构中使用它！ RS256 是使用 RSA 私钥进行签名，使用 RSA 公钥进行验证。公钥即使泄漏也毫无影响，只要确保私钥安全就行。 RS256 可以将验证委托给其他应用，只要将公钥给他们就行。 ES256 和 RS256 一样，都使用私钥签名，公钥验证。算法速度上差距也不大，但是它的签名长度相对短很多（省流量），并且算法强度和 RS256 差不多。 对于单体应用而言，HS256 和 RS256 的安全性没有多大差别。 而对于需要进行多方验证的微服务架构而言，显然只有 RS256/ES256 才能提供足够的安全性。 在使用 RS256 时，只有「身份认证的微服务(auth)」需要用 RSA 私钥生成 JWT，其他微服务使用公开的公钥即可进行签名验证，私钥得到了更好的保护。 更进一步，「JWT 生成」和「JWT 公钥分发」都可以直接委托给第三方的通用工具，比如 hydra。 甚至「JWT 验证」也可以委托给「API 网关」来处理，应用自身可以把认证鉴权完全委托给外部的平台，而应用自身只需要专注于业务。这也是目前的发展趋势。 RFC 7518 - JSON Web Algorithms (JWA) 中给出的 JWT 算法列表如下： +--------------+-------------------------------+--------------------+ | \"alg\" Param | Digital Signature or MAC | Implementation | | Value | Algorithm | Requirements | +--------------+-------------------------------+--------------------+ | HS256 | HMAC using SHA-256 | Required | | HS384 | HMAC using SHA-384 | Optional | | HS512 | HMAC using SHA-512 | Optional | | RS256 | RSASSA-PKCS1-v1_5 using | Recommended | | | SHA-256 | | | RS384 | RSASSA-PKCS1-v1_5 using | Optional | | | SHA-384 | | | RS512 | RSASSA-PKCS1-v1_5 using | Optional | | | SHA-512 | | | ES256 | ECDSA using P-256 and SHA-256 | Recommended+ | | ES384 | ECDSA using P-384 and SHA-384 | Optional | | ES512 | ECDSA using P-521 and SHA-512 | Optional | | PS256 | RSASSA-PSS using SHA-256 and | Optional | | | MGF1 with SHA-256 | | | PS384 | RSASSA-PSS using SHA-384 and | Optional | | | MGF1 with SHA-384 | | | PS512 | RSASSA-PSS using SHA-512 and | Optional | | | MGF1 with SHA-512 | | | none | No digital signature or MAC | Optional | | | performed | | +--------------+-------------------------------+--------------------+ The use of \"+\" in the Implementation Requirements column indicates that the requirement strength is likely to be increased in a future version of the specification. 目前应该所有 jwt 相关的库都支持 HS256/RS256/ES256 这三种算法。 ES256 使用 ECDSA 进行签名，它的安全性和运算速度目前和 RS256 差距不大，但是拥有更短的签名长度。 对于需要频繁发送的 JWT 而言，更短的长度长期下来可以节约大量流量。 因此更推荐使用 ES256 算法。 ","date":"2020-03-03","objectID":"/posts/jwt-algorithm-key-generation/:0:0","tags":["JWT","算法","OpenSSL"],"title":"JWT 签名算法 HS256、RS256 及 ES256 及密钥生成","uri":"/posts/jwt-algorithm-key-generation/"},{"categories":["技术"],"content":"使用 OpenSSL 生成 RSA/ECC 公私钥 RS256 使用 RSA 算法进行签名，可通过如下命令生成 RSA 密钥： # 1. 生成 2048 位（不是 256 位）的 RSA 密钥 openssl genrsa -out rsa-private-key.pem 2048 # 2. 通过密钥生成公钥 openssl rsa -in rsa-private-key.pem -pubout -out rsa-public-key.pem ES256 使用 ECDSA 算法进行签名，该算法使用 ECC 密钥，生成命令如下： # 1. 生成 ec 算法的私钥，使用 prime256v1 算法，密钥长度 256 位。（强度大于 2048 位的 RSA 密钥） openssl ecparam -genkey -name prime256v1 -out ecc-private-key.pem # 2. 通过密钥生成公钥 openssl ec -in ecc-private-key.pem -pubout -out ecc-public-key.pem 密钥的使用应该就不需要介绍了，各类语言都有对应 JWT 库处理这些，请自行查看文档。 如果是调试/学习 JWT，需要手动签名与验证的话，推荐使用 jwt 工具网站 - jwt.io ","date":"2020-03-03","objectID":"/posts/jwt-algorithm-key-generation/:1:0","tags":["JWT","算法","OpenSSL"],"title":"JWT 签名算法 HS256、RS256 及 ES256 及密钥生成","uri":"/posts/jwt-algorithm-key-generation/"},{"categories":["技术"],"content":"参考 RFC 7518 - JSON Web Algorithms (JWA) 什么是 JWT – JSON WEB TOKEN jwt 工具网站 - jwt.io JWT 算法比较 ","date":"2020-03-03","objectID":"/posts/jwt-algorithm-key-generation/:2:0","tags":["JWT","算法","OpenSSL"],"title":"JWT 签名算法 HS256、RS256 及 ES256 及密钥生成","uri":"/posts/jwt-algorithm-key-generation/"},{"categories":["随笔","技术"],"content":" 迟到的年终总结 ","date":"2020-01-31","objectID":"/posts/2019-summary/:0:0","tags":["总结"],"title":"2019 年年终总结","uri":"/posts/2019-summary/"},{"categories":["随笔","技术"],"content":"闲言碎语 我是今年六月底到的深圳，运气很好，第一面就面上了现在所在的公司，以下就叫它 W 公司吧。 公司的技术栈也很适合我，在入职到现在的这半年里，我学到了不少知识。 但是运气也差，只有这么一家公司约了我面试，投的其他简历都石沉大海… 总之，今年尝试参加过两次技术分享，Rancher 的技术沙龙，前几天又去听了 OSChina 的源创会。 ","date":"2020-01-31","objectID":"/posts/2019-summary/:1:0","tags":["总结"],"title":"2019 年年终总结","uri":"/posts/2019-summary/"},{"categories":["随笔","技术"],"content":"技术能力总结 我入职后做的是运维开发，主要负责通过 Jenkins Pipeline + Python 进行自动化的测试、构建和部署： 测试：指 UI 测试、API 测试、压力测试。单元测试算在构建流程中。 构建：更新依赖-\u003e单元测试-\u003e构建 Library 或镜像 公司的内部代码使用分层结构，底层封装了各种第三方包，并实现了一些通用的功能，形成了所谓的中台。目前是通过批量任务逐级自下向上构建。 部署：扫描镜像仓库中各镜像，生成最新的 k8s 部署文件，然后进行部署。 所以这半年中，我差不多熟悉了自动化运维的工作。主要包括 Jenkins Pipeline 的编写，我们基本都是使用 Jenkins 调用 Python 代码来进行具体的构建。 公司的构建有很多自己特殊的需求，Jenkins 自带的插件无法满足。 熟悉了 Python 的 subprocess 库，为了远程调用，又熟悉了 fabric（当作 library 用）。 做压测时，熟悉了 locust 因为基本都是通过命令行进行测试、构建，我现在比前后端组还熟悉 csharp/flutter/golang 的 cli… 学会了 Dockerfile 语法。我们的后端全部都是以容器方式部署的，这个是基本技能。 熟悉并且用上了 Kubernetes. 这东西基本上就是未来了，也将是我的主攻方向。 但是，也存在一些问题： 对 Linux/网络/vSphere 不够了解，导致每次处理这类问题只会排除法。 对监控/日志/告警不够了解，监控面板一堆参数却看不出问题，日志不知道怎么用 kibana 进行搜索，告警还没配过。。 解决问题的能力还有待提升，考虑总是不够全面，老是出问题。（不能让人放心） 总是想得太多，拖慢了解决问题的速度。（这倒也不能完全算是缺点。） ","date":"2020-01-31","objectID":"/posts/2019-summary/:2:0","tags":["总结"],"title":"2019 年年终总结","uri":"/posts/2019-summary/"},{"categories":["随笔","技术"],"content":"今年在技术上的感受 Kubernetes 和云原生正在席卷整个互联网/物联网行业。 Kubernetes 目前主要用于 Stateless 应用，那后端的 数据库/缓存/消息服务 要如何做分布式呢？这也是大家关注的重点。 分布式、微服务模式下的监控(prometheus)、日志分析(elk)、安全、链路追踪(jaeger)，是运维关注的重点。 服务网格正在走向成熟，Istio 很值得学习和试用。 开源的分布式数据库/云数据库成为越来越多企业的选择，开源的 TiDB（HTAP）和阿里云的 PolarDB（计算存储分离）都应该了解了解。 Transaction Processing: 面向交易，数据的变动(增删改)多，涉及的数据量和计算量(查)少，实时性要求高。 Analytical Processing：面向分析，数据的变动少，但涉及的数据量和计算量很多！ HTAP（Hybrid transaction/analytical processing）：混合型数据库，可同时被用于上述两种场景。 Knative/Jenkins-X 这类 Serverless 的 CI/CD 也正在快速发展，需要深入调研。 ","date":"2020-01-31","objectID":"/posts/2019-summary/:3:0","tags":["总结"],"title":"2019 年年终总结","uri":"/posts/2019-summary/"},{"categories":["随笔","技术"],"content":"明年的展望 作为一名萌新运维开发，明年显然还要继续在这条路上继续向前。 我明年的任务，第一件，就是优化掉部分自己目前存在的问题（前面有提到），第二呢，就是紧跟技术潮流。重点有下面几项： 充实自己网络部分欠缺的知识，尤其是 DNS 解析(CoreDNS)和 NAT(iptables)这俩玩意儿。 学习数据库组件的使用和性能调优：MySQL/Redis/ElasticSearch/MongoDB，另外熟悉 PostgreSQL 和分布式数据库 TiDB/Vitess Kubernetes/Istio Kubernetes 上的 CI/CD：Knative, Istio-GitOps 监控告警：Prometheus/Grafana 总结一套故障排除的方法论：网络故障、CPU/RAM/Disk 性能异常等、应用故障等。 最重要的任务，是维护公司这一套微服务在阿里云上的正常运行，积累经验。 关注 CNCF 蓝图 上的各项新技术。 另外呢，就是开发方面的任务： 设计模式应该要学学了！ Python 不能止步于此，要制定源码学习计划。 学习 C# 语言，阅读公司的源码，熟悉企业级的业务代码。 学习 go 语言，用于 DevOps。（其实还想学 rust，不过明年可能没时间） 要把 xhup 那个项目完成，也不知道能不能抽出时间。。 ","date":"2020-01-31","objectID":"/posts/2019-summary/:4:0","tags":["总结"],"title":"2019 年年终总结","uri":"/posts/2019-summary/"},{"categories":["技术"],"content":"Pod 常见错误 OOMKilled: Pod 的内存使用超出了 resources.limits 中的限制，被强制杀死。 SandboxChanged: Pod sandbox changed, it will be killed and re-created: 很可能是由于内存限制导致容器被 OOMKilled，或者其他资源不足 如果是 OOM，容器通常会被重启，kubectl describe 能看到容器上次被重启的原因 State.Last State.Reason = OOMKilled, Exit Code=137. Pod 不断被重启，kubectl describe 显示重启原因 State.Last State.Reason = Error, Exit Code=137，137 对应 SIGKILL(kill -9) 信号，说明容器被强制重启。可能的原因： 最有可能的原因是，存活探针（livenessProbe）检查失败 节点资源不足，内核强制关闭了进程以释放资源，这种情况可以通过 journalctl -k 查看详细的系统日志。 CrashLoopBackoff: Pod 进入 崩溃-重启循环，重启间隔时间从 10 20 40 80 一直翻倍到上限 300 秒，然后以 300 秒为间隔无限重启。 Pod 一直 Pending: 这说明没有任何节点能满足 Pod 的要求，容器无法被调度。比如端口被别的容器用 hostPort 占用，节点有污点等。 FailedCreateSandBox: Failed create pod sandbox: rpc error: code = DeadlineExceeded desc = context deadline exceeded：很可能是 CNI 网络插件的问题（比如 ip 地址溢出）， FailedSync: error determining status: rpc error: code = DeadlineExceeded desc = context deadline exceeded: 常和前两个错误先后出现，很可能是 CNI 网络插件的问题。 开发集群，一次性部署所有服务时，各 Pod 互相争抢资源，导致 Pod 生存探针失败，不断重启，重启进一步加重资源使用。恶性循环。 需要给每个 Pod 加上 resources.requests，这样资源不足时，后续 Pod 会停止调度，直到资源恢复正常。 Pod 出现大量的 Failed 记录，Deployment 一直重复建立 Pod: 通过 kubectl describe/edit pod \u003cpod-name\u003e 查看 pod Events 和 Status，一般会看到失败信息，如节点异常导致 Pod 被驱逐。 Kubernetes 问题排查：Pod 状态一直 Terminating 创建了 Deployment 后，却没有自动创建 Pod: 缺少某些创建 Pod 必要的东西，比如设定的 ServiceAccount 不存在。 Pod 运行失败，状态为 MatchNodeSelector: 对主节点进行关机、迁移等操作，导致主调度器下线时，会在一段时间内导致 Pod 调度失败，调度失败会报这个错。 Pod 仍然存在，但是 Service 的 Endpoints 却为空，找不到对应的 Pod IPs: 遇到过一次，是因为时间跳变（从未来的时间改回了当前时间）导致的问题。 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:1:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"控制面故障可能会导致各类奇怪的异常现象 对于生产环境的集群，因为有高可用，通常我们比较少遇到控制面故障问题。但是一旦控制面发生故障，就可能会导致各类奇怪的异常现象。 如果能在排查问题时，把控制面异常考虑进来，在这种情况下，就能节约大量的排查时间，快速定位到问题。 其中比较隐晦的就是 controller-manager 故障导致的异常： 节点的服务器已经被终止，但是 Kuberntes 里还显示 node 为 Ready 状态，不会更新为 NotReady. 被删除的 Pods 可能会卡在 Terminating 状态，只有强制删除才能删除掉它们。并且确认 Pod 没有 metadata.finalizers 属性 HPA 的动态伸缩功能失效 … 如果这些现象同时发生，就要怀疑是否是 kube-controller-manager 出问题了. 其他控制面异常的详细分析，参见 kubernetes 控制面故障现象及分析 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:1:1","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"Pod 无法删除 可能是某些资源无法被GC，这会导致容器已经 Exited 了，但是 Pod 一直处于 Terminating 状态。 这个问题在网上能搜到很多案例,但大都只是提供了如下的强制清理命令，未分析具体原因： kubectl delete pods \u003cpod\u003e --grace-period=0 --force 最近找到几篇详细的原因分析文章，值得一看： 腾讯云原生 -【Pod Terminating原因追踪系列】之 containerd 中被漏掉的 runc 错误信息 腾讯云原生 -【Pod Terminating原因追踪系列之二】exec连接未关闭导致的事件阻塞 腾讯云原生 -【Pod Terminating原因追踪系列之三】让docker事件处理罢工的cancel状态码 Pod terminating - 问题排查 - KaKu Li 大致总结一下，主要原因来自 docker 18.06 以及 kubernetes 的 docker-shim 运行时的底层逻辑，已经在新版本被修复了。 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:1:2","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"initContainers 不断 restart，但是 Containers 却都显示已 ready Kubernetes 应该确保所有 initContainers 都 Completed，然后才能启动 Containers. 但是我们发现有一个节点上，所有包含 initContainers 的 Pod，状态全都是 Init:CrashLoopBackOff 或者 Init:Error. 而且进一步 kubectl describe po 查看细节，发现 initContainer 的状态为: ... State: Waiting Reason: CrashLoopBackOff Last State: Terminated Reason: Error Exit Code: 2 Started: Tue, 03 Aug 2021 06:02:42 +0000 Finished: Tue, 03 Aug 2021 06:02:42 +0000 Ready: False Restart Count: 67 ... 而 Containers 的状态居然是 ready: ... Host Port: 0/TCP State: Running Started: Tue, 03 Aug 2021 00:35:30 +0000 Ready: True Restart Count: 0 ... initContainers 还未运行成功，而 Containers 却 Ready 了，非常疑惑。 仔细想了下，早上因为磁盘余量告警，有手动运行过 docker system prune 命令，那么问题可能就是这条命令清理掉了已经 exited 的 initContainers 容器，导致 k8s 故障，不断尝试重启该容器。 网上一搜确实有相关的信息： https://stackoverflow.com/questions/62333064/cant-delete-exited-init-container https://github.com/kubernetes/kubernetes/issues/62362 结论：使用外部的垃圾清理命令可能导致 k8s 行为异常。 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:1:3","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"节点常见错误 DiskPressure：节点的可用空间不足。（通过df -h 查看，保证可用空间不小于 15%） The node was low on resource: ephemeral-storage: 同上，节点的存储空间不够了。 节点存储告警可能的原因： kubelet 的资源 GC 设置有问题，遗留的镜像等资源未及时 GC 导致告警 存在运行的 pod 使用了大量存储空间，在节点上通过 docker ps -a --size | grep G 可以查看到 如果使用的是 EKS，并且磁盘告警的挂载点为 /var/lib/kubelet/plugins/kubernetes.io/aws-ebs/mounts/aws/us-east-1b/vol-xxxxx 显然是 EBS 存储卷快满了导致的 可通过 kubectl get pv -A -o yaml | grep -C 30 vol-xxxxx 来定位到具体的存储卷 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:2:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"网络常见错误 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:3:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"1. Ingress/Istio Gateway 返回值 404：不存在该 Service/Istio Gateway，或者是服务自身返回 404 500：大概率是服务自身的错误导致 500，小概率是代理（Sidecar/Ingress 等）的错误 503：服务不可用，有如下几种可能的原因： Service 对应的 Pods 不存在，endpoints 为空 Service 对应的 Pods 全部都 NotReady，导致 endpoints 为空 也有可能是服务自身出错返回的 503 如果你使用了 envoy sidecar， 503 可能的原因就多了。基本上 sidecar 与主容器通信过程中的任何问题都会使 envoy 返回 503，使客户端重试。 详见 Istio：503、UC 和 TCP 502：Bad Gateway，通常是由于上游未返回正确的响应导致的，可能的根本原因： 应用程序未正确处理 SIGTERM 信号，在请求未处理完毕时直接终止了进程。详见 优雅停止（Gracful Shutdown）与 502/504 报错 - K8s 最佳实践 网络插件 bug 504：网关请求 upstream 超时，主要有两种可能 考虑是不是 Ingress Controller 的 IP 列表未更新，将请求代理到了不存在的 ip，导致得不到响应 Service Endpoints 移除不够及时，在 Pod 已经被终止后，仍然有个别请求被路由到了该 Pod，得不到响应导致 504。详见 优雅停止（Gracful Shutdown）与 502/504 报错 - K8s 最佳实践 Pod 响应太慢，代码问题 再总结一下常见的几种错误： 未设置优雅停止，导致 Pod 被重新终止时，有概率出现 502/504 服务的所有 Pods 的状态在「就绪」和「未就绪」之间摆动，导致间歇性地出现大量 503 错误 服务返回 5xx 错误导致客户端不断重试，请求流量被放大，导致服务一直起不来 解决办法：限流、熔断（网关层直接返回固定的相应内容） Ingress 相关网络问题的排查流程： Which ingress controller? Timeout between client and ingress controller, or between ingress controller and backend service/pod? HTTP/504 generated by the ingress controller, proven by logs from the ingress controller? If you port-forward to skip the internet between client and ingress controller, does the timeout still happen? ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:3:1","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"2. 上了 istio sidecar 后，应用程序偶尔（间隔几天半个月）会 redis 连接相关的错误 考虑是否和 tcp 长时间使用有关，比如连接长时间空闲的话，可能会被 istio sidecar 断开。 如果程序自身的重连机制有问题，就会导致这种现象。 确认方法： 检查 istio 的 idleTimeout 时长（默认 1h） 创建三五个没流量的 Pod 放置 1h（与 istio idleTimeout 时长一致），看看是否会准时开始报 redis 的错。 对照组：创建三五个同样没流量的 Pod，但是不注入 istio sidecar，应该一直很正常 这样就能确认问题，后续处理： 抓包观察程序在出错后的 tcp 层行为 查阅 redis sdk 的相关 issue、代码，通过升级 SDK 应该能解决问题。 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:3:2","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"名字空间常见错误 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:4:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"名字空间无法删除 这通常是某些资源如 CR(custom resources)/存储等资源无法释放导致的。 比如常见的 monitoring 名字空间无法删除，应该就是 CR 无法 GC 导致的。 可手动删除 namespace 配置中的析构器（spec.finalizer，在名字空间生命周期结束前会生成的配置项），这样名字空间就会直接跳过 GC 步骤： # 编辑名字空间的配置 kubectl edit namespace \u003cns-name\u003e # 将 spec.finalizers 改成空列表 [] 如果上述方法也无法删除名字空间，也找不到具体的问题，就只能直接从 etcd 中删除掉它了(有风险，谨慎操作！)。方法如下： # 登录到 etcd 容器中，执行如下命令： export ETCDCTL_API=3 cd /etc/kubernetes/pki/etcd/ # 列出所有名字空间 etcdctl --cacert ca.crt --cert peer.crt --key peer.key get /registry/namespaces --prefix --keys-only # （谨慎操作！！！）强制删除名字空间 `monitoring`。这可能导致相关资源无法被 GC！ etcdctl --cacert ca.crt --cert peer.crt --key peer.key del /registry/namespaces/monitoring ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:4:1","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"kubectl/istioctl 等客户端工具异常 socat not found: kubectl 使用 socat 进行端口转发，集群的所有节点，以及本机都必须安装有 socat 工具。 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:5:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"批量清理 Evicted 记录 有时候 Pod 因为节点选择器的问题，被不断调度到有问题的 Node 上，就会不断被 Evicted，导致出现大量的 Evicted Pods。 排查完问题后，需要手动清理掉这些 Evicted Pods. 批量删除 Evicted 记录: kubectl get pods | grep Evicted | awk '{print $1}' | xargs kubectl delete pod ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:6:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"容器镜像GC、Pod驱逐以及节点压力 节点压力 DiskPressure 会导致 Pod 被驱逐，也会触发容器镜像的 GC。 根据官方文档 配置资源不足时的处理方式，Kubelet 提供如下用于配置容器 GC 及 Evicetion 的阈值： --eviction-hard 和 eviction-soft: 对应旧参数 --image-gc-high-threshold，这两个参数配置镜像 GC 及驱逐的触发阈值。磁盘使用率的阈值默认为 85% 区别在于 eviction-hard 是立即驱逐，而 eviction-soft 在超过 eviction-soft-grace-period 之后才驱逐。 --eviction-minimum-reclaim: 对应旧参数 --image-gc-low-threshold。这是进行资源回收（镜像GC、Pod驱逐等）后期望达到的磁盘使用率百分比。磁盘使用率的阈值默认值为 80%。 问：能否为 ImageGC 设置一个比 DiskPressure 更低的阈值？因为我们希望能自动进行镜像 GC，但是不想立即触发 Pod 驱逐。 答：这应该可以通过设置 eviction-soft 和长一点的 eviction-soft-grace-period 来实现。 另外 --eviction-minimum-reclaim 也可以设小一点，清理得更干净。示例如下： --eviction-soft=memory.available\u003c1Gi,nodefs.available\u003c2Gi,imagefs.available\u003c200Gi --eviction-soft-grace-period=3m --eviction-minimum-reclaim=memory.available=0Mi,nodefs.available=1Gi,imagefs.available=2Gi ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:7:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"其他问题 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:8:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"隔天 Istio 等工具的 sidecar 自动注入莫名其妙失效了 如果服务器晚上会关机，可能导致第二天网络插件出问题，导致 sidecar 注入器无法观察到 pod 的创建，也就无法完成 sidecar 注入。 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:9:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"如何重新运行一个 Job？ 我们有一个 Job 因为外部原因运行失败了，修复好后就需要重新运行它。 方法是：删除旧的 Job，再使用同一份配置重建 Job. 如果你使用的是 fluxcd 这类 GitOps 工具，就只需要手工删除旧 Pod，fluxcd 会定时自动 apply 所有配置，这就完成了 Job 的重建。 ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:9:1","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"参考 Kubernetes管理经验 504 Gateway Timeout when accessing workload via ingress Kubernetes Failure Stories Istio：503、UC 和 TCP ","date":"2019-11-24","objectID":"/posts/kubernetes-common-errors-and-solutions/:10:0","tags":["Kubernetes"],"title":"Kubernetes 常见错误、原因及处理方法","uri":"/posts/kubernetes-common-errors-and-solutions/"},{"categories":["技术"],"content":"Manjaro 是一个基于 Arch Linux 的 Linux 滚动发行版，用着挺舒服的。 最大的特点，是包仓库很丰富，而且都很新。代价是偶尔会出些小毛病。 2021-09-22 更新：今天被群友科普，可能我下面列举的几个滚挂事件，可能都和我使用了 archlinuxcn 这个源有关，这确实有可能。 我一年多的使用中，遇到过 qv2-ray 动态链接库炸掉的问题，没专门去找修复方法，好像是等了一两个月，升级了两个大版本才恢复。 另一个就是 VSCode - Incorrect locale ‘en-US’ used everywhere 还遇到过 libguestfs 的一个问题：vrit-v2v/virt-p2v 两个工具被拆分出去，导致 manjaro 只能通过源码安装这俩货。这貌似目前仍旧没有解决。 总的来说体验很不错，能很及时地用上各种新版本的软件。 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:0:0","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"一、pacman/yay 的基础命令 Manjaro 装好后，需要运行的第一条命令： sudo pacman -Syy ## 强制更新 package 目录 sudo pacman-mirrors --interactive --country China # 列出所有国内的镜像源，并提供交互式的界面手动选择镜像源 sudo pacman -Syyu # 强制更新 package 目录，并尝试更新已安装的所有 packages. sudo pacman -S yay # 安装 yay pacman 是 arch/manjaro 的官方包管理器，而刚刚安装的 yay，则是一个能查询 arch linux 的 aur 仓库的第三方包管理器，非常流行。 pacman 的常用命令语法： pacman -S package_name # 安装软件 pacman -S extra/package_name # 安装不同仓库中的版本 pacman -Syu # 升级整个系统，y是更新数据库，yy是强制更新，u是升级软件 pacman -Ss string # 在包数据库中查询软件 pacman -Si package_name # 显示软件的详细信息 pacman -Sc # 清除软件缓存，即/var/cache/pacman/pkg目录下的文件 pacman -R package_name # 删除单个软件 pacman -Rs package_name # 删除指定软件及其没有被其他已安装软件使用的依赖关系 pacman -Qs string # 查询已安装的软件包 pacman -Qi package_name # 查询本地安装包的详细信息 pacman -Ql package_name # 获取已安装软件所包含的文件的列表 pacman -U package.tar.zx # 从本地文件安装 pactree package_name # 显示软件的依赖树 yay 的用法和 pacman 完全类似，上述所有 pacman xxx 命令，均可替换成 yay xxx 执行。 此外，还有一条 yay 命令值得记一下： yay -c # 卸载所有无用的依赖。类比 apt-get autoremove ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:1:0","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"常用软件与配置 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:2:0","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"1. 添加 archlinux 中文社区仓库 Arch Linux 中文社区仓库 是由 Arch Linux 中文社区驱动的非官方用户仓库，包含一些额外的软件包以及已有软件的 git 版本等变种。部分软件包的打包脚本来源于 AUR。 一些国内软件，如果直接从 aur 安装，那就会有一个编译过程，有点慢。而 archlinuxcn 有已经编译好的包，可以直接安装。更新速度也很快，推荐使用。 配置方法见 Arch Linux Chinese Community Repository。 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:2:1","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"2. 安装常用软件 sudo pacman -S google-chrome firefox # 浏览器 sudo pacman -S netease-cloud-music # 网易云音乐 sudo pacman -S noto-fonts-cjk wqy-bitmapfont wqy-microhei wqy-zenhei # 中文字体：思源系列、文泉系列 sudo pacman -S wps-office ttf-wps-fonts sudo pacman -S vim # 命令行编辑器 sudo pacman -S git # 版本管理工具 sudo pacman -S clang make cmake gdb # 编译调试环境 sudo pacman -S visual-studio-code-bin # 代码编辑器 sudo pacman -S wireshark-qt mitmproxy # 抓包工具 sudo pacman -S docker # docker 容器 其中 docker 和 wireshark 需要额外配置，否则会要求管理员权限： sudo groupadd wireshark sudo gpasswd --add $USER wireshark # 将你添加到 wireshark 用户组中 sudo groupadd docker sudo gpasswd --add $USER docker # 同上 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:2:2","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"3. 中文输入法 有两个选择：中州韵（rime）和搜狗拼音（sogoupinyin）。 简单省事用搜狗，要用特殊的输入方案（五笔、音形、二笔等等）就只有 rime 可选了。 3.1 fcitx5-rime 配置小鹤音形 首先安装 fcitx5-rime, 注意这些组件一个都不能省略： sudo pacman -S fcitx5 fcitx5-chinese-addons fcitx5-gtk fcitx5-qt kcm-fcitx5 fcitx5-rime 第二步是修改环境变量，将 fcitx5-rime 设为默认输入法并自动启动。 添加 ~/.pam_environment 文件，内容如下： INPUT_METHOD DEFAULT=fcitx5 GTK_IM_MODULE DEFAULT=fcitx5 QT_IM_MODULE DEFAULT=fcitx5 XMODIFIERS DEFAULT=@im=fcitx5 pam-env 模块会在所有登录会话中读取上面的配置文件，包括 X11 会话和 Wayland 会话。 添加自动启动： # ~/.xprofile 是 x11 GUI 的环境变量配置文件 echo 'fcitx5 \u0026' \u003e\u003e ~/.xprofile 然后，从 http://flypy.ys168.com/ 下载最新的鼠须管（MacOS）配置文件，将解压得到的 rime 文件夹拷贝到 ~/.local/share/fcitx5/ 下： mv rime ~/.local/share/fcitx5/ 现在重启系统，在 fcitx5 配置里面添加 rime，就可以正常使用小鹤音形了。 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:2:3","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"坑 使用过程中，我也遇到了一些坑： 安装软件包时，无法在线安装旧版本！除非你本地有旧版本的安装包没清除，才可以通过缓存安装旧版本。 这种问题没遇到时好说，但有时候新版本有问题，旧安装包也清理掉了无法回退，就非常麻烦。 而且就算你回退了版本，一升级它就又更新了。。 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:3:0","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"彻底删除 Manjaro 及其引导项 最近(2021-01)切换到了 OpenSUSE，体验很好，于是决定删除掉 Manjaro。 一番操作，总结出的删除流程如下（以下命令均需要 root 权限）： # 1. 删除 EFI 引导项 ## 查看 efi 的所有启动项，找到 Manjaro 的编号 efibootmgr ## 删除掉 Manjaro 启动项 sudo efibootmgr --delete-bootnum -b 2 # 2. 删除 manjaro 的 bootloader ## 我使用了 manjaro 默认的安装策略，bootloader 被安装在了和 windows 相同的 EFI 分区下 ## 首先通过 opnsuse 的分区工具，找到 EFI 分区的设备号，然后挂载它 mkdir efi mount /dev/nvme0n1p1 efi # 删除 Manjaro bootloader rm -r EFI/Manjaro # 3. 重建 grub2 引导项 grub2-mkconfig \u003e /boot/grub2/grub.cfg # 4. 最后，通过分区工具删除 Manjaro 的所有分区，我是 SSD，只有一个分区 # 5. 重启系统，所有东西就全删除干净了。 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:4:0","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["技术"],"content":"参考 Arch Linux Wiki - 中文 AUR 仓库 Arch Linux 中文社区仓库 yay - Yet another Yogurt - An AUR Helper written in Go 安装Manjaro之后的配置 Arch Linux Wiki - Fcitx5 ","date":"2019-07-13","objectID":"/posts/manjaro-instruction/:5:0","tags":["Manjaro","Linux","Arch Linux"],"title":"Manjaro 使用指南","uri":"/posts/manjaro-instruction/"},{"categories":["随笔"],"content":"四年大学惨淡收场，坐在火车硬座上，心里有些忐忑。 对面坐着一个 16 岁的女孩子，从合肥去深圳当安检，隐约听到“700 块一个月”，“再怎么着十天也有一休吧”，说实话深感惭愧。 小时候我妈对我有点保护过度，从小到大几乎没下田干过活，在家帮忙干过的活屈指可数。 因为读书尚可，稀里糊涂读了十多年书，现在惨淡收场。 而对面女孩子 16 岁，已经要去离家这么远的地方实习了（当安检），而且还听到对面说“想和他分了，每次都是我给他打电话，他从来没主动过，现在还抱怨我电话打少了……” 感觉我 22 年，有点白活了。。 可即使这样，还是提不起多大动力去复习面试用的知识点。 心里慌的不行，可游戏照打不误。还瞒着家里，花白条分期买了个 6000 的小米游戏本，一月要还 500，万一工作找得不理想，我不知道这个钱窟窿到时候该怎么填上。。。 我的四年大学好像也有过些高光时刻，也有过许多值得铭记的欢乐时光，临到头来却是这么个惨淡的结尾。 也有想过努力努力，可一懒散起来，就有了借口——“当初差点高考都没参加，就直接退学了，现在起码还读了四年的三流一本，见了世面，赚到了。” 不知道十年后我再回首，会不会觉得现在内心的忐忑，不算什么。 总之呢，因为一句「搞计算机的话，深圳工作应该很多吧，不如过来找工作？」，我上了这趟火车。 学业啥的都随它去吧，是不是单车变摩托，就看这一把了… ","date":"2019-06-20","objectID":"/posts/escape-my-university/:0:0","tags":[],"title":"逃离我的大学","uri":"/posts/escape-my-university/"},{"categories":["技术"],"content":" 个人笔记，不保证正确。 ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:0:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"一、关系构建：ForeignKey 与 relationship 关系构建的重点，在于搞清楚这两个函数的用法。ForeignKey 的用法已经在 SQL表达式语言 - 表定义中的约束 讲过了。主要是 ondelete 和 onupdate 两个参数的用法。 ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:1:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"二、relationship relationship 函数在 ORM 中用于构建表之间的关联关系。与 ForeignKey 不同的是，它定义的关系不属于表定义，而是动态计算的。 用它定义出来的属性，相当于 SQL 中的视图。 这个函数有点难用，一是因为它的有几个参数不太好理解，二是因为它的参数非常丰富，让人望而却步。下面通过一对多、多对一、多对多几个场景下 relationship 的使用，来一步步熟悉它的用法。 首先初始化： from sqlalchemy import Table, Column, Integer, ForeignKey from sqlalchemy.orm import relationship from sqlalchemy.ext.declarative import declarative_base Base = declarative_base() ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:2:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"1. 一对多 class Parent(Base): __tablename__ = 'parent' id = Column(Integer, primary_key=True) # 因为 Child 中有 Parent 的 ForeignKey，这边的声明不需要再额外指定什么。 children = relationship(\"Child\") # children 的集合，相当于一个视图。 class Child(Base): __tablename__ = 'child' id = Column(Integer, primary_key=True) parent_id = Column(Integer, ForeignKey('parent.id')) 一个 Parent 可以有多个 Children，通过 relationship，我们就能直接通过 parent.children 得到结果，免去繁琐的 query 语句。 1.1 反向引用 1.1.1 backref 与 back_populates 那如果我们需要得知 child 的 parent 对象呢？能不能直接访问 child.parent？ 为了实现这个功能，SQLAlchemy 提供了 backref 和 back_populates 两个参数。 两个参数的效果完全一致，区别在于，backref 只需要在 Parent 类中声明 children，Child.parent 会被动态创建。 而 back_populates 必须在两个类中显式地使用 back_populates，更显繁琐。（但是也更清晰？） 先看 backref 版： class Parent(Base): __tablename__ = 'parent' id = Column(Integer, primary_key=True) children = relationship(\"Child\", backref=\"parent\") # backref 表示，在 Child 类中动态创建 parent 属性，指向当前类。 # Child 类不需要修改 再看 back_populates 版： class Parent(Base): __tablename__ = 'parent' id = Column(Integer, primary_key=True) children = relationship(\"Child\", back_populates=\"parent\") # back_populates class Child(Base): __tablename__ = 'child' id = Column(Integer, primary_key=True) parent_id = Column(Integer, ForeignKey('parent.id')) # 这边也必须声明，不能省略！ parent = relationship(\"Parent\", back_populates=\"children\") # parent 不是集合，是属性！ NOTE：声明的两个 relationship 不需要多余的说明，SQLAlchemy 能自动识别到 parent.children 是 collection，child.parent 是 attribute. 1.1.2. 反向引用的参数：sqlalchemy.orm.backref(name, **kwargs) 使用 back_populates 时，我们可以很方便地在两个 relationship 函数中指定各种参数： class Parent(Base): __tablename__ = 'parent' id = Column(Integer, primary_key=True) children = relationship(\"Child\", back_populates=\"parent\", lazy='dynamic') # 指定 lazy 的值 class Child(Base): __tablename__ = 'child' id = Column(Integer, primary_key=True) parent_id = Column(Integer, ForeignKey('parent.id')) parent = relationship(\"Parent\", back_populates=\"children\", lazy='dynamic') # 指定 lazy 的值 但是如果使用 backref，因为我们只有一个 relationship 函数，Child.parent 是被隐式创建的，我们该如何指定这个属性的参数呢？ 答案就是 backref() 函数，使用它替代 backref 参数的值： from sqlalchemy.orm import backref class Parent(Base): __tablename__ = 'parent' id = Column(Integer, primary_key=True) children = relationship(\"Child\", backref=backref(\"parent\", lazy='dynamic')) # 使用 backref() 函数，指定 Child.parent 属性的参数 # Child 类不需要修改 backref() 的参数会被传递给 relationship()，因此它俩的参数也完全一致。 ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:2:1","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"2. 多对一 A many-to-one is similar to a one-to-many relationship. The difference is that this relationship is looked at from the “many” side. ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:2:2","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"3. 一对一 class Parent(Base): __tablename__ = 'parent' id = Column(Integer, primary_key=True) child = relationship(\"Child\", uselist=False, # 不使用 collection！这是关键 back_populates=\"parent\") class Child(Base): __tablename__ = 'child' id = Column(Integer, primary_key=True) parent_id = Column(Integer, ForeignKey('parent.id')) # 包含 ForeignKey 的类，此属性默认为 attribute，因此不需要 uselist=False parent = relationship(\"Parent\", back_populates=\"child\") ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:2:3","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"4. 多对多 # 多对多，必须要使用一个关联表！ association_table = Table('association', Base.metadata, Column('left_id', Integer, ForeignKey('left.id')), # 约定俗成的规矩，左边是 parent Column('right_id', Integer, ForeignKey('right.id')) # 右边是 child ) class Parent(Base): __tablename__ = 'left' id = Column(Integer, primary_key=True) children = relationship(\"Child\", secondary=association_table) # 专用参数 secondary，用于指定使用的关联表 class Child(Base): __tablename__ = 'right' id = Column(Integer, primary_key=True) 要添加反向引用时，同样可以使用 backref 或 back_populates. 4.1 user2user 如果多对多关系中的两边都是 user，即都是同一个表时，该怎么声明？ 例如用户的「关注」与「粉丝」，你是 user，你的粉丝是 user，你关注的账号也是 user。 这个时候，关联表 association_table 的两个键都是 user，SQLAlchemy 无法区分主次，需要手动指定，为此需要使用 primaryjoin 和 secondaryjoin 两个参数。 # 关联表，左侧的 user 正在关注右侧的 user followers = db.Table('followers', db.Column('follower_id', db.Integer, db.ForeignKey('user.id')), # 左侧 db.Column('followed_id', db.Integer, db.ForeignKey('user.id')) # 右侧，被关注的 user ) class User(UserMixin, db.Model): id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), index=True, unique=True, nullable=False) email = db.Column(db.String(120), index=True, unique=True, nullable=False) password_hash = db.Column(db.String(128), nullable=False) # 我关注的 users followed = db.relationship( 'User', secondary=followers, # 指定多对多关联表 primaryjoin=(followers.c.follower_id == id), # 左侧，用于获取「我关注的 users」的 join 条件 secondaryjoin=(followers.c.followed_id == id), # 右侧，用于获取「我的粉丝」的 join 条件 lazy='dynamic', # 延迟求值，这样才能用 filter_by 等过滤函数 backref=db.backref('followers', lazy='dynamic')) # followers 也要延迟求值 这里比较绕的，就是容易搞混 primaryjoin 和 secondaryjoin 两个参数。 primaryjoin：（多对多中）用于从子对象查询其父对象的 condition（child.parents），默认只考虑外键。 secondaryjoin：（多对多中）用于从父对象查询其所有子对象的 condition（parent.children），同样的，默认情况下只考虑外键。 ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:2:4","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"三、ORM 层 的 “delete” cascade vs. FOREIGN KEY 层的 “ON DELETE” cascade 之前有讲过 Table 定义中的级联操作：ON DELETE 和 ON UPDATE，可以通过 ForeignKey 的参数指定为 CASCADE. 可 SQLAlchemy 还有一个 relationship 生成 SQL 语句时的配置参数 cascade，另外 passive_deletes 也可以指定为 cascade。 有这么多的 cascade，我真的是很懵。这三个 cascade 到底有何差别呢？ 外键约束中的 ON DELETE 和 ON UPDATE，与 ORM 层的 CASCADE 在功能上，确实有很多重叠的地方。 但是也有很多不同： 数据库层面的 ON DELETE 级联能高效地处理 many-to-one 的关联；我们在 many 方定义外键，也在这里添加 ON DELETE 约束。而在 ORM 层，就刚好相反。SQLAlchemy 在 one 方处理 many 方的删除操作，这意味着它更适合处理 one-to-many 的关联。 数据库层面上，不带 ON DELETE 的外键常用于防止父数据被删除，而导致子数据成为无法被索引到的垃圾数据。如果要在一个 one-to-many 映射上实现这个行为，SQLAlchemy 将外键设置为 NULL 的默认行为可以通过以下两种方式之一捕获： 最简单也最常用的方法，当然是将外键定义为 NOT NULL. 尝试将该列设为 NULL 会触发 NOT NULL constraint exception. 另一种更特殊的方法，是将 passive_deletes 标志设置为字 all. 这会完全禁用 SQLAlchemy 将外键列设置为 NULL 的行为，并且 DELETE 父数据而不会对子数据产生任何影响。这样才能触发数据库层面的 ON DELETE 约束，或者其他的触发器。 数据库层面的 ON DELETE 级联 比 ORM 层面的级联更高效。数据库可以同时在多个 relationship 中链接一系列级联操作。 SQLAlchemy 不需要这么复杂，因为我们通过将 passive_deletes 选项与正确配置的外键约束结合使用，提供与数据库的 ON DELETE 功能的平滑集成。 ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:3:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"方法一：ORM 层的 cascade 实现 relationship 的 cascade 参数决定了修改父表时，什么时候子表要进行级联操作。它的可选项有（str，选项之间用逗号分隔）： save-update：默认选项之一。在 add（对应 SQL 的 insert 或 update）一个对象的时候，会 add 所有它相关联的对象。 merge：默认选项之一。在 merge（相当字典的update操作，有就替换掉，没有就合并）一个对象的时候，会 merge 所有和它相关联的对象。 expunge ：移除操作的时候，会将相关联的对象也进行移除。这个操作只是从session中移除，并不会真正的从数据库中删除。 delete：删除父表数据时，同时删除与它关联的数据。 delete-orphan：当子对象与父对象解除关系时，删除掉此子对象（孤儿）。（其实还是没懂。。） refresh-expire：不常用。 all：表示选中除 delete-orphan 之外的所有选项。（因此 all, delete-orphan 很常用，它才是真正的 all） 默认属性是 “save-update, merge”. 这只是简略的说明，上述几个参数的详细文档见 SQLAlchemy - Cascades ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:3:1","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"方法二：数据库层的 cascade 实现 将 ForeignKey 的 ondelete 和 onupdate 参数指定为 CASCADE，实现数据库层面的级联。 为 relationship 添加关键字参数 passive_deletes=\"all\"，这样就完全禁用 SQLAlchemy 将外键列设置为 NULL 的行为，并且 DELETE 父数据不会对子数据产生任何影响。 这样 DELETE 操作时，就会触发数据库的 ON DELETE 约束，从而级联删除子数据。 ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:3:2","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["技术"],"content":"参考 SQLAlchemy - Relationship Configuration SQLAlchemy - Cascades SQLAlchemy 中的 backref 和 back_populates The Flask Mega-Tutorial Part VIII: Followers hackersandslackers/sqlalchemy-tutorial ","date":"2019-05-21","objectID":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/:4:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（三）：ORM 中的关系构建","uri":"/posts/sqlalchemy-notes-3-relationship-and-foreignkey/"},{"categories":["随笔"],"content":"这网络小说一起头，就停不下来。 开始还只是追更新，每天看看三四本书的更新（一更或二更）就行了，说不上心满意足，但也没多么欲求不满。 到了三月下旬，突然就想看本新书。念头一起就一发不可收拾，只挑二三十万字的连载书看——首要原因是怕收不住手，书太长的话，废寝忘食起来自己遭罪；其次是前二十多万字都可以免费看，后面才是收费章节。 感觉自己陆陆续续可能看了二三十本书，五六百万字就这么过了，二三十个故事就如过眼云烟，转眼就记不得几个书名了。 就像从小到大的同学老师一样，看小说看到讲高中室友，就尝试回想我的高中宿舍，一时竟连自己的床铺都搞错了，仔细回想下，也有好几个室友的名字长相都忘记了。这还算好了，毕竟高中三年，也过了这么长时间才淡忘。这网文的故事有的光怪陆离，有的异想天开，大部分都是专注一个「爽」字，无不是金手指打怪升级的套路。千篇一律下，能记住的没几个。 倒也有特立独行的，因此也就印象尤其深刻，《月明见君来/云胡不喜》是这样一本文笔优美的古言，为着“云胡不喜”一句，那时突然就喜欢上了《诗经》。 还有位作者的星际言情文：《星球上的完美家园》和《未来世界之我心安处》，写得极为细腻。尤其是前者，只是他写的研究生生活，有点刺激我这个曾经信誓旦旦要考研，现在却大学文凭都拿不到的学渣。。就看不下去。 有段时间对日系轻小说青睐有加，觉得里头的优秀作品就是比国内网文高个档次。现在一想，其实都一样，良莠不齐，都喜欢穿越重生异世界的套路。只是看多了动漫，才对轻小说多点好感而已。网文里写的好的书也不少。 这两天突然就有些厌倦了，字看多了开始头疼，厌烦。就像手冲后进入了贤者时间一样。。。这样一想，这书瘾到底还是没毒品那么可怕，再怎么凶猛，疯狂上一个月，也后继乏力了，不会越陷越深。 这一个月深居简出，连QQ都直接掐掉了好几天。我看起小说来就是这样，别的事完全没兴致理，疯狂起来就更是变本加厉。 忽地又想起了自己内心敏感、性格别扭、胆子小、受不得训斥。再加上这一个月的所作所为，真是凭实力啃老+单身。 颓废完了，自卑，就安慰自己全国大学生占比不过3%，又想想战争年代人们的悲惨，就觉得自己已经比很多人都活得好了。 生逢盛世，国泰民安，又能找到自己喜欢的东西，而且主动地追求了。 虽然没有尽全力，但是人生苦短嘛，要及时享乐。 酸甜苦辣混一起，我总归是知足的。 要真能穿越我肯定不会像过去那样干，但是不能穿越也不是太可惜。我经历过的糟心事和很多人有过的绝望比起来，根本不值一提，我还能有什么不满的呢？ 这个世界总归是不会停止转动，也不会随我心意。 我讨厌的繁文缛节在人际交往中是必不可少的，我的自卑是藏不住的，我知识上的短板也是实实在在的。 我还能怎么做呢？总之向前走吧，不论是被人流裹挟着，还是被自己的欲望拉扯着，都只能向前——人生是没有退路的。 ","date":"2019-04-14","objectID":"/posts/webnovel-addiction-recovery/:0:0","tags":["Webnovel","网络小说"],"title":"瘾的退却","uri":"/posts/webnovel-addiction-recovery/"},{"categories":["技术"],"content":" 个人笔记，如有疏漏，还请指正。 使用多线程（threading）和多进程（multiprocessing）完成常规的并发需求，在启动的时候 start、join 等步骤不能省，复杂的需要还要用 1-2 个队列。 随着需求越来越复杂，如果没有良好的设计和抽象这部分的功能层次，代码量越多调试的难度就越大。 对于需要并发执行、但是对实时性要求不高的任务，我们可以使用 concurrent.futures 包中的 PoolExecutor 类来实现。 这个包提供了两个执行器：线程池执行器 ThreadPoolExecutor 和进程池执行器 ProcessPoolExecutor，两个执行器提供同样的 API。 池的概念主要目的是为了重用：让线程或进程在生命周期内可以多次使用。它减少了创建创建线程和进程的开销，提高了程序性能。重用不是必须的规则，但它是程序员在应用中使用池的主要原因。 池，只有固定个数的线程/进程，通过 max_workers 指定。 任务通过 executor.submit 提交到 executor 的任务队列，返回一个 future 对象。 Future 是常见的一种并发设计模式。一个Future对象代表了一些尚未就绪（完成）的结果，在「将来」的某个时间就绪了之后就可以获取到这个结果。 任务被调度到各个 workers 中执行。但是要注意，一个任务一旦被执行，在执行完毕前，会一直占用该 worker！ **如果 workers 不够用，其他的任务会一直等待！**因此 PoolExecutor 不适合实时任务。 import concurrent.futures import time from itertools import count number_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] def evaluate_item(x): for i in count(x): # count 是无限迭代器，会一直递增。 print(f\"{x}- {i}\") time.sleep(0.01) if __name__ == \"__main__\": # 进程池 start_time_2 = time.time() # 使用 with 在离开此代码块时，自动调用 executor.shutdown(wait=true) 释放 executor 资源 with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: # 将 10 个任务提交给 executor，并收集 futures futures = [executor.submit(evaluate_item, item) for item in number_list] # as_completed 方法等待 futures 中的 future 完成 # 一旦某个 future 完成，as_completed 就立即返回该 future # 这个方法，使每次返回的 future，总是最先完成的 future # 而不是先等待任务 1，再等待任务 2... for future in concurrent.futures.as_completed(futures): # result 返回被调用函数的返回值 # 如果调用抛出了异常，result 会抛出同样的异常 # 如果调用被取消，result 抛出 CancelledError 异常 print(future.result()) print (\"Thread pool execution in \" + str(time.time() - start_time_2), \"seconds\") 上面的代码中，item 为 1 2 3 4 5 的五个任务会一直占用所有的 workers，而 6 7 8 9 10 这五个任务会永远等待！！！ ","date":"2019-03-15","objectID":"/posts/python-concurrency-pool-executor/:0:0","tags":["Python","Concurrency","并发"],"title":"Python 并发编程：PoolExecutor 篇","uri":"/posts/python-concurrency-pool-executor/"},{"categories":["技术"],"content":"API 详细说明 concurrent.futures 包含三个部分的 API： PoolExecutor：也就是两个执行器的 API 构造器：主要的参数是 max_workers，用于指定线程池大小（或者说 workers 个数） submit(fn, *args, **kwargs)：将任务函数 fn 提交到执行器，args 和 kwargs 就是 fn 需要的参数。 返回一个 future，用于获取结果 map(func, *iterables, timeout=None, chunksize=1)：当任务是同一个，只有参数不同时，可以用这个方法代替 submit。iterables 的每个元素对应 func 的一组参数。 返回一个 futures 的迭代器 shutdown(wait=True)：关闭执行器，一般都使用 with 管理器自动关闭。 Future：任务被提交给执行器后，会返回一个 future future.result(timout=None)：最常用的方法，返回任务的结果。如果任务尚未结束，这个方法会一直等待！ timeout 指定超时时间，为 None 时没有超时限制。超时会抛出 concurrent.futures.TimeoutError 异常。 如果调用抛出了异常，result 会抛出同样的异常 如果调用被取消，result 抛出 CancelledError 异常 exception(timeout=None)：返回任务抛出的异常。和 result() 一样，也会等待任务结束。 timeout 参数跟 result 一致，超时会抛出 concurrent.futures.TimeoutError 异常。 如果调用抛出了异常，exception 会返回同样的异常，否则返回 None 如果调用被取消，result 抛出 CancelledError 异常 cancel()：取消此任务 add_done_callback(fn)：future 完成后，会执行 fn(future)。 running()：是否正在运行 done()：future 是否已经结束了，boolean …详见官方文档 模块带有的实用函数 concurrent.futures.as_completed(fs, timeout=None)：等待 fs （futures iterable）中的 future 完成 一旦 fs 中的某 future 完成了，这个函数就立即返回该 future。 这个方法，使每次返回的 future，总是最先完成的 future。而不是先等待任务 1，再等待任务 2… 常通过 for future in as_completed(fs): 使用此函数。 concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED)：一直等待，直到 return_when 所指定的事发生，或者 timeout return_when 有三个选项：ALL_COMPLETED（fs 中的 futures 全部完成），FIRST__COMPLETED（fs 中任意一个 future 完成）还有 FIRST_EXCEPTION（某任务抛出异常） ","date":"2019-03-15","objectID":"/posts/python-concurrency-pool-executor/:1:0","tags":["Python","Concurrency","并发"],"title":"Python 并发编程：PoolExecutor 篇","uri":"/posts/python-concurrency-pool-executor/"},{"categories":["技术"],"content":"Future 设计模式 这里的 PoolExecutor 的特点，在于它使用了 Future 设计模式，使任务的执行，与结果的获取，变成一个异步的流程。 **我们先通过 submit/map 将任务放入任务队列，这时任务就已经开始执行了！**然后我们在需要的时候，通过 future 获取结果，或者直接 add_done_callback(fn)。 这里任务的执行是在新的 workers 中的，主进程/线程不会阻塞，因此主线程可以干其他的事。这种方式被称作异步编程。 ","date":"2019-03-15","objectID":"/posts/python-concurrency-pool-executor/:2:0","tags":["Python","Concurrency","并发"],"title":"Python 并发编程：PoolExecutor 篇","uri":"/posts/python-concurrency-pool-executor/"},{"categories":["技术"],"content":"画外 concurrent.futures 基于 multiprocessing.pool 实现，因此实际上它比直接使用 线程/进程 的 Pool 要慢一点。但是它提供了更方便简洁的 API。 ","date":"2019-03-15","objectID":"/posts/python-concurrency-pool-executor/:3:0","tags":["Python","Concurrency","并发"],"title":"Python 并发编程：PoolExecutor 篇","uri":"/posts/python-concurrency-pool-executor/"},{"categories":["技术"],"content":"参考 使用Python进行并发编程-PoolExecutor篇 Python Parallel Programming Cookbook concurrent.futures — Launching parallel tasks 进程线程协程与并发并行 并行设计模式（一）– Future模式 ","date":"2019-03-15","objectID":"/posts/python-concurrency-pool-executor/:4:0","tags":["Python","Concurrency","并发"],"title":"Python 并发编程：PoolExecutor 篇","uri":"/posts/python-concurrency-pool-executor/"},{"categories":["技术"],"content":" 个人笔记，不保证正确。 虽然说看到很多人不看好 asyncio，但是这个东西还是必须学的。。 基于协程的异步，在很多语言中都有，学会了 Python 的，就一通百通。 ","date":"2019-02-14","objectID":"/posts/python-asyncio/:0:0","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"一、生成器 generator Python 的 asyncio 是通过 generator 实现的，要学习 async，先得复习下 generator. ","date":"2019-02-14","objectID":"/posts/python-asyncio/:1:0","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"1. yield 众所周知，yield 是用于定义 generator 函数的关键字，调用该函数，会返回一个 generator \u003e\u003e\u003e def f(): ... yield 1 ... yield 2 ... \u003e\u003e\u003e f() # 返回的是 generator \u003cgenerator object f at 0x7f672c460570\u003e \u003e\u003e\u003e g = f() \u003e\u003e\u003e next(g) # 通过 next 方法从 generator 获取值 1 \u003e\u003e\u003e g.__next__() # next 方法实际是调用了 generator 的 __next__ 方法 2 \u003e\u003e\u003e next(g) # 生成器运行结束，产生一个 StopIteration 的 exception Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e StopIteration 每次调用 next，generator 都只会运行到下一个 yield 关键字所在行，返回 yield 右侧的对象，然后暂停在该处，等待下一次 next 调用。 从上面的例子看，yield 就是延迟求值而已。**但是 yield 还有一个特性，就是它是一个 expression，有返回值！**看例子： \u003e\u003e\u003e def func(): ... r = yield 1 ... yield r ... \u003e\u003e\u003e g = func() \u003e\u003e\u003e next(g) 1 \u003e\u003e\u003e next(g) # 通过 next 调用，yield 的返回值为 None \u003e\u003e\u003e g2 = func() \u003e\u003e\u003e next(g2) # 首先需要通过 next 调用，运行到 yield 语句处 1 \u003e\u003e\u003e g2.send(419) # 现在用 send 方法，这会将当前所在的 yield 语句的值设置为你 send 的值，也就是 419 419 # 然后 generator 运行到下一个 yield，返回右边的值并暂停 generator 有四个实例函数：next、send 是刚刚已经介绍了的，此外还有 throw 用于从 yield 所在处抛出 Exception，和 close 用于关闭 Generator。详见 Generator-iterator methods ","date":"2019-02-14","objectID":"/posts/python-asyncio/:1:1","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"2. yield from 可以理解成是 yield \u003cvalue\u003e from \u003citerable\u003e，每次调用时它都会从 \u003citerable\u003e 中取值，直到遇到 StopIteration。才会从下一个 yield 取值。 \u003e\u003e\u003e def f(): ... yield from [1, 2, 3, 4] # iterable ... yield 5 ... yield from range(4, 0, -1) # iterable ... \u003e\u003e\u003e list(f()) [1, 2, 3, 4, 5, 4, 3, 2, 1] 当然，yield from \u003citerable\u003e 也是一个 expression，也有值。它的值就是 StopIteration 异常的第一个参数，内置类型的这个值都是 None. \u003e\u003e\u003e def f(): ... r = yield from [1, 2] ... yield f\"value of yield from is {r}\" ... \u003e\u003e\u003e list(f()) [1, 2, 'value of yield from is None'] 当 \u003citerable\u003e 是 generator 时，yield from 会直接将函数调用委托给这个子 generator，这里的调用包括了前面说过的 next、send、throw、close 四个函数。 并直接将 sub generator yield 的值 yield 给 caller. ","date":"2019-02-14","objectID":"/posts/python-asyncio/:1:2","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"3. yield 和 return 混用会发生什么？ generator 中的 return value，语义上等同于 rasie StopIteration(value)： \u003e\u003e\u003e def f(): ... yield 1 ... return 2 ... yield 3 # 永远不会被执行 ... \u003e\u003e\u003e g = f() \u003e\u003e\u003e next(g) 1 \u003e\u003e\u003e next(g) # return 引发 StopIteration Traceback (most recent call last): File \"\u003cinput\u003e\", line 1, in \u003cmodule\u003e StopIteration: 2 \u003e\u003e\u003e next(g) # 再次调用，StopIteration 变成无参了。 Traceback (most recent call last): File \"\u003cinput\u003e\", line 1, in \u003cmodule\u003e StopIteration 可以看到 return 引发了 StopIteration 异常，而 return 的值则成了该异常的第一个参数。 之前说过 yield from \u003csub generator\u003e 表达式的值，就是该 \u003csub generator\u003e 的 StopIteration 异常的第一个参数，因此： \u003e\u003e\u003e def f2(): ... a = yield from f() ... yield a # a 是 f() 中 return 的值 ... \u003e\u003e\u003e list(f2()) [1, 2] PEP 479 – Change StopIteration handling inside generators 修改了StopIteration 的行为，该 PEP 使人为 raise 的 StopIteration 引发一个 RuntimeError。 该 PEP 在 Python 3.5 版本添加到 future 中，并在 Python 3.7 成为默认行为。 因此除非你确实想要引发异常，否则应该使用 return 来结束一个 generator 并返回值。 ","date":"2019-02-14","objectID":"/posts/python-asyncio/:1:3","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"二、异步IO、协程与非阻塞 IO 先了解一下 进程线程协程与并发并行 和 各种 IO 模型 ","date":"2019-02-14","objectID":"/posts/python-asyncio/:2:0","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"三、asyncio 的简单使用 asyncio 引入了两个新关键字：async 和 await，其中 async 能放在三个地方： async def：用于定义异步函数和异步生成器 不含有 yield 的是 async def 定义的是协程函数（coroutine function），调用该函数返回协程对象（coroutine object），协程对象需要通过 EventLoop 运行。 内部含有 yield 的 async def 定义的是异步生成器函数（asynchronous generator function），调用该函数返回异步生成器（async_generator） 异步生成器只能用在 Coroutine 中 async def 中不允许使用 yield from async for：表示 for 迭代的是一个异步生成器，该 for 循环的每一次迭代，都是异步的。 只能用在 async def 的内部 async with：表示 with 管理的是一个异步上下文管理器（asynchronous context manager） 该 context manager 的 enter 和 exit 两个步骤是异步的 只能用在 async def 的内部 注意异步 generator、context manager，它的 protocol 都和同步的不同，不能混为一谈。 具体而言，对同步 protocol xxx 函数，它的异步版本为 axxx，就是加个 a。 而 await，就相当于 yield from，差别在于 await 是异步的。还有我们关心的是 await 表达式的值，而 yield from 中我们更关心它向上层 yield 的值。 在 yield from 中，当前生成器调用另一个生成器，当前生成器会挂起，直到另一个生成器返回。 但是在 await 中，当前 Coroutine 挂起时， eventloop 会寻找其他 task 来跑，这就利用上了 IO 漫长的等待时间。 async for 是每次迭代都会 await 一次，如果迭代对象是 IO 操作，这个 IO 等待时间就会被利用上。 async with 也是同样，如果 context 的 enter 和 exit 是 IO 操作，这个 IO 时间就会被 eventloop 用于运行其他 task. 使用 asyncio 时，我们要用 async def 将所有的 IO 操作都定义成异步操作。然后在调用时，都使用 await/async for/async with 来调用。 ","date":"2019-02-14","objectID":"/posts/python-asyncio/:3:0","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"四、Coroutine、Task 和 Future 首先，每个协程对象，都是一个独立的协程单元，协程对象之间可以异步运行。 协程需要放到 EventLoop 内运行，要运行一个协程 a，有三种方法： 通过 asyncio.run(coro) 运行一个协程。 该方法会新建一个 EventLoop 在另一个协程 b 中通过 await 调用 a。当 b 运行时， a 也会被 task 运行。 通过 asyncio.create_task(coro)，将需要运行的协程包装成 task，然后通过 task 相关的方法来异步运行它们。 asyncio.gather(*awaitable_objects): 并发执行所有的 task，阻塞到所有 task 结束。返回一个 result 列表。result 的列表顺序和 future 的顺序一致 asyncio.as_completed(aws, *, loop=None, timeout=None)，和 gather 的区别在于，它返回一个异步迭代器，每次迭代都返回最先完成的一个 future. concurrent.futures 是进程线程的异步执行，而 asyncio 是基于协程的单线程异步执行 ","date":"2019-02-14","objectID":"/posts/python-asyncio/:4:0","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"五、参考 从0到1，Python异步编程的演进之路 怎么掌握 asyncio Python Async/Await入门指南 谈谈Python协程技术的演进 Python Doc - Coroutines Python Doc - asyncio ","date":"2019-02-14","objectID":"/posts/python-asyncio/:5:0","tags":["Python","asyncio"],"title":"Python 异步编程笔记：asyncio","uri":"/posts/python-asyncio/"},{"categories":["技术"],"content":"照例先看层次图 SQLAlchemy 层次结构\" SQLAlchemy 层次结构 ","date":"2019-02-11","objectID":"/posts/sqlalchemy-notes-2-orm-basics/:0:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（二）：ORM 基础","uri":"/posts/sqlalchemy-notes-2-orm-basics/"},{"categories":["技术"],"content":"一、声明映射关系 使用 ORM 时，我们首先需要定义要操作的表（通过 Table），然后再定义该表对应的 Python class，并声明两者之间的映射关系（通过 Mapper）。 方便起见，SQLAlchemy 提供了 Declarative 系统来一次完成上述三个步骤，Declarative 系统提供 base class，这个 base class 会为继承了它的 Python class（可称作 model）创建 Table，并维护两者的映射关系。 from sqlalchemy.ext.declarative import declarative_base from SQLAlchemy import Column, Integer, String Base = declarative_base() # 拿到 Base 类 class User(Base): id = Column(Integer, primary_key=True) username = Column(String(32), nullable=False, index=True) # 添加 index 提升搜索效率 fullname = Column(String(64)) password = Column(String(32)) # 真实情况下一般只存 hash def __repr__(self): return f\"\u003cUser {self.username}\u003e\" 这样就声明好了一个对象-关系映射，上一篇文章说过所有的 Table 都在某个 MetaData 中，可以通过 Base.metadata 获取它。 Base.metadata.create_all(engine) # 通过 metadata 创建表（或者说生成模式 schema） engine 的创建请见上篇文档 SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言 约束条件 可参考 SQL 基础笔记（三）：约束 与 SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言 - 表定义中的约束 使用 ORM 来定义约束条件，与直接使用 SQL 表达式语言定义很类似，也有两种方法： 直接将约束条件作为 Column、ForeignKey 的参数传入。这种方式最简洁，也最常用。 使用 UniqueConstraint、CheckConstraint 等类构造约束，然后放入 __table_args__ 属性中。举例： class User(Base): id = Column(Integer, primary_key=True) username = Column(String(32), nullable=False, index=True) # 添加 index 提升搜索效率 fullname = Column(String(64)) password = Column(String(32)) # 真实情况下一般只存 hash # 顾名思义，这是 `Table` 类的参数的序列。里面的约束条件会被用于构建 __table__ __table_args__ = (UniqueConstraint('username', name='c_user'),) # username 的唯一性约束 def __repr__(self): return f\"\u003cUser {self.username}\u003e\" ","date":"2019-02-11","objectID":"/posts/sqlalchemy-notes-2-orm-basics/:0:1","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（二）：ORM 基础","uri":"/posts/sqlalchemy-notes-2-orm-basics/"},{"categories":["技术"],"content":"二、获取 session 上一节讲 engine 时，我们是通过 connection 来与数据库交互，而在 ORM 中我们使用 Session 访问数据库。 from sqlalchemy.orm import sessionmaker Session = sessionmaker(bind=engine) # 获取 session ","date":"2019-02-11","objectID":"/posts/sqlalchemy-notes-2-orm-basics/:0:2","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（二）：ORM 基础","uri":"/posts/sqlalchemy-notes-2-orm-basics/"},{"categories":["技术"],"content":"三、增删改查 直接使用 SQL 表达式语言时，我们使用 insert()、select()、update()、delete() 四个函数构造 SQL，使用 where() 添加条件，使用 model.join(another_model) 进行 join 操作。 而使用 ORM 时，数据库操作不再与 SQL 直接对应。我们现在是通过操作 Python 对象来操作数据库了。 现在，我们通过 db.session.add()、db.session.delete() 进行添加与删除，使用 db.session.query(Model) 进行查询，通过 filter 和 filter_by 添加过滤条件。 而修改，则是先查询出对应的 row 对象，直接修改这个对象，然后 commit 就行。 增添： ed_user = User(name='ed', fullname='Ed Jones', password='edspassword') # 用构造器构造对象 session.add(ed_user) # 添加，此外还有批量添加 add_all([user1, user2...]) session.commit() # 必须手动 commit 修改： ed_user = session.query(User).filter_by(name='ed').first() # 先获取到 User 对象 ed_user.password = 'f8s7ccs' # 改了密码 session.commit() # 提交 # 批量修改 session.query(User).filter(User.home=='shanghai') \\ .update({User.login_num:0}) # 将所有上海的用户的 login_num 设为 0 session.commit() 删除： ed_user = session.query(User).filter_by(name='ed').first() # 先获取到 User 对象 session.delete(ed_user) # 直接删除（session 知道 ed_user 属于哪个表） session.commit() # 提交 # 批量删除 session.query(User).filter(User.home=='shanghai') \\ .delete() # 删除所有上海的用户 session.commit() 同样的，也可以在外面检查异常，然后调用 session.rollback() 实现失败回滚。 ","date":"2019-02-11","objectID":"/posts/sqlalchemy-notes-2-orm-basics/:0:3","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（二）：ORM 基础","uri":"/posts/sqlalchemy-notes-2-orm-basics/"},{"categories":["技术"],"content":"四、进阶查询 filter_by：使用关键字参数进行过滤，前面的演示中已经用过多次了。 filter：它对应 SQL 表达式语言中的 where，支持各种复杂的 SQL 语法。 group_by: 通过指定 column 分组 distinct(): 去重 join(): 关联 query.filter(User.name == 'ed') # 这个等同于 filter_by，但是更繁琐 query.filter(User.name != 'ed') # 不等于，这个就是 filter_by 无法做到的了 query.filter(User.name.like('%ed%')) # SQL like 的 like 语法 query.filter(User.name.in_(['ed', 'wendy', 'jack'])) # 包含 # 查询还可以嵌套 query.filter(User.name.in_( session.query(User.name).filter(User.name.like('%ed%')) )) query.filter(~User.name.in_(['ed', 'wendy', 'jack'])) # 不包含 query.filter(User.name == None) # NULL 对应 Python 的 None from sqlalchemy import or_, and_, in_ query.filter(or_(User.name == 'ed', User.name == 'wendy')) # OR 语法 query.group_by(User.name) # 分组 query.distinct() # 去重 from sqlalchemy import func # SQL 函数包 session.query(func.count(User.name)).filter_by(xxx=xxx) # 使用 count 函数 # join 关联 # 默认使用内联（inner），即只取两表的交集 session.query(User, Address).filter(User.id==Address.user_id) # 方法一 session.query(User).join(Address).\\ # 方法二 filter(Address.email_address=='jack@google.com') # 外联 outer join，将另一表的列联结到主表，没有的行为 NULL session.query(User).outerjoin(User.addresses) \\ .filter(Address.email_address=='jack@google.com') 执行查询，获取数据 查询返回 query 对象，但 SQL 还没有被执行，直到你调用下列几个方法： # 构造 query 对象 query = session.query(User).filter(User.name.like('%ed')).order_by(User.id) # 1. all 返回所有结果的列表 res_list = query.all() # 2. first 先在 SQL 中加入限制 `limit 1`，然后执行。 res = query.first() # 3. one 执行 sql 并获取所有结果 # 如果结果不止一行，抛出 MultipleResultsFound Error！！！ # 如果结果为空，抛出 NoResultFound Error ！！！ res = query.one() 4. one_or_none 差别在于结果为空，它不抛出异常，而是返回 None res = query.one_or_none() ","date":"2019-02-11","objectID":"/posts/sqlalchemy-notes-2-orm-basics/:0:4","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（二）：ORM 基础","uri":"/posts/sqlalchemy-notes-2-orm-basics/"},{"categories":["技术"],"content":"参考 SQLAlchemy 对象关系入门 SQLAlchemy ORM 的关联映射定义：一对多、多对多 hackersandslackers/sqlalchemy-tutorial ","date":"2019-02-11","objectID":"/posts/sqlalchemy-notes-2-orm-basics/:0:5","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（二）：ORM 基础","uri":"/posts/sqlalchemy-notes-2-orm-basics/"},{"categories":["技术"],"content":"一、WebSocket WebSocket 是一个双向通信协议，它在握手阶段采用 HTTP/1.1 协议（暂时不支持 HTTP/2）。 握手过程如下： 首先客户端向服务端发起一个特殊的 HTTP 请求，其消息头如下： GET /chat HTTP/1.1 // 请求行 Host: server.example.com Upgrade: websocket // required Connection: Upgrade // required Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== // required，一个 16bits 编码得到的 base64 串 Origin: http://example.com // 用于防止未认证的跨域脚本使用浏览器 websocket api 与服务端进行通信 Sec-WebSocket-Protocol: chat, superchat // optional, 子协议协商字段 Sec-WebSocket-Version: 13 如果服务端支持该版本的 WebSocket，会返回 101 响应，响应标头如下： HTTP/1.1 101 Switching Protocols // 状态行 Upgrade: websocket // required Connection: Upgrade // required Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= // required，加密后的 Sec-WebSocket-Key Sec-WebSocket-Protocol: chat // 表明选择的子协议 握手完成后，接下来的 TCP 数据包就都是 WebSocket 协议的帧了。 可以看到，这里的握手不是 TCP 的握手，而是在 TCP 连接内部，从 HTTP/1.1 upgrade 到 WebSocket 的握手。 WebSocket 提供两种协议：不加密的 ws:// 和 加密的 wss://. 因为是用 HTTP 握手，它和 HTTP 使用同样的端口：ws 是 80（HTTP），wss 是 443（HTTPS） 在 Python 编程中，可使用 websockets 实现的异步 WebSocket 客户端与服务端。此外 aiohttp 也提供了 WebSocket 支持。 Note：如果你搜索 Flask 的 WebScoket 插件，得到的第一个结果很可能是 Flask-SocketIO。但是 Flask-ScoektIO 使用的是它独有的 SocketIO 协议，并不是标准的 WebSocket。只是它刚好提供与 WebSocket 相同的功能而已。 SocketIO 的优势在于只要 Web 端使用了 SocketIO.js，就能支持该协议。而纯 WS 协议，只有较新的浏览器才支持。对于客户端非 Web 的情况，更好的选择可能是使用 Flask-Sockets。 ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:1:0","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"JS API // WebSocket API var socket = new WebSocket('ws://websocket.example.com'); // Show a connected message when the WebSocket is opened. socket.onopen = function(event) { console.log('WebSocket is connected.'); }; // Handle messages sent by the server. socket.onmessage = function(event) { var message = event.data; console.log(message); }; // Handle any error that occurs. socket.onerror = function(error) { console.log('WebSocket Error: ' + error); }; ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:1:1","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"二、HTTP/2 HTTP/2 于 2015 年标准化，主要目的是优化性能。其特性如下： 二进制协议：HTTP/2 的消息头使用二进制格式，而非文本格式。并且使用专门设计的 HPack 算法压缩。 多路复用（Multiplexing）：就是说 HTTP/2 可以重复使用同一个 TCP 连接，并且连接是多路的，多个请求或响应可以同时传输。 对比之下，HTTP/1.1 的长连接也能复用 TCP 连接，但是只能串行，不能“多路”。 服务器推送：服务端能够直接把资源推送给客户端，当客户端需要这些文件的时候，它已经在客户端了。（该推送对 Web App 是隐藏的，由浏览器处理） HTTP/2 允许取消某个正在传输的数据流（通过发送 RST_STREAM 帧），而不关闭 TCP 连接。 这正是二进制协议的好处之一，可以定义多种功能的数据帧。 它允许服务端将资源推送到客户端缓存，我们访问淘宝等网站时，经常会发现很多请求的请求头部分会提示“provisional headers are shown”，这通常就是直接从缓存加载了资源，因此请求根本没有被发送。观察 Chrome Network 的 Size 列，这种请求的该字段一般都是 from disk cache 或者 from memroy cache. Chrome 可以通过如下方式查看请求使用的协议： 2019-02-10: 使用 Chrome 查看，目前主流网站基本都已经部分使用了 HTTP/2，知乎、bilibili、GIthub 使用了 wss 协议，也有很多网站使用了 SSE（格式如 data:image/png;base64,\u003cbase64 string\u003e） 而且很多网站都有使用 HTTP/2 + QUIC，该协议的新名称是 HTTP/3，它是基于 UDP 的 HTTP 协议。 ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:2:0","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"SSE 服务端推送事件，是通过 HTTP 长连接进行信息推送的一个功能。 它首先由浏览器向服务端建立一个 HTTP 长连接，然后服务端不断地通过这个长连接将消息推送给浏览器。JS API 如下： // create SSE connection var source = new EventSource('/dates'); // 连接建立时，这些 API 和 WebSocket 的很相似 source.onopen = function(event) { // handle open event }; // 收到消息时（它只捕获未命名 event） source.onmessage = function(event) { var data = event.data; // 发送过来的实际数据（string） var origin = event.origin; // 服务器端URL的域名部分，即协议、域名和端口。 var lastEventId = event.lastEventId; // 数据的编号，由服务器端发送。如果没有编号，这个属性为空。 // handle message }; source.onerror = function(event) { // handle error event }; ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:2:1","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"具体的实现 在收到客户端的 SSE 请求（HTTP 协议）时，服务端返回的响应首部如下： Content-Type: text/event-stream Cache-Control: no-cache Connection: keep-alive 而 body 部分，SSE 定义了四种信息： data：数据栏 event：自定义数据类型 id ：数据 id retry：最大间隔时间，超时则重新连接 body 举例说明： : 这种格式的消息是注释，会被忽略\\n\\n : 通常服务器每隔一段时间就会发送一个注释，防止超时 retry\\n\\n : 下面这个是一个单行数据\\n\\n data: some text\\n\\n : 下面这个是多行数据，在客户端会重组成一个 data\\n\\n data: {\\n data: \"foo\": \"bar\",\\n data: \"baz\", 555\\n data: }\\n\\n : 这是一个命名 event，只会被事件名与之相同的 listener 捕获\\n\\n event: foo\\n data: a foo event\\n\\n : 未命名事件，会被 onmessage 捕获\\n\\n data: an unnamed event\\n\\n event: bar\\n data: a bar event\\n\\n : 这个 id 对应 event.lastEventId\\n\\n id: msg1\\n data: message\\n\\n ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:2:2","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"WebSocket、HTTP/2 与 SSE 的比较 加密与否： WebSocket 支持明文通信 ws:// 和加密 wss://， 而 HTTP/2 协议虽然没有规定必须加密，但是主流浏览器都只支持 HTTP/2 over TLS. SSE 是使用的 HTTP 协议通信，支持 http/https 消息推送： WebSocket是全双工通道，可以双向通信。而且消息是直接推送给 Web App. SSE 只能单向串行地从服务端将数据推送给 Web App. HTTP/2 虽然也支持 Server Push，但是服务器只能主动将资源推送到客户端缓存！并不允许将数据推送到客户端里跑的 Web App 本身。服务器推送只能由浏览器处理，不会在应用程序代码中弹出服务器数据，这意味着应用程序没有 API 来获取这些事件的通知。 为了接近实时地将数据推送给 Web App， HTTP/2 可以结合 SSE（Server-Sent Event）使用。 WebSocket 在需要接近实时双向通信的领域，很有用武之地。而 HTTP/2 + SSE 适合用于展示实时数据。 另外在客户端非浏览器的情况下，使用不加密的 HTTP/2 也是可能的。 ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:2:3","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"requests 查看 HTTP 协议版本号 可以通过 resp.raw.version 得到响应的 HTTP 版本号： \u003e\u003e\u003e import requests \u003e\u003e\u003e resp = requests.get(\"https://zhihu.com\") \u003e\u003e\u003e resp.raw.version 11 但是 requests 默认使用 HTTP/1.1，并且不支持 HTTP/2.（不过这也不是什么大问题，HTTP/2 只是做了性能优化，用 HTTP/1.1 也就是慢一点而已。） ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:2:4","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"三、gRPC 协议 gRPC 是一个远程过程调用框架，默认使用 protobuf3 进行数据的高效序列化与 service 定义，使用 HTTP/2 进行数据传输。 这里讨论的是 gRPC over HTTP/2 协议。 目前 gRPC 主要被用在微服务通信中，但是因为其优越的性能，它也很契合游戏、loT 等需要高性能低延迟的场景。 其实光从协议先进程度上讲，gRPC 基本全面超越 REST: 使用二进制进行数据序列化，比 json 更节约流量、序列化与反序列化也更快。 protobuf3 要求 api 被完全清晰的定义好，而 REST api 只能靠程序员自觉定义。 gRPC 官方就支持从 api 定义生成代码，而 REST api 需要借助 openapi-codegen 等第三方工具。 支持 4 种通信模式：一对一(unary)、客户端流、服务端流、双端流。更灵活 只是目前 gRPC 对 broswer 的支持仍然不是很好，如果你需要通过浏览器访问 api，那 gRPC 可能不是你的菜。 如果你的产品只打算面向 App 等可控的客户端，可以考虑上 gRPC。 对同时需要为浏览器和 APP 提供服务应用而言，也可以考虑 APP 使用 gRPC 协议，而浏览器使用 API 网关提供的 HTTP 接口，在 API 网关上进行 HTTP - gRPC 协议转换。 ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:3:0","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"gRPC over HTTP/2 定义 详细的定义参见官方文档 gRPC over HTTP/2. 这里是简要说明几点： gRPC 完全隐藏了 HTTP/2 本身的 method、headers、path 等语义，这些信息对用户而言完全不可见了。 请求统一使用 POST，响应状态统一为 200。只要响应是标准的 gRPC 格式，响应中的 HTTP 状态码将被完全忽略。 gRPC 定义了自己的 status 状态码、格式固定的 path、还有它自己的 headers。 ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:3:1","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"参考 深入探索 WebSockets 和 HTTP/2 HTTP/2 特性与抓包分析 SSE：服务器发送事件,使用长链接进行通讯 Using server-sent events - MDN Can I Use HTTP/2 on Browsers Python 3.x how to get http version (using requests library) WebSocket 是什么原理？ 原生模块打造一个简单的 WebSocket 服务器 Google Cloud - API design: Understanding gRPC, OpenAPI and REST and when to use them ","date":"2019-02-11","objectID":"/posts/websocket-http2-and-grpc/:4:0","tags":["WebSocket","gRPC","HTTP/2"],"title":"WebSocket、HTTP/2 与 gRPC","uri":"/posts/websocket-http2-and-grpc/"},{"categories":["技术"],"content":"不管是做爬虫还是写 Web App，Chrome 和 Firefox 的 DevTools 都是超常用的，但是经常发现别人的截图有什么字段我找不到，别人的什么功能我的 Chrome 没有，仔细一搜索才知道，原来是我不会用。。 Ctrl + Shift + I：打开 DevTools Ctrl + Shift + J：打开控制台 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:0","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"搜索 Ctrl + F：在当前位置搜索关键字 在网页界面用这个快捷键，就是页内搜索 在 Network 的 Response 页面，就是在 Response 中搜索 Ctrl + Shift + F：全文搜索，在当前 Web App 的所有文件中搜索。 **爬虫必备！！！**要寻找一些特殊字符串的来源，用它搜索屡试不爽。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:1","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"Command 在 DevTools 里按快捷键 Ctrl + Shift + P 就能打开 Command 输入框，它和 vscode/sublime 的 Command 一样，用好了特别方便。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:2","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"Network 1. 属性列 Chrome 可以右键属性列名来增减属性列，Firefox-Dev 也是一样： 2. copy 在 Chrome 中右键某个请求，选中 copy，会给出几个 options： 而 Firefox-Dev 的更强一点，可以复制消息头（请求头和响应头）： 3. response 的 pretty print Chrome 的 Response 页面左下角，有{}按钮，可以 beautify 响应。 而 Firefox-Dev 只在 Debugger 页面提供该按钮，Response 中不支持。 Firefox 响应的 preview 和 payload 是放在 Response 页面下。而 Chrome 是分成了两个标签页 4. 导出 HAR 右键任意一个请求，选择 save all as HAR，就可以导出 HAR 文件。（Chrome 有 with content，导出的 HAR 文件会含有所有请求与响应的 body） 该文件可用于存储当前监听到的所有浏览器请求信息。在以后需要分析这些请求时，将 HAR 文件拖到 Network 页面即可恢复所有请求。 5. Raw Headers（原始消息头） Chrome 只支持查看 HTTP/1.x 的 Raw Headers，对这种请求，会给出 view source 选项。 Chrome 不能查看 HTTP/2 的 Raw Headers。 而 Firefox 则支持查看 HTTP/2 的 Raw Headers。（是恢复后的，HTTP/2 的原始消息头是二进制压缩形式） 它还提供 Edit and Resend 请求的功能，这点要给个赞～ 6. 审查 WebSocket（Chrome only） 在 NetWork 中点击对应的 WebScoket 请求，在右侧选择 Frames 标签，就可以看到所有的消息了 7. 跨页面加载时，保留网络请求记录 当页面重载或者页面跳转时，默认情况下，Network面板下的网络请求记录表也是刷新的。如果想保留之前页面的网络请求数据，可以勾选Preserve log. 常用的一个应用场景：登录/注册时会调用登录/注册API，开发者想查看这个接口返回的情况，但是登录/注册成功后一般会跳转到新的页面，导致了Network面板的请求记录被刷新从而看不到登录/注册接口返回的情况。此时勾选上Preserve log，无论跳转到那个页面，都能在Network网络请求记录表中查看到之前接口返回的情况。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:3","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"JavaScript 控制台 可以通过 $x(\u003cxpath\u003e, \u003cDOM-element\u003e)，用 xpath 查询 DOM 元素。 通过控制台左上方的选单，可以切换 JS 的环境，它默认是当前页面（top）。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:4","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"Elements 页面（Firefox-Dev 是 Inspector 页面） 1. DOM 元素断点（Chrome only） 在 Elements 页面，右键一个元素，有一个 Break on 选项，可以控制在特定事件发生时 Break. - subtree modification: 子节点被修改 - attribute modification：当前节点的属性被修改。（inline style 被修改也会触发此事件） - node removal：节点被移除 2. 检索元素上注册的事件（Chrome only） 在 Elements 页面选中一个元素（或者直接右键检查该元素），然后在右侧窗口，选择 Event Listeners 标签，就可以看到该元素上注册的所有事件。 3. 颜色选择器 选中任一元素，在右侧选择 Styles 选单，会显示当前元素的 css 属性。 其中所有的颜色小方块都是可以点击的，点击颜色方块后 可以将颜色属性转换成多个格式（Chrome only） 默认格式：#207981 RGB格式：rgb(32, 121, 129) HSL格式：hsl(185, 60%, 32%) 提供 color picker，可用于在网页任意位置取色。（Firefox-Dev 也有） 提供复制按键，直接将该颜色当前格式的表达复制到剪切板 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:5","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"元素审查 Ctrl + Shift + C 或者点击 DevTools 最左上角的小箭头按钮，就能进入元素审查模式。 该模式下会自动审查鼠标所指的元素，Elements 页面也会自动定位到该元素。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:6","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"Sources 页面（Firefox-Dev 是 Debuuger 页面） Sources 右侧的 Debugger 支持各种断点调试。 条件断点 Sources 中，在任意 JS 代码的行号上单击鼠标左键，就能在该行设置一个普通断点（在 Response 中可不行）。在行号上右键，能直接设置条件断点。 XHR 断点：在右侧 Debugger 中，可以添加 XHR 断点。 如果条件留空，一旦有 XHR 发起，就会无条件进入调试。 条件是 “Break When URL Contaions ” Watch Expressions：表达式审查 双击选中 JS 代码中的任意变量，然后右键它，可以将该变量添加到 Watch 中，这样就可以随时观察它的值。 也可以在右侧 Watch 中手动输入 JS 表达式。 DOM 元素断点（Chrome only）：在 Elements 部分讲过了。 Chrome 的断点功能比 Firefox-Dev 的更丰富。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:7","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"Screenshot 1. For Chrome 方法一：在 DevTools 界面，按快捷键 Ctrl + Shift + P 打开 Command 窗口，然后输入 screenshot，在下拉栏里选择你需要的截图命令就行。 方法二： 先进 dev tools，点击 左上角的设备图标（toggle device toolbar），然后页面顶部就会出现一个导航栏，在这里好选择设备或者自定义图像尺寸，然后点击该导航栏右侧（不是 dev tools 右侧）的 options 图标，会有两个选项：“截图（capture screenshot）”和“截网页全图（capture full size screenshot）”，如下： 2. For Firefox 只截显示出来的部分：和 Chrome 一样点击设备图标，然后在页面上面的 toolbar 就有截图按钮 截网页全图：在 DevTools 右边的 options 中进入 Settings，勾选 take a screenshot of the entire page，DevTools 右上角就会出现截图按钮了。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:8","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"其他 1. Fake Geolocation（Chrome only） 在 Chrome 中进入 DevTools，点击右上角的 options 按钮，选择 More tools -\u003e Sensors，在 Geolocation 处选择 Custom location，就可以修改地理位置了。 2. 自定义请求头 For Chrome 和 上一小节一样，先进 More tools，选择 Network conditions，取消勾选 Select atuomatically，就可以修改请求头了。 上面的演示中，使用 python-requests/2.21.0 做 user agent，知乎返回 404. For Firefox 打开设备模拟，在 toolbar 的右上角勾选 show user agent，然后就可以在 toolbar 修改 user agent 了： ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:9","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"3. Request Blocking（Chrome only） 在 Network 的任意请求上右键，菜单中就有 Block request URL（阻塞该 URL）和 Block request domain（阻塞请求所在的整个域） 然后就可以在 More tools -\u003e Request blocking 中看到你设置的阻塞条件。 ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:10","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"参考 你不知道的 Chrome 调试技巧 Chrome Dev Tools 中文手册 Firefox Quantum：开发者版本 How to Capture Screenshots in Google Chrome without using Extensions Chrome DevTools - Network ","date":"2019-02-11","objectID":"/posts/web-browser-dev-tools/:0:11","tags":["Chrome","Firefox","DevTools","Browser"],"title":"Chrome 与 Firefox-Dev 的 DevTools","uri":"/posts/web-browser-dev-tools/"},{"categories":["技术"],"content":"前言 如果要在Linux 上设置一个开机自启，出现问题自动重启，并且有良好日志的程序，比较流行的方法有 supervisord、systemd，除此之外，还有 upstart、runit 等类似的工具。 但是自从 systemd 被 ubuntu、centos 等主流 Linux 发行版应用以来，systemd 渐渐成为主流方案。 如果你需要跨平台(Linux/MacOSX/FreeBSD)的方案，那么建议使用 supervisord，如果只需要支持 Linux 则建议选用 systemd. ","date":"2019-01-28","objectID":"/posts/systemd-basics/:1:0","tags":["Linux","Systemd","Init System"],"title":"通过 systemctl 设置自定义 Service","uri":"/posts/systemd-basics/"},{"categories":["技术"],"content":"配置说明 要自定义一个服务，需要在 /usr/lib/systemd/system/ 下添加一个配置文件：\u003csoftware-name\u003e.service 如果 /usr/lib/systemd/system/ 不存在，可考虑使用 /lib/systemd/system/ 或 /etc/systemd/system/ ExecXXX 中的命令，均可以正常使用转义字符以及环境变量插值语法，比如用 \\ 结尾表示换行，用 $Xxx 获取环境变量。 配置文件的内容说明： [Unit]: 服务的启动顺序与依赖关系 Description: 当前服务的简单描述 After: 当前服务（\u003csoftware-name\u003e.service）需要在这些服务启动后，才启动 Before: 和 After 相反，当前服务需要在这些服务启动前，先启动 Wants：表示当前服务\"弱依赖\"于这些服务。即当前服务依赖于它们，但是没有它们，当前服务也能正常运行。 Requires: 表示\"强依赖\"关系，即如果该服务启动失败或异常退出，那么当前服务也必须退出。 [Service] 服务运行参数的设置 Type=forking 后台运行的形式 PIDFile=/software-name/pid pid文件路径 EnvironmentFile=/xxx/prod.env 通过文件设定环境变量，注意这东西不支持环境变量的插值语法 ${xxx} WorkingDirectory=/xxx/xxx 工作目录 ExecStartPre 为启动做准备的命令 ExecStart 服务的具体运行命令（对非 workingdirectory 的文件，必须用绝对路径！ ExecReload 重载命令，如果程序支持 HUP 信号的话，通常将此项设为 `/bin/kill -HUP $MAINPID` ExecStop 停止命令 ExecStartPre：启动服务之前执行的命令 ExecStartPost：启动服务之后执行的命令 ExecStopPost：停止服务之后执行的命令 RuntimeDirectory=xxxx RuntimeDirectoryMode=0775 PrivateTmp=True 表示给服务分配独立的临时空间 RestartSec 自动重启当前服务间隔的秒数 Restart 定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure 等 # 程序的 user 和 group User=ryan Group=ryan 注意：启动、重载、停止命令全部要求使用绝对路径 [Install] 定义如何安装这个配置文件，即怎样做到开机启动。 # Target的含义是服务组，表示一组服务。 WantedBy=multi-user.target 注意，service 文件不支持行内注释！！！注释必须单独一行 ","date":"2019-01-28","objectID":"/posts/systemd-basics/:1:1","tags":["Linux","Systemd","Init System"],"title":"通过 systemctl 设置自定义 Service","uri":"/posts/systemd-basics/"},{"categories":["技术"],"content":"Type 说明 Type 感觉是整个配置文件里面最不好理解的一个配置项，它的实际作用就是：告诉 systemd 你的 Service 是如何启动的 Type=simple（默认值）：ExecStart 命令会立即启动你的服务，并且持续运行，不会退出。 Type=forking：ExecStart 命令会 fork 出你的服务主进程，然后正常退出。使用此 Type 时应同时指定 PIDFile=，systemd 使用它跟踪服务的主进程。 Type=oneshot：ExecStart 命令。可能需要同时设置 RemainAfterExit=yes 使得 systemd 在服务进程退出之后仍然认为服务处于激活状态 Type=notify：与 Type=simple 相同，但约定服务会在就绪后向 systemd 发送一个信号，以表明自己已经启动成功。 细节：systemd 会创建一个 unix socket，并将地址通过 $NOTIFY_SOCKET 环境变量提供给服务，同时监听该 socket 上的信号。服务可以使用 systemd 提供的 C 函数 sd_notify() 或者命令行工具 systemd-notify 发送信号给 systemd. 因为多了个 notify 信号，所以这一 Type 要比 simple 更精确一点。但是需要服务的配合， Type=dbus：若以此方式启动，当指定的 BusName 出现在 DBus 系统总线上时，systemd 认为服务就绪。 Type=idle：没搞明白，不过通常也用不到。 更详细的见 Systemd 入门教程：命令篇 - 阮一峰。 ","date":"2019-01-28","objectID":"/posts/systemd-basics/:1:2","tags":["Linux","Systemd","Init System"],"title":"通过 systemctl 设置自定义 Service","uri":"/posts/systemd-basics/"},{"categories":["技术"],"content":"配置举例 比如 shadsocks Server Service，的配置文件 ss-server.service 的内容为： [Unit] Description=shadsocks server After=network.target auditd.service [Service] Type=forking ExecStart=/usr/local/bin/ssserver -c /etc/shadsocks.json --user shadsocks --pid-file /var/run/shadsocks.pid -d start ExecStop=/usr/local/bin/ssserver -c /etc/shadsocks.json --user shadsocks --pid-file /var/run/shadsocks.pid -d stop PIDFile=/var/run/shadsocks.pid Restart=always RestartSec=4 [Install] WantedBy=multi-user.target 而 enginx 的配置文件 nginx.service 的内容是： [Unit] Description=The NGINX HTTP and reverse proxy server After=syslog.target network-online.target remote-fs.target nss-lookup.target Wants=network-online.target [Service] Type=forking PIDFile=/run/nginx.pid ExecStartPre=/usr/sbin/nginx -t ExecStart=/usr/sbin/nginx ExecReload=/usr/sbin/nginx -s reload ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 为了使用环境变量插值，而使用 sh 启动的 etcd 服务，它的 etcd.service 配置如下: [Unit] Description=etcd key-value store Documentation=https://github.com/etcd-io/etcd After=network.target [Service] Type=simple # EnvironmentFile 不支持使用 ${xxx} 变量插值，这里不适合使用 # EnvironmentFile=/data/etcd.env # -a 表示传递环境变量 ExecStart=/bin/bash -ac '. /data/etcd.env; /data/bin/etcd' Restart=always RestartSec=5s LimitNOFILE=40000 [Install] WantedBy=multi-user.target 如果你不需要在 /data/etcd.env 中使用环境变量的插值语法，那可以这样写: [Unit] Description=etcd key-value store Documentation=https://github.com/etcd-io/etcd After=network.target [Service] Type=notify EnvironmentFile=/data/etcd.env # ExecXXX 的命令中是可以使用 ${Xxx} 插值语法的 ExecStart=/data/bin/etcd \\ --initial-advertise-peer-urls http://${THIS_IP}:2380 \\ --listen-peer-urls http://${THIS_IP}:2380 \\ --advertise-client-urls http://${THIS_IP}:2379 \\ --listen-client-urls http://${THIS_IP}:2379 \\ --initial-cluster \"${NAME_1}=http://${HOST_1}:2380,${NAME_2}=http://${HOST_2}:2380,${NAME_3}=http://${HOST_3}:2380\" Restart=always RestartSec=5s LimitNOFILE=40000 [Install] WantedBy=multi-user.target ","date":"2019-01-28","objectID":"/posts/systemd-basics/:1:3","tags":["Linux","Systemd","Init System"],"title":"通过 systemctl 设置自定义 Service","uri":"/posts/systemd-basics/"},{"categories":["技术"],"content":"服务的启动、关闭 systemctl enable ss-server.service # 启用服务，即开机自动启动 systemctl disable ss-server.service # 取消服务，取消开机启动 systemctl start ss-server.service # 启动服务 systemctl stop ss-server.service # 停止服务 systemctl restart ss-server.service # 重启服务(stop + start) systemctl reload ss-server.service # 服务不 stop，直接加载配置更新等（对应 ExecReload） # 检查状态 systemctl status ss-server.service -l systemctl list-units --type=service # 查看所有服务 ","date":"2019-01-28","objectID":"/posts/systemd-basics/:1:4","tags":["Linux","Systemd","Init System"],"title":"通过 systemctl 设置自定义 Service","uri":"/posts/systemd-basics/"},{"categories":["技术"],"content":"参考 Systemd 入门教程：命令篇 - 阮一峰 systemd.exec 中文手册 ","date":"2019-01-28","objectID":"/posts/systemd-basics/:1:5","tags":["Linux","Systemd","Init System"],"title":"通过 systemctl 设置自定义 Service","uri":"/posts/systemd-basics/"},{"categories":["技术"],"content":" 个人笔记，如有错误烦请指正。 SQLAlchemy 是一个用 Python 实现的 ORM （Object Relational Mapping）框架，它由多个组件构成，这些组件可以单独使用，也能独立使用。它的组件层次结构如下： SQLAlchemy 层次结构\" SQLAlchemy 层次结构 其中最常用的组件，应该是 ORM 和 SQL 表达式语言，这两者既可以独立使用，也能结合使用。 ORM 的好处在于它 自动处理了数据库和 Python 对象之间的映射关系，屏蔽了两套系统之间的差异。程序员不需要再编写复杂的 SQL 语句，直接操作 Python 对象就行。 屏蔽了各数据库之间的差异，更换底层数据库不需要修改 SQL 语句，改下配置就行。 使数据库结构文档化，models 定义很清晰地描述了数据库的结构。 避免了不规范、冗余、风格不统一的 SQL 语句，可以避免很多人为 Bug，也方便维护。 但是 ORM 需要消耗额外的性能来处理对象关系映射，此外用 ORM 做多表关联查询或复杂 SQL 查询时，效率低下。因此它适用于场景不太复杂，性能要求不太苛刻的场景。 都说 ORM 学习成本高，我自己也更倾向于直接使用 SQL 语句（毕竟更熟悉），因此这一篇笔记不涉及 ORM 部分，只记录 SQLAlchemy 的 Engine 与 SQL 表达式语言。 ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:0:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":"一、直接使用 Engine 和 Connections 第一步是创建数据库引擎实例： from sqlalchemy import create_engine engine = create_engine('sqlite:///:memory:', echo=True, # echo=True 表示打印出自动生成的 SQL 语句（通过 logging） pool_size=5, # 连接池容量，默认为 5，生产环境下太小，需要修改。 # 下面是 connection 回收的时间限制，默认 -1 不回收 pool_recycle=7200) # 超过 2 小时就重新连接（MySQL 默认的连接最大闲置时间为 8 小时） create_engine 接受的第一个参数是数据库 URI，格式为 dialect+driver://username:password@host:port/database，dialect 是具体的数据库名称，driver 是驱动名称。key-value 是可选的参数。举例： # PostgreSQL postgresql+psycopg2://scott:tiger@localhost/dbtest # MySQL + PyMySQL（或者用更快的 mysqlclient） mysql+pymysql://scott:tiger@localhost/dbtest # sqlite 内存数据库 # 注意 sqlite 要用三个斜杠，表示不存在 hostname，sqlite://\u003cnohostname\u003e/\u003cpath\u003e sqlite:///:memory: # sqlite 文件数据库 # 四个斜杠是因为文件的绝对路径以 / 开头：/home/ryan/Codes/Python/dbtest.db sqlite:////home/ryan/Codes/Python/dbtest.db # SQL Server + pyodbc # 首选基于 dsn 的连接，dsn 的配置请搜索hhh mssql+pyodbc://scott:tiger@some_dsn 如果你的密码中含有 ‘@’ 等特殊字符，就不能直接放入 URI 中，必须使用 urllib.parse.quote_plus 编码，然后再插入 URI. 引擎创建后，我们就可以直接获取 connection，然后执行 SQL 语句了。这种用法相当于把 SQLAlchemy 当成带 log 的数据库连接池使用： with engine.connect() as conn: res = conn.execute(\"select username from users\") # 无参直接使用 # 使用问号作占位符，前提是下层的 DBAPI 支持。更好的方式是使用 text()，这个后面说 conn.execute(\"INSERT INTO table (id, value) VALUES (?, ?)\", 1, \"v1\") # 参数不需要包装成元组 # 查询返回的是 ResultProxy 对象，有和 dbapi 相同的 fetchone()、fetchall()、first() 等方法，还有一些拓展方法 for row in result: print(\"username:\", row['username']) 但是要注意的是，connection 的 execute 是自动提交的（autocommit），这就像在 shell 里打开一个数据库客户端一样，分号结尾的 SQL 会被自动提交。 只有在 BEGIN TRANSACTION 内部，AUTOCOMMIT 会被临时设置为 FALSE，可以通过如下方法开始一个内部事务： def transaction_a(connection): trans = connection.begin() # 开启一个 transaction try: # do sthings trans.commit() # 这里需要手动提交 except: trans.rollback() # 出现异常则 rollback raise # do other things with engine.connect() as conn: transaction_a(conn) ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:1:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":"1. 使用 text() 构建 SQL 相比直接使用 string，text() 的优势在于它： 提供了统一的参数绑定语法，与具体的 DBAPI 无关。 # 1. 参数绑定语法 from sqlalchemy import text result = connection.execute( # 使用 :key 做占位符 text('select * from table where id \u003c :id and typeName=:type'), {'id': 2,'type':'USER_TABLE'}) # 用 dict 传参数，更易读 # 2. 参数类型指定 from sqlalchemy import DateTime date_param=datetime.today()+timedelta(days=-1*10) sql=\"delete from caw_job_alarm_log where alarm_time \u003c :alarm_time_param\" # bindparams 是 bindparam 的列表，bindparam 则提供参数的一些额外信息（类型、值、限制等） t=text(sql, bindparams=[bindparam('alarm_time_param', type_=DateTime, required=True)]) connection.execute(t, {\"alarm_time_param\": date_param}) 可以很方便地转换 Result 中列的类型 stmt = text(\"SELECT * FROM table\", # 使用 typemap 指定将 id 列映射为 Integer 类型，name 映射为 String 类型 typemap={'id': Integer, 'name': String}, ) result = connection.execute(stmt) # 对多个查询结果，可以用 for obj in result 遍历 # 也可用 fetchone() 只获取一个 ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:1:1","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":"二、SQL 表达式语言 复杂的 SQL 查询可以直接用 raw sql 写，而增删改一般都是单表操作，用 SQL 表达式语言最方便。 SQLAlchemy 表达式语言是一个使用 Python 结构表示关系数据库结构和表达式的系统。 ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:2:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":"1. 定义并创建表 SQL 表达式语言使用 Table 来定义表，而表的列则用 Column 定义。Column 总是关联到一个 Table 对象上。 一组 Table 对象以及它们的子对象的集合就被称作「数据库元数据（database metadata）」。metadata 就像你的网页分类收藏夹，相关的 Table 放在一个 metadata 中。 下面是创建元数据（一组相关联的表）的例子，： from sqlalchemy import Table, Column, Integer, String, MetaData, ForeignKey metadata = MetaData() # 先创建元数据（收藏夹） users = Table('user', metadata, # 创建 user 表，并放到 metadata 中 Column('id', Integer, primary_key=True), Column('name', String), Column('fullname', String) ) addresses = Table('address', metadata, Column('id', Integer, primary_key=True), Column('user_id', None, ForeignKey('user.id')), # 外键约束，引用 user 表的 id 列 Column('email_address', String, nullable=False) ) metadata.create_all(engine) # 使用 engine 创建 metadata 内的所有 Tables（会检测表是否已经存在，所以可以重复调用） 表定义中的约束 应该给所有的约束命名，即为 name 参数指定一个不冲突的列名。详见 The Importance of Naming Constraints 表还有一个属性：约束条件。下面一一进行说明。 外键约束：用于在删除或更新某个值或行时，对主键/外键关系中一组数据列强制进行的操作限制。 用法一：Column('user_id', None, ForeignKey('user.id'))，直接在 Column 中指定。这也是最常用的方法 用法二：通过 ForeignKeyConstraint(columns, refcolumns) 构建约束，作为参数传给 Table. item = Table('item', metadata, # 商品 table Column('id', Integer, primary_key=True), Column('name', String(60), nullable=False), Column('invoice_id', Integer, nullable=False), # 发票 id，是外键 Column('ref_num', Integer, nullable=False), ForeignKeyConstraint(['invoice_id', 'ref_num'], # 当前表中的外键名称 ['invoice.id', 'invoice.ref_num']) # 被引用的外键名称的序列（被引用的表） ) on delete 与 on update：外键约束的两个约束条件，通过 ForeignKey() 或 ForeignKeyConstraint() 的关键字参数 ondelete/onupdate 传入。 可选值有： 默认行为 NO ACTION：什么都不做，直接报错。 CASCADE：删除/更新 父表数据时，从表数据会同时被 删除/更新。（无报错） RESTRICT：不允许直接 删除/更新 父表数据，直接报错。（和默认行为基本一致） SET NULL or SET DEFAULT：删除/更新 父表数据时，将对应的从表数据重置为 NULL 或者默认值。 唯一性约束：UniqueConstraint('col2', 'col3', name='uix_1')，作为参数传给 Table. CHECK 约束：CheckConstraint('col2 \u003e col3 + 5', name='check1')， 作为参数传给 Table. 主键约束：不解释 方法一：通过 Column('id', Integer, primary_key=True) 指定主键。（参数 primary_key 可在多个 Column 上使用） 方法二：使用 PrimaryKeyConstraint from sqlalchemy import PrimaryKeyConstraint my_table = Table('mytable', metadata, Column('id', Integer), Column('version_id', Integer), Column('data', String(50)), PrimaryKeyConstraint('id', 'version_id', name='mytable_pk') ) ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:2:1","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":"2. 增删改查语句 增: # 方法一，使用 values 传参 ins = users.insert().values(name=\"Jack\", fullname=\"Jack Jones\") # 可以通过 str(ins) 查看自动生成的 sql connection.execute(ins) # 方法二，参数传递给 execute() conn.execute(users.insert(), id=2, name='wendy', fullname='Wendy Williams') # 方法三，批量 INSERT，相当于 executemany conn.execute(addresses.insert(), [ # 插入到 addresses 表 {'user_id': 1, 'email_address': 'jack@yahoo.com'}, # 传入 dict 列表 {'user_id': 1, 'email_address': 'jack@msn.com'}, {'user_id': 2, 'email_address': 'www@www.org'}, {'user_id': 2, 'email_address': 'wendy@aol.com'} ]) # 此外，通过使用 bindparam，INSERT 还可以执行更复杂的操作 stmt = users.insert() \\ .values(name=bindparam('_name') + \" .. name\") # string 拼接 conn.execute(stmt, [ {'id':4, '_name':'name1'}, {'id':5, '_name':'name2'}, {'id':6, '_name':'name3'}, ]) 删： _table.delete() \\ .where(_table.c.f1==value1) \\ .where(_table.c.f2==value2) # where 指定条件 改： # 举例 stmt = users.update() \\ .where(users.c.name == 'jack') \\ .values(name='tom') conn.execute(stmt) # 批量更新 stmt = users.update() \\ .where(users.c.name == bindparam('oldname')) \\ .values(name=bindparam('newname')) conn.execute(stmt, [ {'oldname':'jack', 'newname':'ed'}, {'oldname':'wendy', 'newname':'mary'}, {'oldname':'jim', 'newname':'jake'}, ]) 可以看到，所有的条件都是通过 where 指定的，它和后面 ORM 的 filter 接受的参数是一样的。（详细的会在第二篇文章里讲） 查 from sqlalchemy.sql import select # 1. 字段选择 s1 = select([users]) # 相当于 select * from users s2 = select([users.c.name, users.c.fullname]) # 这个就是只 select 一部分 # 2. 添加过滤条件 s3 = select([users]) \\ .where(users.c.id == addresses.c.user_id) res = conn.execute(s1) # 可用 for row in res 遍历结果集，也可用 fetchone() 只获取一行 查询返回的是 ResultProxy 对象，这是 SQLAlchemy 对 Python DB-API 的 cursor 的一个封装类，要从中获取结果行，主要有下列几个方法： row1 = result.fetchone() # 对应 cursor.fetchone() row2 = result.fetchall() # 对应 cursor.fetchall() row3 = result.fetchmany(size=3) # 对应 cursor.fetchmany(size=3) row4 = result.first() # 获取一行，然后立即调用 result 的 close() 方法 col = row[mytable.c.mycol] # 获取 mycol 这一列 result.rowcount # 结果集的行数 同时，result 也实现了 next protocol，因此可以直接用 for 循环遍历 ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:2:2","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":"where 进阶 通过使用 or_、and_、in_ model.join 等方法，where 可以构建更复杂的 SQL 语句。 from sqlalchemy.sql import and_, or_, not_ s = select([(users.c.fullname + \", \" + addresses.c.email_address). label('title')]).\\ where(users.c.id == addresses.c.user_id).\\ where(users.c.name.between('m', 'z')).\\ where( or_( addresses.c.email_address.like('%@aol.com'), addresses.c.email_address.like('%@msn.com') ) ) ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:2:3","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":"链接 使用 Engines 和 Connections SQL 表达式语言入门 SQLAlchemy - 定义约束 SQLAlchemy个人学习笔记完整汇总 hackersandslackers/sqlalchemy-tutorial ","date":"2019-01-21","objectID":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/:3:0","tags":["SQLAlchemy","Python","ORM","后端","数据库","Database"],"title":"SQLAlchemy 学习笔记（一）：Engine 与 SQL 表达式语言","uri":"/posts/sqlalchemy-notes-1-engine-and-sql-expression-language/"},{"categories":["技术"],"content":" 个人笔记不保证正确。 数据类型是限制我们可以在表里存储什么数据的一种方法。不过，对于许多应用来说， 这种限制实在是太粗糙了。比如，一个包含产品价格的字段应该只接受正数。 但是没有哪种标准数据类型只接受正数。 另外一个问题是你可能需要根据其它字段或者其它行的数据来约束字段数据。比如， 在一个包含产品信息的表中，每个产品编号都应该只有一行。 对于这些问题，SQL 允许你在字段和表上定义约束。约束允许你对数据施加任意控制。 如果用户企图在字段里存储违反约束的数据，那么就会抛出一个错误。 这种情况同时也适用于数值来自默认值的情况。 ","date":"2019-01-20","objectID":"/posts/sql-basics-3-restrict/:0:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（三）约束","uri":"/posts/sql-basics-3-restrict/"},{"categories":["技术"],"content":"1. 外键 FOREIGN KEY 外键约束声明一个字段(或者一组字段)的数值必须匹配另外一个表中出现的数值。 创建外键约束的前提是，该外键所在的表已经存在，并且外键必须是 UNIQUE 的。（主键默认 UNIQUE 且 NOT NULL） CREATETABLE\u003c表名\u003e(\u003c字段名\u003e\u003c类型\u003ePRIMARYKEY,\u003c字段名\u003e\u003c类型\u003eREFERENCES\u003c外键所在的表名\u003e(\u003c字段名\u003e),-- 这创建了一个外键 ...); 还有另一种语法，它支持以多个字段为外键（字段约束也可以写成表约束，也就是放在一个独立的行中。而反过来很可能不行）： CREATE TABLE \u003c表名\u003e ( \u003c字段名1\u003e \u003c类型\u003e PRIMARY KEY, \u003c字段名2\u003e \u003c类型\u003e \u003c字段名3\u003e \u003c类型\u003e ... FOREIGN KEY (\u003c字段名2\u003e, \u003c字段名3\u003e) REFERENCES \u003c外键所在的表名\u003e (\u003c字段名4\u003e, \u003c字段名5\u003e) ); 一个表也可以包含多个外键约束。这个特性用于实现表之间的多对多关系。 比如你有关于产品和订单的表，但现在你想允许一个订单可以包含多种产品 (上面那个结构是不允许这么做的)，你可以使用这样的结构： CREATETABLEproducts(product_nointegerPRIMARYKEY,nametext,pricenumeric);CREATETABLEorders(order_idintegerPRIMARYKEY,shipping_addresstext,...);CREATETABLEorder_items(product_nointegerREFERENCESproducts,order_idintegerREFERENCESorders,quantityinteger,PRIMARYKEY(product_no,order_id)); 外键能通过 ALTER 语句添加或删除 ","date":"2019-01-20","objectID":"/posts/sql-basics-3-restrict/:0:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（三）约束","uri":"/posts/sql-basics-3-restrict/"},{"categories":["技术"],"content":"2. 级联操作 ON DELETE 与 ON UPDATE 上面说过：外键约束声明一个字段(或者一组字段)的数值必须匹配另外一个表中出现的数值。 但是以 1. 中最后一个 sql 为例，如果一个订单（order）在创建之后，该订单包含的某个产品（product）被删除了，会发生什么？ 这个例子中，订单包含的产品通过外键被记录在 order_items 表中。现在如果你要删除 product 中某个被 order_items 引用了的行，默认情况为 NO ACTION，就是直接报错。 这个行为也可以手动指定： CREATETABLEproducts(product_nointegerPRIMARYKEY,nametext,pricenumeric);CREATETABLEorders(order_idintegerPRIMARYKEY,shipping_addresstext,...);CREATETABLEorder_items(product_nointegerREFERENCESproductsONDELETERESTRICT,-- 限制，也就是禁止删除被它引用的行 order_idintegerREFERENCESordersONDELETECASCADE,-- 级联，在删除被它引用的行的时候，这一行本身也会被自动删除掉 quantityinteger,PRIMARYKEY(product_no,order_id)); 除了 RESTRICT 和 CASCADE 外，在外键上的动作还有两个选项：SET NULL 和 SET DEFAULT，顾名思义，就是在被引用的行删除后将外键设置为 NULL 或默认值。 ON UPDATE 与 ON DELETE 的动作是一样的，只是 CASCADE 表示同步更新。 ","date":"2019-01-20","objectID":"/posts/sql-basics-3-restrict/:0:2","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（三）约束","uri":"/posts/sql-basics-3-restrict/"},{"categories":["技术"],"content":"3. CHECK 约束 CREATETABLEproducts(product_nointeger,nametext,pricenumericCHECK(price\u003e0)); 你还可以给这个约束取一个独立的名字。这样就可以令错误消息更清晰， 并且在你需要修改它的时候引用这个名字。语法是： CREATETABLEproducts(product_nointeger,nametext,pricenumericCONSTRAINTpositive_priceCHECK(price\u003e0)); 稍微复杂一点的例子： CREATETABLEproducts(product_nointeger,nametext,pricenumericCHECK(price\u003e0),discounted_pricenumeric,CHECK(discounted_price\u003e0ANDprice\u003ediscounted_price)); 同样的，可以为 CHECK 命名，令错误信息更清晰： CREATETABLEproducts(product_nointeger,nametext,pricenumeric,CHECK(price\u003e0),discounted_pricenumeric,CHECK(discounted_price\u003e0),CONSTRAINTvalid_discountCHECK(price\u003ediscounted_price)); 要注意的是，当约束表达式计算结果为真或 NULL 的时候，检查约束会被认为是满足条件的。 因为大多数表达式在含有 NULL 操作数的时候结果都是 NULL ，所以这些约束不能阻止字段值为 NULL 。要排除掉 NULL，只能使用 NOT NULL 约束。（所以就说 NULL 是万恶之源hhh） ","date":"2019-01-20","objectID":"/posts/sql-basics-3-restrict/:0:3","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（三）约束","uri":"/posts/sql-basics-3-restrict/"},{"categories":["技术"],"content":"参考 约束 ","date":"2019-01-20","objectID":"/posts/sql-basics-3-restrict/:0:4","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（三）约束","uri":"/posts/sql-basics-3-restrict/"},{"categories":["技术"],"content":" 个人向，只会记录一些需要注意的点。 ","date":"2019-01-14","objectID":"/posts/julia-notes-1-array/:0:0","tags":["JuliaLang"],"title":"Julia 学习笔记（一）：数组","uri":"/posts/julia-notes-1-array/"},{"categories":["技术"],"content":"前言 学习 Julia 已经有一段时间了，但是进步缓慢。这一方面是最近代码写得少，一方面是 Julia 学习资料少、中文资料更少，但也有我没做笔记的缘故导致学习效率不佳。 最近发现一份很不错的入门教程：Introducing_Julia，但是它的中文版本仍然有很多不足，就打算给它添加翻译和润色（zxj5470 完成了绝大部分翻译工作），顺便总结一份自己的笔记。 NOTE：Julia 的主要语言特征在于类型系统和多重派发，而主要的科学计算特征则是矩阵和整个标准库及生态圈。 ","date":"2019-01-14","objectID":"/posts/julia-notes-1-array/:1:0","tags":["JuliaLang"],"title":"Julia 学习笔记（一）：数组","uri":"/posts/julia-notes-1-array/"},{"categories":["技术"],"content":"一、数组 在 Julia 中，数组被用作列表（lists）、向量（vectors）、表（tables）和矩阵（matrices）。 ","date":"2019-01-14","objectID":"/posts/julia-notes-1-array/:2:0","tags":["JuliaLang"],"title":"Julia 学习笔记（一）：数组","uri":"/posts/julia-notes-1-array/"},{"categories":["技术"],"content":"1. 数组的创建 这里尤其需要注意的是数组构造的几种方法，以及它们的区别。 1.1 一维数组（vector/list） julia\u003e v = [1, 2, 3, 4] # 逗号分隔的语法用于创建一维数组 4-element Array{Int64,1}: 1 2 3 4 向量，指列向量，Julia 使用的是 Fortran Order，各种操作都是列优先于行的。（和 numpy 相反，numpy 是 C Order 的，行优先于列） 1.2. 二维数组（table/matrix） julia\u003e mat = [1 2 3 4] # 空格分隔的语法，用于创建二维数组（或称行向量） 1×4 Array{Int64,2}: 1 2 3 4 julia\u003e [1 2; 3 4] # 分号和换行符(\\n)，用于分隔数组中不同的行 2×2 Array{Int64,2}: 1 2 3 4 空格对应函数 hcat，表示横向拼接各个矩阵/元素。 分号和换行对应函数 vcat，表示垂直拼接各个矩阵/元素。 下面的例子演示了拼接（空格）和单纯分隔各个元素（逗号）的区别： julia\u003e [1 2 [3 4] 5] # 用空格做横向拼接（或称水平拼接） 1×5 Array{Int64,2}: 1 2 3 4 5 julia\u003e [1, 2, [3, 4], 5] # 用逗号分隔 4-element Array{Any,1}: 1 2 [3, 4] 5 能看到在拼接操作中，[3 4] 被“解开”了，而用逗号时，它的行为和 Python 的 list 一样（区别只是 Julia 的 list 列优先）。 使用拼接需要注意的情况举例： julia\u003e [1 2 [3, 4] 5] # 横向拼接要求 items 的行数相同！ ERROR: DimensionMismatch(\"mismatch in dimension 1 (expected 1 got 2)\") 因为 [3, 4] 有两行，而 数组中的其他项是数值，显然行数不同，所以抛出了 Error. 可以想见，垂直拼接则要求 items 的列数相同。 另外当垂直拼接用于基本元素时，效果等同于逗号。（结果都是单列数组） julia\u003e v = [1, 2, 3, 4] 4-element Array{Int64,1}: 1 2 3 4 julia\u003e h = [1; 2; 3; 4] 4-element Array{Int64,1}: 1 2 3 4 julia\u003e [[1; 2]; [3, 4]] # 等价于 [[1, 2]; [3, 4]] 4-element Array{Int64,1}: 1 2 3 4 ","date":"2019-01-14","objectID":"/posts/julia-notes-1-array/:2:1","tags":["JuliaLang"],"title":"Julia 学习笔记（一）：数组","uri":"/posts/julia-notes-1-array/"},{"categories":["技术"],"content":"2. 数组的索引 数组的索引方式和 numpy 很类似。有很多高级索引方式。 这里我想说的是类似“齐次坐标”的索引特性。 首先，单个元素可以看作是零维的向量，数学上零维也可以看作是任意维，因此可以这样玩： julia\u003e 2[1] 2 julia\u003e 2[1, 1] # 被当成二维 2 julia\u003e 2[1][1] # 2[1] 仍然是整数 2 2 julia\u003e 2[1, 1, 1] # 三维 2 julia\u003e 3.14[1] 3.14 julia\u003e π[1, 1] π = 3.1415926535897... julia\u003e '1'[1] '1': ASCII/Unicode U+0031 (category Nd: Number, decimal digit) julia\u003e '1'[1, 1] '1': ASCII/Unicode U+0031 (category Nd: Number, decimal digit) 多维数组也能使用类似“齐次坐标”的索引方式： julia\u003e m = [1 2; 3 4] 2×2 Array{Int64,2}: 1 2 3 4 julia\u003e m[1][1] # m[1] 是整数 1，这相当于 1[1] 1 julia\u003e m[1, 1, 1] 1 julia\u003e m[1, 1, 1, 1] 1 多维矩阵，在更高的维度上，也能被当成“零维”来看待，前面说过了“零维”也相当于“无限维”，所以多维数组也能用这么索引。 但是拓展的维度索引只能是 1！既然被看作“零维”，就只相当于一个点，自然不可能有更高的索引： julia\u003e 1[1, 2] ERROR: BoundsError julia\u003e m[1, 1, 2] ERROR: BoundsError: attempt to access 2×2 Array{Int64,2} at index [1, 1, 2] ... julia\u003e m[1, 1, 1, 2] ERROR: BoundsError: attempt to access 2×2 Array{Int64,2} at index [1, 1, 1, 2] ... ","date":"2019-01-14","objectID":"/posts/julia-notes-1-array/:2:2","tags":["JuliaLang"],"title":"Julia 学习笔记（一）：数组","uri":"/posts/julia-notes-1-array/"},{"categories":["技术"],"content":"3. 推导式（comprehension）与生成器表达式（generator expression） 和 Python 的列表推导式与生成器表达式很像，但是更强大——Julia 是面向矩阵的。 julia\u003e [i+j for i in 1:3 for j in 1:3] # 这个语法和 Python 一致 9-element Array{Int64,1}: 2 3 4 3 4 5 4 5 6 julia\u003e [i+j for i in 1:3, j in 1:3] # 这个是多维的语法 3×3 Array{Int64,2}: 2 3 4 3 4 5 4 5 6 # 在后面加 guard 的情况下，结果坍缩成一维（这时两种语法结果没有差别） julia\u003e [i+j for i in 1:3, j in 1:3 if iseven(i+j)] 5-element Array{Int64,1}: 2 4 4 4 6 # 在前面做判断，因为没有过滤元素，所以仍然保持了原有结构。 julia\u003e [(iseven(i+j) ? 1 : 2) for i in 1:3, j in 1:3] 3×3 Array{Int64,2}: 1 2 1 2 1 2 1 2 1 ","date":"2019-01-14","objectID":"/posts/julia-notes-1-array/:2:3","tags":["JuliaLang"],"title":"Julia 学习笔记（一）：数组","uri":"/posts/julia-notes-1-array/"},{"categories":["技术"],"content":" 可先浏览加粗部分 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:0:0","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["技术"],"content":"一、常见压缩档 *.zip | zip 程序压缩打包的档案； （很常见，但是因为不包含文档名编码信息，跨平台可能会乱码） *.rar | rar 程序压缩打包的档案；（在windows上很常见，但是是商业软件。） *.gz | gzip 程序压缩的档案； （linux目前使用最广泛的压缩格式） *.bz2 | bzip2 程序压缩的档案； *.xz | xz 程序压缩的档案； *.tar | tar 程序打包的资料，并没有压缩过； *.tar.gz | tar 程序打包的档案，其中并且经过 gzip 的压缩 （最常见） *.tar.bz2 | tar 程序打包的档案，其中并且经过 bzip2 的压缩 *.tar.xz | tar 程序打包的档案，其中并且经过 xz 的压缩 （新一代压缩选择） *.7z | 7zip 程序压缩打包的档案。 目前最常见的是 tar.gz tar.xz tar.7z 这三种格式。 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:1:0","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["技术"],"content":"二、以能否压缩多文档分类 gzip bzip2 xz 这三个压缩格式都只能压缩单个文档。（换而言之，该进程的输入输出都是流，不包含文档树信息。） 因此如果要用它们压缩多个文档或目录，需要使用另一个软件来先将要压缩的文档打包成一个文档（包含文档树信息），这个命令就是 tar. 先使用 tar 归档要压缩的多文档，再对生成的 *.tar 使用 上述压缩指令（或者直接使用管道重定向），Linux 下是这样实现多文档压缩的。 而 7z 和 zip，以及 rar 格式，都同时具有了 归档(tar) 和 压缩 两个功能，（也就是该格式包含了文档树信息咯）也就是说它们可以直接压缩多个文档。 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:2:0","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["技术"],"content":"三、各格式使用的算法差别 gzip 成熟的格式，使用的算法基于 DEFLATE。（压缩比适中） 7z 新一代格式，使用的压缩算法可替换，默认是使用的 lzma/lzma2 算法，使用 AES-256 作为加密算法。 xz 同样使用的 lzma/lzma2 算法，不过只能压缩一个文档。（压缩比很高，相对的用时也更多） zip 同样是支持多种算法的压缩格式，默认应该是使用的 DEFLATE 算法。诞生较早，有很多缺陷。（跨平台乱码、容易被破解等） rar 使用 类DEFLATE 的专有算法，使用 AES 加密。(rar5.0 以后使用 AES-256CBC) 不过 zip 被广泛应用在安卓的 apk 格式、java 的 jar、电子书的 epub，还有 github、云硬盘的多文档下载中，原因嘛大概是 zip 很流行，所以不用担心目标平台没解压软件吧。 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:3:0","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["技术"],"content":"四、如何选用压缩方案 tar.gz 在 linux 上最常见，在压缩率和压缩时间上拥有良好的平衡。如果有任何疑惑，就选用它吧，不会错。 tar.xz 是新一代的压缩格式，虽然拥有更好的压缩率，压缩/解压速度相对要慢很多倍。一般在电脑性能足够好的时候，可选用它。 7z 和 xz 同为新一代压缩格式，它更复杂，支持多文档压缩。而且更适合跨平台，推荐使用。 zip 因为跨平台容易导致文档名乱码，不建议使用。（虽然有这样的缺陷，但是却意外的用得很广泛，在前一节有说过） rar 性能不差，但是是商业格式，不开源，不建议使用。（做得比较好的是它的 recovery records，在网络环境不好，容易导致包损坏时，这个功能就特别棒） tar.bz2 算是 linux 压缩历史上，过渡时期的产物，性能也介于 gz 和 xz 之间，一般来说不需要考虑它。 总的来说，就是 Windows 上推荐使用 7z，而 Linux 上 推荐使用 tar.gz tar.xz 7z 之一。此外 rar 的损坏很容易修复，zip 受众多（要注意乱码问题），也可以考虑。 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:4:0","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["技术"],"content":"五、Linux 上的压缩相关指令 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:5:0","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["技术"],"content":"1. tar 指令 通过之前的介绍，可以看出常用的就是 tar gzip xz 等，如果要压缩多个文档，需要先使用tar，再用管道重定向到 gzip 或 xz，比较麻烦，而这几个指令又很常用。于是后来对tar做了增强。 tar 最初只是一个归档进程，而压缩则由其他的压缩软件来完成（一个进程只干一件事）。后来为了方便，丧心病狂地集成了各种压缩指令。因此这里就只介绍这一个命令了（它囊括了所有）。 tar 的选项与参数非常的多！我们只讲几个常用的选项，更多选项您可以自行 man tar 查询啰！ [dmtsai@study ~]$ tar [-z|-j|-J] [cv] [-f 待创建的新档名] filename... \u003c==打包与压缩 [dmtsai@study ~]$ tar [-z|-j|-J] [tv] [-f 既有的 tar档名] \u003c==察看档名 [dmtsai@study ~]$ tar [-z|-j|-J] [xv] [-f 既有的 tar档名] [-C 目录] \u003c==解压缩 选项与参数 -c ：创建打包档案，可搭配 -v 来察看过程中被打包的档名(filename) -t ：察看打包档案的内容含有哪些档名，重点在察看『档名』就是了； -x ：解打包或解压缩的功能，可以搭配 -C (大写) 在特定目录解开 特别留意的是， -c, -t, -x 不可同时出现在一串指令列中。 -z ：透过 gzip 的支持进行压缩/解压缩：此时档名最好为 *.tar.gz -j ：透过 bzip2 的支持进行压缩/解压缩：此时档名最好为 *.tar.bz2 -J ：透过 xz 的支持进行压缩/解压缩：此时档名最好为 *.tar.xz 特别留意， -z, -j, -J 不可以同时出现在一串指令列中 -v ：在压缩/解压缩的过程中，将正在处理的档名显示出来！ -f filename：-f 后面要立刻接要被处理的档名！建议 -f 单独写一个选项啰！(比较不会忘记) -C 目录 ：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 其他后续练习会使用到的选项介绍： -p(小写) ：保留备份资料的原本权限与属性，常用于备份(-c)重要的设定档 -P(大写) ：保留绝对路径，亦即允许备份资料中含有根目录存在之意； –exclude=FILE：在压缩的过程中，不要将 FILE 打包！ 其实最简单的使用 tar 就只要记忆底下的方式即可 压　缩：tar -zcv -f filename.tar.gz \u003c要被压缩的档案或目录名称\u003e 查看文档树：tar -ztv -f filename.tar.gz 解压缩：tar -zxv -f filename.tar.gz -C \u003c欲解压缩的目录\u003e` 上面的命令需要根据压缩格式的不同，选用 -z -j -J 选项，而实际上文档的后缀就已经表明了它的压缩格式，不免让人觉得多余。 因此就有这幺一条通用的压缩/解压 option -a, --auto-compress Use archive suffix to determine the compression program. 使用这个，便有了通用的解压指令： tar -axv -f file.tar.* （它适用于上述三种压缩格式） 仅解压指定的文档 先查看文档树找到需要解压的文档的文档名 tar -zxv -f 打包档.tar.gz 待解开档名 打包某目录，但不含该目录下的某些档案之作法 使用 –exclude=FILE 选项（支持文档名的模式匹配，而且可重复） tar -zcv -f filename.tar.gz directory --exclude=FILE1 --exclude=func* 只打包目录中比指定时刻更新的文档 使用 --newer-mtime=\"2015/06/17\" 选项。 tarfile, tarball tarfile | 纯打包、未压缩的 tar 文档 tarball | 压缩了的 tar 文档 2. zip格式（linux 一般也会自带，详细的请man） 压缩命令：zip 压缩目录：zip -r filename.zip directory r 表示递归压缩，压缩包会包含这个目录 解压命令：unzip 解压到某目录：unzip -d directory filename.zip (-d dir 表示将内容解压到dir目录内) -t 测试压缩档的完整性 -x filename 排除某文档 3. 7z格式（需要p7zip，deepin自带，更多的请man） 查看目录树：7z l file.7z (List contents of archive) 压缩：7z a file.7z file1 directory1 (a 为创建压缩档或向压缩档中添加文档/目录，一次可指定多个要压缩的文档或目录) 解压：7z x file.7z -o directory (解压到指定目录) 测试完整性： 7z t file.7z p7zip 安装好后，会提供 7z、7za、7zr 三个指令，一般来说直接用 7z 就行。 P.S. 7z 不会保存 Linux 文档的用户、用户组信息，因此不能直接用于 Linux 系统备份，此时建议用 tar.xz 或 tar.7z（也就是先用tar打包） 4. rar格式（还是那句话，更多的请man） rar 是非开源的格式，Linux 默认是不会包含 rar 压缩软件的，但是它的解压软件是开源的，deepin 自带 unrar，顺便 7zip 也可解压 rar 文档。 若想用linux创建rar压缩档，需要从rarlab上下载 Linux 版，（deepin源自带）不过要注意的是该 linux 版是 40 天试用版，要长期使用的话，可能需要破解。（rar 的 key 网上一搜一大把） 压缩：rar a file.rar file （这个是试用的） 解压：unrar x file.rar （这个开源免费） 其实我挺中意 rar 的修复功能的，不知道为啥 7z xz 这样的新格式没有添加类似的 recorvery records。上次下个 idea 的 tarball，下了四五次才下到一个完整的，要是用 rar 的话，大概一键修复就好了，可 tar.gz 我不知道怎幺修复，只好一遍遍重复下载。。 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:5:1","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["技术"],"content":"六、参考 档案与档案系统的压缩,打包与备份 维基百科 rar tar gz zip 7z 有什幺区别? - 知乎 为什幺linux的包都是.tar.gz？要解压两次 - 知乎 ","date":"2019-01-14","objectID":"/posts/compression-related-instructions-under-linux/:5:2","tags":["Linux","Compression","压缩","tar"],"title":"常见压缩格式的区别，及 Linux 下的压缩相关指令","uri":"/posts/compression-related-instructions-under-linux/"},{"categories":["随笔"],"content":" 高中考虑志向的时候，我最开始想选择电子信息工程，因为小时候就喜欢摆弄各种电子器件，这个方向硬件软件都能玩，就感觉很有趣，只是担心自己高三太放浪形骸考不上。 偶然想起在学校阅览室读杂志时，曾被科幻世界2013年12期里沖氏武彦的《在回声中重历》给打动——用耳朵“看见”世界实在是太奇妙了，我当时痴痴地幻想了好几天。 这样我开始考虑选择声学。 我从同桌推荐的《刀剑神域》开始接触日本的 ACG 文化，后来接触到初音未来和洛天依，就对歌声合成(singing synthesis)产生了很大的兴趣，仔细一想发现这也应该是声学的范畴，这使我坚定了我选择声学的想法。 从那时到现在的各种破事，实在不想多说，就略过不提了。总之我选择了声学，然后干得很失败。。。 为啥想写这篇文章呢？ 话还得从去年十一月份说起，当时要学 Matlab，就在 bilibili 上找了个教程：自制合成器演奏鸟之诗，讲用 Matlab 做吉他音合成，讲得特别棒，我跟着做出了 guitar-synthesizer 这个小玩意儿。 然后今天发现那个教程的作者就是做歌声合成的，而且从 2011 年 13 岁开始，因为想让初音唱中文，就开始写代码，一写就写到现在，从初中写到留学美国常春藤，从简单的时域拼接到现在的深度神经网络、隐马尔可夫模型。他在上个暑假到雅马哈（vocaloid 的制作公司）实习，并推出了自己第五次重制的歌声合成引擎 Synthesizer V。 这一系列的事迹，七年五次重制，从初中生到现在双修计算机科学和数学，简直让人叹为观止。 这位作者的名字叫华侃如（Kanru Hua），网络常用昵称 sleepwalking，他的个人网站 Kanru Hua’s Website - About Me. 通过他的博客，我了解到歌声合成需要两个方向的知识：信号处理和机器学习。 于是我想起了我的初心。 我小的时候特别喜欢拆各种电子设备，曾经用手机电池和坏手电做过手电筒，再加上个手机振动器用来吓人，还喜欢在家做各种实验。 可整个大学，我的各种手工课实验课弄得一塌糊涂，垫底的存在。这样说来，如果当初选了电子信息工程，可能会混得更差。 信号处理学得一团糟，一直想努力可在这方面总是半途而废。 说到底还是自控力太差，为何我就不能按部就班一回呢？到底是怎么搞的会养成这样的性格，这样的时候会很恨自己窝囊的性格。 如果我也能像室友一样按部就班的完成学业，只在空闲时间做自己的事…可惜没有如果。 经常会告诉自己做过的事已经不可逆转了，不需要后悔，所以也不会后悔。大概潜意识里还是会有怨念，所以才会在这样的时刻爆发出满满的恶意。 只是后悔却不做出改变是没有用的，但我完全不相信自己能改掉这样的性格，自暴自弃。纵欲一时爽，一直纵欲一直爽hhh… 说虽这样说，还是想继续挣扎下去，信号处理就像一道槛，不跨过去我无法面对自己。 “希望明年年底的总结中，我不要再这么丧”，这样大声说出来的话，言就能“灵”吧？我记得我运气一直挺好的（又窝囊到要靠运气。。） 更新： 今天二书介绍给我一篇文章我的编程经历，作者和我一样“不能兼顾兴趣与学业”，大一结束就退学了，现在在阿里巴巴工作。 他博客的观点很中肯： 我家人都是很传统的一代，不理解我学习编程最终能做出什么，他们主张先完成学业，再做这件事。但是我很清楚我自己的智商，不足以多线程处理不同的大领域，所以我顶着压力，努力地做出来他们能看出来的「成绩」，才能换来他们的理解。所以，如果你通过你的理性分析，坚持认为某件事情是对的，就努力的去做，不要放弃了以后看到另一个人做了你曾经想做的东西然后感慨当初应该怎么样怎么样。 –我的编程经历 只有在已经拥有解决问题的能力的时候，才有资格考虑退学这件事。 –你根本用不着退学 我仔细想了想，我不需要太在意自己“不能兼顾”、“自控力太弱”。如果真考虑清楚了得失，我只需要“拥有解决问题的能力”，然后去做我想做的就行了。 我自控力很弱，而且这么多年了一直改不了，即使再延期一年，也有可能还是拿不到毕业证，折磨自己而已。 而上班的话，就暑假实习的经验来看，工作都有进度条催着，反而活的更有朝气。 ","date":"2019-01-08","objectID":"/posts/relive-in-the-echo/:0:0","tags":["闲言碎语","初心","歌声合成"],"title":"在回声中重历","uri":"/posts/relive-in-the-echo/"},{"categories":["技术"],"content":" 本笔记整理自《SQL 基础教程》、《MySQL 必知必会》和网上资料。个人笔记不保证正确。 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:0:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"一、复杂查询 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:1:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"视图 将 SELECT 查询包装成一个虚拟表，该虚拟表就被称为视图。（因为只是一个包装，因此视图的数据也会随着原表的更新而更新） 用途： 简化复杂的SQL查询，用它替换子查询，能降低查询的嵌套深度。 SELECT 查询的重用，减少重复查询。 … 创建视图： CREATEVIEW\u003c视图名称\u003e(\u003c视图列名1\u003e,\u003c视图列名2\u003e...)AS\u003cSELECT语句\u003e; 其中 SELECT 的结果列和视图列名一一对应。 3. 视图的限制 1. 视图的 SELECT 子句，不能包含 ORDER BY 子句。因为视图也是表，而表是集合，它没有顺序。（也有些DB支持该用法，但不通用） 1. 视图的更新：只在很有限的条件下，才能在视图上使用 INSERT/DELETE/UPDATE 这样的变更数据的语句。（视图应该只用于检索，能不更新就不要更新它） 4. 删除视图：DROP VIEW \u003c视图名称\u003e; ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:1:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"子查询 子查询，其实就是一次性的视图: SELECT...FROM(SELECT...-- 这就是一个子查询：嵌套的 select 语句 )AS\u003c别名\u003e... 上面的查询的 FROM 子句中，给另一 SELECT 子句定义了一个别名，并将它作为了查询对象。这就是一个子查询。 子查询不仅能用于 FROM，还能用在 WHERE 子句等很多地方。 关联子查询 即用到了外部数据的子查询语句： SELECT...FROMproductASp1WHERE(SELECT...FROMduckASp2WHEREp1.price\u003ep2.price-- 这里，内部子查询访问了外部查询的表p1，因此是一个关联子查询。 ); ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:1:2","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"二、函数、谓词、CASE 表达式 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:2:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"函数 给出的链接都是 MySQL 的 算术函数 加减乘除：+ - * / ABS 绝对值 MOD 求余 ROUND 四舍五入 字符串函数 CONCAT(str1,str2,…) 拼接 LENGTH(str) 字符串的 bytes 长度 CHAR_LENGTH(str) LOWER/UPPER 大小写转换 REPLACE(str,from_str,to_str) 替换 SUBSTRING(str FROM pos FOR len) 截取 时间和日期函数 CURRENT_DATE 当前日期 CURRENT_TIME 当前时间 CURRENT_TIMESTAMP 当前的日期和时间 EXTRACT(unit FROM date) 截取日期元素，unit 可为 YEAR MONTH HOUR 等等 转换函数 CAST(expr AS type) 将 expr 的结果转换成 type 类型 COALESCE(value,…) 从左往右扫描，返回第一个非 NULL 的值。常用于将 NULL 转换为其他值。eg. COALESCE(sth, 1) 如果 sth 为 NULL 就会返回1. 聚合函数：基本就五个，已经学过了。 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:2:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"谓词 即返回布尔值的表达式 LIKE谓词——简单字符串匹配（慢） 匹配整个列 %：任意字符出现任意次 _：匹配任意一个字符 举例： SELECTnameFROMlistWHEREnameLIKE'%Ryan%';-- 匹配任意包含 'Ryan' 的字符串 REGEXP谓词——正则字符串匹配 MySQL 只实现了通用正则的一个子集，而且是search模式。（非match） 其他 BETWEEN：范围匹配，eg. BETWEEN 1 AND 10 IS NULL、IS NOT NULL IN、NOT IN：是否在某集合内 EXISTS、NOT EXISTS（比较难的一个，入门阶段不要求）：该谓词比较特殊，只需要右侧一个参数，**而且该参数绝大多数情况下，都是一个关联子查询。**而且该子查询的SELECT子句的参数基本可以随意，通常使用SELECT *. 对于子查询有返回值的列，它返回True，否则返回False. 但要注意为 NULL 时返回 UNKNOW.（而 WHERE 只认 True） ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:2:2","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"CASE 表达式 if - else if - else 形式： CASEWHEN\u003c求值表达式\u003eTHEN\u003c表达式\u003eWHEN\u003c求值表达式\u003eTHEN\u003c表达式\u003eWHEN\u003c求值表达式\u003eTHEN\u003c表达式\u003e...ELSE\u003c表达式\u003eEND switch 模式（但不需要break） CASE\u003c表达式\u003eWHEN\u003c表达式\u003eTHEN\u003c表达式\u003eWHEN\u003c表达式\u003eTHEN\u003c表达式\u003e...ELSE\u003c表达式\u003eEND 这是对 CASE 后的元素做switch比较。 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:2:3","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"三、集合运算 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:3:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"注意事项 作为运算对象的结果集，列字段必须一一对应，而且对应列的类型必须相同。 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:3:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"结果集的交并差 \u003c查询1\u003e UNION \u003c查询2\u003e：对两个结果集求并 UNION ALL：添加 ALL 能使结果集包含重复行。 \u003c查询1\u003e INTERSECT \u003c查询2\u003e：两结果集的交集 \u003c查询1\u003e EXCEPT \u003c查询2\u003e：两结果集的差集 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:3:2","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"以列为单位，对表进行联结(JOIN) 最强大的功能之一 交并差是以行为单位的操作，是竖向的运算。而联结是以列为单位的操作，是横向的拼接。 内联(INNER JOIN) 内联结果只包含两表的交集 语法： SELECT...FROM(productINNERJOINshopONproduct.p_id=shop.p_id)WHEREfilter_condition; 使用 跟在 INNER JOIN 子句后的 ON 子句指定联结条件。（这里我特意用了括号，表示 JOIN 和 ON 两个子句是配套的） 也有另一个很常用的语法（但是现在已经不推荐使用）： SELECT...FROMproduct,shopWHEREproduct.p_id=shop.p_idANDfilter_condition; 对于 shop 表中有多行对应同一个 product 的情况（有多人购买了同一款商品），结果中该 product 会被复制给 shop 中的多个购买记录。（也就是说该 product 会变成多行） INNER 可以省略，也就是说只写 JOIN，就默认是 INNER JOIN 外联(OUTER JOIN) **外联以某表为主表，将另一表的列联结到该表。**另一表没有值的列，就用 NULL 代替。使用LEFT 或 RIGHT指定主表。（两个关键字都能实现同样的效果，不过用 LEFT 的多一些） 语法： SELECT...FROMproductLEFTOUTERJOINshopONproduct.p_id=shop.p_id; 这和内联很相似，差别只是联结关键词改成了LEFT OUTER JOIN。这表示以左边的表为主表，把右边的表的内容联结上去。因此左表的所有列都会出现在结果集中。 多表联查举例： -- 登录异常的账号及密码 selectdistinctbatches.identity_numberas'登录失败账号',accounts.passwordfrom((batchesleftouterjointasksonbatches.id=tasks.batch_id)-- 批次表联结具体的任务表 leftouterjoin`status`ontasks.id=status.task_id)-- 再联结上状态表 leftouterjoinaccountsonbatches.identity_number=accounts.identity_number-- 再联结上账号表 where`status`.step_type='check_login'-- 只提取 \"check_login\" 步骤的记录 andstatus.status!='info'-- 状态不为 info，说明登录异常 此外还有 FULL OUTER JOIN 表示返回左右两表的所有行！所有没有匹配的行都给出 NULL P.S. 其中的关键字 OUTER 通常可省略。但是 LEFT、RIGHT、FULL 不可以省略。 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:3:3","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"画外：字段引用符号 如果数据库的字段名/数据库名/表名可能和数据库关键字重复，就需要用引用符号将他们引用起来，消除歧义。 MySQL 中经常用反引号干这个事。 而 SQL Server 则使用方括号。 标准 SQL 使用双引号。在看到这些符号时要知道这些差别。 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:4:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"查询语句分析 MySQL Explain详解 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:5:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"常见问题 ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:6:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":"隐式类型转换 在MySQL中，当操作符与不同类型的操作数一起使用时，会发生类型转换以使操作数兼容。则会发生隐式类型转换。 隐式类型转换会导致查询不会走索引！！！可能会严重拖累性能。另外还可能会导致各种奇怪的问题。 详见 MYSQL隐式类型转换 完。（接下来就是用 Python/Java 连接 MySQL 了） ","date":"2018-06-17","objectID":"/posts/sql-basics-2-queries/:6:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（二）进阶查询","uri":"/posts/sql-basics-2-queries/"},{"categories":["技术"],"content":" 本笔记整理自《SQL 基础教程》、《MySQL 必知必会》和网上资料。个人笔记不保证正确。 ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:0:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"一、基础 SQL，即结构化查询语言，是为访问与操作关系数据库中的数据而设计的语言。 关系数据库以行(row)为单位读写数据 SQL 根据功能的不同，可分为三类（其中DML用得最多，增删查改嘛） DDL(Data Definition Language, 数据定义语言): CREATE/DROP/ALTER DML(Data Manipulation Language, 数据操作语言): SELECT/INSERT/UPDATE/DELETE DCL(Data Control Language, 数据控制语言): COMMIT/ROLLBACK/GRANT/REVOKE SQL 语句要以分号结尾。换行在 SQL 中不表示结束，而等同于空格。 SQL 不区分**关键字(Keyword)**的大小写，但是描述符就不一定了。 这里有个坑：MySQL 中，数据库和表其实就是数据目录下的目录和文件，因而，操作系统的敏感性决定数据库名和表名 是否大小写敏感。这就意味着数据库名和表名在 Windows 中是大小写不敏感的，而在大多数类型的 Unix/Linux 系统中是大小写敏感的。（注意仅指数据库名和表名）可通过修改配置文件的lower_case_table_names属性来统一这一行为。 而字段名、字段内容都是内部数据，是操作系统无关的。它们的大小写敏感性，由 MySQL 的的校对（COLLATE）规则来控制。该规则体现在 MySQL 的 校对字符集（COLLATION）的后缀上：比如 utf8字符集，utf8_general_ci表示不区分大小写，这个是 utf8 字符集默认的校对规则；utf8_general_cs 表示区分大小写，utf8_bin 表示二进制比较，同样也区分大小写 。 SQL 中的字符串和日期需要用单引号引用起来，日期有特定格式年-月-日 修改字符集：set names \u003c字符集名\u003e 记住在 MySQL 中，utf-8mb4 才是完全的 utf-8字符集。 ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:1:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"二、DDL ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:2:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"1. 数据库的创建和删除 创建数据库 CREATEDATABASE\u003c数据库名称\u003e; DROPDATABASE\u003c数据库名称\u003e; ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:2:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"2. 创建表： 关系表的设计 关系表的设计，要确保把信息分解成多个表，一类信息一个表，各表通过某些常用的，基本不会改变的值（即关系表设计中的关系，也常称为外键）互相关联。尽量不要有冗余数据。 语句： CREATETABLE\u003c表名\u003e(\u003c列名1\u003e\u003c数据类型\u003e\u003c该列所需约束\u003e,\u003c列名2\u003e\u003c数据类型\u003e\u003c该列所需约束\u003e,\u003c列名3\u003e\u003c数据类型\u003e\u003c该列所需约束\u003e,...\u003c该表的约束1\u003e,\u003c该表的约束2\u003e...); 举例： CREATETABLE`persons`(`id`INTUNSIGNEDNOTNULLAUTO_INCREMENT,`name`CHAR(20)NOTNULL,PRIMARYKEY(`id`))ENGINE=InnoDBDEFAULTCHARSET=utf8mb4; 后面的是设置引擎和默认字符集。工作上，表的设计一定要深思熟虑，因为改起来很困难。 字段类型（MySQL） 有四类数据类型：字符串、数字、日期、二进制。它们又根据数据长度的区别，下分为多个类型。 字符串： 数字 日期 二进制 约束 SQL 约束是除了数据类型之外，对列中数据追加的限定条件。 类型约束：NOT NULL、AUTO_INCREMENT、UNSIGNED（这个只 MySQL 支持） 默认值：DEFAULT，举例 \u003c列名3\u003e VARCHAR(32) NOT NULL DEFAULT \"los angeles\" 表约束：PRIMARY KEY 主键约束（主键默认 UNIQUE 且 NOT NULL） 此外还有 FOREIGN KEY 和 CHECK 两个约束语句，在进阶笔记中介绍。 P.S. 字段约束也可以写成表约束（比如主键约束），而反过来很可能不行。 ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:2:2","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"3. 删除表和更新表定义 删除表（危险操作） 删除整个表： DROPTABLE\u003c表名\u003e; - 只清空表内数据，但留下表： TRUNCATE\u003c表名\u003e;-- 非标准SQL语句，但是大部分DB都支持。（可能不能ROLLBACK） 更新表定义（麻烦的操作） 所以所创建表前要仔细想好格式了，更新表定义是不得已才能为之。 添加列定义： ALTERTABLE\u003c表名\u003eADDCOLUMN\u003c列名\u003e\u003c数据类型\u003e\u003c该列的约束\u003e; 删除列定义： ALTERTABLE\u003c表名\u003eDROPCOLUMN\u003c列名\u003e; ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:2:3","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"三、DML 万恶之源 NULL ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:3:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"1. 查询（重点） 基本语句： SELECT \u003c字段1\u003e AS \u003c别名1\u003e, \u003c字段2\u003e AS \u003c别名2\u003e, ... FROM \u003c表名\u003e WHERE \u003c过滤条件\u003e; 可用 DISTINCT 修饰列名，使查询结果无重。例：SELECT DISTINCT \u003c列名\u003e FROM \u003c表名\u003e 过滤条件可使用比较运算(\u003c\u003e、=等)和逻辑运算(AND OR NOT). 过滤条件中，比较运算会永远忽略 NULL 值，如果需要对 NULL 值做操作，需要使用 IS NULL 或 IS NOT NULL（说忽略也许不太准确，NULL 既不为真也不为假，反正少用NULL。。） 包含NULL的四则运算，得到的结果总为NULL ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:3:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"2. 聚合与排序（重点） 聚合函数 即对列进行统计分析的函数，主要有五个： COUNT：计算列的行数。（只有COUNT(*)会计算NULL行） SUM：求该列之和。 AVG：求该列的平均值。 MAX/MIN：求该列的 最大/最小 值 NOTE： 聚合函数计算时会排除所有NULL行。只有COUNT(*)例外，NULL行也会被它计数。 MAX/MIN 几乎适用于所有数据类型的列（对非数值型，以其二进制值来排序），而SUM/AVG只能用于数值类型的列。 聚合函数操作的列，也能用DISTINCT修饰。例：SELECT COUNT(DISTINCT \u003c列名\u003e) FROM \u003c表名\u003e 聚合函数只能用于SELECT子句和还没讲的HAVING子句（以及 ORDER BY 子句）中。 分组(GROUP BY) 分组以聚合键为分类标准，将数据分为多个逻辑组，从而能分别对每个组进行聚合运算。（分组是为了分类聚合） 若出现了 GROUP BY 子句，查询结果一定是每一组一行。 GROUP BY 会将 NULL 作为一组特定数据，显示为空。 聚合对SELECT子句的限制 首先要理解的是： 聚合函数的操作对象为某一列，而产生的结果只有一个值。 GROUP BY 的操作对象为一列或者多列，产生的结果呢，是每一组一个值。 因此为了避免歧义，只要使用了聚合函数或 GROUP BY 二者之一，SELECT 子句就只能包含： 常数 其他聚合函数（该聚合函数的操作对象可以为其他列） 如果使用了 GROUP BY 子句，还能包括该子句所指定的列名。（也就是聚合键）但是绝不能包含其他的列名，因为这会有歧义。 此外，还有一个问题是由 SQL 的执行顺序引起的。应该能很容易猜到，SELECT 语句的执行顺序和书写顺序是不一致的。 查询应该是从表开始，所以 FROM 语句一定先执行。然后应该要过滤(WHERE)，再是分组(GROUP BY)，最后才是 SELECT 语句。（就已经学到的子句而言，顺序是这样） 因此按理说，SELECT 语句 定义的别名，是不能在 GROUP BY 里使用的。（也有些DB支持该用法，但不通用） 对聚合结果进行过滤(HAVING) 从刚刚说过的SQL执行顺序可见，WHERE要比GROUP BY先执行，因此如果想过滤分组后的结果，不能用它。而应该使用 HAVING 子句。 HAVING 子句和 WHERE 子句都是用来过滤的，但是执行顺序的不同也就决定了它们的用途不同。 NOTE： 有时候，会发现某个过滤条件，不论是先执行（就是写在WHERE子句中）还是后执行（写在HAVING中）都没问题，这时候应该将它写在WHERE子句中，这样GROUP BY操作的数据会更少，处理更快。 HAVING 子句的元素，也存在和 SELECT 子句同样的限制。不能使用聚合键以外的列名。 排序(ORDER BY) ORDER BY 子句在 SELECT 子句之后执行，因此它能使用 SELECT 子句中定义的别名。（而 GROUP BY 之前已经说过不能用别名了） 格式： SELECT\u003c字段1\u003eAS\u003c别名1\u003e,\u003c字段2\u003eAS\u003c别名2\u003e,...FROM\u003c表名\u003eWHERE\u003c过滤条件1\u003eGROUPBY\u003c列名1\u003e,\u003c列名2\u003e...HAVING\u003c过滤条件2\u003eORDERBY\u003c列名/别名1\u003e,\u003c列名/别名2\u003e...; 多排序键/列：指定多排序键时的排序规则为：优先使用左侧的列，如果该列存在相同值，再接着参考右侧的键，依此类推。（如果左侧键值不同，右侧的键就不会被使用了） NULL 值的顺序：排序键中出现了 NULL 值时，这类值会在结果的开头或结尾汇总，究竟是排在开头还是结尾，并没有特殊规定。 ORDER BY 子句只影响结果的先后顺序，因此排序键可以是结果集以外的东西，比如其他的列，或者使用了 GROUP BY 时，还能用聚合函数。 ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:3:2","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"3. 数据的增、删、改 插入(INSERT INTO) 也算用的多了 语法： INSERTINTO\u003c表名\u003e(列名1,列名2...)VALUES(值1,值2...); 或者也可以使用 SELECT 语句来替代 VALUES 子句，达到将 SELECT 到的结果集插入某表的效果。（但是不要用ORDER BY，因为结果是集，没有顺序，排序是徒劳无功的） 插入时主键不能重复，否则会报错。（因此如果需要包含重复数据，一般都会定义一个自增的id字段） 删除(DELETE) 清空表（危险操作，而且效率不如 TRUNCATE）： DELETEFROM\u003c表名\u003e; 条件删除： DELETEFROM\u003c表名\u003eWHERE\u003c条件\u003e; 因此使用DELETE时，一定要记得带WHERE，不然就好玩了。。 更新(UPDATE) UPDATE\u003c表名\u003eSET\u003c列名1\u003e=\u003c算术表达式1\u003e,\u003c列名2\u003e=\u003c表达式2\u003e,...WHERE\u003c条件\u003e; 同 DELETE 一样，不带 WHERE 子句的 UPDATE 是很危险的。 ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:3:3","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"四、DCL - 事务处理(MySQL) 事务是一系列不可分割的数据库操作，也就是说，这一系列操作要么全部执行，要么全部不执行。如果执行过程中发生了问题（检查执行状态），可以通过执行 ROLLBACK 回滚到该事务执行前的状态。（注意并不会自动回滚） STARTTRANSACTION;-- do somthing COMMIT; START TRANSACTION: 标识事务的开始 COMMIT：提交事务。一旦提交，所执行过的操作就已成定论，恢复不了了。 ROLLBACK：事务回滚，**只能回滚未 COMMIT 的 DML 操作！**也就是说只能用在 START TRANSACTION 和 COMMIT 之间，并且只能回滚 INSERT/UPDATE/DELETE。（回滚 SELECT 没啥意义） SAVEPOINT \u003c保留点\u003e 和 ROLLBACK TO \u003c保留点\u003e：同样只能用在 START TRANSACTION 和 COMMIT 之间，其优势在于，ROLLBACK TO 可以指定回滚到某特定保留点，更灵活，而 ROLLBACK 只能回滚到事务开始前。 需要注意的有： COMMIT 和 ROLLBACK 语句也是事务的结束，因此如果执行了 ROLLBACK，那它与 COMMIT 之间的内容会被跳过。（在这一点上，它相当于大多数 PL 的 return） 如果事务执行出现问题，问题行后面的所有语句都不会被执行！包括 COMMIT 和 ROLLBACK！ 如果想用纯 SQL 实现事务原子性，必须使用存储过程检查执行状态！举例如下： CREATE PROCEDURE my_test() BEGIN DECLARE EXIT HANDLER FOR SQLEXCEPTION ROLLBACK -- 检测到 SQLEXCEPTION 则 rollback，然后 exit START TRANSACTION INSERT INTO table_test VALUES(1, 'A') INSERT INTO table_test VALUES(1, 'B') -- 这里主键冲突，会触发 SQLEXCEPTION COMMIT END CALL my_test() 或者在 PL 中通过异常处理执行 ROLLBACK。（事务虽然中止了，但并未结束！所以仍然可以 ROLLBACK 或者 COMMIT） ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:4:0","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["技术"],"content":"数据何时被提交到数据库 显式提交：在事务中使用 COMMIT 提交数据操作被称为显式提交 隐式提交：非 DML 操作会被立即提交，也就是说这些语句本身就隐含了提交语义 自动提交： 如果 AUTOCOMMIT 被设置为 ON，当前 session 中的 DML 语句会在执行后被自动提交（START TRANSACTION 内部的 DML 除外，在它内部必须显式 COMMIT） 所有的 DML 语句都是要显式提交的，MySQL session 的 AUTOCOMMIT 默认为 ON，所以 DML 会被自动提交。 P.S. 许多语言的数据库 API 会定义自己的事务操作，不一定与这里一致。 ","date":"2018-06-15","objectID":"/posts/sql-basics-1/:4:1","tags":["SQL","数据库","Database"],"title":"SQL 基础笔记（一）","uri":"/posts/sql-basics-1/"},{"categories":["随笔"],"content":"对我而言，学英语是一件挺痛苦的事。从初中开始学英文，可从来不觉得它有趣，主动性也就不强。 直到我开始学计算机，我开始认识到英文是不可避免的。于是尝试了很多方法。 最普遍的方式：背单词，可我从初中背到现在，背单词的计划从没哪次坚持超过一个月的。 后来听说看英文原版书有效，信心满满，结果也是看了一星期 Harry Potter，稍微看了点 Animal Farm，就没后续了。 又想练听力，开始听 ESLPod、EnglishPod，也就听了一个月的时间。。 练口语，听完了《赖世雄美语音标》，又看了点美国的口语纠正视频。这件事干得倒还算可以，口语的确标准了不少。不过也就花了十多天，就没然后了。 我学计算机的过程，和我的英文学习过程也有不少重合的地方。 印象中第一次读英文资料，是想学计算机图形学，被知乎上的高手们推荐看一个英文教程。死嗑了三天，坚持不下去放弃了。。 之后听了季索清学长的推荐，又见知乎上也都说 Python 好，就开始学 Python。看了 A Byte of Python, 印象中花了一天看完的，但是没在脑子里留下啥印象。 后来慢慢的开始熟悉 Python，在图书馆借了 Head First Python 英文版，可能是被厚度吓到了，看了几页就不了了之了。。 再后来用 Github，Pycharm IDEA 也是英文的，Python doc 和 Java doc 也全是英文的，标准库里的注释是英文的，Error 信息是英文的…… 虽然学啥都半途而废，但英文水平的确是慢慢地提升着。 慢慢地，能够不怎么吃力地看懂 Python 标准库了，有问题也可以看英文博客解决了。 最近看一个动漫看完不过瘾，转去看这部动漫的轻小说。轻小说中文翻译的太呆板，发现居然有英文的，直接啃起了英文。 换了好几部小说，现在在看 Grimgar of Fantasy and Ash、Tasogare-iro no Uta Tsukai(黄昏色の詠使い)，还找了个英文动漫网站，颇有以后看动漫也只看英文字幕的打算。希望能持续下去吧。 不过也有点苦恼，因为暑假就要找工作，现在却沉迷看英文小说。。本来这个月该学算法的，可半个月都过了，我的进度大概才认真的时候的五天的样子。。真不知道未来会是啥样。 ","date":"2018-05-16","objectID":"/posts/learning-english/:0:0","tags":["英语","语言学习"],"title":"学英语啊学英语","uri":"/posts/learning-english/"},{"categories":["书藉","影视","随笔"],"content":"看完了动画，也看了点小说。最敬佩、最喜欢、最向往的人物是珠晶，也就是供王。能感觉得到她是所有角色中，最自信、方向最明确的，而且她思考一直比较理性。身为富商之女，年仅十二，却能拥有超出所有国民的觉悟，“既然大人们没有勇气，那就由我去当王！”，并最终称王，不得不敬佩。她有句让人难以忘却的台词，“我之所以能过着比别人更好的生活，是因为我担负了相比更沉重的责任。如果没能完成相应的使命，我就会像峰王一样被砍掉脑袋。而祥琼没有认识到这一点，她不想担负责任，却觉得自己应该享受荣华富贵。” 其次就是“专职心理治疗”的乐俊小老鼠了，我简直有点怀疑存不存在这样可敬的老鼠(废话)。乐俊成熟得不适合当主角，几乎无可挑剔，大概也因此而戏份不多。 而花了大篇幅描写的庆东国的景王，还有一路走来的祥琼和铃、更夜还有泰麒，他们一度迷失掉了自我，虽然作为结果的他们实现了自我救赎，但是这个过程我喜欢不起来。大概因为我也是个偏激的人吧…… 珠晶遇到了顽丘，景王和祥琼被乐俊救赎，铃也有自己的贵人，更夜在斡由被杀时终于承认了自己的错误，泰麒也是被麒麟们合力救回来的。 谁都不可能只活在自己的世界，就能得到救赎。(这样就又得到了一个和刺猬的优雅类似的结论…) ","date":"2018-04-27","objectID":"/posts/the-twelve-kingdoms/:0:0","tags":["读后感","观后感","动漫"],"title":"《十二国记》","uri":"/posts/the-twelve-kingdoms/"},{"categories":["技术"],"content":"一、charAt 与 codePonitAt 我们知道 Java 内部使用的是 utf-16 作为它的 char、String 的字符编码方式，这里我们叫它内部字符集。而 utf-16 是变长编码，一个字符的编码被称为一个 code point，它可能是 16 位 —— 一个 code unit，也可能是 32 位 —— 两个 code unit。 Java 的 char 类型长度为二字节，它对应的是 code unit。换句话说，一个字符的编码，可能需要用两个 char 来存储。 作为一个输入法爱好者，我偶尔会编程处理一些生僻字。其中有些生僻字大概是后来才加入 unicode 字符集里的，直接用 charAt 方法读取它们，会得到一堆问号。原因很清楚 —— 因为这些字符（eg. “𫖯”）是用两个 code unit，也就是两个 char 表示的。charAt 找不到对应的编码，就会将这些 char 输出成「?」。 //示例 public class Test { public static void main(String[] args){ String s = \"𫖯\"; System.out.println(s.length()); //输出：2 System.out.println(s.charAt(0)); //输出：? System.out.println(s.charAt(1)); //输出：? } } 因此，涉及到中文，一定要使用 String 而不是 char，并且使用 codePoint 相关方法来处理它。否则的话，如果用户使用了生僻字，很可能就会得到不想要的结果。 下面是一个使用 codePoint 遍历一个字符串的示例，需要注意的是，codePoint 是 int 类型的（因为 char 不足以保存一个 codepoint），因此需要做些额外的转换： public class Test { public static void main(String[] args){ String s = \"赵孟𫖯孟\"; for (int i = 0; i \u003c s.codePointCount(0,s.length()); i++) { System.out.println( new String(Character.toChars(s.codePointAt(i)))); // 这里的轨迹是：类型为 int 的 codepoint -\u003e char数组 -\u003e String } } } /* 结果： 赵 孟 𫖯 ? */ 问题来了，「𫖯」这个字是正常地输出了，可最后的「孟」却变成了黑人问号。。 原因就在于 codepointAt(i) 是以 char 偏移量索引的。。所以只是这样输出也是不行的。。 正确的遍历姿势是这样的 final int length = s.length(); for (int offset = 0; offset \u003c length; ) { final int codepoint = s.codePointAt(offset); System.out.println(new String(Character.toChars(codepoint))); offset += Character.charCount(codepoint); } 这个代码保持了一个变量offset, 来指示下一个 codepoint 的偏移量。最后那一句在处理完毕后，更新这个偏移量 而 Java 8 添加了 CharSequence#codePoints， 该方法返回一个 IntStream，该流包含所有的 codepoint。可以直接通过 forEach 方法来遍历他。 string.codePoints().forEach( c -\u003e System.out.println(new String(Character.toChars(c))); ); 或者用循环 for(int c : string.codePoints().toArray()){ System.out.println(new String(Character.toChars(c))); } ","date":"2018-03-11","objectID":"/posts/how-java-handles-chinese/:0:1","tags":["Java","字符集","字符编码"],"title":"Java 中文编码分析","uri":"/posts/how-java-handles-chinese/"},{"categories":["技术"],"content":"二、内部字符集与输出字符集（内码与外码） 现在我们知道了中文字符在 java 内部可能会保存成两个 char，可还有个问题：如果我把一个字符输出到某个流，它还会是两个 char，也就是 4 字节么？ 回想一下，Java io 有字符流，字符流使用 jvm 默认的字符集输出，而若要指定字符集，可使用转换流。 因此，一个中文字符，在内部是使用 utf-16 表示，可输出就不一定了。 来看个示例： import java.io.UnsupportedEncodingException; public class Test { public static void main(String[] args) throws UnsupportedEncodingException { String s = \"中\"; //𫖯 System.out.println(s + \": chars: \" + s.length()); System.out.println(s + \": utf-8 bytes:\" + s.getBytes(\"utf-8\").length); System.out.println(s + \": unicode bytes: \" + s.getBytes(\"unicode\").length); System.out.println(s + \": utf-16 bytes: \" + s.getBytes(\"utf-16\").length); } } 输出为： 中: chars: 1 // 2 bytes 中: utf-8 bytes:3 中: unicode bytes: 4 中: utf-16 bytes: 4 𫖯: chars: 2 // 4 bytes 𫖯: utf-8 bytes:4 𫖯: unicode bytes: 6 𫖯: utf-16 bytes: 6 一个「中」字，内部存储只用了一个 char，也就是 2 个字节。可转换成 utf-8 编码后，却用了 3 个字节。怎么会不一样呢，是不是程序出了问题？ 当然不是程序的问题，这是内码(utf-16)转换成外码(utf-8)，字符集发生了改变，所使用的字节数自然也可能会改变。（尤其这俩字符集还都是变长编码） ","date":"2018-03-11","objectID":"/posts/how-java-handles-chinese/:0:2","tags":["Java","字符集","字符编码"],"title":"Java 中文编码分析","uri":"/posts/how-java-handles-chinese/"},{"categories":["技术"],"content":"三、utf-16、utf-16le、utf-16be、bom 不知道在刚刚的示例中，你有没有发现问题：同是 utf-16，为何「中」和「𫖯」的 s.getBytes(\"utf-16\").length 比 s.length 要多个 2？开头就说了 String 也是 utf-16 编码的，这两个数应该相等才对不是吗？ 原因在于，utf-16 以 16 位为单位表示数据，而计算机是以字节为基本单位来存储/读取数据的。因此一个 utf-16 的 code unit 会被存储为两个字节，需要明确指明这两个字节的先后顺序，计算机才能正确地找出它对应的字符。而 utf-16 本身并没有指定这些，所以它会在字符串开头插入一个两字节的数据，来存储这些信息（大端还是小端）。这两个字节被称为BOM（Byte Order Mark）。刚刚发现的多出的两字节就是这么来的。 如果你指定编码为 utf-16le 或 utf-16be，就不会有这个 BOM 的存在了。这时就需要你自己记住该文件的大小端。。 ","date":"2018-03-11","objectID":"/posts/how-java-handles-chinese/:0:3","tags":["Java","字符集","字符编码"],"title":"Java 中文编码分析","uri":"/posts/how-java-handles-chinese/"},{"categories":["技术"],"content":"四、更多：utf-8 unicode 在 windows 中，utf-8 格式的文件也可能会带有 BOM，但 utf-8 的基本单位本来就是一个字节，因此它不需要 BOM 来表示 所谓大小端。这个 BOM 一般是用来表示该文件是一个 utf-8 文件。不过 linux 系统则对这种带 BOM 的文件不太友好。不般不建议加。。（虽如此说，上面的测试中，utf-8 的数据应该是没加 bom 的结果） unicode字符集UCS（Unicode Character Set） 就是一张包含全世界所有文字的一个编码表，但是 UCS 太占内存了，所以实际使用基本都是使用它的其他变体。一般来说，指定字符集时使用的 unicode 基本等同于 utf-16.（所以你会发现第二节演示的小程序里，utf-16 和 unicode 得出的结果是一样的。） ","date":"2018-03-11","objectID":"/posts/how-java-handles-chinese/:0:4","tags":["Java","字符集","字符编码"],"title":"Java 中文编码分析","uri":"/posts/how-java-handles-chinese/"},{"categories":["技术"],"content":"四、与 Python3 对比 python3 在字符串表示上，做了大刀阔斧的改革，python3 的 len(str) 得到的就是 unicode 字符数，因此程序员完全不需要去考虑字符的底层表示的问题。（实际上其内部表示也可能随着更新而变化）带 BOM 的 utf-8 也可通过指定字符集为 utf-8-sig 解决。若需要做字符集层面处理，需要 encode 为特定字符集的 byte 类型。 Encoding pertains mostly to files and transfers. Once loaded into a Python string, text in memory has no notion of an “encoding,” and is simply a sequence of Unicode characters (a.k.a. code points) stored generically. – Learning Python 5th P.S. Python2 存在和 Java 相同的问题 ","date":"2018-03-11","objectID":"/posts/how-java-handles-chinese/:0:5","tags":["Java","字符集","字符编码"],"title":"Java 中文编码分析","uri":"/posts/how-java-handles-chinese/"},{"categories":["技术"],"content":"参考 java 语言中的一个字符占几个字节？ - RednaxelaFX - 知乎 How can I iterate through the unicode codepoints of a Java String? 彻底搞懂字符编码(unicode,mbcs,utf-8,utf-16,utf-32,big endian,little endian…) Java_字符编码 本文允许转载，但要求附上源链接：Java 中文编码分析 ","date":"2018-03-11","objectID":"/posts/how-java-handles-chinese/:0:6","tags":["Java","字符集","字符编码"],"title":"Java 中文编码分析","uri":"/posts/how-java-handles-chinese/"},{"categories":["技术"],"content":" 个人笔记，不保证正确。 ","date":"2018-01-23","objectID":"/posts/process-thread-coroutines-concurrency-parallelism/:0:0","tags":["进程","线程","协程","并发","并行","Coroutines","Concurrency"],"title":"进程线程协程与并发并行","uri":"/posts/process-thread-coroutines-concurrency-parallelism/"},{"categories":["技术"],"content":"一、进程 Process：（并行运算，分布式） 每一个进程，都可以看作是一个完整的 Program，它有自己完全独立的内容。不与其他进程直接共享数据。（一个工作(job)可以由多个 process 完成，例如电脑上的qq/360就会有好几个进程，这种程序可能会有一个守护进程，当主进程挂掉，它会自动重启主进程。） 每个进程可以由多个线程组成。进程抽象由操作系统提供，Linux 是使用 fork 函数，Windows 是用 CreateProccess。 ","date":"2018-01-23","objectID":"/posts/process-thread-coroutines-concurrency-parallelism/:0:1","tags":["进程","线程","协程","并发","并行","Coroutines","Concurrency"],"title":"进程线程协程与并发并行","uri":"/posts/process-thread-coroutines-concurrency-parallelism/"},{"categories":["技术"],"content":"二、线程 Thread：（并发执行） 属于同一个进程的线程之间，是共享一套工作内容的。这使得线程的创建和移除开销很小，但同时也使编程变得复杂。 关于线程，分用户级线程和内核级线程。不同的语言中，这两种线程的对应关系也不尽相同。 多对一模型 将多个用户级线程映射到一个内核级线程，线程管理在用户空间完成，这种模型下操作系统并不知道多线程的存在。Python 就是这种模型。 优点：线程管理是在用户空间进行的，切换上下文开销比较小，性能较高。 缺点：当一个线程在使用内核服务时被阻塞，那么整个进程都会被阻塞；多个线程不能并行地运行在多处理机上。 一对一模型 将每个用户级线程映射到一个内核级线程。Java的线程就属于这种模型。 优点：当一个线程被阻塞后，允许另一个线程继续执行，所以并发能力较强；能很好的利用到CPU的多核心。 缺点：每创建一个用户级线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。并且切换线程要进出内核，代价比较大。 多对多模型 将n个用户级线程映射到m个内核级线程上，要求 m \u003c= n。GO（1.5之后）的协程就属于这种线程模型。 特点：既克服了多对一模型的并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程，开销太大的缺点。又拥有多对一模型和一对一模型各自的优点。 ","date":"2018-01-23","objectID":"/posts/process-thread-coroutines-concurrency-parallelism/:0:2","tags":["进程","线程","协程","并发","并行","Coroutines","Concurrency"],"title":"进程线程协程与并发并行","uri":"/posts/process-thread-coroutines-concurrency-parallelism/"},{"categories":["技术"],"content":"三、协程 Coroutine（并发执行） 如果说线程是轻量级的进程，那么协程就是轻量级的线程。线程跑在进程里，协程就跑在线程里。 优点： 协程是跑在同一个线程里，并且是由程序本身来调度的。协程间的切换就是函数的调用，完全没有线程切换那么大的开销。 线程的数量越多，协程的优势越大 因为协程是程序调度的，它实际上是串行运行的，因此不需要复杂的锁机制来保证线程安全。 在协程中控制共享资源不加锁，只需要判断状态就好了。这免去了锁机制带来的开销。 因为协程跑在单个线程内，所占用的 CPU 资源有限，所以多协程并不能提升计算性能。不仅如此，因为多了程序本身的调度开销，计算密集型程序的性能反而会下降。 此外，协程代码中决不能出现阻塞，否则整个线程都会停下来等待该操作完成，这就麻烦了。 协程适合用于 IO 密集型任务，可用于简化异步 IO 的 callback hell。例如 Python 的 asyncio 就是用协程实现的。 ","date":"2018-01-23","objectID":"/posts/process-thread-coroutines-concurrency-parallelism/:0:3","tags":["进程","线程","协程","并发","并行","Coroutines","Concurrency"],"title":"进程线程协程与并发并行","uri":"/posts/process-thread-coroutines-concurrency-parallelism/"},{"categories":["技术"],"content":"并发并行 由此，又引出两个名词： 并发（Concurrent）：多个任务交替进行。 并行（Parallel）：多个任务同时进行。 一张图说明两者的差别 Note：进程 和 线程 都可能是 并发 或 并行 的。关键看你程序的运行状态。多核是并行的前提。并发则只要求交替执行，因此单核也没问题。 ","date":"2018-01-23","objectID":"/posts/process-thread-coroutines-concurrency-parallelism/:0:4","tags":["进程","线程","协程","并发","并行","Coroutines","Concurrency"],"title":"进程线程协程与并发并行","uri":"/posts/process-thread-coroutines-concurrency-parallelism/"},{"categories":["技术"],"content":"同步异步 同步：不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以协调一致，称这些程序单元是同步执行的。 多线程编程中，所有修改共享变量的行为，都必须加锁，保证顺序执行，保证同步。或者加原子锁，保证该修改操作是原子的。 同步意味着有序 异步：为完成某个任务，不同程序单元之间过程中无需通信协调，也能完成任务的方式。 不相关的程序单元之间可以是异步的。比如爬虫下载网页 异步意味着无序 进程、线程和协程 ","date":"2018-01-23","objectID":"/posts/process-thread-coroutines-concurrency-parallelism/:0:5","tags":["进程","线程","协程","并发","并行","Coroutines","Concurrency"],"title":"进程线程协程与并发并行","uri":"/posts/process-thread-coroutines-concurrency-parallelism/"},{"categories":["随笔"],"content":" 啊啊，还有十天就可以摆脱这个城市，回到那个令人安心的山林里了，一边期待着，一边焦躁着，想着为什么剩下的十天这么难熬这样的问题。 复习又是一塌糊涂，我也太懒了点。 这样懒散的我还做着码完几千行代码这样的春秋大梦，太不现实了。有点想认命了。 半夜一点多，寝室空调还是不习惯，过道阳台上的凉风倒是很舒服，这座城市此刻的静谧倒也有几分韵味。 不过不管怎么说，好想回家… ","date":"2017-06-27","objectID":"/posts/the-end-of-another-semester/:0:0","tags":[],"title":"又一个期末","uri":"/posts/the-end-of-another-semester/"},{"categories":["数学","技术"],"content":"很早就学过欧几里得算法，但是一直不知道它的原理。几乎每本算法书都会提到它，但是貌似只有数学书上才会见到它的原理。。。 前段时间粗粗看了点数论（《什么是数学》），惊讶于这个原理的奇妙。现在把它通俗地写下来，以免自己忘记。 欧几里得算法是求两个数的最大公约数(Greatest Common Divisor (GCD))的算法，我们首先假设有两个数 $a$ 和 $b$，其中 $a$ 是不小于 $b$ 的数， 记 $a$ 被 $b$ 除的余数为 $r$，那么 $a$ 可以写成这样的形式： $$a = bq + r$$ 其中 $q$ 是整数（我们不需要去管 $q$ 到底是多少，这和我们的目标无关）。 现在假设 $a$ 和 $b$ 的一个约数为 $u$，那么 $a$ 和 $b$ 都能被 $u$ 整除，即 $$a = su$$ $$b = tu$$ $s$ 和 $t$ 都是整数（同样的，我们只需要知道存在这样的整数 $s$ 和 $t$ 就行）。 这样可以得出 $$r = a - bq = su - (tu)q = (s - tq)u$$ 所以 $r$ 也能被 $u$ 整除，一般规律如下 $a$ 和 $b$ 的约数也整除它们的余数 $r$，所以 $a$ 和 $b$ 的任一约数同时也是 $b$ 和 $r$ 的约数。 —— 条件一 反过来可以得出 $b$ 和 $r$ 的任一约数同时也是 $a$ 和 $b$ 的约数。 ——条件二 这是因为对 $b$ 和 $r$ 每一个约数 $v$，有 $$b = kv$$ $$r = cv$$ 于是有 $$a = bq + r = (kv)q + cv = (kq + c)v$$ 由条件一和条件二可知 $a$ 和 $b$ 的约数的集合，全等于 $b$ 和 $r$ 的约数的集合。 于是 $a$ 和 $b$ 的最大公约数，就是 $b$ 和 $r$ 的最大公约数。 接下来用递推法， $a \\div b$ 余 $r$，现在设 $b \\div r$ 余 $r_1$ $r \\div r_1$ 余 $r_2$ …… $r_{n-3} \\div r_{n-2}$ 余 $r_{n-1}$ $r_{n-2} \\div r_{n-1}$ 余 $r_n=0$ 因为 $a \\ge b$，可以看出余数 $r_n$ 会越来越小，最终变成 $0$. 当 $r_{n-1} \\neq 0$ 且 $r_n = 0$ 时，可知 $r_{n-2}$ 可被 $r_{n-1}$ 整除（余数为 $0$ 嘛） 此时 $r_{n-2}$ 和 $r_{n-1}$ 的约数就只有：$r_{n-1}$ 和 $r_{n-1}$ 的因数，所以他们的最大公约数就是 $r_{n-1}$！ 所以 $r_{n-1}$ 就是 $a$ 和 $b$ 的最大公约数。（若 $r = 0$，则 $b$ 为最大公约数） 这个递推法写成c语言函数是这样的（比推导更简洁…）: unsigned int Gcd(unsigned int M,unsigned int N){ unsigned int Rem; while(N){ Rem = M % N; M = N; N = Rem; } return Rem; } 可以发现这里没有要求 M\u003e=N，这是因为如果那样，循环会自动交换它们的值。 P.S. 此外，还有最小公倍数(Least Common Multiple (LCM))算法，详见 GCD and LCM calculator ","date":"2017-05-26","objectID":"/posts/mathematics-in-euclidean-gcd/:0:0","tags":["算法"],"title":"欧几里得算法求最大公约数(GCD)的数学原理","uri":"/posts/mathematics-in-euclidean-gcd/"},{"categories":["随笔"],"content":"生活总是在给你希望之时，再埋点伏笔。本来我以为进了大学，就是一个全新的世界了，我可以重新开始，只要我很努力很努力，一切困难都将不堪一击。 显然那个时候，我还不知道，现实不同于想象。 高三在高压下全线崩溃，因此对大学寄予了过多期望。但这期望同时也带来了更大的压力。 我患上了阅读焦虑症。 从进入大学的那一刻起，就开始疯狂地制定阅读计划，泡图书馆，看各种学习方法、读书方法、记忆方法、速读术之类的书籍，恨不得一目十行。 但是很快的，我就发现自己出了问题：我太想提升自己了，因此翻开书的第一页，就期盼着翻到最后一页，读书的愉悦，被对看完一本书的渴望冲淡了。更多的时候，感觉到的是还没把这本书看完的焦虑。 而且因为长时间全神贯注，一本书看不到一半，耐心也渐渐失去，于是翻页速度越来越快，这个时候所谓的“阅读”已经名存实亡了。 这样的阅读的结果，只是在读书量上徒然添加几个数字，于自我提升而言，却是收效甚微。我很明白这一点，但是明白和作出改变之间，隔着一道鸿沟，我怎么也跨不过去。明明知道松弛有度效率会更高，但是心理上的焦虑让我无法说服自己放下书本哪怕一分钟，直到自己的耐心消耗殆尽…… 买了一大堆文学书放在柜头。可笑的是，大一整整一年，除了韩寒，我没看任何一本文学书超过半小时。“快速浏览”完十几本方法类书籍后，我开始阅读技术书籍。但是除了韩寒的书和几本技术书籍，阅读过程中的焦虑感从未远离我，这不仅降低了我的学习效率，更让我的倦怠期长了数倍(过度消耗精力)。其结果是，往往一本厚一点的书读上两三天，就有半个月会厌倦到不想碰它。 我能感觉到如果按着计划读书，我的成果绝不会差到现在这样。也想着有计划性一点，可是一看QQ，人家初三的小男孩已经学遍了高中数学、算法、初等数论、自然数学……网上认识的同龄人已经开始做神经网络了，知乎上一大群自学者也在努力攻克python/c/算法，我就停不下来，甚至平静下来做个计划都觉得浪费时间(实际上很明显这样带着焦虑阅读才是浪费时间)。 迫切的想要成为那个“自己想要成为的人”，因此连基本的理性都无法保持。 我想要的是从容、带着脑子的阅读，而不是这样走马观花，盲目追求量的阅读。 我又焦虑地打开知乎，不断搜索，然后写下这篇文章。 ","date":"2017-03-07","objectID":"/posts/reading-anxiety/:0:0","tags":["阅读","焦虑"],"title":"我患上了阅读焦虑症","uri":"/posts/reading-anxiety/"},{"categories":["随笔"],"content":" 2017年2月的18号，清晨6点。天还只是朦朦亮，当空挂着半边弯月，一颗不知名的星星(大约是大角星)缀在月的旁边。 还没开学，学校几乎看不到人。 南食堂的一楼已亮起了灯，鸟儿们开始鸣叫个不停，可以听出有好几种鸟叫声。 易海仍是风平浪静。 我背着书包，拖着皮箱，耳边最清晰的声音便是皮箱轮胎与地面的摩擦声。 手机随便放起一首歌，恰好是《遥远的歌》。这首歌真是应景呢，逝去的时光遥远得无法触及，自己也离家千里，未来更是难以捉摸。 我还会记得吗？记得这个我印象中，最宁静安详的，安徽建筑大学。 ","date":"2017-02-18","objectID":"/posts/quiet-and-peaceful-campus/:0:0","tags":[],"title":"少有人迹的校园","uri":"/posts/quiet-and-peaceful-campus/"},{"categories":["随笔"],"content":" 上个暑假，刚刚从低谷爬出来，那时候整个人散发着一股子向上的气息，豪情万丈，甚至感染了周围的亲朋好友。那个时候，满以为以后的挫折都不能阻挡我的脚步。 可是，到底为什么，现在又变成了这个样子了呢？人生这样的东西，总是出人意料，以至于怎么也猜不透。 十二月十四，我度过了我的十九岁生日，现在应该正是那所谓的青春将逝未逝之时。而我的青春应该最辉煌的时候，我在干什么呢？ 我在翻山越岭。 上山时一路坎坷，累的要死不活的。陡然间萌生退意，心就在不断挣扎。就在却意战胜壮志之时，忽然间天地开阔，才发觉自己已然站在了大山之巅，于是一切痛苦尽皆远去，心也变得如这天地一般开阔。这个时候自然豪情万丈，看山山美，看水水秀。想当然的就觉得后面的山岭有再多的阻碍，也不能阻挡这个见过如此美景的登山人了。 可是事与愿违，山岭就像时间一样看不到边，翻过了一座又是一座，这又是一种更大的痛苦。这个登山人身心俱疲，只好万事随缘，继续一脚深，一脚浅的往那无尽山岭行去。 最近看了是枝裕和的电影《比海更深》，“我的人生到底出了什么差错？” 这样一个问句，道出了多少辛酸苦辣……想起了以前写过一篇文章，标题是《对不起，我没有成为你想成为的那个人》。 理想与现实之间仿佛总隔着一道鸿沟。 现在没有了万丈豪情，不再敢说“未来将是一片坦途”；也没有绝望到要写“我的人生到底出了什么差错？”这样的句子，那还是用我最喜欢的那个模棱两可的四字词作结吧。 且行且寻 ","date":"2017-02-06","objectID":"/posts/the-holiday-is-coming-to-an-end/:0:0","tags":[],"title":"忽而假末","uri":"/posts/the-holiday-is-coming-to-an-end/"}]
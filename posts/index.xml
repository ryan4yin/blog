<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>所有文章 - Ryan4Yin's Space</title><link>https://ryan4yin.space/posts/</link><description>所有文章 | Ryan4Yin's Space</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>xiaoyin_c@qq.com (ryan4yin)</managingEditor><webMaster>xiaoyin_c@qq.com (ryan4yin)</webMaster><lastBuildDate>Sun, 15 Aug 2021 19:11:29 +0800</lastBuildDate><atom:link href="https://ryan4yin.space/posts/" rel="self" type="application/rss+xml"/><item><title>iptables 及 docker 容器网络分析</title><link>https://ryan4yin.space/posts/iptables-and-container-networks/</link><pubDate>Sun, 15 Aug 2021 19:11:29 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/iptables-and-container-networks/</guid><description><![CDATA[<blockquote>
<p>本文仅针对 ipv4 网络</p>
</blockquote>
<p><a href="https://www.netfilter.org/projects/iptables/index.html" target="_blank" rel="noopener noreferrer">iptables</a> 提供了包过滤、NAT 以及其他的包处理能力，iptables 应用最多的两个场景是 firewall 和 NAT</p>
<p>iptables 及新的 nftables 都是基于 netfilter 开发的，是 netfilter 的子项目。</p>
<p>但是 eBPF 社区目前正在开发旨在取代 netfilter 的新项目 bpfilter，他们的目标之一是兼容 iptables/nftables 规则，让我们拭目以待吧。</p>
<h2 id="iptables-基础概念---四表五链">iptables 基础概念 - 四表五链</h2>
<blockquote>
<p>实际上还有张 SELinux 相关的 security 表（应该是较新的内核新增的，但是不清楚是哪个版本加的），但是我基本没接触过，就略过了。</p>
</blockquote>
<p>详细的说明参见 <a href="https://www.zsythink.net/archives/1199" target="_blank" rel="noopener noreferrer">iptables详解（1）：iptables概念 - 朱双印</a>，这篇文章写得非常棒！把 iptables 讲清楚了。</p>
<p>默认情况下，iptables 提供了四张表（不考虑 security 的话）和五条链，数据在这四表五链中的处理流程如下图所示：</p>
<blockquote>
<p>在这里的介绍中，可以先忽略掉图中 link layer 层的链路，它属于 ebtables 的范畴。另外 <code>conntrack</code> 也暂时忽略，在下一小节会详细介绍 conntrack 的功能。</p>
</blockquote>
<p><figure><a class="lightgallery" href="/images/netfilter/netfilter-packet-flow.png" title="/images/netfilter/netfilter-packet-flow.png" data-thumbnail="/images/netfilter/netfilter-packet-flow.png" data-sub-html="<h2>netfilter 数据包处理流程，来自 wikipedia</h2>">
        
    </a><figcaption class="image-caption">netfilter 数据包处理流程，来自 wikipedia</figcaption>
    </figure></p>
<p>对照上图，对于发送到某个用户层程序的数据而言，流量顺序如下：</p>
<ul>
<li>首先进入 PREROUTING 链，依次经过这三个表： raw -&gt; mangle -&gt; nat</li>
<li>然后进入 INPUT 链，这个链上也有三个表，处理顺序是：mangle -&gt; nat -&gt; filter</li>
<li>过了 INPUT 链后，数据才会进入内核协议栈，最终到达用户层程序。</li>
</ul>
<p>用户层程序发出的报文，则依次经过这几个表：OUTPUT -&gt; POSTROUTING</p>
<p>从图中也很容易看出，如果数据 dst ip 不是本机任一接口的 ip，那它通过的几个链依次是：PREROUTEING -&gt; FORWARD -&gt; POSTROUTING</p>
<p>五链的功能和名称完全一致，应该很容易理解。下面按优先级分别介绍下链中的四个表：</p>
<ul>
<li>raw: 对收到的数据包在连接跟踪前进行处理。一般用不到，可以忽略
<ul>
<li>一旦用户使用了 RAW 表，RAW 表处理完后，将跳过 NAT 表和 ip_conntrack 处理，即不再做地址转换和数据包的链接跟踪处理了</li>
</ul>
</li>
<li>mangle: 用于修改报文、给报文打标签</li>
<li>nat: 主要用于做网络地址转换，SNAT 或者 DNAT</li>
<li>filter: 主要用于过滤数据包</li>
</ul>
<p>数据在按优先级经过四个表的处理时，一旦在某个表中匹配到一条规则 A,下一条处理规则就由规则 A 的 target 参数指定，<strong>后续的所有表</strong>都会被忽略。target 有如下几种类型：</p>
<ul>
<li>ACCEPT: 直接允许数据包通过</li>
<li>DROP: 直接丢弃数据包，对程序而言就是 100% 丢包</li>
<li>REJECT: 丢弃数据包，但是会给程序返回  RESET。这个对程序更友好，但是存在安全隐患，通常不使用。</li>
<li>MASQUERADE: （伪装）将 src ip 改写为网卡 ip，和 SNAT 的区别是它会自动读取网卡 ip。路由设备必备。</li>
<li>SNAT/DNAT: 顾名思义，做网络地址转换</li>
<li>REDIRECT: 在本机做端口映射</li>
<li>LOG: 在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。
<ul>
<li>只有这个 target 特殊一些，匹配它的数据仍然可以匹配后续规则，不会直接跳过。</li>
</ul>
</li>
<li>其他类型，可以用到的时候再查</li>
</ul>
<p>理解了上面这张图，以及四个表的用途，就很容易理解 iptables 的命令了。</p>
<h2 id="常用命令">常用命令</h2>
<blockquote>
<p><strong>注意</strong>: 下面提供的 iptables 命令做的修改是未持久化的，重启就会丢失！在下一节会简单介绍持久化配置的方法。</p>
</blockquote>
<p>命令格式：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">iptables <span class="o">[</span>-t table<span class="o">]</span> <span class="o">{</span>-A<span class="p">|</span>-C<span class="p">|</span>-D<span class="o">}</span> chain <span class="o">[</span>-m matchname <span class="o">[</span>per-match-options<span class="o">]]</span> -j targetname <span class="o">[</span>per-target-options<span class="o">]</span>
</code></pre></td></tr></table>
</div>
</div><p>其中 table 默认为 <code>filter</code> 表，但是感觉系统管理员实际使用最多的是 INPUT 表，用于设置防火墙。</p>
<p>以下简单介绍在 INPUT 表上添加、修改规则，来设置防火墙：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># --add 允许 80 端口通过</span>
iptables -A INPUT -p tcp --dport <span class="m">80</span> -j ACCEPT

<span class="c1"># --list-rules 查看所有规则</span>
iptables -S

<span class="c1"># --list-rules 查看 INPUT 表中的所有规则</span>
iptables -S INPUT
<span class="c1"># 查看 iptables 中的所有规则（比 -L 更详细）</span>

<span class="c1"># ---delete 通过编号删除规则</span>
iptables -D <span class="m">1</span>
<span class="c1"># 或者通过完整的规则参数来删除规则</span>
iptables -D INPUT -p tcp --dport <span class="m">80</span> -j ACCEPT

<span class="c1"># --replace 通过编号来替换规则内容</span>
iptables -R INPUT <span class="m">1</span> -s 192.168.0.1 -j DROP

<span class="c1"># --insert 在指定的位置插入规则，可类比链表的插入</span>
iptables -I INPUT <span class="m">1</span> -p tcp --dport <span class="m">80</span> -j ACCEPT

<span class="c1"># 在匹配条件前面使用感叹号表示取反</span>
<span class="c1"># 如下规则表示接受所有来自 docker0，但是目标接口不是 docker0 的流量</span>
iptables -A FORWARD -i docker0 ! -o docker0 -j ACCEPT

<span class="c1"># --policy 设置某个链的默认规则</span>
<span class="c1"># 很多系统管理员会习惯将连接公网的服务器，默认规则设为 DROP，提升安全性，避免错误地开放了端口。</span>
<span class="c1"># 但是也要注意，默认规则设为 DROP 前，一定要先把允许 ssh 端口的规则加上，否则就尴尬了。</span>
iptables -P INPUT DROP

<span class="c1"># --flush 清空 INPUT 表上的所有规则</span>
iptables -F INPUT
</code></pre></td></tr></table>
</div>
</div><hr>
<blockquote>
<p>本文后续分析时，假设用户已经清楚 linux bridge、veth 等虚拟网络接口相关知识。
如果你还缺少这些前置知识，请先阅读文章 <a href="https://ryan4yin.space/posts/linux-virtual-network-interfaces/" target="_blank" rel="noopener noreferrer">Linux 中的虚拟网络接口</a>。</p>
</blockquote>
<h2 id="conntrack-连接跟踪与-nat">conntrack 连接跟踪与 NAT</h2>
<p>在讲 conntrack 之间，我们再回顾下前面给出过的 netfilter 数据处理流程图：</p>
<p><figure><a class="lightgallery" href="/images/netfilter/netfilter-packet-flow.png" title="/images/netfilter/netfilter-packet-flow.png" data-thumbnail="/images/netfilter/netfilter-packet-flow.png" data-sub-html="<h2>netfilter 数据包处理流程，来自 wikipedia</h2>">
        
    </a><figcaption class="image-caption">netfilter 数据包处理流程，来自 wikipedia</figcaption>
    </figure></p>
<p>上一节中我们忽略了图中的 conntrack，它就是本节的主角——netfilter 的连接跟踪（connection tracking）模块。</p>
<p>netfilter/conntrack 是 iptables 实现 SNAT/DNAT/MASQUERADE 的前提条件，上面的流程图显示， conntrack 在 PREROUTEING 和 OUTPUT 表的 raw 链之后生效。</p>
<p>下面以 docker 默认的 bridge 网络为例详细介绍下 conntrack 的功能。</p>
<p>首先，这是我在「Linux 的虚拟网络接口」文中给出过的 docker0 网络架构图:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">+-----------------------------------------------+-----------------------------------+-----------------------------------+
|                      Host                     |           Container A             |           Container B             |
|                                               |                                   |                                   |
|   +---------------------------------------+   |    +-------------------------+    |    +-------------------------+    |
|   |       Network Protocol Stack          |   |    |  Network Protocol Stack |    |    |  Network Protocol Stack |    |
|   +----+-------------+--------------------+   |    +-----------+-------------+    |    +------------+------------+    |
|        ^             ^                        |                ^                  |                 ^                 |
|........|.............|........................|................|..................|.................|.................|
|        v             v  ↓                     |                v                  |                 v                 |
|   +----+----+  +-----+------+                 |          +-----+-------+          |           +-----+-------+         |
|   | .31.101 |  | 172.17.0.1 |      +------+   |          | 172.17.0.2  |          |           |  172.17.0.3 |         |
|   +---------+  +-------------&lt;----&gt;+ veth |   |          +-------------+          |           +-------------+         |
|   |  eth0   |  |   docker0  |      +--+---+   |          | eth0(veth)  |          |           | eth0(veth)  |         |
|   +----+----+  +-----+------+         ^       |          +-----+-------+          |           +-----+-------+         |
|        ^             ^                |       |                ^                  |                 ^                 |
|        |             |                +------------------------+                  |                 |                 |
|        |             v                        |                                   |                 |                 |
|        |          +--+---+                    |                                   |                 |                 |
|        |          | veth |                    |                                   |                 |                 |
|        |          +--+---+                    |                                   |                 |                 |
|        |             ^                        |                                   |                 |                 |
|        |             +------------------------------------------------------------------------------+                 |
|        |                                      |                                   |                                   |
|        |                                      |                                   |                                   |
+-----------------------------------------------+-----------------------------------+-----------------------------------+
         v
    Physical Network  (192.168.31.0/24)
</code></pre></td></tr></table>
</div>
</div><p>docker 会在 iptables 中为 docker0 网桥添加如下规则：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">-t nat -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE

-t filter -P DROP
-t filter -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
</code></pre></td></tr></table>
</div>
</div><p>这几行规则使 docker 容器能正常访问外部网络。<code>MASQUERADE</code> 在请求出网时，会自动做 <code>SNAT</code>，将 src ip 替换成出口网卡的 ip.
这样数据包能正常出网，而且对端返回的数据包现在也能正常回到出口网卡。</p>
<p>现在问题就来了：<strong>出口网卡收到返回的数据包后，还能否将数据包转发到数据的初始来源端——某个 docker 容器</strong>？难道 docker 还额外添加了与 MASQUERADE 对应的 dst ip 反向转换规则？</p>
<p>实际上这一步依赖的是本节的主角——iptables 提供的 conntrack 连接跟踪功能（在「参考」中有一篇文章详细介绍了此功能）。</p>
<p>连接跟踪对 NAT 的贡献是：在做 NAT 转换时，无需手动添加额外的规则来执行<strong>反向转换</strong>以实现数据的双向传输。netfilter/conntrack 系统会记录 NAT 的连接状态，NAT 地址的反向转换是根据这个状态自动完成的。</p>
<p>比如上图中的 <code>Container A</code> 通过 bridge 网络向 baidu.com 发起了 N 个连接，这时数据的处理流程如下：</p>
<ul>
<li>首先 <code>Container A</code> 发出的数据包被 MASQUERADE 规则处理，将 src ip 替换成 eth0 的 ip，然后发送到物理网络 <code>192..168.31.0/24</code>。
<ul>
<li>conntrack 系统记录此连接被 NAT 处理前后的状态信息，并将其状态设置为 NEW，表示这是新发起的一个连接</li>
</ul>
</li>
<li>对端 baidu.com 返回数据包后，会首先到达 eth0 网卡</li>
<li>conntrack 查表，发现返回数据包的连接已经记录在表中并且状态为 NEW，于是它将连接的状态修改为 ESTABLISHED，并且将 dst_ip 改为 <code>172.17.0.2</code> 然后发送出去
<ul>
<li>注意，这个和 tcp 的 ESTABLISHED 没任何关系</li>
</ul>
</li>
<li>经过路由匹配，数据包会进入到 docker0，然后匹配上 iptables 规则：<code>-t filter -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT</code>，数据直接被放行</li>
<li>数据经过 veth 后，最终进入到 <code>Container A</code> 中，交由容器的内核协议栈处理。</li>
<li>数据被 <code>Container A</code> 的内核协议栈发送到「发起连接的应用程序」。</li>
</ul>
<h3 id="实际测试-conntrack">实际测试 conntrack</h3>
<p>现在我们来实际测试一下，看看是不是这么回事：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 使用 tcpdump 分别在出口网卡 wlp4s0 （相当于 eth0）和 dcoker0 网桥上抓包，后面会用来分析</span>
❯ sudo tcpdump -i wlp4s0 -n &gt; wlp4s0.dump   <span class="c1"># 窗口一，抓 wlp4s0 的包</span>
❯ sudo tcpdump -i docker0 -n &gt; docker0.dump  <span class="c1"># 窗口二，抓 docker0 的包</span>
</code></pre></td></tr></table>
</div>
</div><p>现在新建窗口三，启动一个容器，通过 curl 命令低速下载一个视频文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">❯ docker run --rm --name curl -it curlimages/curl &#34;https://media.w3.org/2010/05/sintel/trailer.mp4&#34; -o /tmp/video.mp4 --limit-rate 100k
</code></pre></td></tr></table>
</div>
</div><p>然后新建窗口四，在宿主机查看 conntrack 状态</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">❯ sudo zypper in conntrack-tools  <span class="c1"># 这个记得先提前安装好</span>
❯ sudo conntrack -L <span class="p">|</span> grep 172.17
<span class="c1"># curl 通过 NAT 网络发起了一个 dns 查询请求，DNS 服务器是网关上的 192.168.31.1</span>
udp      <span class="m">17</span> <span class="m">22</span> <span class="nv">src</span><span class="o">=</span>172.17.0.4 <span class="nv">dst</span><span class="o">=</span>192.168.31.1 <span class="nv">sport</span><span class="o">=</span><span class="m">59423</span> <span class="nv">dport</span><span class="o">=</span><span class="m">53</span> <span class="nv">src</span><span class="o">=</span>192.168.31.1 <span class="nv">dst</span><span class="o">=</span>192.168.31.228 <span class="nv">sport</span><span class="o">=</span><span class="m">53</span> <span class="nv">dport</span><span class="o">=</span><span class="m">59423</span> <span class="o">[</span>ASSURED<span class="o">]</span> <span class="nv">mark</span><span class="o">=</span><span class="m">0</span> <span class="nv">use</span><span class="o">=</span><span class="m">1</span>
<span class="c1"># curl 通过 NAT 网络向 media.w3.org 发起了 tcp 连接</span>
tcp      <span class="m">6</span> <span class="m">298</span> ESTABLISHED <span class="nv">src</span><span class="o">=</span>172.17.0.4 <span class="nv">dst</span><span class="o">=</span>198.18.5.130 <span class="nv">sport</span><span class="o">=</span><span class="m">54636</span> <span class="nv">dport</span><span class="o">=</span><span class="m">443</span> <span class="nv">src</span><span class="o">=</span>198.18.5.130 <span class="nv">dst</span><span class="o">=</span>192.168.31.228 <span class="nv">sport</span><span class="o">=</span><span class="m">443</span> <span class="nv">dport</span><span class="o">=</span><span class="m">54636</span> <span class="o">[</span>ASSURED<span class="o">]</span> <span class="nv">mark</span><span class="o">=</span><span class="m">0</span> <span class="nv">use</span><span class="o">=</span><span class="m">1</span>
</code></pre></td></tr></table>
</div>
</div><p>等 curl 命令跑个十来秒，然后关闭所有窗口及应用程序，接下来进行数据分析：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 前面查到的，本地发起请求的端口是 54636，下面以此为过滤条件查询数据</span>

<span class="c1"># 首先查询 wlp4s0/eth0 进来的数据，可以看到本机的 dst_ip 为 192.168.31.228.54636</span>
❯ cat wlp4s0.dump <span class="p">|</span> grep <span class="m">54636</span> <span class="p">|</span> head -n <span class="m">15</span>
18:28:28.349321 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>S<span class="o">]</span>, seq 750859357, win 64240, options <span class="o">[</span>mss 1460,sackOK,TS val <span class="m">3365688110</span> ecr 0,nop,wscale 7<span class="o">]</span>, length <span class="m">0</span>
18:28:28.350757 IP 198.18.5.130.443 &gt; 192.168.31.228.54636: Flags <span class="o">[</span>S.<span class="o">]</span>, seq 2381759932, ack 750859358, win 28960, options <span class="o">[</span>mss 1460,sackOK,TS val <span class="m">22099541</span> ecr 3365688110,nop,wscale 5<span class="o">]</span>, length <span class="m">0</span>
18:28:28.350814 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>.<span class="o">]</span>, ack 1, win 502, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688111</span> ecr 22099541<span class="o">]</span>, length <span class="m">0</span>
18:28:28.357345 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 1:518, ack 1, win 502, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688118</span> ecr 22099541<span class="o">]</span>, length <span class="m">517</span>
18:28:28.359253 IP 198.18.5.130.443 &gt; 192.168.31.228.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 518, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099542</span> ecr 3365688118<span class="o">]</span>, length <span class="m">0</span>
18:28:28.726544 IP 198.18.5.130.443 &gt; 192.168.31.228.54636: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 1:2622, ack 518, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688118<span class="o">]</span>, length <span class="m">2621</span>
18:28:28.726616 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>.<span class="o">]</span>, ack 2622, win 482, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688487</span> ecr 22099579<span class="o">]</span>, length <span class="m">0</span>
18:28:28.727652 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 518:598, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">80</span>
18:28:28.727803 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 598:644, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">46</span>
18:28:28.727828 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 644:693, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">49</span>
18:28:28.727850 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 693:728, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">35</span>
18:28:28.727875 IP 192.168.31.228.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 728:812, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">84</span>
18:28:28.729241 IP 198.18.5.130.443 &gt; 192.168.31.228.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 598, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688488<span class="o">]</span>, length <span class="m">0</span>
18:28:28.729245 IP 198.18.5.130.443 &gt; 192.168.31.228.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 644, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688488<span class="o">]</span>, length <span class="m">0</span>
18:28:28.729247 IP 198.18.5.130.443 &gt; 192.168.31.228.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 693, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688488<span class="o">]</span>, length <span class="m">0</span>


<span class="c1"># 然后再查询 docker0 上的数据，能发现本地的地址为 172.17.0.4.54636</span>
❯ cat docker0.dump <span class="p">|</span> grep <span class="m">54636</span> <span class="p">|</span> head -n <span class="m">20</span>
18:28:28.349299 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>S<span class="o">]</span>, seq 750859357, win 64240, options <span class="o">[</span>mss 1460,sackOK,TS val <span class="m">3365688110</span> ecr 0,nop,wscale 7<span class="o">]</span>, length <span class="m">0</span>
18:28:28.350780 IP 198.18.5.130.443 &gt; 172.17.0.4.54636: Flags <span class="o">[</span>S.<span class="o">]</span>, seq 2381759932, ack 750859358, win 28960, options <span class="o">[</span>mss 1460,sackOK,TS val <span class="m">22099541</span> ecr 3365688110,nop,wscale 5<span class="o">]</span>, length <span class="m">0</span>
18:28:28.350812 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>.<span class="o">]</span>, ack 1, win 502, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688111</span> ecr 22099541<span class="o">]</span>, length <span class="m">0</span>
18:28:28.357328 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 1:518, ack 1, win 502, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688118</span> ecr 22099541<span class="o">]</span>, length <span class="m">517</span>
18:28:28.359281 IP 198.18.5.130.443 &gt; 172.17.0.4.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 518, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099542</span> ecr 3365688118<span class="o">]</span>, length <span class="m">0</span>
18:28:28.726578 IP 198.18.5.130.443 &gt; 172.17.0.4.54636: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 1:2622, ack 518, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688118<span class="o">]</span>, length <span class="m">2621</span>
18:28:28.726610 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>.<span class="o">]</span>, ack 2622, win 482, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688487</span> ecr 22099579<span class="o">]</span>, length <span class="m">0</span>
18:28:28.727633 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 518:598, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">80</span>
18:28:28.727798 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 598:644, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">46</span>
18:28:28.727825 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 644:693, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">49</span>
18:28:28.727847 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 693:728, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">35</span>
18:28:28.727871 IP 172.17.0.4.54636 &gt; 198.18.5.130.443: Flags <span class="o">[</span>P.<span class="o">]</span>, seq 728:812, ack 2622, win 501, options <span class="o">[</span>nop,nop,TS val <span class="m">3365688488</span> ecr 22099579<span class="o">]</span>, length <span class="m">84</span>
18:28:28.729308 IP 198.18.5.130.443 &gt; 172.17.0.4.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 598, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688488<span class="o">]</span>, length <span class="m">0</span>
18:28:28.729324 IP 198.18.5.130.443 &gt; 172.17.0.4.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 644, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688488<span class="o">]</span>, length <span class="m">0</span>
18:28:28.729328 IP 198.18.5.130.443 &gt; 172.17.0.4.54636: Flags <span class="o">[</span>.<span class="o">]</span>, ack 693, win 939, options <span class="o">[</span>nop,nop,TS val <span class="m">22099579</span> ecr 3365688488<span class="o">]</span>, length <span class="m">0</span>
</code></pre></td></tr></table>
</div>
</div><p>能看到数据确实在进入 docker0 网桥前，dst_ip 确实被从 <code>192.168.31.228</code>（wlp4s0 的 ip）被修改为了 <code>172.17.0.4</code>（<code>Container A</code> 的 ip）.</p>
<h3 id="nat-如何分配端口">NAT 如何分配端口？</h3>
<p>上一节我们实际测试发现，docker 容器的流量在经过 iptables 的 MASQUERADE 规则处理后，只有 src ip 被修改了，而 port 仍然是一致的。</p>
<p>但是如果 NAT 不修改连接的端口，实际上是会有问题的。如果有两个容器同时向 <code>ip: 198.18.5.130, port: 443</code> 发起请求，又恰好使用了同一个 src port，在宿主机上就会出现端口冲突！
因为这两个请求被 SNAT 时，如果只修改 src ip，那它们映射到的将是主机上的同一个连接！</p>
<p>这个问题 NAT 是如何解决的呢？我想如果遇到这种情况，NAT 应该会通过一定的规则选用一个不同的端口。</p>
<p>有空可以翻一波源码看看这个，待续&hellip;</p>
<h2 id="如何持久化-iptables-配置">如何持久化 iptables 配置</h2>
<p>首先需要注意的是，centos7/opensuse 15 都已经切换到了 firewalld 作为防火墙配置软件，
而 ubuntu18.04 lts 也换成了 ufw 来配置防火墙。</p>
<p>包括 docker 应该也是在启动的时候动态添加 iptables 配置。</p>
<p>对于上述新系统，还是建议直接使用 firewalld/ufw 配置防火墙吧，或者网上搜下关闭 ufw/firewalld、启用 iptables 持久化的解决方案。</p>
<p>本文主要目的在于理解 docker 容器网络的原理，以及为后面理解 kubernetes 网络插件 calico/flannel 打好基础，因此就不多介绍持久化了。</p>
<h2 id="docker-如何使用-iptables--虚拟网络接口实现容器网络">Docker 如何使用 iptables + 虚拟网络接口实现容器网络</h2>
<h3 id="通过-docker-run-运行容器">通过 docker run 运行容器</h3>
<p>首先，使用 <code>docker run</code> 运行几个容器，检查下网络状况：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 运行一个 debian 容器和一个 nginx</span>
❯ docker run -dit --name debian --rm debian:buster sleep <span class="m">1000000</span>
❯ docker run -dit --name nginx --rm nginx:1.19-alpine 

<span class="c1">#　查看网络接口，有两个 veth 接口（而且都没设 ip 地址），分别连接到两个容器的 eth0（dcoker0 网络架构图前面给过了，可以往前面翻翻对照下）</span>
❯ ip addr ls
...
5: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue state UP group default 
    link/ether 02:42:42:c7:12:ba brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:42ff:fec7:12ba/64 scope link 
       valid_lft forever preferred_lft forever
100: veth16b37ea@if99: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue master docker0 state UP group default 
    link/ether 42:af:34:ae:74:ae brd ff:ff:ff:ff:ff:ff link-netnsid <span class="m">0</span>
    inet6 fe80::40af:34ff:feae:74ae/64 scope link 
       valid_lft forever preferred_lft forever
102: veth4b4dada@if101: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue master docker0 state UP group default 
    link/ether 9e:f1:58:1a:cf:ae brd ff:ff:ff:ff:ff:ff link-netnsid <span class="m">1</span>
    inet6 fe80::9cf1:58ff:fe1a:cfae/64 scope link 
       valid_lft forever preferred_lft forever

<span class="c1"># 两个 veth 接口都连接到了 docker0 上面，说明两个容器都使用了 docker 默认的 bridge 网络</span>
❯ sudo brctl show
bridge name     bridge id               STP enabled     interfaces
docker0         8000.024242c712ba       no              veth16b37ea
                                                        veth4b4dada

<span class="c1"># 查看路由规则</span>
❯ ip route ls
default via 192.168.31.1 dev wlp4s0 proto dhcp metric <span class="m">600</span>
<span class="c1">#下列路由规则将 `172.17.0.0/16` 网段的所有流量转发到 docker0</span>
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
192.168.31.0/24 dev wlp4s0 proto kernel scope link src 192.168.31.228 metric <span class="m">600</span> 

<span class="c1"># 查看　iptables 规则</span>
<span class="c1"># NAT 表</span>
❯ sudo iptables -t nat -S
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P OUTPUT ACCEPT
-P POSTROUTING ACCEPT
-N DOCKER
<span class="c1"># 所有目的地址在本机的，都先交给 DOCKER 链处理一波</span>
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
<span class="c1"># （容器访问外部网络）所有出口不为 docker0 的流量，都做下 SNAT，把 src ip 换成出口接口的 ip 地址</span>
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A DOCKER -i docker0 -j RETURN

<span class="c1"># filter 表</span>
❯ sudo iptables -t filter -S
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
-N DOCKER
-N DOCKER-ISOLATION-STAGE-1
-N DOCKER-ISOLATION-STAGE-2
-N DOCKER-USER
<span class="c1"># 所有流量都必须先经过如下两个表处理，没问题才能继续往下走</span>
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
-A FORWARD -j DOCKER-USER
<span class="c1"># （容器访问外部网络）出去的流量走了 MASQUERADE，回来的流量会被 conntrack 识别并转发回来，这里允许返回的数据包通过。</span>
<span class="c1"># 这里直接 ACCEPT 被 conntrack 识别到的流量</span>
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
<span class="c1"># 将所有访问 docker0 的流量都转给自定义链 DOCKER 处理</span>
-A FORWARD -o docker0 -j DOCKER
<span class="c1"># 允许所有来自 docker0 的流量通过，不论下一跳是否是 docker0</span>
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
<span class="c1"># 下面三个表目前啥规则也没有，就是简单的 RETURN，交给后面的表继续处理</span>
-A DOCKER-ISOLATION-STAGE-1 -j RETURN
-A DOCKER-ISOLATION-STAGE-2 -j RETURN
-A DOCKER-USER -j RETURN
</code></pre></td></tr></table>
</div>
</div><p>接下来使用如下 docker-compose 配置启动一个 caddy　容器，添加自定义 network 和端口映射，待会就能验证 docker 是如何实现这两种网络的了。</p>
<p><code>docker-compose.yml</code> 内容：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;3.3&#34;</span><span class="w">
</span><span class="w"></span><span class="nt">services</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">caddy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;caddy:2.2.1-alpine&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">container_name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;caddy&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">restart</span><span class="p">:</span><span class="w"> </span><span class="l">always</span><span class="w">
</span><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="l">caddy file-server --browse --root /data/static</span><span class="w">
</span><span class="w">    </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="s2">&#34;8081:80&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="s2">&#34;/home/ryan/Downloads:/data/static&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">networks</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="l">caddy-1</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">networks</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">caddy-1</span><span class="p">:</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>现在先用上面的配置启动 caddy 容器，然后再查看网络状况：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 启动 caddy</span>
❯ docker-compose up -d
<span class="c1"># 查下 caddy 容器的 ip</span>
&gt; docker inspect caddy <span class="p">|</span> grep IPAddress
...
    <span class="s2">&#34;IPAddress&#34;</span>: <span class="s2">&#34;172.18.0.2&#34;</span>,

<span class="c1"># 查看网络接口，可以看到多了一个网桥，它就是上一行命令创建的 caddy-1 网络</span>
<span class="c1"># 还多了一个 veth，它连接到了 caddy 容器的 eth0(veth) 接口</span>
❯ ip addr ls
...
5: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue state UP group default 
    link/ether 02:42:42:c7:12:ba brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:42ff:fec7:12ba/64 scope link 
       valid_lft forever preferred_lft forever
100: veth16b37ea@if99: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue master docker0 state UP group default 
    link/ether 42:af:34:ae:74:ae brd ff:ff:ff:ff:ff:ff link-netnsid <span class="m">0</span>
    inet6 fe80::40af:34ff:feae:74ae/64 scope link 
       valid_lft forever preferred_lft forever
102: veth4b4dada@if101: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue master docker0 state UP group default 
    link/ether 9e:f1:58:1a:cf:ae brd ff:ff:ff:ff:ff:ff link-netnsid <span class="m">1</span>
    inet6 fe80::9cf1:58ff:fe1a:cfae/64 scope link 
       valid_lft forever preferred_lft forever
103: br-ac3e0514d837: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue state UP group default 
    link/ether 02:42:7d:95:ba:7e brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-ac3e0514d837
       valid_lft forever preferred_lft forever
    inet6 fe80::42:7dff:fe95:ba7e/64 scope link 
       valid_lft forever preferred_lft forever
105: veth0c25c6f@if104: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue master br-ac3e0514d837 state UP group default 
    link/ether 9a:03:e1:f0:26:ea brd ff:ff:ff:ff:ff:ff link-netnsid <span class="m">2</span>
    inet6 fe80::9803:e1ff:fef0:26ea/64 scope link 
       valid_lft forever preferred_lft forever


<span class="c1"># 查看网桥，能看到 caddy 容器的 veth 接口连在了 caddy-1 这个网桥上，没有加入到 docker0 网络</span>
❯ sudo brctl show
bridge name     bridge id               STP enabled     interfaces
br-ac3e0514d837         8000.02427d95ba7e       no              veth0c25c6f
docker0         8000.024242c712ba       no              veth16b37ea
                                                        veth4b4dada

<span class="c1"># 查看路由，能看到新网桥使用的地址段是 172.18.0.0/16，是 docker0 递增上来的 </span>
❯ ip route ls
default via 192.168.31.1 dev wlp4s0 proto dhcp metric <span class="m">600</span> 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 
<span class="c1"># 多了一个网桥的</span>
172.18.0.0/16 dev br-ac3e0514d837 proto kernel scope link src 172.18.0.1 
192.168.31.0/24 dev wlp4s0 proto kernel scope link src 192.168.31.228 metric <span class="m">600</span> 

<span class="c1"># iptables 中也多了 caddy-1 网桥的 MASQUERADE 规则，以及端口映射的规则</span>
❯ sudo iptables -t nat -S
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P OUTPUT ACCEPT
-P POSTROUTING ACCEPT
-N DOCKER
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -s 172.18.0.0/16 ! -o br-ac3e0514d837 -j MASQUERADE
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
<span class="c1"># 端口映射过来的入网流量，都做下 SNAT，把 src ip 换成出口 docker0 的 ip 地址</span>
-A POSTROUTING -s 172.18.0.2/32 -d 172.18.0.2/32 -p tcp -m tcp --dport <span class="m">80</span> -j MASQUERADE
-A DOCKER -i br-ac3e0514d837 -j RETURN
-A DOCKER -i docker0 -j RETURN
<span class="c1"># 主机上所有其他接口进来的 tcp 流量，只要目标端口是 8081，就转发到 caddy 容器去（端口映射）</span>
<span class="c1"># DOCKER 是被 PREROUTEING 链的 target，因此这会导致流量直接走了 FORWARD 链，直接绕过了通常设置在 INPUT 链的主机防火墙规则！</span>
-A DOCKER ! -i br-ac3e0514d837 -p tcp -m tcp --dport <span class="m">8081</span> -j DNAT --to-destination 172.18.0.2:80

❯ sudo iptables -t filter -S
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
-N DOCKER
-N DOCKER-ISOLATION-STAGE-1
-N DOCKER-ISOLATION-STAGE-2
-N DOCKER-USER
-A FORWARD -j DOCKER-USER
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
<span class="c1"># 给 caddy-1 bridge 网络添加的转发规则，与 docker0 的规则完全一一对应，就不多介绍了。</span>
-A FORWARD -o br-ac3e0514d837 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o br-ac3e0514d837 -j DOCKER
-A FORWARD -i br-ac3e0514d837 ! -o br-ac3e0514d837 -j ACCEPT
-A FORWARD -i br-ac3e0514d837 -o br-ac3e0514d837 -j ACCEPT
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
<span class="c1"># 这一条仍然是端口映射相关的规则，接受所有从其他接口过来的，请求 80 端口且出口是 caddy-1 网桥的流量</span>
-A DOCKER -d 172.18.0.2/32 ! -i br-ac3e0514d837 -o br-ac3e0514d837 -p tcp -m tcp --dport <span class="m">80</span> -j ACCEPT
<span class="c1"># 当存在多个 bridge 网络的时候，docker 就会在下面两个 STAGE 链中处理将它们隔离开，禁止互相访问</span>
-A DOCKER-ISOLATION-STAGE-1 -i br-ac3e0514d837 ! -o br-ac3e0514d837 -j DOCKER-ISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -i docker0 ! -o docker0 -j DOCKER-ISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -j RETURN
<span class="c1"># 这里延续上面 STAGE-1 的处理，彻底隔离两个网桥的流量</span>
-A DOCKER-ISOLATION-STAGE-2 -o br-ac3e0514d837 -j DROP
-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP
-A DOCKER-ISOLATION-STAGE-2 -j RETURN
-A DOCKER-USER -j RETURN
</code></pre></td></tr></table>
</div>
</div><p>到这里，我们简单地分析了下 docker 如何通过 iptables 实现 bridge 网络和端口映射。
有了这个基础，后面就可以尝试深入分析 kubernetes 网络插件 flannel/calico/cilium 了哈哈。</p>
<h2 id="rootless-容器的网络实现">Rootless 容器的网络实现</h2>
<p>如果容器运行时也在 Rootless 模式下运行，那它就没有权限在宿主机添加 bridge/veth 等虚拟网络接口，这种情况下，我们前面描述的容器网络就无法设置了。</p>
<p>那么 podman/containerd(nerdctl) 目前是如何在 Rootless 模式下构建容器网络的呢？</p>
<p>查看文档，发现它们都用到了 rootlesskit 相关的东西，而 rootlesskit 提供了 rootless 网络的几个实现，文档参见 <a href="https://github.com/rootless-containers/rootlesskit/blob/master/docs/network.md" target="_blank" rel="noopener noreferrer">rootlesskit/docs/network.md</a></p>
<p>其中目前推荐使用，而且 podman/containerd(nerdctl) 都默认使用的方案，是 <a href="https://github.com/rootless-containers/slirp4netns" target="_blank" rel="noopener noreferrer">rootless-containers/slirp4netns</a></p>
<p>以 containerd(nerdctl) 为例，按官方文档安装好后，随便启动几个容器，然后在宿主机查 <code>iptables</code>/<code>ip addr ls</code>，会发现啥也没有。
这显然是因为 rootless 模式下 containerd 改不了宿主机的 iptables 配置和虚拟网络接口。但是可以查看到宿主机 slirp4netns 在后台运行：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">❯ ps aux <span class="p">|</span> grep tap
ryan     <span class="m">11644</span>  0.0  0.0   <span class="m">5288</span>  <span class="m">3312</span> ?        S    00:01   0:02 slirp4netns --mtu <span class="m">65520</span> -r <span class="m">3</span> --disable-host-loopback --enable-sandbox --enable-seccomp <span class="m">11625</span> tap0
</code></pre></td></tr></table>
</div>
</div><p>但是我看半天文档，只看到怎么使用 <code>rootlesskit</code>/<code>slirp4netns</code> 创建新的名字空间，没看到有介绍如何进入一个已存在的 <code>slirp4netns</code> 名字空间&hellip;</p>
<p>使用 <code>nsenter -a -t 11644</code> 也一直报错，任何程序都是 <code>no such binary</code>&hellip;</p>
<p>以后有空再重新研究一波&hellip;</p>
<p>总之能确定的是，它通过在虚拟的名字空间中创建了一个 <code>tap</code> 虚拟接口来实现容器网络，性能相比前面介绍的网络多少是要差一点的。</p>
<h2 id="nftables">nftables</h2>
<p>前面介绍了 iptables 以及其在 docker 和防火墙上的应用。但是实际上目前各大 Linux 发行版都已经不建议使用 iptables 了，甚至把 iptables 重命名为了 <code>iptables-leagacy</code>.</p>
<p>目前 opensuse/debian/opensuse 都已经预装了并且推荐使用 nftables，<strong>而且 firewalld 已经默认使用 nftables 作为它的后端了</strong>。</p>
<p>我在 opensuse tumbleweed 上实测，firewalld 添加的是 nftables 配置，而 docker 仍然在用旧的 iptables，也就是说我现在的机器上有两套 netfilter 工具并存：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># 查看 iptables 数据
&gt; iptables -S
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
-N DOCKER
-N DOCKER-ISOLATION-STAGE-1
-N DOCKER-ISOLATION-STAGE-2
-N DOCKER-USER
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
-A FORWARD -o br-e3fbbb7a1b3a -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o br-e3fbbb7a1b3a -j DOCKER
...

# 确认下是否使用了 nftables 的兼容层，结果提示请我使用 iptables-legacy
&gt; iptables-nft -S
# Warning: iptables-legacy tables present, use iptables-legacy to see them
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT

# 查看 nftables 规则，能看到三张 firewalld 生成的 table
&gt; nft list ruleset
table inet firewalld {
    ...
}
table ip firewalld {
    ...
}
table ip6 firewalld {
    ...
}
</code></pre></td></tr></table>
</div>
</div><p>但是现在 kubernetes/docker 都还是用的 iptables，nftables 我学了用处不大，以后有空再补充。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://www.zsythink.net/archives/1199" target="_blank" rel="noopener noreferrer">iptables详解（1）：iptables概念</a></li>
<li><a href="https://linux.cn/article-13364-1.html" target="_blank" rel="noopener noreferrer">网络地址转换（NAT）之报文跟踪</a></li>
<li><a href="https://developer.aliyun.com/article/700923" target="_blank" rel="noopener noreferrer">容器安全拾遗 - Rootless Container初探</a></li>
<li><a href="https://en.wikipedia.org/wiki/Netfilter" target="_blank" rel="noopener noreferrer">netfilter - wikipedia</a></li>
</ul>
]]></description></item><item><title>Linux 中的虚拟网络接口</title><link>https://ryan4yin.space/posts/linux-virtual-network-interfaces/</link><pubDate>Sat, 14 Aug 2021 11:13:03 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/linux-virtual-network-interfaces/</guid><description><![CDATA[<blockquote>
<p>本文用到的字符画工具：<a href="https://github.com/zenghongtu/vscode-asciiflow2" target="_blank" rel="noopener noreferrer">vscode-asciiflow2</a></p>
</blockquote>
<blockquote>
<p>注意: 本文中使用 <code>ip</code> 命令创建或修改的任何网络配置，都是未持久化的，主机重启即消失。</p>
</blockquote>
<p>Linux 具有强大的虚拟网络能力，这也是 openstack 网络、docker 容器网络以及 kubernetes 网络等虚拟网络的基础。</p>
<p>这里介绍 Linux 常用的虚拟网络接口类型：TUN/TAP、bridge、veth、ipvlan/macvlan、vlan 以及 vxlan/geneve.</p>
<h2 id="一tuntap-虚拟网络接口">一、tun/tap 虚拟网络接口</h2>
<p>tun/tap 是操作系统内核中的虚拟网络设备，他们为用户层程序提供数据的接收与传输。</p>
<p>普通的物理网络接口如 eth0，它的两端分别是内核协议栈和外面的物理网络。</p>
<p>而对于 TUN/TAP 虚拟接口如 tun0，它的一端一定是连接的用户层程序，另一端则视配置方式的不同而变化，可以直连内核协议栈，也可以是某个 bridge（后面会介绍）。
Linux 通过内核模块 TUN 提供 tun/tap 功能，该模块提供了一个设备接口 <code>/dev/net/tun</code> 供用户层程序读写，用户层程序通过 <code>/dev/net/tun</code> 读写主机内核协议栈的数据。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">&gt; modinfo tun
filename:       /lib/modules/5.13.6-1-default/kernel/drivers/net/tun.ko.xz
alias:          devname:net/tun
alias:          char-major-10-200
license:        GPL
author:         (C) 1999-2004 Max Krasnyansky &lt;maxk@qualcomm.com&gt;
description:    Universal TUN/TAP device driver
...

&gt; ls /dev/net/tun
/dev/net/tun
</code></pre></td></tr></table>
</div>
</div><p>一个 TUN 设备的示例图如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">             
+----------------------------------------------------------------------+
|                                                                      |
|  +--------------------+      +--------------------+                  |
|  | User Application A |      | User Application B +&lt;-----+           |
|  +------------+-------+      +-------+------------+      |           |
|               | 1                    | 5                 |           |
|...............+......................+...................|...........|
|               ↓                      ↓                   |           |
|         +----------+           +----------+              |           |
|         | socket A |           | socket B |              |           |
|         +-------+--+           +--+-------+              |           |
|                 | 2               | 6                    |           |
|.................+.................+......................|...........|
|                 ↓                 ↓                      |           |
|             +------------------------+          +--------+-------+   |
|             | Network Protocol Stack |          |  /dev/net/tun  |   |
|             +--+-------------------+-+          +--------+-------+   |
|                | 7                 | 3                   ^           |
|................+...................+.....................|...........|
|                ↓                   ↓                     |           |
|        +----------------+    +----------------+        4 |           |
|        |      eth0      |    |      tun0      |          |           |
|        +-------+--------+    +-----+----------+          |           |
|    10.32.0.11  |                   |   192.168.3.11      |           |
|                | 8                 +---------------------+           |
|                |                                                     |
+----------------+-----------------------------------------------------+
                 ↓
         Physical Network
</code></pre></td></tr></table>
</div>
</div><p>因为 TUN/TAP 设备的一端是内核协议栈，显然流入 tun0 的数据包是先经过本地的路由规则匹配的。</p>
<p>路由匹配成功，数据包被发送到 tun0 后，tun0 发现另一端是通过 <code>/dev/net/tun</code> 连接到应用程序 B，就会将数据丢给应用程序 B。</p>
<p>应用程序对数据包进行处理后，可能会构造新的数据包，通过物理网卡发送出去。比如常见的 VPN 程序就是把原来的数据包封装/加密一遍，再发送给 VPN 服务器。</p>
<h3 id="c-语言编程测试-tun-设备">C 语言编程测试 TUN 设备</h3>
<p>为了使用 tun/tap 设备，用户层程序需要通过系统调用打开 <code>/dev/net/tun</code> 获得一个读写该设备的文件描述符(FD)，并且调用 <code>ioctl()</code> 向内核注册一个 TUN 或 TAP 类型的虚拟网卡(实例化一个 tun/tap 设备)，其名称可能是 <code>tun0/tap0</code> 等。</p>
<p>此后，用户程序可以通过该 TUN/TAP 虚拟网卡与主机内核协议栈（或者其他网络设备）交互。当用户层程序关闭后，其注册的 TUN/TAP 虚拟网卡以及自动生成的路由表相关条目都会被内核释放。</p>
<p>可以把用户层程序看做是网络上另一台主机，他们通过 tun/tap 虚拟网卡相连。</p>
<p>一个简单的 C 程序示例如下，它每次收到数据后，都只单纯地打印一下收到的字节数：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-c" data-lang="c"><span class="cp">#include</span> <span class="cpf">&lt;linux/if.h&gt;</span><span class="cp">
</span><span class="cp">#include</span> <span class="cpf">&lt;linux/if_tun.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;sys/ioctl.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;fcntl.h&gt;</span><span class="cp">
</span><span class="cp">#include</span> <span class="cpf">&lt;string.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
</span><span class="cp">#include</span><span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
</span><span class="cp">#include</span><span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="kt">int</span> <span class="nf">tun_alloc</span><span class="p">(</span><span class="kt">int</span> <span class="n">flags</span><span class="p">)</span>
<span class="p">{</span>

    <span class="k">struct</span> <span class="n">ifreq</span> <span class="n">ifr</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">fd</span><span class="p">,</span> <span class="n">err</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">clonedev</span> <span class="o">=</span> <span class="s">&#34;/dev/net/tun&#34;</span><span class="p">;</span>

    <span class="c1">// 打开 tun 文件，获得 fd
</span><span class="c1"></span>    <span class="k">if</span> <span class="p">((</span><span class="n">fd</span> <span class="o">=</span> <span class="n">open</span><span class="p">(</span><span class="n">clonedev</span><span class="p">,</span> <span class="n">O_RDWR</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">fd</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ifr</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">ifr</span><span class="p">));</span>
    <span class="n">ifr</span><span class="p">.</span><span class="n">ifr_flags</span> <span class="o">=</span> <span class="n">flags</span><span class="p">;</span>

    <span class="c1">// 向内核注册一个 TUN 网卡，并与前面拿到的 fd 关联起来
</span><span class="c1"></span>    <span class="c1">// 程序关闭时，注册的 tun 网卡及自动生成的相关路由策略，会被自动释放
</span><span class="c1"></span>    <span class="k">if</span> <span class="p">((</span><span class="n">err</span> <span class="o">=</span> <span class="n">ioctl</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="n">TUNSETIFF</span><span class="p">,</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">ifr</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">close</span><span class="p">(</span><span class="n">fd</span><span class="p">);</span>
        <span class="k">return</span> <span class="n">err</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">&#34;Open tun/tap device: %s for reading...</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">ifr</span><span class="p">.</span><span class="n">ifr_name</span><span class="p">);</span>

    <span class="k">return</span> <span class="n">fd</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>

    <span class="kt">int</span> <span class="n">tun_fd</span><span class="p">,</span> <span class="n">nread</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">buffer</span><span class="p">[</span><span class="mi">1500</span><span class="p">];</span>

    <span class="cm">/* Flags: IFF_TUN   - TUN device (no Ethernet headers)
</span><span class="cm">     *        IFF_TAP   - TAP device
</span><span class="cm">     *        IFF_NO_PI - Do not provide packet information
</span><span class="cm">     */</span>
    <span class="n">tun_fd</span> <span class="o">=</span> <span class="n">tun_alloc</span><span class="p">(</span><span class="n">IFF_TUN</span> <span class="o">|</span> <span class="n">IFF_NO_PI</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">tun_fd</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">perror</span><span class="p">(</span><span class="s">&#34;Allocating interface&#34;</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">nread</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">tun_fd</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">));</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">nread</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">perror</span><span class="p">(</span><span class="s">&#34;Reading from interface&#34;</span><span class="p">);</span>
            <span class="n">close</span><span class="p">(</span><span class="n">tun_fd</span><span class="p">);</span>
            <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">&#34;Read %d bytes from tun/tap device</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">nread</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p>接下来开启三个终端窗口来测试上述程序，分别运行上面的 tun 程序、tcpdump 和 iproute2 指令。</p>
<p>首先通过编译运行上述 c 程序，程序会阻塞住，等待数据到达：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># 编译，请忽略部分 warning
&gt; gcc mytun.c -o mytun

# 创建并监听 tun 设备需要 root 权限
&gt; sudo mytun 
Open tun/tap device: tun0 for reading...
</code></pre></td></tr></table>
</div>
</div><p>现在使用 iproute2 查看下链路层设备：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># 能发现最后面有列出名为 tun0 的接口，但是状态为 down
❯ ip addr ls
......
3: wlp4s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether c0:3c:59:36:a4:16 brd ff:ff:ff:ff:ff:ff
    inet 192.168.31.228/24 brd 192.168.31.255 scope global dynamic noprefixroute wlp4s0
       valid_lft 41010sec preferred_lft 41010sec
    inet6 fe80::4ab0:130f:423b:5d37/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever
7: tun0: &lt;POINTOPOINT,MULTICAST,NOARP&gt; mtu 1500 qdisc noop state DOWN group default qlen 500
    link/none 

# 为 tun0 设置 ip 地址，注意不要和其他接口在同一网段，会导致路由冲突
&gt; sudo ip addr add 172.21.22.23/24 dev tun0
# 启动 tun0 这个接口，这一步会自动向路由表中添加将 172.21.22.23/24 路由到 tun0 的策略
&gt; sudo ip link set tun0 up
#确认上一步添加的路由策略是否存在
❯ ip route ls
default via 192.168.31.1 dev wlp4s0 proto dhcp metric 600 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
172.21.22.0/24 dev tun0 proto kernel scope link src 172.21.22.23 
192.168.31.0/24 dev wlp4s0 proto kernel scope link src 192.168.31.228 metric 600 

# 此时再查看接口，发现 tun0 状态为 unknown
&gt; ip addr ls
......
8: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500
    link/none 
    inet 172.21.22.23/24 scope global tun0
       valid_lft forever preferred_lft forever
    inet6 fe80::3d52:49b5:1cf3:38fd/64 scope link stable-privacy 
       valid_lft forever preferred_lft forever

# 使用 tcpdump 尝试抓下 tun0 的数据，会阻塞在这里，等待数据到达
&gt; tcpdump -i tun0
</code></pre></td></tr></table>
</div>
</div><p>现在再启动第三个窗口发点数据给 tun0，持续观察前面 <code>tcpdump</code> 和 <code>mytun</code> 的日志:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># 直接 ping tun0 的地址，貌似有问题，数据没进 mytun 程序，而且还有响应
❯ ping -c 4 172.21.22.23
PING 172.21.22.23 (172.21.22.23) 56(84) bytes of data.
64 bytes from 172.21.22.23: icmp_seq=1 ttl=64 time=0.167 ms
64 bytes from 172.21.22.23: icmp_seq=2 ttl=64 time=0.180 ms
64 bytes from 172.21.22.23: icmp_seq=3 ttl=64 time=0.126 ms
64 bytes from 172.21.22.23: icmp_seq=4 ttl=64 time=0.141 ms

--- 172.21.22.23 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3060ms
rtt min/avg/max/mdev = 0.126/0.153/0.180/0.021 ms

# 但是 ping 该网段下的其他地址，流量就会被转发给 mytun 程序，因为 mytun 啥数据也没回，自然丢包率 100%
# tcpdump 和 mytun 都会打印出相关日志
❯ ping -c 4 172.21.22.26
PING 172.21.22.26 (172.21.22.26) 56(84) bytes of data.

--- 172.21.22.26 ping statistics ---
4 packets transmitted, 0 received, 100% packet loss, time 3055ms
</code></pre></td></tr></table>
</div>
</div><p>下面给出 mytun 的输出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">Read 84 bytes from tun/tap device
Read 84 bytes from tun/tap device
Read 84 bytes from tun/tap device
Read 84 bytes from tun/tap device
</code></pre></td></tr></table>
</div>
</div><p>以及 tcpdump 的输出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">00:22:03.622684 IP (tos 0x0, ttl 64, id 37341, offset 0, flags [DF], proto ICMP (1), length 84)
    172.21.22.23 &gt; 172.21.22.26: ICMP echo request, id 11, seq 1, length 64
00:22:04.633394 IP (tos 0x0, ttl 64, id 37522, offset 0, flags [DF], proto ICMP (1), length 84)
    172.21.22.23 &gt; 172.21.22.26: ICMP echo request, id 11, seq 2, length 64
00:22:05.653356 IP (tos 0x0, ttl 64, id 37637, offset 0, flags [DF], proto ICMP (1), length 84)
    172.21.22.23 &gt; 172.21.22.26: ICMP echo request, id 11, seq 3, length 64
00:22:06.677341 IP (tos 0x0, ttl 64, id 37667, offset 0, flags [DF], proto ICMP (1), length 84)
    172.21.22.23 &gt; 172.21.22.26: ICMP echo request, id 11, seq 4, length 64
</code></pre></td></tr></table>
</div>
</div><p>更复杂的 tun 程序，可以参考</p>
<ul>
<li><a href="https://github.com/gregnietsky/simpletun" target="_blank" rel="noopener noreferrer">simpletun</a></li>
<li><a href="https://github.com/marywangran/simpletun" target="_blank" rel="noopener noreferrer">marywangran/simpletun</a></li>
<li><a href="https://github.com/marywangran/gotun-tunnel/blob/main/tun/tun.go" target="_blank" rel="noopener noreferrer">tun go 语言版</a></li>
</ul>
<h3 id="tun-与-tap-的区别">TUN 与 TAP 的区别</h3>
<p>TUN 和 TAP 的区别在于工作的网络层次不同，用户程序通过 TUN 设备只能读写网络层的 IP 数据包，而 TAP 设备则支持读写链路层的数据包（通常是以太网数据包，带有 Ethernet headers）。</p>
<p>TUN 与 TAP 的关系，就类似于 socket 和 raw socket.</p>
<p>TUN/TAP 应用最多的场景是 VPN 代理，比如:</p>
<ol>
<li><a href="https://github.com/ryan4yin/clash" target="_blank" rel="noopener noreferrer">clash</a>: 一个支持各种规则的隧道，也支持 TUN 模式</li>
<li><a href="https://github.com/xjasonlyu/tun2socks/wiki" target="_blank" rel="noopener noreferrer">tun2socks</a>: 一个全局透明代理，和 VPN 的工作模式一样，它通过创建虚拟网卡+修改路由表，在第三层网络层代理系统流量。</li>
</ol>
<h2 id="二veth">二、veth</h2>
<p>veth 接口总是成对出现，一对 veth 接口就类似一根网线，从一端进来的数据会从另一端出去。</p>
<p>同时 veth 又是一个虚拟网络接口，因此它和 TUN/TAP 或者其他物理网络接口一样，也都能配置 mac/ip 地址（但是并不是一定得配 mac/ip 地址）。</p>
<p>其主要作用就是连接不同的网络，比如在容器网络中，用于将容器的 namespace 与 root namespace 的网桥 br0 相连。
容器网络中，容器侧的 veth 自身设置了 ip/mac 地址并被重命名为 eth0，作为容器的网络接口使用，而主机侧的 veth 则直接连接在 docker0/br0 上面。</p>
<p>使用 veth 实现容器网络，需要结合下一小节介绍的 bridge，在下一小节将给出容器网络结构图。</p>
<h2 id="三bridge">三、bridge</h2>
<p>Linux Bridge 是工作在链路层的网络交换机，由 Linux 内核模块 <code>brige</code> 提供，它负责在所有连接到它的接口之间转发链路层数据包。</p>
<p>添加到 Bridge 上的设备被设置为只接受二层数据帧并且转发所有收到的数据包到 Bridge 中。
在 Bridge 中会进行一个类似物理交换机的查MAC端口映射表、转发、更新MAC端口映射表这样的处理逻辑，从而数据包可以被转发到另一个接口/丢弃/广播/发往上层协议栈，由此 Bridge 实现了数据转发的功能。</p>
<p>如果使用 tcpdump 在 Bridge 接口上抓包，可以抓到网桥上所有接口进出的包，因为这些数据包都要通过网桥进行转发。</p>
<p>与物理交换机不同的是，Bridge 本身可以设置 IP 地址，可以认为当使用 <code>brctl addbr br0</code> 新建一个 br0 网桥时，系统自动创建了一个同名的隐藏 <code>br0</code> 网络接口。<code>br0</code> 一旦设置 IP 地址，就意味着这个隐藏的 br0 接口可以作为路由接口设备，参与 IP 层的路由选择(可以使用 <code>route -n</code> 查看最后一列 <code>Iface</code>)。因此只有当 <code>br0</code> 设置 <code>IP</code> 地址时，Bridge 才有可能将数据包发往上层协议栈。</p>
<p>但被添加到 Bridge 上的网卡是不能配置 IP 地址的，他们工作在数据链路层，对路由系统不可见。</p>
<p>它常被用于在虚拟机、主机上不同的 namepsaces 之间转发数据。</p>
<h3 id="虚拟机场景桥接模式">虚拟机场景（桥接模式）</h3>
<p>以 qemu-kvm 为例，在虚拟机的桥接模式下，qemu-kvm 会为每个虚拟机创建一个 tun/tap 虚拟网卡并连接到 br0 网桥。
虚拟机内部的网络接口 <code>eth0</code> 是 qemu-kvm 软件模拟的，实际上虚拟机内网络数据的收发都会被 qemu-kvm 转换成对 <code>/dev/net/tun</code> 的读写。</p>
<p>以发送数据为例，整个流程如下：</p>
<ul>
<li>虚拟机发出去的数据包先到达 qemu-kvm 程序</li>
<li>数据被用户层程序 qemu-kvm 写入到 <code>/dev/net/tun</code>，到达 tap 设备</li>
<li>tap 设备把数据传送到 br0 网桥</li>
<li>br0 把数据交给 eth0 发送出去</li>
</ul>
<p>整个流程跑完，数据包都不需要经过宿主机的协议栈，效率高。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">+------------------------------------------------+-----------------------------------+-----------------------------------+
|                       Host                     |           VirtualMachine1         |           VirtualMachine2         |
|                                                |                                   |                                   |
|    +--------------------------------------+    |    +-------------------------+    |    +-------------------------+    |
|    |         Network Protocol Stack       |    |    |  Network Protocol Stack |    |    |  Network Protocol Stack |    |
|    +--------------------------------------+    |    +-------------------------+    |    +-------------------------+    |
|                       ↑                        |                ↑                  |                 ↑                 |
|.......................|........................|................|..................|.................|.................|
|                       ↓                        |                ↓                  |                 ↓                 |
|                  +--------+                    |            +-------+              |             +-------+             |
|                  | .3.101 |                    |            | .3.102|              |             | .3.103|             |
|     +------+     +--------+     +-------+      |            +-------+              |             +-------+             |
|     | eth0 |&lt;---&gt;|   br0  |&lt;---&gt;|tun/tap|      |            | eth0  |              |             | eth0  |             |
|     +------+     +--------+     +-------+      |            +-------+              |             +-------+             |
|         ↑             ↑             ↑      +--------+           ↑                  |                 ↑                 |
|         |             |             +------|qemu-kvm|-----------+                  |                 |                 |
|         |             ↓                    +--------+                              |                 |                 |
|         |         +-------+                    |                                   |                 |                 |
|         |         |tun/tap|                    |                                   |                 |                 |
|         |         +-------+                    |                                   |                 |                 |
|         |             ↑                        |            +--------+             |                 |                 |
|         |             +-------------------------------------|qemu-kvm|-------------|-----------------+                 |
|         |                                      |            +--------+             |                                   |
|         |                                      |                                   |                                   |
+---------|--------------------------------------+-----------------------------------+-----------------------------------+
          ↓
    Physical Network  (192.168.3.0/24)
</code></pre></td></tr></table>
</div>
</div><h3 id="跨-namespace-通信场景容器网络nat-模式">跨 namespace 通信场景（容器网络，NAT 模式）</h3>
<blockquote>
<p>docker/podman 提供的 bridge 网络模式，就是使用 veth+bridge+iptalbes 实现的。我会在下一篇文章详细介绍「容器网络」。</p>
</blockquote>
<p>由于容器运行在自己单独的 network namespace 里面，所以和虚拟机一样，它们也都有自己单独的协议栈。</p>
<p>容器网络的结构和虚拟机差不多，但是它改用了 NAT 网络，并把 tun/tap 换成了 veth，导致 docker0 过来的数据，要先经过宿主机协议栈，然后才进入 veth 接口。</p>
<p>多了一层 NAT，以及多走了一层宿主机协议栈，都会导致性能下降。</p>
<p>示意图如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">+-----------------------------------------------+-----------------------------------+-----------------------------------+
|                      Host                     |           Container 1             |           Container 2             |
|                                               |                                   |                                   |
|   +---------------------------------------+   |    +-------------------------+    |    +-------------------------+    |
|   |       Network Protocol Stack          |   |    |  Network Protocol Stack |    |    |  Network Protocol Stack |    |
|   +----+-------------+--------------------+   |    +-----------+-------------+    |    +------------+------------+    |
|        ^             ^                        |                ^                  |                 ^                 |
|........|.............|........................|................|..................|.................|.................|
|        v             v  ↓                     |                v                  |                 v                 |
|   +----+----+  +-----+------+                 |          +-----+-------+          |           +-----+-------+         |
|   | .31.101 |  | 172.17.0.1 |      +------+   |          | 172.17.0.2  |          |           |  172.17.0.3 |         |
|   +---------+  +-------------&lt;----&gt;+ veth |   |          +-------------+          |           +-------------+         |
|   |  eth0   |  |   docker0  |      +--+---+   |          | eth0(veth)  |          |           | eth0(veth)  |         |
|   +----+----+  +-----+------+         ^       |          +-----+-------+          |           +-----+-------+         |
|        ^             ^                |       |                ^                  |                 ^                 |
|        |             |                +------------------------+                  |                 |                 |
|        |             v                        |                                   |                 |                 |
|        |          +--+---+                    |                                   |                 |                 |
|        |          | veth |                    |                                   |                 |                 |
|        |          +--+---+                    |                                   |                 |                 |
|        |             ^                        |                                   |                 |                 |
|        |             +------------------------------------------------------------------------------+                 |
|        |                                      |                                   |                                   |
|        |                                      |                                   |                                   |
+-----------------------------------------------+-----------------------------------+-----------------------------------+
         v
    Physical Network  (192.168.31.0/24)
</code></pre></td></tr></table>
</div>
</div><p>每创建一个新容器，都会在容器的 namespace 里新建一个 veth 接口并命令为 eth0，同时在主 namespace 创建一个 veth，将容器的 eth0 与 docker0 连接。</p>
<p>可以在容器中通过 iproute2 查看到， eth0 的接口类型为 <code>veth</code>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">❯ docker run -it --rm debian:buster bash
root@5facbe4ddc1e:/# ip --details addr ls
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class="m">65536</span> qdisc noqueue state UNKNOWN group default qlen <span class="m">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity <span class="m">0</span> minmtu <span class="m">0</span> maxmtu <span class="m">0</span> numtxqueues <span class="m">1</span> numrxqueues <span class="m">1</span> gso_max_size <span class="m">65536</span> gso_max_segs <span class="m">65535</span> 
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
20: eth0@if21: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc noqueue state UP group default 
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid <span class="m">0</span> promiscuity <span class="m">0</span> minmtu <span class="m">68</span> maxmtu <span class="m">65535</span> 
    veth numtxqueues <span class="m">1</span> numrxqueues <span class="m">1</span> gso_max_size <span class="m">65536</span> gso_max_segs <span class="m">65535</span> 
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre></td></tr></table>
</div>
</div><p>同时在宿主机中能看到对应的 veth 设备是绑定到了 docker0 网桥的：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">❯ sudo brctl show
bridge name     bridge id               STP enabled     interfaces
docker0         8000.0242fce99ef5       no              vethea4171a
</code></pre></td></tr></table>
</div>
</div><h2 id="四macvlan">四、macvlan</h2>
<blockquote>
<p>目前 docker/podman 都支持使用 <code>--driver macvlan</code> 来使用 <code>macvlan</code> 创建容器网络。</p>
</blockquote>
<blockquote>
<p><a href="https://docs.docker.com/network/macvlan/" target="_blank" rel="noopener noreferrer">Use macvlan networks - Docker Docs</a></p>
</blockquote>
<blockquote>
<p>参考文档：<a href="https://cizixs.com/2017/02/14/network-virtualization-macvlan/" target="_blank" rel="noopener noreferrer">linux 网络虚拟化： macvlan</a></p>
</blockquote>
<p>macvlan 是比较新的 Linux 特性，需要内核版本 &gt;= 3.9，它被用于在主机的网络接口（父接口）上配置多个虚拟子接口，这些子接口都拥有各自独立的 mac 地址，也可以配上 ip 地址进行通讯。</p>
<p>macvlan 下的虚拟机或者容器网络和主机在同一个网段中，共享同一个广播域。macvlan 和 bridge 比较相似，但因为它省去了 bridge 的存在，所以配置和调试起来比较简单，而且效率也相对高。除此之外，macvlan 自身也完美支持 VLAN。</p>
<p>如果希望容器或者虚拟机放在主机相同的网络中，享受已经存在网络栈的各种优势，可以考虑 macvlan。</p>
<h2 id="五ipvlan">五、ipvlan</h2>
<blockquote>
<p>目前 docker 已支持使用 <code>--driver ipvlan</code> 来使用 <code>ipvlan</code> 创建容器网络，<a href="https://github.com/containers/podman/issues/10478" target="_blank" rel="noopener noreferrer">podman 正计划支持</a>.
<a href="https://docs.docker.com/network/ipvlan/" target="_blank" rel="noopener noreferrer">Use ipvlan networks - Docker Docs</a>
<a href="https://cizixs.com/2017/02/17/network-virtualization-ipvlan/" target="_blank" rel="noopener noreferrer">linux 网络虚拟化： ipvlan</a></p>
</blockquote>
<p>ipvlan 和 macvlan 的功能很类似，也是用于在主机的网络接口（父接口）上配置出多个虚拟的子接口。但不同的是，ipvlan 的各子接口没有独立的 mac 地址，它们和主机的父接口共享 mac 地址。</p>
<blockquote>
<p>因为 mac 地址共享，所以如果使用 DHCP，就要注意不能使用 mac 地址做 DHCP，需要额外配置唯一的 clientID.</p>
</blockquote>
<p>如果你遇到以下的情况，请考虑使用 ipvlan：</p>
<ul>
<li>父接口对 mac 地址数目有限制，或者在 mac 地址过多的情况下会造成严重的性能损失</li>
<li>工作在 802.11(wireless)无线网络中（macvlan 无法和无线网络共同工作）</li>
<li>希望搭建比较复杂的网络拓扑（不是简单的二层网络和 VLAN），比如要和 BGP 网络一起工作</li>
</ul>
<h2 id="六vlan">六、vlan</h2>
<p>vlan 即虚拟局域网，是一个链路层的广播域隔离技术，可以用于切分局域网，解决广播泛滥和安全性问题。被隔离的广播域之间需要上升到第三层才能完成通讯。</p>
<p>常用的企业路由器如 ER-X 基本都可以设置 vlan，Linux 也直接支持了 vlan.</p>
<p>以太网数据包有一个专门的字段提供给 vlan 使用，vlan 数据包会在该位置记录它的 VLAN ID，交换机通过该 ID 来区分不同的 VLAN，只将该以太网报文广播到该 ID 对应的 VLAN 中。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 在主机的 eth0 接口上创建一个虚拟 vlan 接口 eth0.100</span>
ip link add link eth0 name eth0.100 <span class="nb">type</span> vlan id <span class="m">100</span>

</code></pre></td></tr></table>
</div>
</div><h2 id="七xvlangeneve">七、xvlan/geneve</h2>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/36165475" target="_blank" rel="noopener noreferrer">VXLAN vs VLAN</a></p>
</blockquote>
<blockquote>
<p><a href="https://datatracker.ietf.org/doc/html/rfc8926" target="_blank" rel="noopener noreferrer">rfc8926 - Geneve: Generic Network Virtualization Encapsulation</a>
<a href="https://datatracker.ietf.org/doc/html/rfc7348" target="_blank" rel="noopener noreferrer">rfc7348 - Virtual eXtensible Local Area Network (VXLAN)</a></p>
</blockquote>
<p>在介绍 vxlan 前，先说明下两个名词的含义：</p>
<ul>
<li><strong>underlay 网络</strong>：即物理网络</li>
<li><strong>overlay 网络</strong>：指在现有的物理网络之上构建的虚拟网络。其实就是一种隧道技术，将原生态的二层数据帧报文进行封装后通过隧道进行传输。</li>
</ul>
<p>vxlan 与 geneve 都是 overlay 网络协议，它俩都是使用 UDP 包来封装链路层的以太网帧。</p>
<p>vxlan 在 2014 年标准化，而 geneve 在 2020 年底才通过草案阶段，目前尚未形成最终标准。但是目前 linux/cilium 都已经支持了 geneve.</p>
<p>geneve 相对 vxlan 最大的变化，是它更灵活——它的 header 长度是可变的。</p>
<h2 id="五虚拟网络接口的速率">五、虚拟网络接口的速率</h2>
<p>Loopback 和本章讲到的其他虚拟网络接口一样，都是一种软件模拟的网络设备。
他们的速率是不是也像物理链路一样，存在链路层（比如以太网）的带宽限制呢？</p>
<p>比如目前很多老旧的网络设备，都是只支持到百兆以太网，这就决定了它的带宽上限。
即使是较新的设备，目前基本也都只支持到千兆，也就是 1GbE 以太网标准，那本文提到的虚拟网络接口单纯在本机内部通信，是否也存在这样的制约呢？是否也只能跑到 1GbE?</p>
<p>使用 ethtool 检查：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># docker 容器的 veth 接口速率
&gt; ethtool vethe899841 | grep Speed
        Speed: 10000Mb/s

# 网桥看起来没有固定的速率
&gt; ethtool docker0 | grep Speed
        Speed: Unknown!

# tun0 设备的默认速率貌似是 10Mb/s ?
&gt; ethtool tun0 | grep Speed
        Speed: 10Mb/s

# 此外 ethtool 无法检查 lo 以及 wifi 的速率
</code></pre></td></tr></table>
</div>
</div><h3 id="网络性能实测">网络性能实测</h3>
<p>接下来实际测试一下，先给出机器参数：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">❯ cat /etc/os-release 
NAME=&#34;openSUSE Tumbleweed&#34;
# VERSION=&#34;20210810&#34;
...

❯ uname -a
Linux legion-book 5.13.8-1-default #1 SMP Thu Aug 5 08:56:22 UTC 2021 (967c6a8) x86_64 x86_64 x86_64 GNU/Linux


❯ lscpu
Architecture:                    x86_64
CPU(s):                          16
Model name:                      AMD Ryzen 7 5800H with Radeon Graphics
...

# 内存，单位 MB
❯ free -m
               total        used        free      shared  buff/cache   available
Mem:           27929        4482       17324         249        6122       22797
Swap:           2048           0        2048
</code></pre></td></tr></table>
</div>
</div><p>使用 iperf3 测试：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 启动服务端</span>
iperf3 -s

-------------
<span class="c1"># 新窗口启动客户端，通过 loopback 接口访问 iperf3-server，大概 49Gb/s</span>
❯ iperf3 -c 127.0.0.1
Connecting to host 127.0.0.1, port <span class="m">5201</span>
<span class="o">[</span>  5<span class="o">]</span> <span class="nb">local</span> 127.0.0.1 port <span class="m">48656</span> connected to 127.0.0.1 port <span class="m">5201</span>
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr  Cwnd
<span class="o">[</span>  5<span class="o">]</span>   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   1.00-2.00   sec  4.61 GBytes  39.6 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   2.00-3.00   sec  5.69 GBytes  48.9 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   3.00-4.00   sec  6.11 GBytes  52.5 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   4.00-5.00   sec  6.04 GBytes  51.9 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   5.00-6.00   sec  6.05 GBytes  52.0 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   6.00-7.00   sec  6.01 GBytes  51.6 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   7.00-8.00   sec  6.05 GBytes  52.0 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   8.00-9.00   sec  6.34 GBytes  54.5 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   9.00-10.00  sec  5.91 GBytes  50.8 Gbits/sec    <span class="m">0</span>   1.62 MBytes       
- - - - - - - - - - - - - - - - - - - - - - - - -
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  57.3 GBytes  49.2 Gbits/sec    <span class="m">0</span>             sender
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  57.3 GBytes  49.2 Gbits/sec                  receiver

<span class="c1"># 客户端通过 wlp4s0 wifi 网卡(192.168.31.228)访问 iperf3-server，实际还是走的本机，但是速度要比 loopback 快一点，可能是默认设置的问题</span>
❯ iperf3 -c 192.168.31.228
Connecting to host 192.168.31.228, port <span class="m">5201</span>
<span class="o">[</span>  5<span class="o">]</span> <span class="nb">local</span> 192.168.31.228 port <span class="m">43430</span> connected to 192.168.31.228 port <span class="m">5201</span>
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr  Cwnd
<span class="o">[</span>  5<span class="o">]</span>   0.00-1.00   sec  5.12 GBytes  43.9 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   1.00-2.00   sec  5.29 GBytes  45.5 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   2.00-3.00   sec  5.92 GBytes  50.9 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   3.00-4.00   sec  6.00 GBytes  51.5 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   4.00-5.00   sec  5.98 GBytes  51.4 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   5.00-6.00   sec  6.05 GBytes  52.0 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   6.00-7.00   sec  6.16 GBytes  52.9 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   7.00-8.00   sec  6.08 GBytes  52.2 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   8.00-9.00   sec  6.00 GBytes  51.6 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   9.00-10.00  sec  6.01 GBytes  51.6 Gbits/sec    <span class="m">0</span>   1.25 MBytes       
- - - - - - - - - - - - - - - - - - - - - - - - -
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  58.6 GBytes  50.3 Gbits/sec    <span class="m">0</span>             sender
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  58.6 GBytes  50.3 Gbits/sec                  receiver

<span class="c1"># 从容器中访问宿主机的 iperf3-server，速度几乎没区别</span>
❯ docker run  -it --rm --name<span class="o">=</span>iperf3-server networkstatic/iperf3 -c 192.168.31.228
Connecting to host 192.168.31.228, port <span class="m">5201</span>
<span class="o">[</span>  5<span class="o">]</span> <span class="nb">local</span> 172.17.0.2 port <span class="m">43436</span> connected to 192.168.31.228 port <span class="m">5201</span>
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr  Cwnd
<span class="o">[</span>  5<span class="o">]</span>   0.00-1.00   sec  4.49 GBytes  38.5 Gbits/sec    <span class="m">0</span>    <span class="m">403</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   1.00-2.00   sec  5.31 GBytes  45.6 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   2.00-3.00   sec  6.14 GBytes  52.8 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   3.00-4.00   sec  5.85 GBytes  50.3 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   4.00-5.00   sec  6.14 GBytes  52.7 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   5.00-6.00   sec  5.99 GBytes  51.5 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   6.00-7.00   sec  5.86 GBytes  50.4 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   7.00-8.00   sec  6.05 GBytes  52.0 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   8.00-9.00   sec  5.99 GBytes  51.5 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   9.00-10.00  sec  6.12 GBytes  52.5 Gbits/sec    <span class="m">0</span>    <span class="m">544</span> KBytes       
- - - - - - - - - - - - - - - - - - - - - - - - -
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  58.0 GBytes  49.8 Gbits/sec    <span class="m">0</span>             sender
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  58.0 GBytes  49.8 Gbits/sec                  receiver
</code></pre></td></tr></table>
</div>
</div><p>把 iperf3-server 跑在容器里再测一遍：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 在容器中启动 iperf3-server，并映射到宿主机端口 6201</span>
&gt; docker run  -it --rm --name<span class="o">=</span>iperf3-server -p 6201:5201 networkstatic/iperf3 -s
&gt; docker inspect --format <span class="s2">&#34;{{ .NetworkSettings.IPAddress }}&#34;</span> iperf3-server
172.17.0.2
-----------------------------
<span class="c1"># 测试容器之间互访的速度，ip 为 iperf3-server 的容器 ip，速度要慢一些。</span>
<span class="c1"># 毕竟过了 veth -&gt; veth -&gt; docker0 -&gt; veth -&gt; veth 五层虚拟网络接口</span>
❯ docker run  -it --rm networkstatic/iperf3 -c 172.17.0.2
Connecting to host 172.17.0.2, port <span class="m">5201</span>
<span class="o">[</span>  5<span class="o">]</span> <span class="nb">local</span> 172.17.0.3 port <span class="m">40776</span> connected to 172.17.0.2 port <span class="m">5201</span>
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr  Cwnd
<span class="o">[</span>  5<span class="o">]</span>   0.00-1.00   sec  4.74 GBytes  40.7 Gbits/sec    <span class="m">0</span>    <span class="m">600</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   1.00-2.00   sec  4.48 GBytes  38.5 Gbits/sec    <span class="m">0</span>    <span class="m">600</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   2.00-3.00   sec  5.38 GBytes  46.2 Gbits/sec    <span class="m">0</span>    <span class="m">600</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   3.00-4.00   sec  5.39 GBytes  46.3 Gbits/sec    <span class="m">0</span>    <span class="m">600</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   4.00-5.00   sec  5.42 GBytes  46.6 Gbits/sec    <span class="m">0</span>    <span class="m">600</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   5.00-6.00   sec  5.39 GBytes  46.3 Gbits/sec    <span class="m">0</span>    <span class="m">600</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   6.00-7.00   sec  5.38 GBytes  46.2 Gbits/sec    <span class="m">0</span>    <span class="m">635</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   7.00-8.00   sec  5.37 GBytes  46.1 Gbits/sec    <span class="m">0</span>    <span class="m">667</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   8.00-9.00   sec  6.01 GBytes  51.7 Gbits/sec    <span class="m">0</span>    <span class="m">735</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   9.00-10.00  sec  5.74 GBytes  49.3 Gbits/sec    <span class="m">0</span>    <span class="m">735</span> KBytes       
- - - - - - - - - - - - - - - - - - - - - - - - -
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  53.3 GBytes  45.8 Gbits/sec    <span class="m">0</span>             sender
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  53.3 GBytes  45.8 Gbits/sec                  receiver

<span class="c1"># 本机直接访问容器 ip，走的是 docker0 网桥，居然还挺快</span>
❯ iperf3 -c 172.17.0.2
Connecting to host 172.17.0.2, port <span class="m">5201</span>
<span class="o">[</span>  5<span class="o">]</span> <span class="nb">local</span> 172.17.0.1 port <span class="m">56486</span> connected to 172.17.0.2 port <span class="m">5201</span>
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr  Cwnd
<span class="o">[</span>  5<span class="o">]</span>   0.00-1.00   sec  5.01 GBytes  43.0 Gbits/sec    <span class="m">0</span>    <span class="m">632</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   1.00-2.00   sec  5.19 GBytes  44.6 Gbits/sec    <span class="m">0</span>    <span class="m">703</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   2.00-3.00   sec  6.46 GBytes  55.5 Gbits/sec    <span class="m">0</span>    <span class="m">789</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   3.00-4.00   sec  6.80 GBytes  58.4 Gbits/sec    <span class="m">0</span>    <span class="m">789</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   4.00-5.00   sec  6.82 GBytes  58.6 Gbits/sec    <span class="m">0</span>    <span class="m">913</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   5.00-6.00   sec  6.79 GBytes  58.3 Gbits/sec    <span class="m">0</span>   <span class="m">1007</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   6.00-7.00   sec  6.63 GBytes  56.9 Gbits/sec    <span class="m">0</span>   1.04 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   7.00-8.00   sec  6.75 GBytes  58.0 Gbits/sec    <span class="m">0</span>   1.04 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   8.00-9.00   sec  6.19 GBytes  53.2 Gbits/sec    <span class="m">0</span>   1.04 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   9.00-10.00  sec  6.55 GBytes  56.3 Gbits/sec    <span class="m">0</span>   1.04 MBytes       
- - - - - - - - - - - - - - - - - - - - - - - - -
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  63.2 GBytes  54.3 Gbits/sec    <span class="m">0</span>             sender
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  63.2 GBytes  54.3 Gbits/sec                  receiver

<span class="c1"># 如果走本机 loopback 地址 + 容器端口映射，速度就慢了好多</span>
<span class="c1"># 或许是因为用 iptables 做端口映射导致的？</span>
❯ iperf3 -c 127.0.0.1 -p <span class="m">6201</span>
Connecting to host 127.0.0.1, port <span class="m">6201</span>
<span class="o">[</span>  5<span class="o">]</span> <span class="nb">local</span> 127.0.0.1 port <span class="m">48862</span> connected to 127.0.0.1 port <span class="m">6201</span>
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr  Cwnd
<span class="o">[</span>  5<span class="o">]</span>   0.00-1.00   sec  2.71 GBytes  23.3 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   1.00-2.00   sec  3.64 GBytes  31.3 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   2.00-3.00   sec  4.08 GBytes  35.0 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   3.00-4.00   sec  3.49 GBytes  30.0 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   4.00-5.00   sec  5.50 GBytes  47.2 Gbits/sec    <span class="m">2</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   5.00-6.00   sec  4.06 GBytes  34.9 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   6.00-7.00   sec  4.12 GBytes  35.4 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   7.00-8.00   sec  3.99 GBytes  34.3 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   8.00-9.00   sec  3.49 GBytes  30.0 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
<span class="o">[</span>  5<span class="o">]</span>   9.00-10.00  sec  5.51 GBytes  47.3 Gbits/sec    <span class="m">0</span>   1.37 MBytes       
- - - - - - - - - - - - - - - - - - - - - - - - -
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  40.6 GBytes  34.9 Gbits/sec    <span class="m">2</span>             sender
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  40.6 GBytes  34.9 Gbits/sec                  receiver

<span class="c1"># 可走 wlp4s0 + 容器端口映射，速度也不慢啊</span>
❯ iperf3 -c 192.168.31.228 -p <span class="m">6201</span>
Connecting to host 192.168.31.228, port <span class="m">6201</span>
<span class="o">[</span>  5<span class="o">]</span> <span class="nb">local</span> 192.168.31.228 port <span class="m">54582</span> connected to 192.168.31.228 port <span class="m">6201</span>
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr  Cwnd
<span class="o">[</span>  5<span class="o">]</span>   0.00-1.00   sec  4.34 GBytes  37.3 Gbits/sec    <span class="m">0</span>    <span class="m">795</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   1.00-2.00   sec  4.78 GBytes  41.0 Gbits/sec    <span class="m">0</span>    <span class="m">834</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   2.00-3.00   sec  6.26 GBytes  53.7 Gbits/sec    <span class="m">0</span>    <span class="m">834</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   3.00-4.00   sec  6.30 GBytes  54.1 Gbits/sec    <span class="m">0</span>    <span class="m">875</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   4.00-5.00   sec  6.26 GBytes  53.8 Gbits/sec    <span class="m">0</span>    <span class="m">875</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   5.00-6.00   sec  5.75 GBytes  49.4 Gbits/sec    <span class="m">0</span>    <span class="m">875</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   6.00-7.00   sec  5.49 GBytes  47.2 Gbits/sec    <span class="m">0</span>    <span class="m">966</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   7.00-8.00   sec  5.72 GBytes  49.1 Gbits/sec    <span class="m">2</span>    <span class="m">966</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   8.00-9.00   sec  4.81 GBytes  41.3 Gbits/sec    <span class="m">2</span>    <span class="m">966</span> KBytes       
<span class="o">[</span>  5<span class="o">]</span>   9.00-10.00  sec  5.98 GBytes  51.4 Gbits/sec    <span class="m">0</span>    <span class="m">966</span> KBytes       
- - - - - - - - - - - - - - - - - - - - - - - - -
<span class="o">[</span> ID<span class="o">]</span> Interval           Transfer     Bitrate         Retr
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  55.7 GBytes  47.8 Gbits/sec    <span class="m">4</span>             sender
<span class="o">[</span>  5<span class="o">]</span>   0.00-10.00  sec  55.7 GBytes  47.8 Gbits/sec                  receiver
</code></pre></td></tr></table>
</div>
</div><p>总的来看，loopback、bridge、veth 这几个接口基本上是没被限速的，veth 有查到上限为 10000Mb/s（10Gb/s） 感觉也是个假数字，
实际上测出来的数据基本在 35Gb/s 到 55Gb/s 之间，视情况浮动。</p>
<p>性能的变化和虚拟网络设备的链路和类型有关，或许和默认配置的区别也有关系。</p>
<p>另外 TUN 设备这里没有测，<code>ethtool tun0</code> 查到的值是比较离谱的 10Mb/s，但是感觉不太可能这么慢，有时间可以再测一波看看。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://segmentfault.com/a/1190000009249039" target="_blank" rel="noopener noreferrer">Linux虚拟网络设备之tun/tap</a></li>
<li><a href="https://segmentfault.com/a/1190000009251098" target="_blank" rel="noopener noreferrer">Linux虚拟网络设备之veth</a></li>
<li><a href="https://opengers.github.io/openstack/openstack-base-virtual-network-devices-bridge-and-vlan/" target="_blank" rel="noopener noreferrer">云计算底层技术-虚拟网络设备(Bridge,VLAN)</a></li>
<li><a href="https://opengers.github.io/openstack/openstack-base-virtual-network-devices-tuntap-veth/" target="_blank" rel="noopener noreferrer">云计算底层技术-虚拟网络设备(tun/tap,veth)</a></li>
<li><a href="https://www.kernel.org/doc/Documentation/networking/tuntap.txt" target="_blank" rel="noopener noreferrer">Universal TUN/TAP device driver - Kernel Docs</a></li>
<li><a href="https://backreference.org/2010/03/26/tuntap-interface-tutorial/" target="_blank" rel="noopener noreferrer">Tun/Tap interface tutorial</a></li>
<li><a href="https://stackoverflow.com/questions/5832308/linux-loopback-performance-with-tcp-nodelay-enabled" target="_blank" rel="noopener noreferrer">Linux Loopback performance with TCP_NODELAY enabled</a></li>
</ul>
]]></description></item><item><title>Linux 网络工具中的瑞士军刀 - socat &amp; netcat</title><link>https://ryan4yin.space/posts/socat-netcat/</link><pubDate>Sun, 11 Apr 2021 16:38:13 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/socat-netcat/</guid><description><![CDATA[<blockquote>
<p>文中的命令均在 macOS Big Sur 和 Opensuse Tumbleweed 上测试通过</p>
</blockquote>
<h2 id="socat--netcat">socat &amp; netcat</h2>
<p>netcat(network cat) 是一个历史悠久的网络工具包，被称作 TCP/IP 的瑞士军刀，各大 Linux 发行版都有默认安装 openbsd 版本的 netcat，它的命令行名称为 <code>nc</code>.</p>
<p>而 socat(socket cat)，官方文档描述它是 <code>&quot;netcat++&quot; (extended design, new implementation)</code>，项目比较活跃，kubernetes-client(kubectl) 底层就是使用的它做各种流量转发。</p>
<p>在不方便安装 socat 的环境中，我们可以使用系统自带的 netcat.
而在其他环境，可以考虑优先使用 socat.</p>
<h2 id="一简介">一、简介</h2>
<p>socat 的基本命令格式：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">socat <span class="o">[</span>参数<span class="o">]</span> 地址1 地址2
</code></pre></td></tr></table>
</div>
</div><p>给 socat 提供两个地址，socat 干的活就是把两个地址的流对接起来。左边地址的输出传给右边，同时又把右边地址的输出传给左边，也就是一个<strong>双向的数据管道</strong>。</p>
<p>听起来好像没啥特别的，但是实际上计算机网络干的活也就是数据传输而已，却影响了整个世界，不可小觑它的功能。</p>
<p>socat 支持非常多的地址类型：<code>-</code>/stdio，TCP, TCP-LISTEN, UDP, UDP-LISTEN, OPEN, EXEC, SOCKS, PROXY 等等，可用于端口监听、链接，文件和进程读写，代理桥接等等。</p>
<p>socat 的功能就是这么简单，命令行参数也很简洁，唯一需要花点精力学习的就是它各种地址的定义和搭配写法。</p>
<p>而 netcat 定义貌似没这么严谨，可以简单的理解为网络版的 cat 命令 2333</p>
<h2 id="二安装方法">二、安装方法</h2>
<p>各发行版都自带 netcat，包名通常为 <code>nc-openbsd</code>，因此这里只介绍 socat 的安装方法：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Debian/Ubuntu</span>
sudo apt install socat

<span class="c1"># CentOS/RedHat</span>
sudo yum install socat

<span class="c1"># macOS</span>
brew install socat
</code></pre></td></tr></table>
</div>
</div><p>其他发行版基本也都可以使用包管理器安装 socat</p>
<h2 id="三常用命令">三、常用命令</h2>
<h3 id="1-网络调试">1. 网络调试</h3>
<h4 id="11-检测远程端口的可连接性确认防火墙没问题">1.1 检测远程端口的可连接性（确认防火墙没问题）</h4>
<blockquote>
<p>以前你可能学过如何用 telnet 来做这项测试，不过现在很多发行版基本都不自带 telnet 了，还需要额外安装。
telnet 差不多已经快寿终正寝了，还是建议使用更专业的 socat/netcat</p>
</blockquote>
<p>使用 socat/netcat 检测远程端口的可连接性：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># -d[ddd] 增加日志详细程度，-dd  Prints fatal, error, warning, and notice messages.</span>
socat -dd - TCP:192.168.1.252:3306

<span class="c1"># -v 显示详细信息</span>
<span class="c1"># -z 不发送数据，效果为立即关闭连接，快速得出结果</span>
nc -vz 192.168.1.2 <span class="m">8080</span>

<span class="c1"># -vv 显示更详细的内容</span>
<span class="c1"># -w2 超时时间设为 2 秒</span>
<span class="c1"># 使用 nc 做简单的端口扫描</span>
nc -vv -w2 -z 192.168.1.2 20-500
</code></pre></td></tr></table>
</div>
</div><h4 id="12-测试本机端口是否能正常被外部访问检测防火墙路由">1.2 测试本机端口是否能正常被外部访问（检测防火墙、路由）</h4>
<p>在本机监听一个 TCP 端口，接收到的内容传到 stdout，同时将 stdin 的输入传给客户端：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 服务端启动命令，socat/nc 二选一</span>
socat TCP-LISTEN:7000 -
<span class="c1"># -l --listening</span>
nc -l <span class="m">7000</span>

<span class="c1"># 客户端连接命令，socat/nc 二选一</span>
socat TCP:192.168.31.123:7000 -
nc 192.168.11.123 <span class="m">7000</span>
</code></pre></td></tr></table>
</div>
</div><p>UDP 协议的测试也非常类似，使用 netcat 的示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 服务端，只监听 ipv4</span>
nc -u -l <span class="m">8080</span>

<span class="c1"># 客户端</span>
nc -u 192.168.31.123 <span class="m">8080</span>
<span class="c1"># 客户端本机测试，注意 localhost 会被优先解析为 ipv6! 这会导致服务端(ipv4)的 nc 接收不到数据！</span>
nc -u localhost <span class="m">8080</span>
</code></pre></td></tr></table>
</div>
</div><p>使用 socat 的 UDP 测试示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">socat UDP-LISTEN:7000 -

socat UDP:192.168.31.123:7000 -
</code></pre></td></tr></table>
</div>
</div><h4 id="13-调试-tls-协议">1.3 调试 TLS 协议</h4>
<blockquote>
<p>参考 socat 官方文档：<a href="http://www.dest-unreach.org/socat/doc/socat-openssltunnel.html" target="_blank" rel="noopener noreferrer">Securing Traffic Between two Socat Instances Using SSL</a></p>
</blockquote>
<blockquote>
<p>测试证书及私钥的生成参见 <a href="https://ryan4yin.space/posts/about-tls-cert/" rel="">TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段</a></p>
</blockquote>
<p>模拟一个 mTLS 服务器，监听 4433 端口，接收到的数据同样输出到 stdout：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># socat 需要使用同时包含证书和私钥的 pem 文件，生成方法如下</span>
cat server.key server.crt &gt; server.pem
cat client.key client.crt &gt; client.pem

<span class="c1"># 服务端启动命令</span>
socat openssl-listen:4433,reuseaddr,cert<span class="o">=</span>server.pem,cafile<span class="o">=</span>client.crt -

<span class="c1"># 客户端连接命令</span>
socat - openssl-connect:192.168.31.123:4433,cert<span class="o">=</span>client.pem,cafile<span class="o">=</span>server.crt
<span class="c1"># 或者使用 curl 连接(我们知道 ca.crt 和 server.crt 都能被用做 cacert/cafile)</span>
curl -v --cacert ca.crt --cert client.crt --key client.key --tls-max 1.2 https://192.168.31.123:4433
</code></pre></td></tr></table>
</div>
</div><p>上面的命令使用了 mTLS 双向认证的协议，可通过设定 <code>verify=0</code> 来关掉客户端认证，示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">
<span class="c1"># socat 需要使用同时包含证书和私钥的 pem 文件，生成方法如下</span>
cat server.key server.crt &gt; server.pem

<span class="c1"># 服务端启动命令</span>
socat openssl-listen:4433,reuseaddr,cert<span class="o">=</span>server.pem,verify<span class="o">=</span><span class="m">0</span> -

<span class="c1"># 客户端连接命令，如果 ip/域名不受证书保护，就也需要添加 verify=0</span>
socat - openssl-connect:192.168.31.123:4433,cafile<span class="o">=</span>server.crt
<span class="c1"># 或者使用 curl 连接，证书无效请添加 -k 跳过证书验证</span>
curl -v --cacert server.crt https://192.168.31.123:4433
</code></pre></td></tr></table>
</div>
</div><h2 id="2-数据传输">2. 数据传输</h2>
<p>通常传输文件时，我都习惯使用 scp/ssh/rsync，但是 socat 其实也可以传输文件。</p>
<p>以将 demo.tar.gz 从主机 A 发送到主机 B 为例，
首先在数据发送方 A 执行如下命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># -u 表示数据只从左边的地址单向传输给右边（socat 默认是一个双向管道）</span>
<span class="c1"># -U 和 -u 相反，数据只从右边单向传输给左边</span>
socat -u open:demo.tar.gz tcp-listen:2000,reuseaddr
</code></pre></td></tr></table>
</div>
</div><p>然后在数据接收方 B 执行如下命令，就能把文件接收到：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">socat -u tcp:192.168.1.252:2000 open:demo.tar.gz,create
<span class="c1"># 如果觉得太繁琐，也可以直接通过 stdout 重定向</span>
socat -u tcp:192.168.1.252:2000 - &gt; demo.tar.gz
</code></pre></td></tr></table>
</div>
</div><p>使用 netcat 也可以实现数据传输：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 先在接收方启动服务端</span>
nc -l -p <span class="m">8080</span> &gt; demo.tar.gz
<span class="c1"># 再在发送方启动客户端发送数据</span>
nc 192.168.1.2 <span class="m">8080</span> &lt; demo.tar.gz
</code></pre></td></tr></table>
</div>
</div><h2 id="3-担当临时的-web-服务器">3. 担当临时的 web 服务器</h2>
<p>使用 <code>fork</code> <code>reuseaddr</code> <code>SYSTEM</code> 三个命令，再用 <code>systemd</code>/<code>supervisor</code> 管理一下，就可以用几行命令实现一个简单的后台服务器。</p>
<p>下面的命令将监听 8080 端口，并将数据流和 web.py 的 stdio 连接起来，可以直接使用浏览器访问 <code>http://&lt;ip&gt;:8080</code> 来查看效果。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">socat TCP-LISTEN:8080,reuseaddr,fork SYSTEM:<span class="s2">&#34;python3 web.py&#34;</span>
</code></pre></td></tr></table>
</div>
</div><p>假设 <code>web.py</code> 的内容为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="s2">&#34;hello world&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>那 <code>curl localhost:8080</code> 就应该会输出 <code>hello world</code></p>
<h2 id="4-端口转发">4. 端口转发</h2>
<p>监听 8080 端口，建立该端口与 <code>baidu.com:80</code> 之间的双向管道:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">socat TCP-LISTEN:8080,fork,reuseaddr  TCP:baidu.com:80
</code></pre></td></tr></table>
</div>
</div><p>拿 curl 命令测试一下，应该能正常访问到百度：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 注意指定 Host</span>
curl -v -H <span class="s1">&#39;Host: baidu.com&#39;</span> localhost:8080
</code></pre></td></tr></table>
</div>
</div><h2 id="参考">参考</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/347722248" target="_blank" rel="noopener noreferrer">新版瑞士军刀：socat - 韦易笑 - 知乎</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/83959309" target="_blank" rel="noopener noreferrer">用好你的瑞士军刀/netcat - 韦易笑 - 知乎</a></li>
<li><a href="http://www.dest-unreach.org/socat/" target="_blank" rel="noopener noreferrer">socat - Multipurpose relay</a></li>
</ul>
]]></description></item><item><title>脚踏实地，仰望星空</title><link>https://ryan4yin.space/posts/no-more-dreams/</link><pubDate>Sat, 13 Feb 2021 10:32:56 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/no-more-dreams/</guid><description><![CDATA[<!-- 每个人的一生都是一次远行 -->
<meting-js server="netease" type="song" id="176048" theme="#448aff"></meting-js>
<h2 id="年轻真好">年轻真好</h2>
<p>最近看了些前辈们的博客，很多是在计算机行业工作几十年的前辈，还有许嵩的文章。</p>
<p>我更深刻地认识到了一件事：我当下的很多文章，都能看得出我在很认真的思考、总结，但是总是有很明显的稚嫩的感觉在里面——我自认为这是「学生型思维」。</p>
<p>我总是喜欢讲「且行且寻」、「自己的眼界还太狭窄了，我对世界还很缺乏了解」、「根本看不清好坏，就无法独立做出决策」诸如此类。</p>
<p>我把这样的文章写出来，前辈们给我留言「博主只是沉淀的时间还远远不够。憋着急，年轻就是最大的资本。」、「只想说年轻真好，使劲折腾才知道要什么东西」。</p>
<p>嗯，我理解到了，因为我「<strong>年轻</strong>」，所以写出这样的文章没问题，可以使劲去折腾、去探索、去思考。</p>
<h2 id="三十而立">三十而立</h2>
<blockquote>
<p>子曰：吾，十有五，而志于学，三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲，不逾矩。</p>
</blockquote>
<p>孔子说：“我十五岁立志学习，三十岁在人生道路上站稳脚跟，四十岁心中不再迷惘，五十岁知道上天给我安排的命运，六十岁听到别人说话就能分辨是非真假，七十岁能随心所欲地说话做事，又不会超越规矩。”</p>
<p>「四十而不惑」对我而言可能还太远，但「三十而立」却是已经能预见到了的，没几年了。</p>
<p><strong>三十而立，人到了三十岁，就应该知道自己如何立身处世，尘世滚滚中能守住自己的一点本真不失</strong>。</p>
<p>三十岁，已不是一个年轻的年纪了。</p>
<p><strong>如果我到了三十岁，还去写些「自己的眼界还太狭窄了，我对世界还很缺乏了解」、「我根本看不清好坏，很多时候无法独立做出决策」，那就贻笑大方了</strong>。</p>
<p>所以即使说「年轻就是最大的资本」，也不是能随意挥霍的！人生这条道路上我们踽踽独行，道阻且长，眼光要放长远一点、多看一点，不要把自己限制住了，更不应该原地踏步！</p>
<h2 id="许嵩我没有梦想">许嵩——我没有梦想</h2>
<p>这两天看多了前辈们的博客，就想找点非虚构的书藉看看，补充点阅历。</p>
<p>昨天向朋友们讨书看，@rea.ink 就给我推荐许嵩的《海上灵光》。意外地发现了<a href="http://blog.sina.com.cn/vae" target="_blank" rel="noopener noreferrer">许嵩的新浪博客</a>。</p>
<p>博客的内容都很老了，最新的一篇是 2013 年。但是这并不妨碍其中见解的价值</p>
<div class="details admonition reference open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw"></i>海上灵光——许嵩<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>以前媒体问我接下来有什么计划或梦想时我总是很愣的回答，我没有梦想。</p>
<p>真的，一个年过半百的人还把梦想这种字眼挂在嘴上是很乏味的。</p>
<p>睁大眼看看眼前的生活，周遭的一切吧。</p>
<p>脚踏实地认真过好每一天的生活吧。</p>
<p>至于心底的信念——是决计不必拿出来高谈阔论的。</p>
</div>
        </div>
    </div>
<div class="details admonition reference open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw"></i>出离心——许嵩<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>这几个月，走过了不少地方。</p>
<p>每到一处，采访我的媒体通常会有这么一问：你的音乐理想是什么？</p>
<p>而当答案是“我从来没有理想”时，我迎接那些错愕的眼神。</p>
<p>年轻的时候，拥有一些世俗的念想（比如声名远播？）、一些物质上的期待（比如大房子好车子？）、一些精神上的憧憬（比如寻得佳偶？）、一些相对崇高的目标（比如造福子孙？！），似乎的确能让一些人更有动力的过活每一天。</p>
<p>但如果，岁月在你脸上已然留下不少年轮——你坐船的动机仍然只是到达一座岛，别人把岛上的一切美妙和宝藏说给你听就可以让你划船划的更带劲儿——那我能对你说些什么呢？</p>
</div>
        </div>
    </div>
<h2 id="池建强你老了">池建强——你老了</h2>
<p>这两天读到了一篇池建强写的<a href="http://macshuo.com/?p=1491" target="_blank" rel="noopener noreferrer">《你老了》</a>，作者是极客时间创始人，真的是年过半百的技术人了。</p>
<div class="details admonition reference open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw"></i>你老了 - 池建强的随想录<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>40 以后，不惑是不可能的，恐慌是与日俱增的。四十不惑，说得不是你想明白了，而是你想不明白的，可能就想不明白了，生日变成另一种仪式，它严肃的告诉你，同学，不要有任何幻想了，接受这个现实，你已经不再年轻了。再卖萌也改变不了这个事实。</p>
<p>人们总会长大，成熟，衰老，一如万事万物。今何在说，人从一出生开始，就踏上了自己的西游路，一路向西，到了尽头，就是虚无，人就没了。所有人都不可避免要奔向那个归宿，你没办法选择，没办法回头。</p>
</div>
        </div>
    </div>
<div class="details admonition reference open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw"></i>你老了 - 池建强的随想录<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>你跳不出这个世界，是因为你不知道这个世界有多大，一旦你知道了，你就超出了它。</p>
<p>年龄也是如此。</p>
</div>
        </div>
    </div>
<h2 id="梦想不要多的想看世界也不是靠说的">梦想不要多的，想看世界也不是靠说的</h2>
<p>既然说了要多走走看看，那就多看多想。</p>
<p>就像许嵩写的那样，不必去高谈阔论什么理想与信念，实际行动才是最有力的证明。</p>
<blockquote>
<p>Keep eyes on the stars, and feet on the ground.</p>
</blockquote>
]]></description></item><item><title>云原生流水线 Argo Workflows 的安装、使用以及个人体验</title><link>https://ryan4yin.space/posts/expirence-of-argo-workflow/</link><pubDate>Wed, 27 Jan 2021 15:37:27 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/expirence-of-argo-workflow/</guid><description><![CDATA[<blockquote>
<p>注意：这篇文章并不是一篇入门教程，学习 Argo Workflows 请移步官方文档 <a href="https://argoproj.github.io/argo-workflows/" target="_blank" rel="noopener noreferrer">Argo Documentation</a></p>
</blockquote>
<p><a href="https://github.com/argoproj/argo-workflows/" target="_blank" rel="noopener noreferrer">Argo Workflows</a> 是一个云原生工作流引擎，专注于<strong>编排并行任务</strong>。它的特点如下：</p>
<ol>
<li>使用 Kubernetes 自定义资源(CR)定义工作流，其中工作流中的每个步骤都是一个容器。</li>
<li>将多步骤工作流建模为一系列任务，或者使用有向无环图（DAG）描述任务之间的依赖关系。</li>
<li>可以在短时间内轻松运行用于机器学习或数据处理的计算密集型作业。</li>
<li>Argo Workflows 可以看作 Tekton 的加强版，因此显然也可以通过 Argo Workflows 运行 CI/CD 流水线(Pipielines)。</li>
</ol>
<p>阿里云是 Argo Workflows 的深度使用者和贡献者，另外 Kubeflow 底层的工作流引擎也是 Argo Workflows.</p>
<h2 id="一argo-workflows-对比-jenkins">一、Argo Workflows 对比 Jenkins</h2>
<p>我们在切换到 Argo Workflows 之前，使用的 CI/CD 工具是 Jenkins，下面对 Argo Workflows 和 Jenkins 做一个比较详细的对比，
以了解 Argo Workflows 的优缺点。</p>
<h3 id="1-workflow-的定义">1. Workflow 的定义</h3>
<p><code>Workflow</code> 使用 kubernetes CR 进行定义，因此显然是一份 yaml 配置。</p>
<p>一个 Workflow，就是一个运行在 Kubernetes 上的流水线，对应 Jenkins 的一次 Build.</p>
<p>而 WorkflowTemplate 则是一个可重用的 Workflow 模板，对应 Jenkins 的一个 Job.</p>
<p><code>WorkflowTemplate</code> 的 yaml 定义和 <code>Workflow</code> 完全一致，只有 <code>Kind</code> 不同！</p>
<p>WorkflowTemplate 可以被其他 Workflow 引用并触发，也可以手动传参以生成一个 Workflow 工作流。</p>
<h3 id="2-workflow-的编排">2. Workflow 的编排</h3>
<p>Argo Workflows 相比其他流水线项目(Jenkins/Tekton/Drone/Gitlab-CI)而言，最大的特点，就是它强大的流水线编排能力。</p>
<p>其他流水线项目，对流水线之间的关联性考虑得很少，基本都假设流水线都是互相独立的。</p>
<p>而 Argo Workflows 则假设「任务」之间是有依赖关系的，针对这个依赖关系，它提供了两种协调编排「任务」的方法：Steps 和 DAG</p>
<p>再借助 <a href="https://argoproj.github.io/argo/workflow-templates/#referencing-other-workflowtemplates" target="_blank" rel="noopener noreferrer">templateRef</a> 或者 <a href="https://argoproj.github.io/argo/workflow-of-workflows/" target="_blank" rel="noopener noreferrer">Workflow of Workflows</a>，就能实现 Workflows 的编排了。</p>
<p><strong>我们之所以选择 Argo Workflows 而不是 Tekton，主要就是因为 Argo 的流水线编排能力比 Tekton 强大得多。</strong>（也许是因为我们的后端中台结构比较特殊，导致我们的 CI 流水线需要具备复杂的编排能力）</p>
<p>一个复杂工作流的示例如下：</p>
<p><figure><a class="lightgallery" href="/images/expirence-of-argo-workflow/complex-workflows.png" title="/images/expirence-of-argo-workflow/complex-workflows.png" data-thumbnail="/images/expirence-of-argo-workflow/complex-workflows.png" data-sub-html="<h2>https://github.com/argoproj/argo/issues/1088#issuecomment-445884543</h2>">
        
    </a><figcaption class="image-caption">https://github.com/argoproj/argo/issues/1088#issuecomment-445884543</figcaption>
    </figure></p>
<h3 id="3-workflow-的声明式配置">3. Workflow 的声明式配置</h3>
<p>Argo 使用 Kubernetes 自定义资源(CR)来定义 Workflow，熟悉 Kubernetes Yaml 的同学上手应该都很快。</p>
<p>下面对 Workflow 定义文件和 Jenkinsfile 做个对比：</p>
<ol>
<li>argo 完全使用 yaml 来定义流水线，学习成本比 Jenkinsfile 的 groovy 低。对熟悉 Kubernetes 的同学尤其如此。</li>
<li>将 jenkinsfile 用 argo 重写后，代码量出现了明显的膨胀。一个 20 行的 Jenkinsfile，用 Argo 重写可能就变成了 60 行。</li>
</ol>
<p>配置出现了膨胀是个问题，但是考虑到它的可读性还算不错，
而且 Argo 的 Workflow 编排功能，能替代掉我们目前维护的部分 Python 构建代码，以及一些其他优点，配置膨胀这个问题也就可以接受了。</p>
<h3 id="4-web-ui">4. Web UI</h3>
<p>Argo Workflows 的 Web UI 感觉还很原始。确实该支持的功能都有，但是它貌似不是面向「用户」的，功能比较底层。</p>
<p>它不像 Jenkins 一样，有很友好的使用界面(虽然说 Jenkins 的 UI 也很显老&hellip;)</p>
<p>另外它所有的 Workflow 都是相互独立的，没办法直观地找到一个 WorkflowTemplate 的所有构建记录，只能通过 label/namespace 进行分类，通过任务名称进行搜索。</p>
<p>而 Jenkins 可以很方便地看到同一个 Job 的所有构建历史。</p>
<h3 id="5-workflow-的分类">5. Workflow 的分类</h3>
<h4 id="为何需要对-workflow-做细致的分类">为何需要对 Workflow 做细致的分类</h4>
<p>常见的微服务项目，往往会拆分成众多 Git 仓库（微服务）进行开发，众多的 Git 仓库会使我们创建众多的 CI/CD 流水线。
如果没有任何的分类，这一大堆的流水线如何管理，就成了一个难题。</p>
<p>最显见的需求：前端和后端的流水线最好能区分一下，往下细分，前端的 Web 端和客户端最好也能区分，后端的业务层和中台最好也区分开来。</p>
<p>另外我们还希望将运维、自动化测试相关的任务也集成到这个系统中来（目前我们就是使用 Jenkins 完成运维、自动化测试任务的），
如果没有任何分类，这一大堆流水线将混乱无比。</p>
<h4 id="argo-workflows-的分类能力">Argo Workflows 的分类能力</h4>
<p>当 Workflow 越来越多的时候，如果不做分类，一堆 WorkflowTemplate 堆在一起就会显得特别混乱。（没错，我觉得 Drone 就有这个问题&hellip;）</p>
<p>Argo 是完全基于 Kubernetes 的，因此目前它也只能通过 namespace/labels 进行分类。</p>
<p>这样的分类结构和 Jenkins 的视图-文件夹体系大相径庭，目前感觉不是很好用（也可能纯粹是 Web UI 的锅）。</p>
<h3 id="6-触发构建的方式">6. 触发构建的方式</h3>
<p>Argo Workflows 的流水线有多种触发方式：</p>
<ul>
<li>手动触发：手动提交一个 Workflow，就能触发一次构建。可以通过 <a href="https://argoproj.github.io/argo/workflow-templates/#create-workflow-from-workflowtemplate-spec" target="_blank" rel="noopener noreferrer">workflowTemplateRef</a> 直接引用一个现成的流水线模板。</li>
<li>定时触发：<a href="https://argoproj.github.io/argo/cron-workflows/" target="_blank" rel="noopener noreferrer">CronWorkflow</a></li>
<li>通过 Git 仓库变更触发：借助 <a href="https://github.com/argoproj/argo-events" target="_blank" rel="noopener noreferrer">argo-events</a> 可以实现此功能，详见其文档。
<ul>
<li>另外目前也不清楚 WebHook 的可靠程度如何，会不会因为宕机、断网等故障，导致 Git 仓库变更了，而 Workflow 却没触发，而且还没有任何显眼的错误通知？如果这个错误就这样藏起来了，就可能会导致很严重的问题！</li>
</ul>
</li>
</ul>
<h3 id="7-secrets-管理">7. secrets 管理</h3>
<p>Argo Workflows 的流水线，可以从 kubernetes secrets/configmap 中获取信息，将信息注入到环境变量中、或者以文件形式挂载到 Pod 中。</p>
<p>Git 私钥、Harbor 仓库凭据、CD 需要的 kubeconfig，都可以直接从 secrets/configmap 中获取到。</p>
<p>另外因为 Vault 很流行，也可以将 secrets 保存在 Vault 中，再通过 vault agent 将配置注入进 Pod。</p>
<h3 id="8-artifacts">8. Artifacts</h3>
<p>Argo 支持接入对象存储，做全局的 Artifact 仓库，本地可以使用 MinIO.</p>
<p>使用对象存储存储 Artifact，最大的好处就是可以在 Pod 之间随意传数据，Pod 可以完全分布式地运行在 Kubernetes 集群的任何节点上。</p>
<p>另外也可以考虑借助 Artifact 仓库实现跨流水线的缓存复用（未测试），提升构建速度。</p>
<h3 id="9-容器镜像的构建">9. 容器镜像的构建</h3>
<p>借助 Kaniko 等容器镜像构建工具，可以实现容器镜像的分布式构建。</p>
<p>Kaniko 对构建缓存的支持也很好，可以直接将缓存存储在容器镜像仓库中。</p>
<h3 id="10-客户端sdk">10. 客户端/SDK</h3>
<p>Argo 有提供一个命令行客户端，也有 HTTP API 可供使用。</p>
<p>如下项目值得试用：</p>
<ul>
<li><a href="https://github.com/argoproj-labs/argo-client-python" target="_blank" rel="noopener noreferrer">argo-client-python</a>: Argo Workflows 的 Python 客户端
<ul>
<li>说实话，感觉和 kubernetes-client/python 一样难用，毕竟都是 openapi-generator 生成出来的&hellip;</li>
</ul>
</li>
<li><a href="https://github.com/argoproj-labs/argo-python-dsl" target="_blank" rel="noopener noreferrer">argo-python-dsl</a>: 使用 Python DSL 编写 Argo Workflows
<ul>
<li>感觉使用难度比 yaml 高，也不太好用。</li>
</ul>
</li>
<li><a href="https://github.com/couler-proj/couler" target="_blank" rel="noopener noreferrer">couler</a>: 为  Argo/Tekton/Airflow 提供统一的构建与管理接口
<ul>
<li>理念倒是很好，待研究</li>
</ul>
</li>
</ul>
<p>感觉 couler 挺不错的，可以直接用 Python 写 WorkflowTemplate，这样就一步到位，所有 CI/CD 代码全部是 Python 了。</p>
<p>此外，因为 Argo Workflows 是 kubernetes 自定义资源 CR，也可以使用 helm/kustomize 来做 workflow 的生成。</p>
<p>目前我们一些步骤非常多，但是重复度也很高的 Argo 流水线配置，就是使用 helm 生成的——关键数据抽取到 values.yaml 中，使用 helm 模板 + <code>range</code> 循环来生成 workflow 配置。</p>
<h2 id="二安装-argo-workflowshttpsargoprojgithubioargoinstallation">二、<a href="https://argoproj.github.io/argo/installation/" target="_blank" rel="noopener noreferrer">安装 Argo Workflows</a></h2>
<p>安装一个集群版(cluster wide)的 Argo Workflows，使用 MinIO 做 artifacts 存储：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/argoproj/argo/stable/manifests/install.yaml
</code></pre></td></tr></table>
</div>
</div><p>部署 MinIO:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">helm repo add minio https://helm.min.io/ <span class="c1"># official minio Helm charts</span>
<span class="c1"># 查看历史版本</span>
helm search repo minio/minio -l <span class="p">|</span> head
<span class="c1"># 下载并解压 chart</span>
helm pull minio/minio --untar --version 8.0.9

<span class="c1"># 编写 custom-values.yaml，然后部署 minio</span>
kubectl create namespace minio
helm install minio ./minio -n argo -f custom-values.yaml
</code></pre></td></tr></table>
</div>
</div><p>minio 部署好后，它会将默认的 <code>accesskey</code> 和 <code>secretkey</code> 保存在名为 <code>minio</code> 的 secret 中。
我们需要修改 argo 的配置，将 minio 作为它的默认 artifact 仓库。</p>
<p>在 configmap <code>workflow-controller-configmap</code> 的 data 中添加如下字段：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">  artifactRepository: <span class="p">|</span>
    <span class="c1"># 是否将 main 容器的日志保存为 artifact，这样 pod 被删除后，仍然可以在 artifact 中找到日志</span>
    archiveLogs: <span class="nb">true</span>
    s3:
      bucket: argo-bucket   <span class="c1"># bucket 名称，这个 bucket 需要先手动创建好！</span>
      endpoint: minio:9000  <span class="c1"># minio 地址</span>
      insecure: <span class="nb">true</span>
      <span class="c1"># 从 minio 这个 secret 中获取 key/secret</span>
      accessKeySecret:
        name: minio
        key: accesskey
      secretKeySecret:
        name: minio
        key: secretkey
</code></pre></td></tr></table>
</div>
</div><p>现在还差最后一步：手动进入 minio 的 Web UI，创建好 <code>argo-bucket</code> 这个 bucket.
直接访问 minio 的 9000 端口（需要使用 nodeport/ingress 等方式暴露此端口）就能进入 Web UI，使用前面提到的 secret <code>minio</code> 中的 key/secret 登录，就能创建 bucket.</p>
<h3 id="serviceaccount-配置httpsargoprojgithubioargoservice-accounts"><a href="https://argoproj.github.io/argo/service-accounts/" target="_blank" rel="noopener noreferrer">ServiceAccount 配置</a></h3>
<p>Argo Workflows 依赖于 ServiceAccount 进行验证与授权，而且默认情况下，它使用所在 namespace 的 <code>default</code> ServiceAccount 运行 workflow.</p>
<p>可 <code>default</code> 这个 ServiceAccount 默认根本没有任何权限！所以 Argo 的 artifacts, outputs, access to secrets 等功能全都会因为权限不足而无法使用！</p>
<p>为此，Argo 的官方文档提供了两个解决方法。</p>
<p>方法一，直接给 default 绑定 <code>cluster-admin</code> ClusterRole，给它集群管理员的权限，只要一行命令（但是显然安全性堪忧）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubectl create rolebinding default-admin --clusterrole<span class="o">=</span>admin --serviceaccount<span class="o">=</span>&lt;namespace&gt;:default -n &lt;namespace&gt;
</code></pre></td></tr></table>
</div>
</div><p>方法二，官方给出了<a href="https://argoproj.github.io/argo/workflow-rbac/" target="_blank" rel="noopener noreferrer">Argo Workflows 需要的最小权限的 Role 定义</a>，方便起见我将它改成一个 ClusterRole:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">rbac.authorization.k8s.io/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterRole</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">argo-workflow-role</span><span class="w">
</span><span class="w"></span><span class="nt">rules</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="c"># pod get/watch is used to identify the container IDs of the current pod</span><span class="w">
</span><span class="w"></span><span class="c"># pod patch is used to annotate the step&#39;s outputs back to controller (e.g. artifact location)</span><span class="w">
</span><span class="w"></span>- <span class="nt">apiGroups</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="l">pods</span><span class="w">
</span><span class="w">  </span><span class="nt">verbs</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="l">get</span><span class="w">
</span><span class="w">  </span>- <span class="l">watch</span><span class="w">
</span><span class="w">  </span>- <span class="l">patch</span><span class="w">
</span><span class="w"></span><span class="c"># logs get/watch are used to get the pods logs for script outputs, and for log archival</span><span class="w">
</span><span class="w"></span>- <span class="nt">apiGroups</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="l">pods/log</span><span class="w">
</span><span class="w">  </span><span class="nt">verbs</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="l">get</span><span class="w">
</span><span class="w">  </span>- <span class="l">watch</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>创建好上面这个最小的 ClusterRole，然后为每个名字空间，跑一下如下命令，给 default 账号绑定这个 clusterrole:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubectl create rolebinding default-argo-workflow --clusterrole<span class="o">=</span>argo-workflow-role  --serviceaccount<span class="o">=</span>&lt;namespace&gt;:default -n &lt;namespace&gt;
</code></pre></td></tr></table>
</div>
</div><p>这样就能给 default 账号提供最小的 workflow 运行权限。</p>
<p>或者如果你希望使用别的 ServiceAccount 来运行 workflow，也可以自行创建 ServiceAccount，然后再走上面方法二的流程，但是最后，要记得在 workflow 的 <code>spec.serviceAccountName</code> 中设定好 ServiceAccount 名称。</p>
<h3 id="workflow-executorshttpsargoprojgithubioargoworkflow-executors"><a href="https://argoproj.github.io/argo/workflow-executors/" target="_blank" rel="noopener noreferrer">Workflow Executors</a></h3>
<p>Workflow Executor 是符合特定接口的一个进程(Process)，Argo 可以通过它执行一些动作，如监控 Pod 日志、收集 Artifacts、管理容器生命周期等等&hellip;</p>
<p>Workflow Executor 有多种实现，可以通过前面提到的 configmap <code>workflow-controller-configmap</code> 来选择。</p>
<p>可选项如下：</p>
<ol>
<li>docker(默认): 目前使用范围最广，但是安全性最差。它要求一定要挂载访问 <code>docker.sock</code>，因此一定要 root 权限！</li>
<li>kubelet: 应用非常少，目前功能也有些欠缺，目前也必须提供 root 权限</li>
<li>Kubernetes API (k8sapi): 直接通过调用 k8sapi 实现日志监控、Artifacts 手机等功能，非常安全，但是性能欠佳。</li>
<li>Process Namespace Sharing (pns): 安全性比 k8sapi 差一点，因为 Process 对其他所有容器都可见了。但是相对的性能好很多。</li>
</ol>
<p>在 docker 被 kubernetes 抛弃的当下，如果你已经改用 containerd 做为 kubernetes 运行时，那 argo 将会无法工作，因为它默认使用 docker 作为运行时！</p>
<p>我们建议将 workflow executore 改为 <code>pns</code>，兼顾安全性与性能，<code>workflow-controller-configmap</code> 按照如下方式修改：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ConfigMap</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">workflow-controller-configmap</span><span class="w">
</span><span class="w"></span><span class="nt">data</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">config</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span><span class="sd">    # ...省略若干配置...
</span><span class="sd">
</span><span class="sd">    # Specifies the container runtime interface to use (default: docker)
</span><span class="sd">    # must be one of: docker, kubelet, k8sapi, pns
</span><span class="sd">    containerRuntimeExecutor: pns
</span><span class="sd">    # ...</span><span class="w">    
</span></code></pre></td></tr></table>
</div>
</div><h2 id="三使用-argo-workflows-做-ci-工具">三、使用 Argo Workflows 做 CI 工具</h2>
<p>官方的 Reference 还算详细，也有提供非常多的 examples 供我们参考，这里提供我们几个常用的 workflow 定义。</p>
<p>使用 Kaniko 构建容器镜像:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># USAGE:</span><span class="w">
</span><span class="w"></span><span class="c">#</span><span class="w">
</span><span class="w"></span><span class="c"># push 镜像需要一个 config.json, 这个 json 需要被挂载到 `kaniko/.docker/config.json`.</span><span class="w">
</span><span class="w"></span><span class="c"># 为此，你首先需要构建 config.json 文件，并使用它创建一个 kubernetes secret:</span><span class="w">
</span><span class="w"></span><span class="c">#</span><span class="w">
</span><span class="w"></span><span class="c">#    export DOCKER_REGISTRY=&#34;registry.svc.local&#34;</span><span class="w">
</span><span class="w"></span><span class="c">#    export DOCKER_USERNAME=&lt;username&gt;</span><span class="w">
</span><span class="w"></span><span class="c">#    export DOCKER_TOKEN=&#39;&lt;password&gt;&#39;   # 对于 harbor 仓库而言，token 就是账号的 password.</span><span class="w">
</span><span class="w"></span><span class="c">#    kubectl create secret generic docker-config --from-literal=&#34;config.json={\&#34;auths\&#34;: {\&#34;$DOCKER_REGISTRY\&#34;: {\&#34;auth\&#34;: \&#34;$(echo -n $DOCKER_USERNAME:$DOCKER_TOKEN|base64)\&#34;}}}&#34;</span><span class="w">
</span><span class="w"></span><span class="c">#</span><span class="w">
</span><span class="w"></span><span class="c"># clone git 仓库也需要 git credentails，这可以通过如下命令创建：</span><span class="w">
</span><span class="w"></span><span class="c"># </span><span class="w">
</span><span class="w"></span><span class="c">#    kubectl create secret generic private-git-creds --from-literal=username=&lt;username&gt; --from-file=ssh-private-key=&lt;filename&gt;</span><span class="w">
</span><span class="w"></span><span class="c"># </span><span class="w">
</span><span class="w"></span><span class="c"># REFERENCES:</span><span class="w">
</span><span class="w"></span><span class="c">#</span><span class="w">
</span><span class="w"></span><span class="c"># * https://github.com/argoproj/argo/blob/master/examples/buildkit-template.yaml</span><span class="w">
</span><span class="w"></span><span class="c">#</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">argoproj.io/v1alpha1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">WorkflowTemplate</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">build-image</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">arguments</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">parameters</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">repo </span><span class="w"> </span><span class="c"># 源码仓库</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">git@gitlab.svc.local:ryan4yin/my-app.git</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">branch</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">main</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">context-path</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">.</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">dockerfile</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">Dockerfile</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">image </span><span class="w"> </span><span class="c"># 构建出的镜像名称</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">registry.svc.local/ryan4yin/my-app:latest</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cache-image</span><span class="w">
</span><span class="w">        </span><span class="c"># 注意，cache-image 不能带 tag! cache 是直接通过 hash 值来索引的！</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">registry.svc.local/build-cache/my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">entrypoint</span><span class="p">:</span><span class="w"> </span><span class="l">main</span><span class="w">
</span><span class="w">  </span><span class="nt">templates</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">main</span><span class="w">
</span><span class="w">      </span><span class="nt">steps</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- - <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">build-image</span><span class="w">
</span><span class="w">          </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="l">build-image</span><span class="w">
</span><span class="w">          </span><span class="nt">arguments</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">artifacts</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">git-repo</span><span class="w">
</span><span class="w">                </span><span class="nt">git</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span><span class="nt">repo</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;{{workflow.parameters.repo}}&#34;</span><span class="w">
</span><span class="w">                  </span><span class="nt">revision</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;{{workflow.parameters.branch}}&#34;</span><span class="w">
</span><span class="w">                  </span><span class="nt">insecureIgnoreHostKey</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">                  </span><span class="nt">usernameSecret</span><span class="p">:</span><span class="w">
</span><span class="w">                    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">private-git-creds</span><span class="w">
</span><span class="w">                    </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">username</span><span class="w">
</span><span class="w">                  </span><span class="nt">sshPrivateKeySecret</span><span class="p">:</span><span class="w">
</span><span class="w">                    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">private-git-creds</span><span class="w">
</span><span class="w">                    </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">ssh-private-key</span><span class="w">
</span><span class="w">            </span><span class="nt">parameters</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">context-path</span><span class="w">
</span><span class="w">                </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;{{workflow.parameters.context-path}}&#34;</span><span class="w">
</span><span class="w">              </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">dockerfile</span><span class="w">
</span><span class="w">                </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;{{workflow.parameters.dockerfile}}&#34;</span><span class="w">
</span><span class="w">              </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">image</span><span class="w">
</span><span class="w">                </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;{{workflow.parameters.image}}&#34;</span><span class="w">
</span><span class="w">              </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cache-image</span><span class="w">
</span><span class="w">                </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;{{workflow.parameters.cache-image}}&#34;</span><span class="w">
</span><span class="w">    </span><span class="c"># build-image 作为一个通用的 template，不应该直接去引用 workflow.xxx 中的 parameters/artifacts</span><span class="w">
</span><span class="w">    </span><span class="c"># 这样做的好处是复用性强，这个 template 可以被其他 workflow 引用。</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">build-image</span><span class="w">
</span><span class="w">      </span><span class="nt">inputs</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">artifacts</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">git-repo</span><span class="w">
</span><span class="w">        </span><span class="nt">parameters</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">context-path</span><span class="w">
</span><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">dockerfile</span><span class="w">
</span><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">image</span><span class="w">
</span><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cache-image</span><span class="w">
</span><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">docker-config</span><span class="w">
</span><span class="w">          </span><span class="nt">secret</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">secretName</span><span class="p">:</span><span class="w"> </span><span class="l">docker-config</span><span class="w">
</span><span class="w">      </span><span class="nt">container</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">gcr.io/kaniko-project/executor:v1.3.0</span><span class="w">
</span><span class="w">        </span><span class="c"># 挂载 docker credential</span><span class="w">
</span><span class="w">        </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">docker-config</span><span class="w">
</span><span class="w">            </span><span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/kaniko/.docker/</span><span class="w">
</span><span class="w">        </span><span class="c"># 以 context 为工作目录</span><span class="w">
</span><span class="w">        </span><span class="nt">workingDir</span><span class="p">:</span><span class="w"> </span><span class="l">/work/{{inputs.parameters.context-path}}</span><span class="w">
</span><span class="w">        </span><span class="nt">args</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- --<span class="l">context=.</span><span class="w">
</span><span class="w">          </span>- --<span class="l">dockerfile={{inputs.parameters.dockerfile}}</span><span class="w">
</span><span class="w">          </span><span class="c"># destination 可以重复多次，表示推送多次</span><span class="w">
</span><span class="w">          </span>- --<span class="l">destination={{inputs.parameters.image}}</span><span class="w">
</span><span class="w">          </span><span class="c"># 私有镜像仓库，可以考虑不验证 tls 证书（有安全风险）</span><span class="w">
</span><span class="w">          </span>- --<span class="l">skip-tls-verify</span><span class="w">
</span><span class="w">          </span><span class="c"># - --skip-tls-verify-pull</span><span class="w">
</span><span class="w">          </span><span class="c"># - --registry-mirror=&lt;xxx&gt;.mirror.aliyuncs.com</span><span class="w">
</span><span class="w">          </span>- --<span class="l">reproducible</span><span class="w"> </span><span class="c">#  Strip timestamps out of the image to make it reproducible</span><span class="w">
</span><span class="w">          </span><span class="c"># 使用镜像仓库做远程缓存仓库</span><span class="w">
</span><span class="w">          </span>- --<span class="l">cache=true</span><span class="w">
</span><span class="w">          </span>- --<span class="l">cache-repo={{inputs.parameters.cache-image}}</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h2 id="四常见问题">四、常见问题</h2>
<h3 id="1-workflow-默认使用-root-账号">1. workflow 默认使用 root 账号？</h3>
<p>workflow 的流程默认使用 root 账号，如果你的镜像默认使用非 root 账号，而且要修改文件，就很可能遇到 Permission Denined 的问题。</p>
<p>解决方法：通过 Pod Security Context 手动设定容器的 user/group:</p>
<ul>
<li><a href="https://argoproj.github.io/argo/workflow-pod-security-context/" target="_blank" rel="noopener noreferrer">Workflow Pod Security Context</a></li>
</ul>
<p>安全起见，我建议所有的 workflow 都手动设定 <code>securityContext</code>，示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">argoproj.io/v1alpha1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">WorkflowTemplate</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">xxx</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">runAsNonRoot</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">runAsUser</span><span class="p">:</span><span class="w"> </span><span class="m">1000</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>或者也可以通过 <code>workflow-controller-configmap</code> 的 <code>workflowDefaults</code> 设定默认的 workflow 配置。</p>
<h3 id="2-如何从-hashicorp-vault-中读取-secrets">2. 如何从 hashicorp vault 中读取 secrets?</h3>
<blockquote>
<p>参考 <a href="https://github.com/argoproj/argo/issues/3267#issuecomment-650119636" target="_blank" rel="noopener noreferrer">Support to get secrets from Vault</a></p>
</blockquote>
<p>hashicorp vault 目前可以说是云原生领域最受欢迎的 secrets 管理工具。
我们在生产环境用它做为分布式配置中心，同时在本地 CI/CD 中，也使用它存储相关的敏感信息。</p>
<p>现在迁移到 argo，我们当然希望能够有一个好的方法从 vault 中读取配置。</p>
<p>目前最推荐的方法，是使用 vault 的 vault-agent，将 secrets 以文件的形式注入到 pod 中。</p>
<p>通过 valut-policy - vault-role - k8s-serviceaccount 一系列认证授权配置，可以制定非常细粒度的 secrets 权限规则，而且配置信息阅后即焚，安全性很高。</p>
<h3 id="3-如何在多个名字空间中使用同一个-secrets">3. 如何在多个名字空间中使用同一个 secrets?</h3>
<p>使用 Namespace 对 workflow 进行分类时，遇到的一个常见问题就是，如何在多个名字空间使用 <code>private-git-creds</code>/<code>docker-config</code>/<code>minio</code>/<code>vault</code> 等 workflow 必要的 secrets.</p>
<p>常见的方法是把 secrets 在所有名字空间 create 一次。</p>
<p>但是也有更方便的 secrets 同步工具：</p>
<p>比如，使用 <a href="https://github.com/kyverno/kyverno" target="_blank" rel="noopener noreferrer">kyverno</a> 进行 secrets 同步的配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kyverno.io/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterPolicy</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">sync-secrets</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">background</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">  </span><span class="nt">rules</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># 将 secret vault 从 argo Namespace 同步到其他所有 Namespace</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">sync-vault-secret</span><span class="w">
</span><span class="w">    </span><span class="nt">match</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">kinds</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="l">Namespace</span><span class="w">
</span><span class="w">    </span><span class="nt">generate</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Secret</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">regcred</span><span class="w">
</span><span class="w">      </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;{{request.object.metadata.name}}&#34;</span><span class="w">
</span><span class="w">      </span><span class="nt">synchronize</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">      </span><span class="nt">clone</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">argo</span><span class="w">
</span><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vault</span><span class="w">
</span><span class="w">  </span><span class="c"># 可以配置多个 rules，每个 rules 同步一个 secret</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>上面提供的 kyverno 配置，会实时地监控所有 Namespace 变更，一但有新 Namespace 被创建，它就会立即将 <code>vault</code> secret 同步到该 Namespace.</p>
<p>或者，使用专门的 secrets/configmap 复制工具：<a href="https://github.com/mittwald/kubernetes-replicator" target="_blank" rel="noopener noreferrer">kubernetes-replicator</a></p>
<h3 id="4-argo-对-cr-资源的验证不够严谨写错了-key-都不报错">4. Argo 对 CR 资源的验证不够严谨，写错了 key 都不报错</h3>
<p>待研究</p>
<h3 id="5-如何归档历史数据">5. 如何归档历史数据？</h3>
<p>Argo 用的时间长了，跑过的 Workflows/Pods 全都保存在 Kubernetes/Argo Server 中，导致 Argo 越用越慢。</p>
<p>为了解决这个问题，Argo 提供了一些配置来限制 Workflows 和 Pods 的数量，详见：<a href="https://argoproj.github.io/argo/cost-optimisation/#limit-the-total-number-of-workflows-and-pods" target="_blank" rel="noopener noreferrer">Limit The Total Number Of Workflows And Pods</a></p>
<p>这些限制都是 Workflow 的参数，如果希望设置一个全局默认的限制，可以按照如下示例修改 argo 的 <code>workflow-controller-configmap</code> 这个 configmap:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ConfigMap</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">workflow-controller-configmap</span><span class="w">
</span><span class="w"></span><span class="nt">data</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">config</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span><span class="sd">    # Default values that will apply to all Workflows from this controller, unless overridden on the Workflow-level
</span><span class="sd">    # See more: docs/default-workflow-specs.md
</span><span class="sd">    workflowDefaults:
</span><span class="sd">      spec:
</span><span class="sd">        # must complete in 8h (28,800 seconds)
</span><span class="sd">        activeDeadlineSeconds: 28800
</span><span class="sd">        # keep workflows for 1d (86,400 seconds)
</span><span class="sd">        ttlStrategy:
</span><span class="sd">          secondsAfterCompletion: 86400
</span><span class="sd">          # secondsAfterSuccess: 5
</span><span class="sd">          # secondsAfterFailure: 500
</span><span class="sd">        # delete all pods as soon as they complete
</span><span class="sd">        podGC:
</span><span class="sd">          # 可选项：&#34;OnPodCompletion&#34;, &#34;OnPodSuccess&#34;, &#34;OnWorkflowCompletion&#34;, &#34;OnWorkflowSuccess&#34;
</span><span class="sd">          strategy: OnPodCompletion</span><span class="w">    
</span></code></pre></td></tr></table>
</div>
</div><h3 id="6-argo-的其他进阶配置">6. Argo 的其他进阶配置</h3>
<p>Argo Workflows 的配置，都保存在 <code>workflow-controller-configmap</code> 这个 configmap 中，我们前面已经接触到了它的部分内容。</p>
<p>这里给出此配置文件的完整 examples: <a href="https://github.com/argoproj/argo/blob/master/docs/workflow-controller-configmap.yaml">https://github.com/argoproj/argo/blob/master/docs/workflow-controller-configmap.yaml</a></p>
<p>其中一些可能需要自定义的参数如下：</p>
<ul>
<li><code>parallelism</code>: workflow 的最大并行数量</li>
<li><code>persistence</code>: 将完成的 workflows 保存到 postgresql/mysql 中，这样即使 k8s 中的 workflow 被删除了，还能查看 workflow 记录
<ul>
<li>也支持配置过期时间</li>
</ul>
</li>
<li><code>sso</code>: 启用单点登录</li>
</ul>
<h3 id="7-是否应该尽量使用-cicd-工具提供的功能">7. 是否应该尽量使用 CI/CD 工具提供的功能？</h3>
<p>我从同事以及网络上，了解到部分 DevOps 人员主张尽量自己使用 Python/Go 来实现 CI/CD 流水线，CI/CD 工具提供的功能能不使用就不要使用。</p>
<p>因此有此一问。下面做下详细的分析：</p>
<p>尽量使用 CI/CD 工具提供的插件/功能，好处是不需要自己去实现，可以降低维护成本。
但是相对的运维人员就需要深入学习这个 CI/CD 工具的使用，另外还会和 CI/CD 工具绑定，会增加迁移难度。</p>
<p>而尽量自己用 Python 等代码去实现流水线，让 CI/CD 工具只负责调度与运行这些 Python 代码，
那 CI/CD 就可以很方便地随便换，运维人员也不需要去深入学习 CI/CD 工具的使用。
缺点是可能会增加 CI/CD 代码的复杂性。</p>
<p>我观察到 argo/drone 的一些 examples，发现它们的特征是：</p>
<ol>
<li>所有 CI/CD 相关的逻辑，全都实现在流水线中，不需要其他构建代码</li>
<li>每一个 step 都使用专用镜像：golang/nodejs/python
<ol>
<li>比如先使用 golang 镜像进行测试、构建，再使用 kaniko 将打包成容器镜像</li>
</ol>
</li>
</ol>
<p>那是否应该尽量使用 CI/CD 工具提供的功能呢？
<strong>其实这就是有多种方法实现同一件事，该用哪种方法的问题。这个问题在各个领域都很常见。</strong></p>
<p>以我目前的经验来看，需要具体问题具体分析，以 Argo Workflows 为例：</p>
<ol>
<li>流水线本身非常简单，那完全可以直接使用 argo 来实现，没必要自己再搞个 python 脚本
<ol>
<li>简单的流水线，迁移起来往往也非常简单。没必要为了可迁移性，非要用 argo 去调用 python 脚本。</li>
</ol>
</li>
<li>流水线的步骤之间包含很多逻辑判断/数据传递，那很可能是你的流水线设计有问题！
<ol>
<li><strong>流水线的步骤之间传递的数据应该尽可能少！复杂的逻辑判断应该尽量封装在其中一个步骤中！</strong></li>
<li>这种情况下，就应该使用 python 脚本来封装复杂的逻辑，而不应该将这些逻辑暴露到 Argo Workflows 中！</li>
</ol>
</li>
<li>我需要批量运行很多的流水线，而且它们之间还有复杂的依赖关系：那显然应该利用上 argo wrokflow 的高级特性。
<ol>
<li>argo 的 dag/steps 和 workflow of workflows 这两个功能结合，可以简单地实现上述功能。</li>
</ol>
</li>
</ol>
<h2 id="8-如何提升-argo-workflows-的创建和销毁速度">8. 如何提升 Argo Workflows 的创建和销毁速度？</h2>
<p>我们发现 workflow 的 pod，创建和销毁消耗了大量时间，尤其是销毁。
这导致我们单个流水线在 argo 上跑，还没在 jenkins 上跑更快。</p>
<h2 id="使用体验">使用体验</h2>
<p>目前已经使用 Argo Workflows 一个月多了，总的来说，最难用的就是 Web UI。</p>
<p>其他的都是小问题，只有 Web UI 是真的超难用，感觉根本就没有好好做过设计&hellip;</p>
<p>急需一个第三方 Web UI&hellip;</p>
<h2 id="画外---如何处理其他-kubernetes-资源之间的依赖关系">画外 - 如何处理其他 Kubernetes 资源之间的依赖关系</h2>
<p>Argo 相比其他 CI 工具，最大的特点，是它假设「任务」之间是有依赖关系的，因此它提供了多种协调编排「任务」的方法。</p>
<p>但是貌似 Argo CD 并没有继承这个理念，Argo CD 部署时，并不能在 kubernetes 资源之间，通过 DAG 等方法定义依赖关系。</p>
<p>微服务之间存在依赖关系，希望能按依赖关系进行部署，而 ArgoCD/FluxCD 部署 kubernetes yaml 时都是不考虑任何依赖关系的。这里就存在一些矛盾。</p>
<p>解决这个矛盾的方法有很多，我查阅了很多资料，也自己做了一些思考，得到的最佳实践来自<a href="https://developer.aliyun.com/article/573791" target="_blank" rel="noopener noreferrer">解决服务依赖 - 阿里云 ACK 容器服务</a>，它给出了两种方案：</p>
<ol>
<li><strong>应用端服务依赖检查</strong>: 即在微服务的入口添加依赖检查逻辑，确保所有依赖的微服务/数据库都可访问了，就续探针才能返回 200. 如果超时就直接 Crash</li>
<li><strong>独立的服务依赖检查逻辑</strong>: 部分遗留代码使用方法一改造起来或许会很困难，这时可以考虑使用 <strong>pod initContainer</strong> 或者容器的启动脚本中，加入依赖检查逻辑。</li>
</ol>
<p>但是这两个方案也还是存在一些问题，在说明问题前，我先说明一下我们「<strong>按序部署</strong>」的应用场景。</p>
<p>我们是一个很小的团队，后端做 RPC 接口升级时，通常是直接在开发环境做全量升级+测试。
因此运维这边也是，每次都是做全量升级。</p>
<p>因为没有协议协商机制，新的微服务的「RPC 服务端」将兼容 v1 v2 新旧两种协议，而新的「RPC 客户端」将直接使用 v2 协议去请求其他微服务。
这就导致我们<strong>必须先升级「RPC 服务端」，然后才能升级「RPC 客户端」</strong>。</p>
<p>为此，在进行微服务的全量升级时，就需要沿着 RPC 调用链路按序升级，这里就涉及到了 Kubernetes 资源之间的依赖关系。</p>
<p>前面讲了，阿里云提供的「应用端服务依赖检查」和「独立的服务依赖检查逻辑」是最佳实践。它们的优点有：</p>
<ol>
<li>简化部署逻辑，每次直接做全量部署就 OK。</li>
<li>提升部署速度，具体体现在：GitOps 部署流程只需要走一次（按序部署要很多次）、所有镜像都提前拉取好了、所有 Pod 也都提前启动了。</li>
</ol>
<p>但是这里有个问题是「灰度发布」或者「滚动更新」，这两种情况下都存在<strong>新旧版本共存</strong>的问题。</p>
<p>如果出现了 RPC 接口升级，那就必须先完成「RPC 服务端」的「灰度发布」或者「滚动更新」，再去更新「RPC 客户端」。</p>
<p>否则如果直接对所有微服务做灰度更新，只依靠「服务依赖检查」，就会出现这样的问题——「RPC 服务端」处于「薛定谔」状态，你调用到的服务端版本是新还是旧，取决于负载均衡的策略和概率。</p>
<p>**因此在做 RPC 接口的全量升级时，只依靠「服务依赖检查」是行不通的。**我目前想到的方案，有如下几种：</p>
<ul>
<li>我们当前的使用方案：<strong>直接在 yaml 部署这一步实现按序部署</strong>，每次部署后就轮询 kube-apiserver，确认全部灰度完成，再进行下一阶段的 yaml 部署。</li>
<li><strong>让后端加个参数来控制客户端使用的 RPC 协议版本，或者搞一个协议协商</strong>。这样就不需要控制微服务发布顺序了。</li>
<li>社区很多有状态应用的部署都涉及到部署顺序等复杂操作，目前流行的解决方案是<strong>使用 Operator+CRD 来实现这类应用的部署</strong>。Operator 会自行处理好各个组件的部署顺序。</li>
</ul>
<h2 id="参考文档">参考文档</h2>
<ul>
<li><a href="https://www.infoq.cn/article/fFZPvrKtbykg53x03IaH" target="_blank" rel="noopener noreferrer">Argo加入CNCF孵化器，一文解析Kubernetes原生工作流</a></li>
</ul>
<p>视频:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=fKiU7txd4RI&amp;list=PLj6h78yzYM2Pn8RxfLh2qrXBDftr6Qjut&amp;index=149" target="_blank" rel="noopener noreferrer">How to Multiply the Power of Argo Projects By Using Them Together - Hong Wang</a></li>
</ul>]]></description></item><item><title>secrets 管理工具 Vault 的介绍、安装及使用</title><link>https://ryan4yin.space/posts/expirence-of-vault/</link><pubDate>Sun, 24 Jan 2021 09:31:41 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/expirence-of-vault/</guid><description><![CDATA[<p><a href="https://github.com/hashicorp/vault" target="_blank" rel="noopener noreferrer">Vault</a> 是 hashicorp 推出的 secrets 管理、加密即服务与权限管理工具。它的功能简介如下：</p>
<ol>
<li>secrets 管理：支持保存各种自定义信息、自动生成各类密钥，vault 自动生成的密钥还能自动轮转(rotate)</li>
<li>认证方式：支持接入各大云厂商的账号体系（比如阿里云RAM子账号体系）或者 LDAP 等进行身份验证，不需要创建额外的账号体系。</li>
<li>权限管理：通过 policy，可以设定非常细致的 ACL 权限。</li>
<li>密钥引擎：也支持接管各大云厂商的账号体系（比如阿里云RAM子账号体系），实现 API Key 的自动轮转。</li>
<li>支持接入 kubernetes rbac 权限体系，通过 serviceaccount+role 为每个 Pod 单独配置权限。</li>
</ol>
<ul>
<li>支持通过 sidecar/init-container 将 secrets 注入到 pod 中，或者通过 k8s operator 将 vault 数据同步到 k8s secrets 中</li>
</ul>
<p>在使用 Vault 之前，我们是以携程开源的 <a href="https://github.com/ctripcorp/apollo" target="_blank" rel="noopener noreferrer">Apollo</a> 作为微服务的分布式配置中心。</p>
<p>Apollo 在国内非常流行。它功能强大，支持配置的继承，也有提供 HTTP API 方便自动化。
缺点是权限管理和 secrets 管理比较弱，也不支持信息加密，不适合直接存储敏感信息。因此我们现在切换到了 Vault.</p>
<p>目前我们本地的 CI/CD 流水线和云上的微服务体系，都是使用的 Vault 做 secrets 管理.</p>
<h2 id="一vault-基础概念">一、Vault 基础概念</h2>
<blockquote>
<p>「基本概念」这一节，基本都翻译自官方文档: <a href="https://www.vaultproject.io/docs/internals/architecture">https://www.vaultproject.io/docs/internals/architecture</a></p>
</blockquote>
<p>首先看一下 Vault 的架构图：</p>
<p><figure><a class="lightgallery" href="/images/expirence-of-vault/vault-layers.png" title="/images/expirence-of-vault/vault-layers.png" data-thumbnail="/images/expirence-of-vault/vault-layers.png" data-sub-html="<h2>vault layers</h2>">
        
    </a><figcaption class="image-caption">vault layers</figcaption>
    </figure></p>
<p>可以看到，几乎所有的组件都从属于「安全屏障(security barrier)」，
Vault 可以简单地被划分为 Storage Backend、安全屏障(security barrier) 和 HTTP API 三个部分。</p>
<p>「安全屏障(security barrier)」是 Vault(金库) 周围的「钢铁」和「混凝土」，Storage Backend 和 Vault 之间的所有数据流动都需要经过这个「屏障(barrier)」。</p>
<p>barrier 确保只有加密数据会被写入 Storage Backend，加密数据在经过 barrier 被读出的过程中被验证与解密。</p>
<p>和银行金库(bank vault)非常类似，barrier 也必须先解封，才能解密 storage backend 中的数据。</p>
<h3 id="1-数据存储及加密解密">1. 数据存储及加密解密</h3>
<p>Storage Backend(后端存储): Vault 自身不存储数据，因此需要为它配置一个「Storage Backend」。
「Storage Backend」是不受信任的，只用于存储加密数据。</p>
<p>Initialaztion(初始化): vault 在首次启动时需要初始化，这一步生成一个「加密密钥(encryption key)」用于加密数据，加密完成的数据才能被保存到 Storage Backend.</p>
<p>Unseal(解封): Vault 启动后，因为不知道「加密密钥(ncryption key)」，它会进入「封印(Sealed)」状态，在「解封(Unseal)」前无法进行任何操作。</p>
<p>「加密密钥」被「master key」保护，我们必须提供「master key」才能完成 Unseal 操作。</p>
<p>默认情况下，vault 使用<a href="https://medium.com/taipei-ethereum-meetup/%E7%A7%81%E9%91%B0%E5%88%86%E5%89%B2-shamirs-secret-sharing-7a70c8abf664" target="_blank" rel="noopener noreferrer">沙米尔密钥共享算法</a>
将「master key」分割成五个「Key Shares(分享密钥)」，必须要提供其中任意三个「Key Shares」才能重建出「master key」从而完成 Unseal.</p>
<p><figure><a class="lightgallery" href="/images/expirence-of-vault/vault-shamir-secret-sharing.svg" title="/images/expirence-of-vault/vault-shamir-secret-sharing.svg" data-thumbnail="/images/expirence-of-vault/vault-shamir-secret-sharing.svg" data-sub-html="<h2>vault-shamir-secret-sharing</h2>">
        
    </a><figcaption class="image-caption">vault-shamir-secret-sharing</figcaption>
    </figure></p>
<blockquote>
<p>「Key Shares」的数量，以及重建「master key」最少需要的 key shares 数量，都是可以调整的。
沙米尔密钥共享算法也可以关闭，这样 master key 将被直接用于 Unseal.</p>
</blockquote>
<h3 id="2-认证系统及权限系统">2. 认证系统及权限系统</h3>
<p>在解封完成后，Vault 就可以开始处理请求了。</p>
<p>HTTP 请求进入后的整个处理流程都由 vault core 管理，core 会强制进行 ACL 检查，并确保审计日志(audit logging)完成记录。</p>
<p>客户端首次连接 vault 时，需要先完成身份认证，vault 的「auth methods」模块有很多身份认证方法可选：</p>
<ol>
<li>用户友好的认证方法，适合管理员使用：username/password、云服务商、ldap
<ol>
<li>在创建 user 的时候，需要为 user 绑定 policy，给予合适的权限。</li>
</ol>
</li>
<li>应用友好的方法：public/private keys、tokens、kubernetes、jwt</li>
</ol>
<p>身份验证请求流经 Core 并进入 auth methods，auth methods 确定请求是否有效并返回「关联策略(policies)」的列表。</p>
<p>ACL Policies 由 policy store 负责管理与存储，由 core 进行 ACL 检查。
ACL 的默认行为是拒绝，这意味着除非明确配置 Policy 允许某项操作，否则该操作将被拒绝。</p>
<p>在通过 auth methods 完成了身份认证，并且返回的「关联策略」也没毛病之后，「token store」将会生成并管理一个新的 token，
这个 token 会被返回给客户端，用于进行后续请求。</p>
<p>类似 web 网站的 cookie，token 也都存在一个 lease 租期或者说有效期，这加强了安全性。</p>
<p>token 关联了相关的策略 policies，这些策略将被用于验证请求的权限。</p>
<p>请求经过验证后，将被路由到 secret engine。如果 secret engine 返回了一个 secret（由 vault 自动生成的 secret），
Core 会将其注册到 expiration manager，并给它附加一个 lease ID。lease ID 被客户端用于更新(renew)或吊销(revoke)它得到的 secret.</p>
<p>如果客户端允许租约(lease)到期，expiration manager 将自动吊销这个 secret.</p>
<p>Core 负责处理审核代理(audit brok)的请求及响应日志，将请求发送到所有已配置的审核设备(audit devices)。</p>
<h3 id="3-secret-engine">3. Secret Engine</h3>
<p>Secret Engine 是保存、生成或者加密数据的组件，它非常灵活。</p>
<p>有的 Secret Engines 只是单纯地存储与读取数据，比如 kv 就可以看作一个加密的 Redis。
而其他的 Secret Engines 则连接到其他的服务并按需生成动态凭证。</p>
<p>还有些 Secret Engines 提供「加密即服务(encryption as a service)」 - transit、证书管理等。</p>
<p>常用的 engine 举例：</p>
<ol>
<li>AliCloud Secrets Engine: 基于 RAM 策略动态生成 AliCloud Access Token，或基于 RAM 角色动态生成 AliCloud STS 凭据
<ul>
<li>Access Token 会自动更新(Renew)，而 STS 凭据是临时使用的，过期后就失效了。</li>
</ul>
</li>
<li>kv: 键值存储，可用于存储一些静态的配置。它一定程度上能替代掉携程的 Apollo 配置中心。</li>
<li>Transit Secrets Engine: 提供加密即服务的功能，它只负责加密和解密，不负责存储。主要应用场景是帮 app 加解密数据，但是数据仍旧存储在 MySQL 等数据库中。</li>
</ol>
<h2 id="二部署-vault">二、部署 Vault</h2>
<p>官方建议<a href="https://www.vaultproject.io/docs/platform/k8s/helm/run" target="_blank" rel="noopener noreferrer">通过 Helm 部署 vault</a>，大概流程：</p>
<ol>
<li>使用 helm/docker 部署运行 vault.</li>
<li>初始化/解封 vault: vault 安全措施，每次重启必须解封(可设置自动解封).</li>
</ol>
<h3 id="0-如何选择存储后端">0. 如何选择存储后端？</h3>
<p>首先，我们肯定需要 HA，至少要保留能升级到 HA 的能力，所以不建议选择不支持 HA 的后端。</p>
<p>而具体的选择，就因团队经验而异了，人们往往倾向于使用自己熟悉的、知根知底的后端，或者选用云服务。</p>
<p>比如我们对 MySQL/PostgreSQL 比较熟悉，而且使用云服务提供的数据库不需要考虑太多的维护问题，MySQL 作为一个通用协议也不会被云厂商绑架，那我们就倾向于使用 MySQL/PostgreSQL.</p>
<p>而如果你们是本地自建，那你可能更倾向于使用 Etcd/Consul/Raft 做后端存储。</p>
<h3 id="1-docker-compose-部署非-ha">1. docker-compose 部署（非 HA）</h3>
<blockquote>
<p>推荐用于本地开发测试环境，或者其他不需要高可用的环境。</p>
</blockquote>
<p><code>docker-compose.yml</code> 示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;3.3&#39;</span><span class="w">
</span><span class="w"></span><span class="nt">services</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">vault</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># 文档：https://hub.docker.com/_/vault</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">vault:1.6.0</span><span class="w">
</span><span class="w">    </span><span class="nt">container_name</span><span class="p">:</span><span class="w"> </span><span class="l">vault</span><span class="w">
</span><span class="w">    </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="c"># rootless 容器，内部不能使用标准端口 443</span><span class="w">
</span><span class="w">      </span>- <span class="s2">&#34;443:8200&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">restart</span><span class="p">:</span><span class="w"> </span><span class="l">always</span><span class="w">
</span><span class="w">    </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="c"># 审计日志存储目录，默认不写审计日志，启用 `file` audit backend 时必须提供一个此文件夹下的路径</span><span class="w">
</span><span class="w">      </span>- <span class="l">./logs:/vault/logs</span><span class="w">
</span><span class="w">      </span><span class="c"># 当使用 file data storage 插件时，数据被存储在这里。默认不往这写任何数据。</span><span class="w">
</span><span class="w">      </span>- <span class="l">./file:/vault/file</span><span class="w">
</span><span class="w">      </span><span class="c"># 配置目录，vault 默认 `/valut/config/` 中所有以 .hcl/.json 结尾的文件</span><span class="w">
</span><span class="w">      </span><span class="c"># config.hcl 文件内容，参考 cutom-vaules.yaml</span><span class="w">
</span><span class="w">      </span>- <span class="l">./config.hcl:/vault/config/config.hcl</span><span class="w">
</span><span class="w">      </span><span class="c"># TLS 证书</span><span class="w">
</span><span class="w">      </span>- <span class="l">./certs:/certs</span><span class="w">
</span><span class="w">    </span><span class="c"># vault 需要锁定内存以防止敏感值信息被交换(swapped)到磁盘中</span><span class="w">
</span><span class="w">    </span><span class="c"># 为此需要添加如下能力</span><span class="w">
</span><span class="w">    </span><span class="nt">cap_add</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="l">IPC_LOCK</span><span class="w">
</span><span class="w">    </span><span class="c"># 必须手动设置 entrypoint，否则 vault 将以 development 模式运行</span><span class="w">
</span><span class="w">    </span><span class="nt">entrypoint</span><span class="p">:</span><span class="w"> </span><span class="l">vault server -config /vault/config/config.hcl</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p><code>config.hcl</code> 内容如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-hcl" data-lang="hcl"><span class="n">ui</span> <span class="o">=</span> <span class="kt">true</span>

<span class="err">//</span> <span class="k">使用文件做数据存储</span><span class="err">（</span><span class="k">单节点</span><span class="err">）</span>
<span class="k">storage</span> <span class="s2">&#34;file&#34;</span> {
<span class="n">  path</span>    <span class="o">=</span> <span class="s2">&#34;/vault/file&#34;</span>
}

<span class="k">listener</span> <span class="s2">&#34;tcp&#34;</span> {
<span class="n">  address</span> <span class="o">=</span> <span class="s2">&#34;[::]:8200&#34;</span>

<span class="n">  tls_disable</span> <span class="o">=</span> <span class="kt">false</span>
<span class="n">  tls_cert_file</span> <span class="o">=</span> <span class="s2">&#34;/certs/server.crt&#34;</span>
<span class="n">  tls_key_file</span>  <span class="o">=</span> <span class="s2">&#34;/certs/server.key&#34;</span>
}
</code></pre></td></tr></table>
</div>
</div><p>将如上两份配置保存在同一非文件夹内，同时在 <code>./certs</code> 中提供 TLS 证书 <code>server.crt</code> 和私钥 <code>server.key</code>。</p>
<p>然后 <code>docker-compose up -d</code> 就能启动运行一个 vault 实例。</p>
<h3 id="install-by-helm">2. 通过 helm 部署高可用的 vault</h3>
<blockquote>
<p>推荐用于生产环境</p>
</blockquote>
<p>通过 helm 部署：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 添加 valut 仓库</span>
helm repo add hashicorp https://helm.releases.hashicorp.com
<span class="c1"># 查看 vault 版本号</span>
helm search repo hashicorp/vault -l <span class="p">|</span> head
<span class="c1"># 下载某个版本号的 vault</span>
helm pull hashicorp/vault --version  0.11.0 --untar
</code></pre></td></tr></table>
</div>
</div><p>参照下载下来的 <code>./vault/values.yaml</code> 编写 <code>custom-values.yaml</code>，
部署一个以 <code>mysql</code> 为后端存储的 HA vault，配置示例如下:</p>
<blockquote>
<p>配置内容虽然多，但是大都是直接拷贝自 <code>./vault/values.yaml</code>，改动很少。
测试 Vault 时可以忽略掉其中大多数的配置项。</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">global</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># enabled is the master enabled switch. Setting this to true or false</span><span class="w">
</span><span class="w">  </span><span class="c"># will enable or disable all the components within this chart by default.</span><span class="w">
</span><span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="c"># TLS for end-to-end encrypted transport</span><span class="w">
</span><span class="w">  </span><span class="nt">tlsDisable</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">injector</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># True if you want to enable vault agent injection.</span><span class="w">
</span><span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># If true, will enable a node exporter metrics endpoint at /metrics.</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># Mount Path of the Vault Kubernetes Auth Method.</span><span class="w">
</span><span class="w">  </span><span class="nt">authPath</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;auth/kubernetes&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="nt">certs</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># secretName is the name of the secret that has the TLS certificate and</span><span class="w">
</span><span class="w">    </span><span class="c"># private key to serve the injector webhook. If this is null, then the</span><span class="w">
</span><span class="w">    </span><span class="c"># injector will default to its automatic management mode that will assign</span><span class="w">
</span><span class="w">    </span><span class="c"># a service account to the injector to generate its own certificates.</span><span class="w">
</span><span class="w">    </span><span class="nt">secretName</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c"># caBundle is a base64-encoded PEM-encoded certificate bundle for the</span><span class="w">
</span><span class="w">    </span><span class="c"># CA that signed the TLS certificate that the webhook serves. This must</span><span class="w">
</span><span class="w">    </span><span class="c"># be set if secretName is non-null.</span><span class="w">
</span><span class="w">    </span><span class="nt">caBundle</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c"># certName and keyName are the names of the files within the secret for</span><span class="w">
</span><span class="w">    </span><span class="c"># the TLS cert and private key, respectively. These have reasonable</span><span class="w">
</span><span class="w">    </span><span class="c"># defaults but can be customized if necessary.</span><span class="w">
</span><span class="w">    </span><span class="nt">certName</span><span class="p">:</span><span class="w"> </span><span class="l">tls.crt</span><span class="w">
</span><span class="w">    </span><span class="nt">keyName</span><span class="p">:</span><span class="w"> </span><span class="l">tls.key</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">server</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># Resource requests, limits, etc. for the server cluster placement. This</span><span class="w">
</span><span class="w">  </span><span class="c"># should map directly to the value of the resources field for a PodSpec.</span><span class="w">
</span><span class="w">  </span><span class="c"># By default no direct resource request is made.</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># Enables a headless service to be used by the Vault Statefulset</span><span class="w">
</span><span class="w">  </span><span class="nt">service</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="c"># Port on which Vault server is listening</span><span class="w">
</span><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8200</span><span class="w">
</span><span class="w">    </span><span class="c"># Target port to which the service should be mapped to</span><span class="w">
</span><span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="m">8200</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># This configures the Vault Statefulset to create a PVC for audit</span><span class="w">
</span><span class="w">  </span><span class="c"># logs.  Once Vault is deployed, initialized and unseal, Vault must</span><span class="w">
</span><span class="w">  </span><span class="c"># be configured to use this for audit logs.  This will be mounted to</span><span class="w">
</span><span class="w">  </span><span class="c"># /vault/audit</span><span class="w">
</span><span class="w">  </span><span class="c"># See https://www.vaultproject.io/docs/audit/index.html to know more</span><span class="w">
</span><span class="w">  </span><span class="nt">auditStorage</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># Run Vault in &#34;HA&#34; mode. There are no storage requirements unless audit log</span><span class="w">
</span><span class="w">  </span><span class="c"># persistence is required.  In HA mode Vault will configure itself to use Consul</span><span class="w">
</span><span class="w">  </span><span class="c"># for its storage backend.  The default configuration provided will work the Consul</span><span class="w">
</span><span class="w">  </span><span class="c"># Helm project by default.  It is possible to manually configure Vault to use a</span><span class="w">
</span><span class="w">  </span><span class="c"># different HA backend.</span><span class="w">
</span><span class="w">  </span><span class="nt">ha</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c"># Set the api_addr configuration for Vault HA</span><span class="w">
</span><span class="w">    </span><span class="c"># See https://www.vaultproject.io/docs/configuration#api_addr</span><span class="w">
</span><span class="w">    </span><span class="c"># If set to null, this will be set to the Pod IP Address</span><span class="w">
</span><span class="w">    </span><span class="nt">apiAddr</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c"># config is a raw string of default configuration when using a Stateful</span><span class="w">
</span><span class="w">    </span><span class="c"># deployment. Default is to use a Consul for its HA storage backend.</span><span class="w">
</span><span class="w">    </span><span class="c"># This should be HCL.</span><span class="w">
</span><span class="w">    
</span><span class="w">    </span><span class="c"># Note: Configuration files are stored in ConfigMaps so sensitive data </span><span class="w">
</span><span class="w">    </span><span class="c"># such as passwords should be either mounted through extraSecretEnvironmentVars</span><span class="w">
</span><span class="w">    </span><span class="c"># or through a Kube secret.  For more information see: </span><span class="w">
</span><span class="w">    </span><span class="c"># https://www.vaultproject.io/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations</span><span class="w">
</span><span class="w">    </span><span class="nt">config</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span><span class="sd">      ui = true
</span><span class="sd">
</span><span class="sd">      listener &#34;tcp&#34; {
</span><span class="sd">        address = &#34;[::]:8200&#34;
</span><span class="sd">        cluster_address = &#34;[::]:8201&#34;
</span><span class="sd">
</span><span class="sd">        # 注意，这个值要和 helm 的参数 global.tlsDisable 一致
</span><span class="sd">        tls_disable = false
</span><span class="sd">        tls_cert_file = &#34;/etc/certs/vault.crt&#34;
</span><span class="sd">        tls_key_file  = &#34;/etc/certs/vault.key&#34;
</span><span class="sd">      }
</span><span class="sd">
</span><span class="sd">      # storage &#34;postgresql&#34; {
</span><span class="sd">      #   connection_url = &#34;postgres://username:password@&lt;host&gt;:5432/vault?sslmode=disable&#34;
</span><span class="sd">      #   ha_enabled = true
</span><span class="sd">      # }
</span><span class="sd">
</span><span class="sd">      service_registration &#34;kubernetes&#34; {}
</span><span class="sd">
</span><span class="sd">      # Example configuration for using auto-unseal, using AWS KMS. 
</span><span class="sd">      # the cluster must have a service account that is authorized to access AWS KMS, throught an IAM Role.
</span><span class="sd">      # seal &#34;awskms&#34; {
</span><span class="sd">      #   region     = &#34;us-east-1&#34;
</span><span class="sd">      #   kms_key_id = &#34;&lt;some-key-id&gt;&#34;
</span><span class="sd">      #   默认情况下插件会使用 awskms 的公网 enpoint，但是也可以使用如下参数，改用自行创建的 vpc 内网 endpoint
</span><span class="sd">      #   endpoint   = &#34;https://&lt;vpc-endpoint-id&gt;.kms.us-east-1.vpce.amazonaws.com&#34;
</span><span class="sd">      # }</span><span class="w">      
</span><span class="w">
</span><span class="w">  </span><span class="c"># Definition of the serviceAccount used to run Vault.</span><span class="w">
</span><span class="w">  </span><span class="c"># These options are also used when using an external Vault server to validate</span><span class="w">
</span><span class="w">  </span><span class="c"># Kubernetes tokens.</span><span class="w">
</span><span class="w">  </span><span class="nt">serviceAccount</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">create</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;vault&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="c"># 如果要使用 auto unseal 的话，这个填写拥有 awskms 权限的 AWS IAM Role</span><span class="w">
</span><span class="w">      </span><span class="nt">eks.amazonaws.com/role-arn</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;role-arn&gt;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Vault UI</span><span class="w">
</span><span class="w"></span><span class="nt">ui</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">publishNotReadyAddresses</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">serviceType</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterIP</span><span class="w">
</span><span class="w">  </span><span class="nt">activeVaultPodOnly</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">externalPort</span><span class="p">:</span><span class="w"> </span><span class="m">8200</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>现在使用自定义的 <code>custom-values.yaml</code> 部署 vautl:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubectl create namespace vault
<span class="c1"># 安装/升级 valut</span>
helm upgrade --install vault ./vault --namespace vault -f custom-values.yaml
</code></pre></td></tr></table>
</div>
</div><h3 id="3-初始化initalize并解封unseal-vault">3. 初始化(initalize)并解封(unseal) vault</h3>
<blockquote>
<p>官方文档：<a href="https://learn.hashicorp.com/tutorials/vault/kubernetes-raft-deployment-guide?in=vault/kubernetes#install-vault" target="_blank" rel="noopener noreferrer">Initialize and unseal Vault - Vault on Kubernetes Deployment Guide</a></p>
</blockquote>
<p>通过 helm 部署 vault，默认会部署一个三副本的 StatefulSet，但是这三个副本都会处于 NotReady 状态（docker 方式部署的也一样）。
接下来还需要手动初始化(initalize)并解封(unseal) vault，才能 <code>Ready</code>:</p>
<ol>
<li>第一步：从三个副本中随便选择一个，运行 vault 的初始化命令：<code>kubectl exec -ti vault-0 -- vault operator init</code>
<ol>
<li>初始化操作会返回 5 个 unseal keys，以及一个 Initial Root Token，这些数据非常敏感非常重要，一定要保存到安全的地方！</li>
</ol>
</li>
<li>第二步：在每个副本上，使用任意三个 unseal keys 进行解封操作。
<ol>
<li>一共有三个副本，也就是说要解封 3*3 次，才能完成 vault 的完整解封！</li>
</ol>
</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 每个实例都需要解封三次！</span>
<span class="c1">## Unseal the first vault server until it reaches the key threshold</span>
$ kubectl <span class="nb">exec</span> -ti vault-0 -- vault operator unseal <span class="c1"># ... Unseal Key 1</span>
$ kubectl <span class="nb">exec</span> -ti vault-0 -- vault operator unseal <span class="c1"># ... Unseal Key 2</span>
$ kubectl <span class="nb">exec</span> -ti vault-0 -- vault operator unseal <span class="c1"># ... Unseal Key 3</span>
</code></pre></td></tr></table>
</div>
</div><p>这样就完成了部署，但是要注意，<strong>vault 实例每次重启后，都需要重新解封！也就是重新进行第二步操作！</strong></p>
<h3 id="4-初始化并设置自动解封">4. 初始化并设置自动解封</h3>
<p>在未设置 auto unseal 的情况下，vault 每次重启都要手动解封所有 vault 实例，实在是很麻烦，在云上自动扩缩容的情况下，vault 实例会被自动调度，这种情况就更麻烦了。</p>
<p>为了简化这个流程，可以考虑配置 auto unseal 让 vault 自动解封。</p>
<p>自动解封目前有两种方法：</p>
<ol>
<li>使用阿里云/AWS/Azure 等云服务提供的密钥库来管理 encryption key
<ol>
<li>AWS: <a href="https://www.vaultproject.io/docs/configuration/seal/awskms" target="_blank" rel="noopener noreferrer">awskms Seal</a>
<ol>
<li>如果是 k8s 集群，vault 使用的 ServiceAccount 需要有权限使用 AWS KMS，它可替代掉 config.hcl 中的 access_key/secret_key 两个属性</li>
</ol>
</li>
<li>阿里云：<a href="https://www.vaultproject.io/docs/configuration/seal/alicloudkms" target="_blank" rel="noopener noreferrer">alicloudkms Seal</a></li>
</ol>
</li>
<li>如果你不想用云服务，那可以考虑 <a href="https://learn.hashicorp.com/tutorials/vault/autounseal-transit" target="_blank" rel="noopener noreferrer">autounseal-transit</a>，这种方法使用另一个 vault 实例提供的 transit 引擎来实现 auto-unseal.</li>
<li>简单粗暴：直接写个 crontab 或者在 CI 平台上加个定时任务去执行解封命令，以实现自动解封。不过这样安全性就不好说了。</li>
</ol>
<p>以使用 awskms 为例，首先创建 aws IAM 的 policy 内容如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
    <span class="nt">&#34;Version&#34;</span><span class="p">:</span> <span class="s2">&#34;2012-10-17&#34;</span><span class="p">,</span>
    <span class="nt">&#34;Statement&#34;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&#34;Sid&#34;</span><span class="p">:</span> <span class="s2">&#34;VaultKMSUnseal&#34;</span><span class="p">,</span>
            <span class="nt">&#34;Effect&#34;</span><span class="p">:</span> <span class="s2">&#34;Allow&#34;</span><span class="p">,</span>
            <span class="nt">&#34;Action&#34;</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">&#34;kms:Decrypt&#34;</span><span class="p">,</span>
                <span class="s2">&#34;kms:Encrypt&#34;</span><span class="p">,</span>
                <span class="s2">&#34;kms:DescribeKey&#34;</span>
            <span class="p">],</span>
            <span class="nt">&#34;Resource&#34;</span><span class="p">:</span> <span class="s2">&#34;*&#34;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p>然后创建 IAM Role 绑定上面的 policy，并为 vault 的 k8s serviceaccount 创建一个 IAM Role，绑定上这个 policy.</p>
<p>这样 vault 使用的 serviceaccount 自身就拥有了访问 awskms 的权限，也就不需要额外通过 access_key/secret_key 来访问 awskms.</p>
<p>关于 IAM Role 和 k8s serviceaccount 如何绑定，参见官方文档：<a href="https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html" target="_blank" rel="noopener noreferrer">IAM roles for EKS service accounts</a></p>
<p>完事后再修改好前面提供的 helm 配置，部署它，最后使用如下命令初始化一下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 初始化命令和普通模式并无不同</span>
kubectl <span class="nb">exec</span> -ti vault-0 -- vault operator init
<span class="c1"># 会打印出一个 root token，以及五个 Recovery Key（而不是 Unseal Key）</span>
<span class="c1"># Recover Key 不再用于解封，但是重新生成 root token 等操作仍然会需要用到它.</span>
</code></pre></td></tr></table>
</div>
</div><p>然后就大功告成了，可以尝试下删除 vault 的 pod，新建的 Pod 应该会自动解封。</p>
<h2 id="三vault-自身的配置管理">三、Vault 自身的配置管理</h2>
<p>Vault 本身是一个复杂的 secrets 工具，它提供了 <strong>Web UI</strong> 和 <strong>CLI</strong> 用于手动管理与查看 Vault 的内容。</p>
<p>但是作为一名 DevOps，我们当然更喜欢自动化的方法，这有两种选择:</p>
<ul>
<li>使用 vault 的 sdk: python-<a href="https://github.com/hvac/hvac" target="_blank" rel="noopener noreferrer">hvac</a></li>
<li>使用 <a href="https://github.com/hashicorp/terraform-provider-vault" target="_blank" rel="noopener noreferrer">terraform-provider-vault</a> 或者 <a href="https://github.com/pulumi/pulumi-vault" target="_blank" rel="noopener noreferrer">pulumi-vault</a> 实现 vault 配置的自动化管理。</li>
</ul>
<p>Web UI 适合手工操作，而 sdk/<code>terraform-provider-vault</code> 则适合用于自动化管理 vault.</p>
<p>我们的测试环境就是使用 <code>pulumi-vault</code> 完成的自动化配置 vault policy 和 kubernetes role，然后自动化注入所有测试用的 secrets.</p>
<h3 id="1-使用-pulumi-自动化配置-vault">1. 使用 pulumi 自动化配置 vault</h3>
<p>使用 pulumi 管理 vault 配置的优势是很大的，因为云上资源的敏感信息（数据库账号密码、资源 ID、RAM子账号）都是 pulumi 创建的。</p>
<p>再结合使用 pulumi_valut，就能实现敏感信息自动生成后，立即保存到 vault 中，实现完全自动化。</p>
<p>后续微服务就可以通过 kubernetes 认证，直接从 vault 读取敏感信息。</p>
<p>或者是写入到本地的 vault 中留做备份，在需要的时候，管理员能登入进去查看相关敏感信息。</p>
<h4 id="11-token-的生成">1.1 Token 的生成</h4>
<p>pulumi_vault 本身挺简单的，声明式的配置嘛，直接用就是了。</p>
<p>但是它一定要求提供 <code>VAULT_TOKEN</code> 作为身份认证的凭证（实测 userpass/approle 都不能直接使用，会报错 <code>no vault token found</code>），而且 pulumi 还会先生成临时用的 child token，然后用这个 child token
进行后续的操作。</p>
<p>首先安全起见，肯定不应该直接提供 root token！root token 应该封存，除了紧急情况不应该启用。</p>
<p>那么应该如何生成一个权限有限的 token 给 vault 使用呢？
我的方法是创建一个 userpass 账号，通过 policy 给予它有限的权限。
然后先手动(或者自动)登录获取到 token，再将 token 提供给 pulumi_vault 使用。</p>
<p>这里面有个坑，就是必须给 userpass 账号创建 child token 的权限：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-hcl" data-lang="hcl"><span class="k">path</span> <span class="s2">&#34;local/*&#34;</span> {
<span class="n">  capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;read&#34;, &#34;list&#34;</span><span class="p">]</span>
}

<span class="err">//</span> <span class="k">允许创建</span> <span class="k">child</span> <span class="k">token</span>
<span class="k">path</span> <span class="s2">&#34;auth/token/create&#34;</span> {
<span class="n">  capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;create&#34;, &#34;read&#34;, &#34;update&#34;, &#34;delete&#34;, &#34;list&#34;</span><span class="p">]</span>
}
</code></pre></td></tr></table>
</div>
</div><p>不给这个权限，pulumi_vault 就会一直报错。。</p>
<p>然后还得给它「自动化配置」需要的权限，比如自动创建/更新 policy/secrets/kubernetes 等等，示例如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-hcl" data-lang="hcl"><span class="c1"># To list policies - Step 3
</span><span class="c1"></span><span class="k">path</span> <span class="s2">&#34;sys/policy&#34;</span>
{
<span class="n">  capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;read&#34;</span><span class="p">]</span>
}<span class="c1">
</span><span class="c1">
</span><span class="c1"># Create and manage ACL policies broadly across Vault
</span><span class="c1"></span><span class="k">path</span> <span class="s2">&#34;sys/policy/*&#34;</span>
{
<span class="n">  capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;create&#34;, &#34;read&#34;, &#34;update&#34;, &#34;delete&#34;, &#34;list&#34;, &#34;sudo&#34;</span><span class="p">]</span>
}<span class="c1">
</span><span class="c1">
</span><span class="c1"># List, create, update, and delete key/value secrets
</span><span class="c1"></span><span class="k">path</span> <span class="s2">&#34;secret/*&#34;</span>
{
<span class="n">  capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;create&#34;, &#34;read&#34;, &#34;update&#34;, &#34;delete&#34;, &#34;list&#34;, &#34;sudo&#34;</span><span class="p">]</span>
}

<span class="k">path</span> <span class="s2">&#34;auth/kubernetes/role/*&#34;</span>
{
<span class="n">  capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;create&#34;, &#34;read&#34;, &#34;update&#34;, &#34;list&#34;</span><span class="p">]</span>
}
</code></pre></td></tr></table>
</div>
</div><h2 id="四在-kubernetes-中使用-vault-注入-secrets">四、在 Kubernetes 中使用 vault 注入 secrets</h2>
<p><figure><a class="lightgallery" href="/images/expirence-of-vault/vault-k8s-auth-workflow.png" title="/images/expirence-of-vault/vault-k8s-auth-workflow.png" data-thumbnail="/images/expirence-of-vault/vault-k8s-auth-workflow.png" data-sub-html="<h2>vault-k8s-auth-workflow</h2>">
        
    </a><figcaption class="image-caption">vault-k8s-auth-workflow</figcaption>
    </figure></p>
<p>前面提到过 vault 支持通过 Kubernetes 的 ServiceAccount 为每个 Pod 单独分配权限。</p>
<p>应用程序有两种方式去读取 vault 中的配置：</p>
<ol>
<li>借助 Vault Sidecar，将 secrets 以文件的形式自动注入到 Pod 中，比如 <code>/vault/secrets/config.json</code>
<ul>
<li>vault sidecar 在常驻模式下每 15 秒更新一次配置，应用程序可以使用 <code>watchdog</code> 实时监控 secrets 文件的变更。</li>
</ul>
</li>
<li>应用程序自己使用 SDK 直接访问 vault api 获取 secrets</li>
</ol>
<p>上述两种方式，都可以借助 Kubernetes ServiceAccount 进行身份验证和权限分配。</p>
<p>下面以 Sidecar 模式为例，介绍如何将 secrets 以文件形式注入到 Pod 中。</p>
<h3 id="1-部署并配置-vault-agent">1. 部署并配置 vault agent</h3>
<p>首先启用 Vault 的 Kubernetes 身份验证:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 配置身份认证需要在 vault pod 中执行，启动 vault-0 的交互式会话</span>
kubectl <span class="nb">exec</span> -n vault -it vault-0 -- /bin/sh
<span class="nb">export</span> <span class="nv">VAULT_TOKEN</span><span class="o">=</span><span class="s1">&#39;&lt;your-root-token&gt;&#39;</span>
<span class="nb">export</span> <span class="nv">VAULT_ADDR</span><span class="o">=</span><span class="s1">&#39;http://localhost:8200&#39;</span>
 
<span class="c1"># 启用 Kubernetes 身份验证</span>
vault auth <span class="nb">enable</span> kubernetes

<span class="c1"># kube-apiserver API 配置，vault 需要通过 kube-apiserver 完成对 serviceAccount 的身份验证</span>
vault write auth/kubernetes/config <span class="se">\
</span><span class="se"></span>    <span class="nv">token_reviewer_jwt</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>cat /var/run/secrets/kubernetes.io/serviceaccount/token<span class="k">)</span><span class="s2">&#34;</span> <span class="se">\
</span><span class="se"></span>    <span class="nv">kubernetes_host</span><span class="o">=</span><span class="s2">&#34;https://</span><span class="nv">$KUBERNETES_PORT_443_TCP_ADDR</span><span class="s2">:443&#34;</span> <span class="se">\
</span><span class="se"></span>    <span class="nv">kubernetes_ca_cert</span><span class="o">=</span>@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
</code></pre></td></tr></table>
</div>
</div><h4 id="11-使用集群外部的-valut-实例">1.1 使用集群外部的 valut 实例</h4>
<blockquote>
<p>如果你没这个需求，请跳过这一节。</p>
</blockquote>
<blockquote>
<p>详见 <a href="https://learn.hashicorp.com/tutorials/vault/kubernetes-external-vault?in=vault/kubernetes#install-the-vault-helm-chart-configured-to-address-an-external-vault" target="_blank" rel="noopener noreferrer">Install the Vault Helm chart configured to address an external Vault</a></p>
</blockquote>
<p>kubernetes 也可以和外部的 vault 实例集成，集群中只部署 vault-agent.</p>
<p>这适用于多个 kubernetes 集群以及其他 APP 共用一个 vault 实例的情况，比如我们本地的多个开发测试集群，就都共用着同一个 vault 实例，方便统一管理应用的 secrets.</p>
<p>首先，使用 helm chart 部署 vault-agent，接入外部的 vault 实例。使用的 <code>custom-values.yaml</code> 示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">global</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># enabled is the master enabled switch. Setting this to true or false</span><span class="w">
</span><span class="w">  </span><span class="c"># will enable or disable all the components within this chart by default.</span><span class="w">
</span><span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="c"># TLS for end-to-end encrypted transport</span><span class="w">
</span><span class="w">  </span><span class="nt">tlsDisable</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">injector</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># True if you want to enable vault agent injection.</span><span class="w">
</span><span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># If multiple replicas are specified, by default a leader-elector side-car</span><span class="w">
</span><span class="w">  </span><span class="c"># will be created so that only one injector attempts to create TLS certificates.</span><span class="w">
</span><span class="w">  </span><span class="nt">leaderElector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">repository</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;gcr.io/google_containers/leader-elector&#34;</span><span class="w">
</span><span class="w">      </span><span class="nt">tag</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;0.4&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">ttl</span><span class="p">:</span><span class="w"> </span><span class="l">60s</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># If true, will enable a node exporter metrics endpoint at /metrics.</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># External vault server address for the injector to use. Setting this will</span><span class="w">
</span><span class="w">  </span><span class="c"># disable deployment of a  vault server along with the injector.</span><span class="w">
</span><span class="w">  </span><span class="c"># TODO 这里的 https ca.crt 要怎么设置？mTLS 又该如何配置？</span><span class="w">
</span><span class="w">  </span><span class="nt">externalVaultAddr</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;https://&lt;external-vault-url&gt;&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># Mount Path of the Vault Kubernetes Auth Method.</span><span class="w">
</span><span class="w">  </span><span class="nt">authPath</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;auth/kubernetes&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="nt">certs</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># secretName is the name of the secret that has the TLS certificate and</span><span class="w">
</span><span class="w">    </span><span class="c"># private key to serve the injector webhook. If this is null, then the</span><span class="w">
</span><span class="w">    </span><span class="c"># injector will default to its automatic management mode that will assign</span><span class="w">
</span><span class="w">    </span><span class="c"># a service account to the injector to generate its own certificates.</span><span class="w">
</span><span class="w">    </span><span class="nt">secretName</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c"># caBundle is a base64-encoded PEM-encoded certificate bundle for the</span><span class="w">
</span><span class="w">    </span><span class="c"># CA that signed the TLS certificate that the webhook serves. This must</span><span class="w">
</span><span class="w">    </span><span class="c"># be set if secretName is non-null.</span><span class="w">
</span><span class="w">    </span><span class="nt">caBundle</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c"># certName and keyName are the names of the files within the secret for</span><span class="w">
</span><span class="w">    </span><span class="c"># the TLS cert and private key, respectively. These have reasonable</span><span class="w">
</span><span class="w">    </span><span class="c"># defaults but can be customized if necessary.</span><span class="w">
</span><span class="w">    </span><span class="nt">certName</span><span class="p">:</span><span class="w"> </span><span class="l">tls.crt</span><span class="w">
</span><span class="w">    </span><span class="nt">keyName</span><span class="p">:</span><span class="w"> </span><span class="l">tls.key</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>部署命令和 <a href="#install-by-helm" rel="">通过 helm 部署 vault</a> 一致，只要更换 <code>custom-values.yaml</code> 就行。</p>
<p>vault-agent 部署完成后，第二步是为 vault 创建 serviceAccount、secret 和 ClusterRoleBinding，以允许 vault 审查 kubernetes 的 token, 完成对 pod 的身份验证. yaml 配置如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ServiceAccount</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vault-auth</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">vault</span><span class="w">
</span><span class="w"></span><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Secret</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vault-auth</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">vault</span><span class="w">
</span><span class="w">  </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">kubernetes.io/service-account.name</span><span class="p">:</span><span class="w"> </span><span class="l">vault-auth</span><span class="w">
</span><span class="w"></span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes.io/service-account-token</span><span class="w">
</span><span class="w"></span><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">rbac.authorization.k8s.io/v1beta1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterRoleBinding</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">role-tokenreview-binding</span><span class="w">
</span><span class="w"></span><span class="nt">roleRef</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">apiGroup</span><span class="p">:</span><span class="w"> </span><span class="l">rbac.authorization.k8s.io</span><span class="w">
</span><span class="w">  </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterRole</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">system:auth-delegator</span><span class="w">
</span><span class="w"></span><span class="nt">subjects</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ServiceAccount</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vault-auth</span><span class="w">
</span><span class="w">    </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">vault</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>现在在 vault 实例这边，启用 kubernetes 身份验证，在 vault 实例内，执行如下命令：</p>
<blockquote>
<p>vault 实例内显然没有 kubectl 和 kubeconfig，简便起见，下列的 vault 命令也可以通过 Web UI 完成。</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">export</span> <span class="nv">VAULT_TOKEN</span><span class="o">=</span><span class="s1">&#39;&lt;your-root-token&gt;&#39;</span>
<span class="nb">export</span> <span class="nv">VAULT_ADDR</span><span class="o">=</span><span class="s1">&#39;http://localhost:8200&#39;</span>
 
<span class="c1"># 启用 Kubernetes 身份验证</span>
vault auth <span class="nb">enable</span> kubernetes
 
<span class="c1"># kube-apiserver API 配置，vault 需要通过 kube-apiserver 完成对 serviceAccount 的身份验证</span>
<span class="c1"># TOKEN_REVIEW_JWT: 就是我们前面创建的 secret `vault-auth`</span>
<span class="nv">TOKEN_REVIEW_JWT</span><span class="o">=</span><span class="k">$(</span>kubectl -n vault get secret vault-auth -o go-template<span class="o">=</span><span class="s1">&#39;{{ .data.token }}&#39;</span> <span class="p">|</span> base64 --decode<span class="k">)</span>
<span class="c1"># kube-apiserver 的 ca 证书</span>
<span class="nv">KUBE_CA_CERT</span><span class="o">=</span><span class="k">$(</span>kubectl -n vault config view --raw --minify --flatten -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.clusters[].cluster.certificate-authority-data}&#39;</span> <span class="p">|</span> base64 --decode<span class="k">)</span>
<span class="c1"># kube-apiserver 的 url</span>
<span class="nv">KUBE_HOST</span><span class="o">=</span><span class="k">$(</span>kubectl config view --raw --minify --flatten -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.clusters[].cluster.server}&#39;</span><span class="k">)</span>

vault write auth/kubernetes/config <span class="se">\
</span><span class="se"></span>        <span class="nv">token_reviewer_jwt</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$TOKEN_REVIEW_JWT</span><span class="s2">&#34;</span> <span class="se">\
</span><span class="se"></span>        <span class="nv">kubernetes_host</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$KUBE_HOST</span><span class="s2">&#34;</span> <span class="se">\
</span><span class="se"></span>        <span class="nv">kubernetes_ca_cert</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$KUBE_CA_CERT</span><span class="s2">&#34;</span>
</code></pre></td></tr></table>
</div>
</div><p>这样，就完成了 kubernetes 与外部 vault 的集成！</p>
<h3 id="2-关联-k8s-rbac-权限系统和-vault">2. 关联 k8s rbac 权限系统和 vault</h3>
<p>接下来需要做的事：</p>
<ol start="2">
<li>通过 vault policy 定义好每个 role（微服务）能访问哪些资源。</li>
<li>为每个微服务生成一个 role，这个 role 需要绑定对应的 vault policy 及 kubernetes serviceaccount
<ol>
<li>这个 role 是 vault 的 kubernetes 插件自身的属性，它和 kubernetes role 没有半毛钱关系。</li>
</ol>
</li>
<li>创建一个 ServiceAccount，并使用这个 使用这个 ServiceAccount 部署微服务</li>
</ol>
<p>其中第一步和第二步都可以通过 vault api 自动化完成.
第三步可以通过 kubectl 部署时完成。</p>
<p>方便起见，vault policy / role / k8s serviceaccount 这三个配置，都建议和微服务使用相同的名称。</p>
<blockquote>
<p>上述配置中，role 起到一个承上启下的作用，它关联了 k8s serviceaccount 和 vault policy 两个配置。</p>
</blockquote>
<p>比如创建一个名为 <code>my-app-policy</code> 的 vault policy，内容为:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-hcl" data-lang="hcl"><span class="c1"># 允许读取数据
</span><span class="c1"></span><span class="k">path</span> <span class="s2">&#34;my-app/data/*&#34;</span> {
<span class="n">   capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;read&#34;, &#34;list&#34;</span><span class="p">]</span>
}
<span class="err">//</span> <span class="k">允许列出</span> <span class="k">myapp</span> <span class="k">中的所有数据</span><span class="p">(</span><span class="k">kv</span> <span class="k">v2</span><span class="p">)</span>
<span class="k">path</span> <span class="s2">&#34;myapp/metadata/*&#34;</span> {
<span class="n">    capabilities</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;read&#34;, &#34;list&#34;</span><span class="p">]</span>
}
</code></pre></td></tr></table>
</div>
</div><p>然后在 vault 的 kuberntes 插件配置中，创建 role <code>my-app-role</code>，配置如下:</p>
<ol>
<li>关联 k8s default 名字空间中的 serviceaccount <code>my-app-account</code>，并创建好这个 serviceaccount.</li>
<li>关联 vault token policy，这就是前面创建的 <code>my-app-policy</code></li>
<li>设置 token period（有效期）</li>
</ol>
<p>这之后，每个微服务就能通过 serviceaccount 从 vault 中读取 <code>my-app</code> 中的所有信息了。</p>
<h3 id="3-部署-pod">3. 部署 Pod</h3>
<blockquote>
<p>参考文档：<a href="https://www.vaultproject.io/docs/platform/k8s/injector">https://www.vaultproject.io/docs/platform/k8s/injector</a></p>
</blockquote>
<p>下一步就是将配置注入到微服务容器中，这需要使用到 Agent Sidecar Injector。
vault 通过 sidecar 实现配置的自动注入与动态更新。</p>
<p>具体而言就是在 Pod 上加上一堆 Agent Sidecar Injector 的注解，如果配置比较多，也可以使用 configmap 保存，在注解中引用。</p>
<p>需要注意的是 vault-inject-agent 有两种运行模式：</p>
<ol>
<li>init 模式: 仅在 Pod 启动前初始化一次，跑完就退出（Completed）</li>
<li>常驻模式: 容器不退出，持续监控 vault 的配置更新，维持 Pod 配置和 vualt 配置的同步。</li>
</ol>
<p>示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">minReadySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">progressDeadlineSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">60</span><span class="w">
</span><span class="w">  </span><span class="nt">revisionHistoryLimit</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">strategy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">rollingUpdate</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">maxUnavailable</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RollingUpdate</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">vault.hashicorp.com/agent-init-first</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;true&#39;</span><span class="w">  </span><span class="c"># 是否使用 initContainer 提前初始化配置文件</span><span class="w">
</span><span class="w">        </span><span class="nt">vault.hashicorp.com/agent-inject</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;true&#39;</span><span class="w">
</span><span class="w">        </span><span class="nt">vault.hashicorp.com/secret-volume-path</span><span class="p">:</span><span class="w"> </span><span class="l">vault</span><span class="w">
</span><span class="w">        </span><span class="nt">vault.hashicorp.com/role</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;my-app-role&#34;</span><span class="w">  </span><span class="c"># vault kubernetes 插件的 role 名称</span><span class="w">
</span><span class="w">        </span><span class="nt">vault.hashicorp.com/agent-inject-template-config.json</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span><span class="sd">          </span><span class="w">          </span><span class="c"># 渲染模板的语法在后面介绍</span><span class="w">
</span><span class="w">        </span><span class="nt">vault.hashicorp.com/agent-limits-cpu</span><span class="p">:</span><span class="w"> </span><span class="l">250m</span><span class="w">
</span><span class="w">        </span><span class="nt">vault.hashicorp.com/agent-requests-cpu</span><span class="p">:</span><span class="w"> </span><span class="l">100m</span><span class="w">
</span><span class="w">        </span><span class="c"># 包含 vault 配置的 configmap，可以做更精细的控制</span><span class="w">
</span><span class="w">        </span><span class="c"># vault.hashicorp.com/agent-configmap: my-app-vault-config</span><span class="w">
</span><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">registry.svc.local/xx/my-app:latest</span><span class="w">
</span><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span><span class="w">        </span><span class="c"># 此处省略若干配置...</span><span class="w">
</span><span class="w">      </span><span class="nt">serviceAccountName</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-account</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>常见错误：</p>
<ul>
<li>vault-agent(sidecar) 报错: <code>namespace not authorized</code>
<ul>
<li><code>auth/kubernetes/config</code> 中的 role 没有绑定 Pod 的 namespace</li>
</ul>
</li>
<li>vault-agent(sidecar) 报错: <code>permission denied</code>
<ul>
<li>检查 <code>vault</code> 实例的日志，应该有对应的错误日志，很可能是 <code>auth/kubernetes/config</code> 没配对，vault 无法验证 kube-apiserver 的 tls 证书，或者使用的 kubernetes token 没有权限。</li>
</ul>
</li>
<li>vault-agent(sidecar) 报错: <code>service account not authorized</code>
<ul>
<li><code>auth/kubernetes/config</code> 中的 role 没有绑定 Pod 使用的 serviceAccount</li>
</ul>
</li>
</ul>
<h3 id="4-vault-agent-配置">4. vault agent 配置</h3>
<p>vault-agent 的配置，需要注意的有：</p>
<ol>
<li>如果使用 configmap 提供完整的 <code>config.hcl</code> 配置，注意 <code>agent-init</code></li>
</ol>
<p>vautl-agent 的 template 说明：</p>
<p>目前来说最流行的配置文件格式应该是 json/yaml，以 json 为例，
对每个微服务的 kv 数据，可以考虑将它所有的个性化配置都保存在 <code>&lt;engine-name&gt;/&lt;service-name&gt;/</code> 下面，然后使用如下 template 注入配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">{
    {{ range secrets &#34;&lt;engine-name&gt;/metadata/&lt;service-name&gt;/&#34; }}
        &#34;{{ printf &#34;%s&#34; . }}&#34;: 
        {{ with secret (printf &#34;&lt;engine-name&gt;/&lt;service-name&gt;/%s&#34; .) }}
        {{ .Data.data | toJSONPretty }},
        {{ end }}
    {{ end }}
}
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>template 的详细语法参见: <a href="https://github.com/hashicorp/consul-template#secret">https://github.com/hashicorp/consul-template#secret</a></p>
</blockquote>
<blockquote>
<p>注意：v2 版本的 kv secrets，它的 list 接口有变更，因此在遍历 v2 kv secrets 时，
必须要写成 <code>range secrets &quot;&lt;engine-name&gt;/metadata/&lt;service-name&gt;/&quot;</code>，也就是中间要插入 <code>metadata</code>，而且 policy 中必须开放 <code>&lt;engine-name&gt;/metadata/&lt;service-name&gt;/</code> 的 read/list 权限！
官方文档完全没提到这一点，我通过 wireshark 抓包调试，对照官方的 <a href="https://www.vaultproject.io/api-docs/secret/kv/kv-v2" target="_blank" rel="noopener noreferrer">KV Secrets Engine - Version 2 (API)</a> 才搞明白这个。</p>
</blockquote>
<p>这样生成出来的内容将是 json 格式，不过有个不兼容的地方：最后一个 secrets 的末尾有逗号 <code>,</code>
渲染出的效果示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
    <span class="nt">&#34;secret-a&#34;</span><span class="p">:</span> <span class="p">{</span>
  <span class="nt">&#34;a&#34;</span><span class="p">:</span> <span class="s2">&#34;b&#34;</span><span class="p">,</span>
  <span class="nt">&#34;c&#34;</span><span class="p">:</span> <span class="s2">&#34;d&#34;</span>
<span class="p">},</span>
    <span class="nt">&#34;secret-b&#34;</span><span class="p">:</span> <span class="p">{</span>
  <span class="nt">&#34;v&#34;</span><span class="p">:</span> <span class="s2">&#34;g&#34;</span><span class="p">,</span>
  <span class="nt">&#34;r&#34;</span><span class="p">:</span> <span class="s2">&#34;c&#34;</span>
<span class="p">},</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p>因为存在尾部逗号(trailing comma)，直接使用 json 标准库解析它会报错。
那该如何去解析它呢？我在万能的 stackoverflow 上找到了解决方案：<strong>yaml 完全兼容 json 语法，并且支持尾部逗号！</strong></p>
<p>以 python 为例，直接 <code>yaml.safe_load()</code> 就能完美解析 vault 生成出的 json 内容。</p>
<h3 id="5-拓展在-kubernetes-中使用-vault-的其他姿势">5. 拓展：在 kubernetes 中使用 vault 的其他姿势</h3>
<p>除了使用官方提供的 sidecar 模式进行 secrets 注入，社区也提供了一些别的方案，可以参考：</p>
<ul>
<li><a href="https://github.com/hashicorp/vault-csi-provider" target="_blank" rel="noopener noreferrer">hashicorp/vault-csi-provider</a>: 官方的 Beta 项目，通过 Secrets Store CSI 驱动将 vault secrets 以数据卷的形式挂载到 pod 中</li>
<li><a href="https://github.com/external-secrets/kubernetes-external-secrets" target="_blank" rel="noopener noreferrer">kubernetes-external-secrets</a>: 提供 CRD 定义，根据定义将 secret 从 vault 中同步到 kubernetes secrets</li>
</ul>
<p>官方的 sidecar/init-container 模式仍然是最推荐使用的。</p>
<h2 id="五使用-vault-实现-aws-iam-credentials-的自动轮转">五、使用 vault 实现 AWS IAM Credentials 的自动轮转</h2>
<p>待续。。。</p>
]]></description></item><item><title>TLS 协议、TLS 证书、TLS 证书的配置方法、TLS 加密的破解手段</title><link>https://ryan4yin.space/posts/about-tls-cert/</link><pubDate>Sun, 17 Jan 2021 21:53:26 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/about-tls-cert/</guid><description><![CDATA[<h2 id="更新记录">更新记录</h2>
<ul>
<li><i class="far fa-square fa-fw"></i> 补充 TLS 协议的详细流程</li>
<li><i class="far fa-check-square fa-fw"></i> 完成 TLS 证书的详细介绍</li>
</ul>
<hr>
<h2 id="一tls-协议">一、TLS 协议</h2>
<p>我们需要加密网络数据以实现安全通信，但是有一个现实的问题：</p>
<ol>
<li>非对称加密算法（RSA/ECC 等）可以方便地对数据进行签名/验证，但是计算速度慢。</li>
<li>对称加密算法（ChaCha20/AES 等）计算速度快，强度高，但是无法安全地生成与保管密钥。</li>
</ol>
<p>于是 TLS 协议在握手阶段使用非对称算法验证服务端，并使用 ECDHE 密钥交换算法（Elliptic Curve Diffie-Hellman key exchange）安全地生成一个临时的对称密钥，然后使用对称算法进行加密通信。</p>
<p>然后在后续的每次数据交换过程中，都使用 ECDHE 算法生成新的对称密钥，然后使用新密钥加密解密数据。</p>
<p></p>
<p>上述的 TLS 协议流程，提供了「完美前向保密（Perfect Forward Secrecy）」特性，前向保密能够保护过去进行的通讯不受密码或密钥在未来暴露的威胁。
即使攻击者破解出了一个「对称密钥」，也只能获取到一次事务中的数据，黑客必须破解出整个 TLS 连接中所有事务的对称密钥，才能得到完整的数据。</p>
<blockquote>
<p>tls1.1/tls1.2 也可以使用非前向安全的算法！要注意！</p>
</blockquote>
<blockquote>
<p>本文的主要介绍 TLS 协议在使用方面的内容，ECDHE 等算法及 TLS 握手流程的详细内容，请查阅其他文档。</p>
</blockquote>
<p>TLS 通过两个证书来实现服务端身份验证，以及对称密钥的安全生成：</p>
<ol>
<li>CA 证书：浏览器/操作系统自带，用于验证服务端的 TLS 证书的签名。保证服务端证书可信。</li>
<li>TLS 证书：使用 CA 证书验证了 TLS 证书可信后，将使用这个 TLS 证书进行协商，以安全地生成一个对称密钥。</li>
</ol>
<p>CA 证书和 TLS 证书，都只在 TLS 握手阶段有用到，之后的通信就与它们无关了。</p>
<h2 id="二tls-证书介绍">二、TLS 证书介绍</h2>
<h3 id="1-证书是什么">1. 证书是什么？</h3>
<p>证书，其实就是非对称加密中的公钥，加上一些别的信息组成的一个文件。</p>
<p>比如 CA 证书，就是 CA 公钥+CA机构相关信息构成的一个文件。</p>
<p>而 TLS 证书，则包含公钥+申请者信息(你)，颁发者(CA)的信息+签名(使用 CA 私钥加密的证书 Hash)，以及一些其他信息。</p>
<p>CA 证书中的公钥，能用于验证 TLS 证书中签名的正确性，也就能用于判断证书是否可信。</p>
<p>你可以尝试使用浏览器查看 Google 的证书详情，我使用 Firefox 查看到的内容如下：</p>
<p></p>
<p>证书文件的格式叫做 X.509，由 <a href="https://tools.ietf.org/html/rfc5280" target="_blank" rel="noopener noreferrer">RFC5280</a> 规范详细定义。</p>
<h3 id="2-tls-证书支持保护的域名类型">2. TLS 证书支持保护的域名类型</h3>
<p>TLS 证书支持配置多个域名，并且支持所谓的通配符（泛）域名。
但是通配符域名证书的匹配规则，<strong>和 DNS 解析中的匹配规则并不一致</strong>！</p>
<p>根据<a href="https://help.aliyun.com/document_detail/28542.html" target="_blank" rel="noopener noreferrer">证书选型和购买 - 阿里云文档</a> 的解释，<strong>通配符证书只支持同级匹配</strong>，详细说明如下：</p>
<ol>
<li>一级通配符域名：可保护该通配符域名（主域名）自身和该域名所有的一级子域名。
<ul>
<li>例如：一级通配符域名 <code>*.aliyun.com</code> 可以用于保护 <code>aliyun.com</code>、<code>www.aliyun.com</code> 以及其他所有一级子域名。
但是不能用于保护任何二级子域名，如 <code>xx.aa.aliyun.com</code></li>
</ul>
</li>
<li>二级或二级以上通配符域名：只能保护该域名同级的所有通配域名，不支持保护该通配符域名本身。
<ul>
<li>例如：<code>*.a.aliyun.com</code> 只支持保护它的所有同级域名，不能用于保护三级子域名。</li>
</ul>
</li>
</ol>
<p>要想保护多个二三级子域，只能在生成 TLS 证书时，添加多个通配符域名。
因此设计域名规则时，要考虑到这点，尽量不要使用层级太深的域名！有些信息可以通过 <code>-</code> 来拼接以减少域名层级，比如阿里云的 oss 域名：</p>
<ol>
<li>公网：<code>oss-cn-shenzhen.aliyuncs.com</code></li>
<li>内网：<code>oss-cn-shenzhen-internal.aliyuncs.com</code></li>
</ol>
<h2 id="三tls-证书的生成">三、TLS 证书的生成</h2>
<blockquote>
<p><a href="https://github.com/openssl/openssl" target="_blank" rel="noopener noreferrer">OpenSSL</a> 是目前使用最广泛的网络加密算法库，这里以它为例介绍证书的生成。
另外也可以考虑使用 <a href="https://github.com/cloudflare/cfssl" target="_blank" rel="noopener noreferrer">cfssl</a>.</p>
</blockquote>
<p>前面讲到了 TLS 协议的握手需要使用到两个证书：</p>
<ol>
<li>TLS 证书（服务端证书）：这个是服务端需要配置的数据加密证书。
<ul>
<li>服务端需要持有这个 TLS 证书本身，以及证书的私钥。</li>
<li>握手时服务端需要将 TLS 证书发送给客户端。</li>
</ul>
</li>
<li>CA 证书：这是受信的根证书，客户端可用于验证所有使用它进行签名的 TLS 证书。
<ul>
<li>CA 证书的私钥由权威机构持有，客户端（比如浏览器）则保有 CA 证书自身。</li>
</ul>
</li>
</ol>
<p>在 TLS 连接的建立阶段，客户端（如浏览器）会使用 CA 证书的公钥对服务端的证书签名进行验证，验证成功则说明该证书是受信任的。</p>
<h3 id="1-tls-证书的类型">1. TLS 证书的类型</h3>
<p>按照证书的生成方式进行分类，证书有三种类型：</p>
<ol>
<li>由权威 CA 机构签名的 TLS 证书：这类证书会被浏览器、小程序等第三方应用/服务商信任。申请证书时需要验证你的所有权，也就使证书无法伪造。
<ul>
<li>如果你的 API 需要提供给第三方应用/服务商/浏览器访问，那就必须向权威 CA 机构申请此类证书。</li>
</ul>
</li>
<li>本地签名证书 - <code>tls_locally_signed_cert</code>：即由本地 CA 证书签名的 TLS 证书
<ul>
<li>本地 CA 证书，就是自己使用 <code>openssl</code> 等工具生成的 CA 证书。</li>
<li>这类证书不会被浏览器/小程序等第三方应用/服务商信任，证书就可以被伪造。</li>
<li>这类证书的缺点是无法与第三方应用/服务商建立安全的连接。</li>
<li>如果客户端是完全可控的（比如是自家的 APP），那可以自行验证证书的可靠性（公钥锁定、双向 TLS 验证）。这种场景下使用此类证书是安全可靠的。可以不使用权威CA机构颁发的证书。</li>
</ul>
</li>
<li>自签名证书 - <code>tls_self_signed_cert</code>: 和 <code>tls_locally_signed_cert</code> 类似，但使用 TLS 证书自己充当 CA 证书（我签我自己），生成出的证书就叫自签名证书。
<ul>
<li>注意:<strong>更广义地讲，自签名证书，就是「并非由权威 CA 机构签名的 TLS 证书」</strong>，也就是同时指代了 <code>tls_self_signed_cert</code> 和 <code>tls_locally_signed_cert</code>。这也是「自签名证书」应用最广泛的一种含义。</li>
</ul>
</li>
</ol>
<p>总的来说，权威CA机构颁发的证书，可以被第三方的应用信任，但是自己生成的不行。
而越贵的权威证书，安全性与可信度就越高，或者可以保护更多的域名。</p>
<p>在客户端可控的情况下，可以考虑使用「本地签名证书」（方便、省钱），将这个证书预先埋入客户端中用于验证。</p>
<p>而「自签名证书」主要是方便，能不用还是尽量不要使用。</p>
<h3 id="2-向权威ca机构申请受信-tls-证书">2. 向权威CA机构申请「受信 TLS 证书」</h3>
<p>免费的 TLS 证书有两种方式获取：</p>
<ol>
<li>部分 TLS 提供商有提供免费证书的申请，有效期为一年，但是不支持泛域名。</li>
<li>申请 <a href="https://letsencrypt.org" target="_blank" rel="noopener noreferrer">Let&rsquo;s Encrypt 免费证书</a>
<ul>
<li>很多代理工具都有提供 Let&rsquo;s Encrypt 证书的 Auto Renewal，比如:
<ul>
<li><a href="/network-proxy&#43;web-server/traefik/README.md" rel="">Traefik</a></li>
<li><a href="https://github.com/caddyserver/caddy" target="_blank" rel="noopener noreferrer">Caddy</a></li>
<li><a href="https://github.com/nginx-proxy/docker-letsencrypt-nginx-proxy-companion" target="_blank" rel="noopener noreferrer">docker-letsencrypt-nginx-proxy-companion</a></li>
</ul>
</li>
<li>网上也有一些 <a href="https://github.com/certbot/certbot" target="_blank" rel="noopener noreferrer">certbot</a> 插件，可以通过 DNS 提供商的 API 进行 Let&rsquo;s Encrypt 证书的 Auto Renewal，比如：
<ul>
<li><a href="https://github.com/tengattack/certbot-dns-aliyun" target="_blank" rel="noopener noreferrer">certbot-dns-aliyun</a></li>
</ul>
</li>
<li>terraform 也有相关 provider: <a href="https://github.com/vancluever/terraform-provider-acme" target="_blank" rel="noopener noreferrer">terraform-provider-acme</a></li>
</ul>
</li>
</ol>
<p>收费证书可以在各 TLS 提供商处购买，比如国内的阿里云腾讯云等。</p>
<p>完整的证书申请流程如下：</p>
<p></p>
<p>为了方便用户，图中的申请人(Applicant)自行处理的部分，目前很多证书申请网站也可以自动处理，用户只需要提供相关信息即可。</p>
<h3 id="3-生成本地签名证书或者自签名证书">3. 生成「本地签名证书」或者「自签名证书」</h3>
<p>除了被第三方信任的「受信 TLS 证书」，在内网环境，我们需要也使用 TLS 证书保障通信安全，这时我们可能会选择自己生成证书，而不是向权威机构申请证书。</p>
<p>可能的原因如下：</p>
<ol>
<li>要向权威机构申请证书，那是要给钱的。而在内网环境下，并无必要使用权威证书。</li>
<li>内网环境使用的可能是非公网域名（<code>xxx.local</code>/<code>xxx.lan</code>/<code>xxx.srv</code> 等），权威机构不签发这种域名的证书。（因为没有人唯一地拥有这个域名）</li>
</ol>
<p>前面介绍过，自己生成的证书有两种方类型：</p>
<ol>
<li>本地签名证书：生成两个独立的密钥对，一个用于 CA 证书，另一个用于 TLS 证书。使用 CA 证书对 TLS 证书进行签名。</li>
<li>自签名证书（我签我自己）：TLS 证书和 CA 证书都使用同一个密钥对，使用 TLS 证书对它自己进行签名。
<ul>
<li>测试发现这种方式得到的证书貌似不包含 SAN 属性！因此不支持多域名。</li>
</ul>
</li>
</ol>
<p>一般来说，直接生成一个泛域名的「自签名证书」就够了，但是它不方便拓展——客户端对每个「自签名证书」，都需要单独添加一次信任。
而「本地签名证书」就没这个问题，one <code>ca.crt</code> rules them all.</p>
<p>总的来说，使用「自签名证书」不方便进行拓展，未来可能会遇到麻烦。因此建议使用「本地签名证书」。</p>
<p>另外介绍下这里涉及到的几种文件类型：</p>
<ol>
<li><code>xxx.key</code>: 就是一个私钥，一般是一个 RSA 私钥，长度通常指定为 2048 位。
<ul>
<li>CA 证书和 TLS 证书的私钥都是通过这种方式生成的。</li>
</ul>
</li>
<li><code>xxx.csr</code>: 即 Certificate Sign Request，证书签名请求。使用 openssl 等工具，通过 TLS 密钥+TLS 证书的相关信息，可生成出一个 CSR 文件。
<ul>
<li>域名（Common Name, CN）就是在这里指定的，可以使用泛域名。</li>
<li>用户将 csr 文件发送给 CA 机构，进行进一步处理。</li>
</ul>
</li>
<li><code>xxx.crt</code>: 这就是我们所说的 TLS 证书，CA 证书和服务端 TLS 证书都是这个格式。
<ul>
<li>使用 CA 证书、CA 密钥对 <code>csr</code> 文件进行签名，就能得到最终的服务端 TLS 证书——一个 <code>crt</code> 文件。</li>
</ul>
</li>
</ol>
<p>生成一个「自签名证书」或者「本地签名证书」（RSA256 算法），有两个步骤：</p>
<ol>
<li>编写证书签名请求的配置文件 <code>csr.conf</code>:
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">[ req ]
default_bits = 2048
prompt = no
default_md = sha256
req_extensions = req_ext
distinguished_name = dn

[ dn ]
C = CN  # Contountry
ST = &lt;state&gt;
L = &lt;city&gt;
O = &lt;organization&gt;
OU = &lt;organization unit&gt;
CN = *.svc.local  # 泛域名，这个字段已经被 chrome/apple 弃用了。

[ alt_names ]  # 备用名称，chrome/apple 目前只信任这里面的域名。
DNS.1 = *.svc.local  # 一级泛域名
DNS.2 = *.aaa.svc.local  # 二级泛域名
DNS.3 = *.bbb.svc.local  # 二级泛域名

[ req_ext ]
subjectAltName = @alt_names

[ v3_ext ]
subjectAltName=@alt_names  # Chrome 要求必须要有 subjectAltName(SAN)
authorityKeyIdentifier=keyid,issuer:always
basicConstraints=CA:FALSE
keyUsage=keyEncipherment,dataEncipherment,digitalSignature
extendedKeyUsage=serverAuth,clientAuth
</code></pre></td></tr></table>
</div>
</div><ul>
<li>此文件的详细文档：<a href="https://www.openssl.org/docs/man1.1.1/man5/" target="_blank" rel="noopener noreferrer">OpenSSL file formats and conventions</a></li>
</ul>
</li>
<li>生成证书：
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 1. 生成 2048 位 的 RSA 密钥</span>
openssl genrsa -out server.key <span class="m">2048</span>
<span class="c1"># 2. 通过第一步编写的配置文件，生成证书签名请求（公钥+申请者信息）</span>
openssl req -new -key server.key -out server.csr -config csr.conf
<span class="c1"># 3. 生成最终的证书，这里指定证书有效期 3650 天</span>
<span class="c1">## 3.1 方法一（自签名）：使用 server.key 进行自签名。这种方式得到的证书不包含 SAN！不支持多域名！</span>
openssl req -x509 -sha256 -days <span class="m">3650</span> -key server.key -in server.csr -out server.crt
<span class="c1">## 3.2 方法二（本地签名）：生成 ca 证书，并且使用 CA 证书、CA 密钥对 `csr` 文件进行签名</span>
<span class="c1">### 3.2.1 ca 私钥</span>
openssl genrsa -out ca.key <span class="m">2048</span>
<span class="c1">### 3.2.2 ca 证书，ca 证书的有效期尽量设长一点，因为不方便更新换代。</span>
openssl req -x509 -new -nodes -key ca.key -subj <span class="s2">&#34;/CN=MyLocalRootCA&#34;</span> -days <span class="m">10000</span> -out ca.crt
<span class="c1">### 3.2.3 签名，得到最终的 TLS 证书，它包含四部分内容：公钥+申请者信息 + 颁发者(CA)的信息+签名(使用 CA 私钥加密)</span>
openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key <span class="se">\
</span><span class="se"></span>  -CAcreateserial -out server.crt -days <span class="m">3650</span> <span class="se">\
</span><span class="se"></span>  -extensions v3_ext -extfile csr.conf
</code></pre></td></tr></table>
</div>
</div></li>
</ol>
<p>上述流程生成一个 x509 证书链，详细的参数说明，参见 <a href="https://tools.ietf.org/html/rfc5280" target="_blank" rel="noopener noreferrer">RFC5280 - Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile</a></p>
<h3 id="4-关于证书寿命">4. 关于证书寿命</h3>
<p>对于公开服务，服务端证书的有效期不要超过 825 天（27 个月）！而 2020 年 11 月起，新申请的服务端证书有效期缩短到了 398 天（13 个月）。目前 Apple/Mozilla/Chrome 都发表了相应声明，证书有效期超过上述限制的，将被浏览器/Apple设备禁止使用。</p>
<p>对于其他用途的证书，如果更换起来很麻烦，可以考虑放宽条件。
比如 kubernetes 集群的加密证书，可以考虑有效期设长一些，比如 10 年。</p>
<p>据<a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ2MjI5OA==&amp;mid=2664079008&amp;idx=1&amp;sn=dede1114d5705880ea757f8d9ae4c92d" target="_blank" rel="noopener noreferrer">云原生安全破局｜如何管理周期越来越短的数字证书？</a>所述，大量知名企业如 特斯拉/微软/领英/爱立信 都曾因未及时更换 TLS 证书导致服务暂时不可用。</p>
<p>因此 TLS 证书最好是设置自动轮转！人工维护不可靠！
目前很多 Web 服务器/代理，都支持自动轮转 Let&rsquo;s Encrypt 证书。
另外 Vault 等安全工具，也支持自动轮转私有证书。</p>
<h3 id="5-拓展1基于-ecc-算法的-tls-证书">5. 拓展1：基于 ECC 算法的 TLS 证书</h3>
<blockquote>
<p>Let&rsquo;s Encrypt 目前也已经支持了 ECC 证书。</p>
</blockquote>
<p>ECC(Elliptic Curve Cryptography) 算法被认为是比 RSA 更优秀的算法。与 RSA 算法相比，ECC 算法使用更小的密钥大小，但可提供同样的安全性，这使计算更快，降低了能耗，并节省了内存和带宽。</p>
<p>对于 RSA 密钥，可以提供不同的密钥大小（密钥大小越大，加密效果越好）。
而对于 ECC 密钥，您应选择要用哪种曲线生成密钥对。各个组织（ANSI X9.62、NIST、SECG）命名了多种曲线，可通过如下命名查看 openssl 支持的所有椭圆曲线名称：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">openssl ecparam -list_curves
</code></pre></td></tr></table>
</div>
</div><p>生成一个自签名的 ECC 证书的命令示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 生成 ec 算法的私钥，使用 prime256v1 算法，密钥长度 256 位。（强度大于 2048 位的 RSA 密钥）</span>
openssl ecparam -genkey -name prime256v1 -out key.pem
<span class="c1"># 生成证书签名请求，需要输入域名(Common Name, CN)等相关信息</span>
openssl req -new -sha256 -key key.pem -out csr.csr -config csr.conf
<span class="c1"># 生成最终的证书，这里指定证书有效期 10 年</span>
<span class="c1">## 方法一：自签名证书</span>
openssl req -x509 -sha256 -days <span class="m">3650</span> -key key.pem -in csr.csr -out certificate.pem
<span class="c1">## 方法二：使用 ca 进行签名，方法参考前面</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="6-拓展2使用-openssl-生成-sshjwt-密钥对">6. 拓展2：使用 OpenSSL 生成 SSH/JWT 密钥对</h3>
<p>RSA/ECC 这两类非对称加密算法被广泛的应用在各类加密通讯中。
SSH/JWT 都支持 RSA-SHA256 及 ECDSA-SHA256 等基于 RSA/ECDSA 的签名/加密算法，因此使用 OpenSSL 生成的密钥对，也应该能用于 SSH 协议加密、JWT 签名等场景。</p>
<blockquote>
<p>ECDSA 是一种基于 ECC 和 DSA 的加密算法</p>
</blockquote>
<p>既然 SSH/TLS/JWT 使用的是相同的密钥对，那理所当然地，SSH/JWT 密钥对应该也可以通过 OpenSSL 生成出来。</p>
<p>生成 RSA 密钥对的命令如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 1. 生成 2048 位（不是 256 位）的 RSA 密钥</span>
openssl genrsa -out rsa-private-key.pem <span class="m">2048</span>

<span class="c1"># 2. 通过密钥生成公钥，JWT 使用此公钥验证签名</span>
openssl rsa -in rsa-private-key.pem -pubout -out rsa-public-key.pem

<span class="c1"># 3. SSH 使用专用的公钥格式，需要使用 ssh-keygen 转换下格式</span>
ssh-keygen -i -mPKCS8 -f rsa-public-key.pem -y &gt; rsa-public.pub
</code></pre></td></tr></table>
</div>
</div><p>生成 ECC 密钥对的命令如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 1. 生成 ec 算法的私钥，使用 prime256v1 算法，密钥长度 256 位。（强度大于 2048 位的 RSA 密钥）</span>
openssl ecparam -genkey -name prime256v1 -out ecc-private-key.pem
<span class="c1"># 2. 通过密钥生成公钥</span>
openssl ec -in ecc-private-key.pem -pubout -out ecc-public-key.pem

<span class="c1"># 3. SSH 使用专用的公钥格式，需要使用 ssh-keygen 转换下格式</span>
ssh-keygen -i -mPKCS8 -f ecc-public-key.pem -y &gt; ecc-public.pub
</code></pre></td></tr></table>
</div>
</div><p>JWT 签名及验证只需要使用标准的私钥-公钥对，即 <code>ecc-private-key.pem</code>/<code>ecc-public-key.pem</code>.</p>
<p>而 SSH 需要使用专用的公钥格式，因此它的使用的密钥对应该是 <code>ecc-private-key.pem</code>/<code>ecc-public.pub</code></p>
<p>注：SSH 目前推荐使用 ed25519 算法，而 JWT 目前推荐使用 ECDSA 算法。</p>
<h4 id="61-加密与签名">6.1 加密与签名</h4>
<ul>
<li>
<p>加密与解密：公钥用于对数据进行加密，私钥用于对数据进行解密</p>
</li>
<li>
<p>签名与验证：私钥用于对数据进行签名，公钥用于对签名进行验证</p>
</li>
<li>
<p><a href="https://www.zhihu.com/question/25912483/answer/31653639" target="_blank" rel="noopener noreferrer">加密与签名的公私钥，用途刚好相反！</a></p>
</li>
</ul>
<h2 id="四服务端与客户端的证书配置">四、服务端与客户端的证书配置</h2>
<h3 id="1-服务端的-tls-证书配置">1. 服务端的 TLS 证书配置</h3>
<p>要支持 HTTPS 协议，服务端需要两个文件：</p>
<ol>
<li>TLS 证书私钥(RSA 私钥或 EC 私钥)：<code>server.key</code></li>
<li>TLS 证书（包含公钥）：<code>server.crt</code></li>
</ol>
<p>一般如 Nginx 等服务端应用，都可以通过配置文件指定这两个文件的位置。修改配置后重新启动，就有 TLS 了，可以通过 https 协议访问测试。</p>
<h4 id="11-完美前向保密">1.1 完美前向保密</h4>
<p>旧版本的 TLS 协议并不一定能保证前向保密，为了保证前向安全，需要在服务端配置中进行一定设置。
具体的设置方法参见 <a href="https://ssl-config.mozilla.org/#server=nginx" target="_blank" rel="noopener noreferrer">ssl-config - mozilla</a>，该网站提供三个安全等级的配置：</p>
<ol>
<li>「Intermediate」：查看生成出的 <code>ssl-cipher</code> 属性，发现它只支持 <code>ECDHE</code>/<code>DHE</code> 开头的算法。因此它保证前向保密。
<ul>
<li>对于需要通过浏览器访问的 API，推荐选择这个等级。</li>
</ul>
</li>
<li>「Mordern」：只支持 <code>TLSv1.3</code>，该协议废弃掉了过往所有不安全的算法，保证前向保密，安全性极高，性能也更好。
<ul>
<li>对于不需要通过浏览器等旧终端访问的 API，请直接选择这个等级。</li>
</ul>
</li>
<li>「Old」：除非你的用户使用非常老的终端进行访问，否则请不要考虑这个选项！</li>
</ol>
<p>另外阿里云负载均衡器配置前向保密的方法参见：<a href="https://help.aliyun.com/document_detail/90740.html" target="_blank" rel="noopener noreferrer">管理TLS安全策略 - 负载均衡 - 阿里云文档</a></p>
<h3 id="2-客户端的-tls-证书配置针对本地签名的证书">2. 客户端的 TLS 证书配置（针对本地签名的证书）</h3>
<p>如果你在证书不是权威 CA 机构颁发的（比如是一个自签名证书），那就需要在客户端将这个 TLS 证书添加到受信证书列表中。
这个步骤可以在 OS 层面进行——添加到 OS 的默认证书列表中，也可以在代码层面完成——指定使用某个证书进行 TLS 验证。</p>
<ol>
<li>Linux: 使用如下命令安装证书
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">sudo cp ca.crt /usr/local/share/ca-certificates/server.crt
sudo update-ca-certificates
</code></pre></td></tr></table>
</div>
</div></li>
<li>Windows: 通过证书管理器 <code>certmgr.msc</code> 将证书安装到 <code>受信任的根证书颁发机构</code>，Chrome 的小锁就能变绿了。</li>
<li>编程：使用 HTTPS 客户端的 api 指定使用的 TLS 证书</li>
<li>Docker-Client: 参见 <a href="https://docs.docker.com/registry/insecure/#use-self-signed-certificates" target="_blank" rel="noopener noreferrer">Use self-signed certificates - Docker Docs</a></li>
</ol>
<h4 id="21-证书锁定certifacte-pining技术">2.1 证书锁定(Certifacte Pining)技术</h4>
<p>即使使用了 TLS 协议对流量进行加密，并且保证了前向保密，也无法保证流量不被代理！</p>
<p>这是因为客户端大多是直接依靠了操作系统内置的证书链进行 TLS 证书验证，而 Fiddler 等代理工具可以将自己的 TLS 证书添加到该证书链中。</p>
<p>为了防止流量被 Fiddler 等工具使用上述方式监听流量，出现了「证书锁定」技术。
方法是在客户端中硬编码证书的指纹（Hash值，或者直接保存整个证书的内容也行），在建立 TLS 连接前，先计算使用的证书的指纹是否匹配，否则就中断连接。</p>
<p>这种锁定方式需要以下几个前提才能确保流量不被监听：</p>
<ol>
<li>客户端中硬编码的证书指纹不会被篡改。</li>
<li>指纹验证不能被绕过。
<ol>
<li>目前有公开技术（XPosed+JustTrustMe）能破解 Android 上常见的 HTTPS 请求库，直接绕过证书检查。</li>
<li>针对上述问题，可以考虑加大绕过的难度。或者 App 检测自己是否运行在 Xposed 等虚拟环境下。</li>
</ol>
</li>
<li>用于 TLS 协议的证书不会频繁更换。（如果更换了，指纹就对不上了。）</li>
</ol>
<p>而对于第三方的 API，因为我们不知道它们会不会更换 TLS 证书，就不能直接将证书指纹硬编码在客户端中。
这时可以考虑从服务端获取这些 API 的证书指纹（附带私钥签名用于防伪造）。</p>
<p>为了实现证书的轮转(rotation)，可以在新版本的客户端中包含多个证书指纹，这样能保证同时有多个可信证书，达成证书的轮转。（类比 JWT 的公钥轮转机制）</p>
<blockquote>
<p>证书锁定技术几乎等同于 SSH 协议的 <code>StrictHostKeyChecking</code> 选项，客户端会验证服务端的公钥指纹（key fingerprint），验证不通过则断开连接。</p>
</blockquote>
<h4 id="22-公钥锁定public-key-pining">2.2 公钥锁定(Public Key Pining)</h4>
<p>前面提到过，TLS 证书其实就是公钥+申请者(你)和颁发者(CA)的信息+签名(使用 CA 私钥加密)，因此我们也可以考虑只锁定其中的公钥。</p>
<p>「公钥锁定」比「证书锁定」更灵活，这样证书本身其实就可以直接轮转了（证书有过期时间），而不需要一个旧证书和新证书共存的中间时期。</p>
<p><strong>如果不考虑实现难度的话，「公钥锁定」是更推荐的技术。</strong></p>
<h2 id="五tls-双向认证mutual-tls-authentication-mtls">五、TLS 双向认证(Mutual TLS authentication, mTLS)</h2>
<p>TLS 协议（tls1.0+，RFC: <a href="https://tools.ietf.org/html/rfc5246#section-7.4.4" target="_blank" rel="noopener noreferrer">TLS1.2 - RFC5246</a>）中，定义了服务端请求验证客户端证书的方法。这
个方法是可选的。如果使用上这个方法，那客户端和服务端就会在 TLS 协议的握手阶段进行互相认证。这种验证方式被称为双向 TLS 认证(mTLS, mutual TLS)。</p>
<p>传统的「TLS 单向认证」技术，只在客户端去验证服务端是否可信。
而「TLS 双向认证（mTLS）」，则添加了服务端验证客户端是否可信的步骤（第三步）：</p>
<ol>
<li>客户端发起请求</li>
<li>「验证服务端是否可信」：服务端将自己的 TLS 证书发送给客户端，客户端通过自己的 CA 证书链验证这个服务端证书。</li>
<li>「验证客户端是否可信」：客户端将自己的 TLS 证书发送给服务端，服务端使用它的 CA 证书链验证该客户端证书。</li>
<li>协商对称加密算法及密钥</li>
<li>使用对称加密进行后续通信。</li>
</ol>
<p>因为相比传统的 TLS，mTLS 只是添加了「验证客户端」这样一个步骤，所以这项技术也被称为「Client Authetication」.</p>
<p>mTLS 需要用到两套 TLS 证书：</p>
<ol>
<li>服务端证书：这个证书签名已经介绍过了。</li>
<li>客户端证书：客户端证书貌似对证书信息（如 CN/SAN 域名）没有任何要求，只要证书能通过 CA 签名验证就行。</li>
</ol>
<p>使用 openssl 生成 TLS 客户端证书（ca 和 csr.conf 可以直接使用前面生成服务端证书用到的，也可以另外生成）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 1. 生成 2048 位 的 RSA 密钥</span>
openssl genrsa -out client.key <span class="m">2048</span>
<span class="c1"># 2. 通过第一步编写的配置文件，生成证书签名请求</span>
openssl req -new -key client.key -out client.csr -config csr.conf
<span class="c1"># 3. 生成最终的证书，这里指定证书有效期 3650 天</span>
<span class="c1">### 使用前面生成的 ca 证书对客户端证书进行签名（客户端和服务端共用 ca 证书）</span>
openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key <span class="se">\
</span><span class="se"></span>   -CAcreateserial -out client.crt -days <span class="m">3650</span> <span class="se">\
</span><span class="se"></span>   -extensions v3_ext -extfile csr.conf
</code></pre></td></tr></table>
</div>
</div><p>mTLS 的应用场景主要在「零信任网络架构」，或者叫「无边界网络」中。
比如微服务之间的互相访问，就可以使用 mTLS。
这样就能保证每个 RPC 调用的客户端，都是其他微服务（或者别的可信方），防止黑客入侵后为所欲为。</p>
<p>目前查到如下几个Web服务器/代理支持 mTLS:</p>
<ol>
<li>Traefik: <a href="https://docs.traefik.io/v2.0/https/tls/#client-authentication-mtls" target="_blank" rel="noopener noreferrer">Docs - Client Authentication (mTLS)</a></li>
<li>Nginx: <a href="https://community.openhab.org/t/using-nginx-reverse-proxy-for-client-certificate-authentication-start-discussion/43064" target="_blank" rel="noopener noreferrer">Using NGINX Reverse Proxy for client certificate authentication</a>
<ol>
<li>主要参数是两个：<code>ssl_client_certificate /etc/nginx/client-ca.pem</code> 和 <code>ssl_verify_client on</code></li>
</ol>
</li>
</ol>
<h3 id="mtls-的安全性">mTLS 的安全性</h3>
<p>如果将 mTLS 用在 App 安全上，存在的风险是：</p>
<ol>
<li>客户端中隐藏的证书是否可以被提取出来，或者黑客能否 Hook 进 App 中，直接使用证书发送信息。</li>
<li>如果客户端私钥设置了「密码（passphrase）」，那这个密码是否能很容易被逆向出来？</li>
</ol>
<p>mTLS 和「公钥锁定/证书锁定」对比：</p>
<ol>
<li>公钥锁定/证书锁定：只在客户端进行验证。
<ol>
<li>但是在服务端没有进行验证。这样就无法鉴别并拒绝第三方应用（爬虫）的请求。</li>
<li>加强安全的方法，是通过某种算法生成动态的签名。爬虫生成不出来这个签名，请求就被拒绝。</li>
</ol>
</li>
<li>mTLS: 服务端和客户端都要验证对方。
<ol>
<li>保证双边可信，在客户端证书不被破解的情况下，就能 Ban 掉所有的爬虫或代理技术。</li>
</ol>
</li>
</ol>
<h2 id="六-tls-协议的破解手段">六 TLS 协议的破解手段</h2>
<h3 id="1-客户端逆向破解手段总结">1. 客户端逆向/破解手段总结</h3>
<p>要获取一个应用的数据，有两个方向：</p>
<ol>
<li>服务端入侵：现代应用的服务端突破难度通常都比较客户端高，注入等漏洞底层框架就有处理。</li>
<li>客户端逆向+爬虫：客户端是离用户最近的地方，也是最容易被突破的地方。
<ol>
<li>mTLS 常见的破解手段，是找到老版本的安装包，发现很容易就能提取出客户端证书。。</li>
</ol>
</li>
</ol>
<p>待续</p>
<h2 id="七通过-openssl-对-tls-证书进行-curd增删查改">七、通过 OpenSSL 对 TLS 证书进行 CURD（增删查改）</h2>
<h3 id="1-查询与验证">1. 查询与验证</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 查看证书(crt)信息</span>
openssl x509 -noout -text -in server.crt

<span class="c1"># 查看证书请求(csr)信息</span>
openssl req -noout -text -in server.csr

<span class="c1"># 查看 RSA 私钥(key)信息</span>
openssl rsa -noout -text -in server.key

<span class="c1"># 验证证书是否可信</span>
<span class="c1">## 1. 使用系统的证书链进行验证。因为是自签名证书，会验证失败</span>
openssl verify server.crt
<span class="c1">## 2. 使用 ca.crt 进行验证。验证成功。</span>
openssl verify -CAfile ca.crt server.crt
</code></pre></td></tr></table>
</div>
</div><h3 id="2-证书格式转换">2. 证书格式转换</h3>
<p>openssl 模式使用 PEM 格式的证书，这个证书格式将证书编码为 base64 格式进行保存。
另外一类使用广泛的证书，是 PKCS#12、PKCS#8，以及 Windows 上常用的 DER 格式。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># pem 格式转 pkcs12，公钥和私钥都放里面</span>
openssl pkcs12 -export -in client.crt -inkey client.key -out client.p12
<span class="c1"># 按提示输入保护密码</span>
</code></pre></td></tr></table>
</div>
</div><p>或者 p12 转 pem:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">openssl pkcs12 -in xxx.p12 -out xxx.crt -clcerts -nokeys
openssl pkcs12 -in xxx.p12 -out xxx.key -nocerts -nodes
</code></pre></td></tr></table>
</div>
</div><p>微信/支付宝等支付相关的数字证书，通常就使用 pkcs12 格式，使用商户号做加密密码，然后编码为 base64 再提供给用户。</p>
<h2 id="参考">参考</h2>
<h3 id="tls-协议">TLS 协议</h3>
<ul>
<li><a href="https://halfrost.com/https_tls1-2_handshake/" target="_blank" rel="noopener noreferrer">HTTPS 温故知新（三） —— 直观感受 TLS 握手流程(上)</a></li>
<li><a href="https://halfrost.com/https-key-cipher/" target="_blank" rel="noopener noreferrer">HTTPS 温故知新（五） —— TLS 中的密钥计算</a></li>
</ul>
<h3 id="tls-证书">TLS 证书</h3>
<ul>
<li>
<p><a href="https://kubernetes.io/docs/concepts/cluster-administration/certificates/" target="_blank" rel="noopener noreferrer">Certificates - Kubernetes Docs</a></p>
</li>
<li>
<p><a href="https://www.cnblogs.com/kyrios/p/tls-and-certificates.html" target="_blank" rel="noopener noreferrer">TLS/HTTPS 证书生成与验证</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/57710573" target="_blank" rel="noopener noreferrer">ECC作为SSL/TLS证书加密算法的优势</a></p>
</li>
<li>
<p><a href="https://cloud.tencent.com/developer/article/1407305" target="_blank" rel="noopener noreferrer">ECC证书的生成和验签</a></p>
</li>
<li>
<p><a href="https://zh.wikipedia.org/wiki/%E5%89%8D%E5%90%91%E4%BF%9D%E5%AF%86" target="_blank" rel="noopener noreferrer">前向保密(Forward Secrecy) - WikiPedia</a></p>
</li>
<li>
<p><a href="https://help.aliyun.com/document_detail/28542.html" target="_blank" rel="noopener noreferrer">证书选型和购买 - 阿里云文档</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ2MjI5OA==&amp;mid=2664079008&amp;idx=1&amp;sn=dede1114d5705880ea757f8d9ae4c92d" target="_blank" rel="noopener noreferrer">云原生安全破局｜如何管理周期越来越短的数字证书？</a></p>
</li>
</ul>
<p>另外两个关于 CN(Common Name) 和 SAN(Subject Altnative Name) 的问答：</p>
<ul>
<li><a href="https://serverfault.com/questions/880804/can-not-get-rid-of-neterr-cert-common-name-invalid-error-in-chrome-with-self" target="_blank" rel="noopener noreferrer">Can not get rid of <code>net::ERR_CERT_COMMON_NAME_INVALID</code> error in chrome with self-signed certificates</a></li>
<li><a href="https://stackoverflow.com/questions/5935369/ssl-how-do-common-names-cn-and-subject-alternative-names-san-work-together" target="_blank" rel="noopener noreferrer">SSL - How do Common Names (CN) and Subject Alternative Names (SAN) work together?</a></li>
</ul>
<p>关于证书锁定/公钥锁定技术：</p>
<ul>
<li><a href="https://owasp.org/www-community/controls/Certificate_and_Public_Key_Pinning" target="_blank" rel="noopener noreferrer">Certificate and Public Key Pinning - OWASP</a></li>
<li><a href="https://security.stackexchange.com/questions/85209/difference-between-certificate-pinning-and-public-key-pinning" target="_blank" rel="noopener noreferrer">Difference between certificate pinning and public key pinning</a></li>
</ul>
<p>加密/签名算法相关：</p>
<ul>
<li><a href="http://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html" target="_blank" rel="noopener noreferrer">RSA算法原理（二）</a></li>
</ul>
<p>其他：</p>
<ul>
<li><a href="https://www.openssl.org/docs/man1.1.1/" target="_blank" rel="noopener noreferrer">OpenSSL ManPage</a></li>
<li><a href="https://www.jianshu.com/p/f5f93c89155e" target="_blank" rel="noopener noreferrer">openssl 查看证书</a></li>
</ul>
]]></description></item><item><title>QEMU-KVM 虚拟化环境的搭建与使用</title><link>https://ryan4yin.space/posts/qemu-kvm-usage/</link><pubDate>Sun, 17 Jan 2021 21:34:04 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/qemu-kvm-usage/</guid><description><![CDATA[<h2 id="qemukvm-虚拟化">QEMU/KVM 虚拟化</h2>
<p>QEMU/KVM 是目前最流行的虚拟化技术，它基于 Linux 内核提供的 kvm 模块，结构精简，性能损失小，而且开源免费（对比收费的 vmware），因此成了大部分企业的首选虚拟化方案。</p>
<p>目前各大云厂商的虚拟化方案，新的服务器实例基本都是用的 KVM 技术。即使是起步最早，一直重度使用 Xen 的 AWS，从 EC2 C5 开始就改用了基于 KVM 定制的 Nitro 虚拟化技术。</p>
<p>但是 KVM 作为一个企业级的底层虚拟化技术，却没有对桌面使用做深入的优化，因此如果想把它当成桌面虚拟化软件来使用，替代掉 VirtualBox/VMware，有一定难度。</p>
<p>本文是我个人学习 KVM 的一个总结性文档，其目标是使用 KVM 作为桌面虚拟化软件。</p>
<h2 id="一安装-queukvm">一、安装 QUEU/KVM</h2>
<p>QEMU/KVM 环境需要安装很多的组件，它们各司其职：</p>
<ol>
<li>qemu: 模拟各类输入输出设备（网卡、磁盘、USB端口等）
<ul>
<li>qemu 底层使用 kvm 模拟 CPU 和 RAM，比软件模拟的方式快很多。</li>
</ul>
</li>
<li>libvirt: 提供简单且统一的工具和 API，用于管理虚拟机，屏蔽了底层的复杂结构。（支持 qemu-kvm/virtualbox/vmware）</li>
<li>ovmf: 为虚拟机启用 UEFI 支持</li>
<li>virt-manager: 用于管理虚拟机的 GUI 界面（可以管理远程 kvm 主机）。</li>
<li>virt-viewer: 通过 GUI 界面直接与虚拟机交互（可以管理远程 kvm 主机）。</li>
<li>dnsmasq vde2 bridge-utils openbsd-netcat: 网络相关组件，提供了以太网虚拟化、网络桥接、NAT网络等虚拟网络功能。
<ul>
<li>dnsmasq 提供了 NAT 虚拟网络的 DHCP 及 DNS 解析功能。</li>
<li>vde2: 以太网虚拟化</li>
<li>bridge-utils: 顾名思义，提供网络桥接相关的工具。</li>
<li>openbsd-netcat: TCP/IP 的瑞士军刀，详见 <a href="https://ryan4yin.space/posts/socat-netcat/" rel="">socat &amp; netcat</a>，这里不清楚是哪个网络组件会用到它。</li>
</ul>
</li>
</ol>
<p>安装命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># archlinux/manjaro</span>
sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat

<span class="c1"># ubuntu,参考了官方文档，但未测试</span>
sudo apt install qemu-kvm libvirt-daemon-system virt-manager virt-viewer virtinst bridge-utils

<span class="c1"># centos,参考了官方文档，但未测试</span>
sudo yum groupinstall <span class="s2">&#34;Virtualization Host&#34;</span>
sudo yum install virt-manager virt-viewer virt-install

<span class="c1"># opensuse</span>
<span class="c1"># see: https://doc.opensuse.org/documentation/leap/virtualization/html/book-virt/cha-vt-installation.html</span>
sudo yast2 virtualization
<span class="c1"># enter to terminal ui, select kvm + kvm tools, and then install it.</span>
</code></pre></td></tr></table>
</div>
</div><p>安装完成后，还不能直接使用，需要做些额外的工作。请继续往下走。</p>
<h3 id="1-libguestfs---虚拟机磁盘映像处理工具">1. libguestfs - 虚拟机磁盘映像处理工具</h3>
<p><a href="https://libguestfs.org/" target="_blank" rel="noopener noreferrer">libguestfs</a> 是一个虚拟机磁盘映像处理工具，可用于直接修改/查看/虚拟机映像、转换映像格式等。</p>
<p>它提供的命令列表如下：</p>
<ol>
<li><code>virt-df centos.img</code>: 查看硬盘使用情况</li>
<li><code>virt-ls centos.img /</code>: 列出目录文件</li>
<li><code>virt-copy-out -d domain /etc/passwd /tmp</code>：在虚拟映像中执行文件复制</li>
<li><code>virt-list-filesystems /file/xx.img</code>：查看文件系统信息</li>
<li><code>virt-list-partitions /file/xx.img</code>：查看分区信息</li>
<li><code>guestmount -a /file/xx.qcow2(raw/qcow2都支持) -m /dev/VolGroup/lv_root --rw /mnt</code>：直接将分区挂载到宿主机</li>
<li><code>guestfish</code>: 交互式 shell，可运行上述所有命令。</li>
<li><code>virt-v2v</code>: 将其他格式的虚拟机(比如 ova) 转换成 kvm 虚拟机。</li>
<li><code>virt-p2v</code>: 将一台物理机转换成虚拟机。</li>
</ol>
<p>学习过程中可能会使用到上述命令，提前安装好总不会有错，安装命令如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># opensuse</span>
sudo zypper install libguestfs

<span class="c1"># archlinux/manjaro，目前缺少 virt-v2v/virt-p2v 组件</span>
sudo pacman -S libguestfs

<span class="c1"># ubuntu</span>
sudo apt install libguestfs-tools

<span class="c1"># centos</span>
sudo yum install libguestfs-tools
</code></pre></td></tr></table>
</div>
</div><h3 id="2-启动-qemukvm">2. 启动 QEMU/KVM</h3>
<p>通过 systemd 启动 libvirtd 后台服务：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">sudo systemctl <span class="nb">enable</span> libvirtd.service
sudo systemctl start libvirtd.service
</code></pre></td></tr></table>
</div>
</div><h3 id="3-让非-root-用户能正常使用-kvm">3. 让非 root 用户能正常使用 kvm</h3>
<p>qumu/kvm 装好后，默认情况下需要 root 权限才能正常使用它。
为了方便使用，首先编辑文件 <code>/etc/libvirt/libvirtd.conf</code>:</p>
<ol>
<li><code>unix_sock_group = &quot;libvirt&quot;</code>，取消这一行的注释，使 <code>libvirt</code> 用户组能使用 unix 套接字。</li>
<li><code>unix_sock_rw_perms = &quot;0770&quot;</code>，取消这一行的注释，使用户能读写 unix 套接字。</li>
</ol>
<p>然后新建 libvirt 用户组，将当前用户加入该组：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">newgrp libvirt
sudo usermod -aG libvirt <span class="nv">$USER</span>
</code></pre></td></tr></table>
</div>
</div><p>最后重启 libvirtd 服务，应该就能正常使用了：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">sudo systemctl restart libvirtd.service
</code></pre></td></tr></table>
</div>
</div><h3 id="3-启用嵌套虚拟化">3. 启用嵌套虚拟化</h3>
<p>如果你需要<strong>在虚拟机中运行虚拟机</strong>（比如在虚拟机里测试 katacontainers 等安全容器技术），那就需要启用内核模块 kvm_intel 实现嵌套虚拟化。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 临时启用 kvm_intel 嵌套虚拟化</span>
sudo modprobe -r kvm_intel
sudo modprobe kvm_intel <span class="nv">nested</span><span class="o">=</span><span class="m">1</span>
<span class="c1"># 修改配置，永久启用嵌套虚拟化</span>
<span class="nb">echo</span> <span class="s2">&#34;options kvm-intel nested=1&#34;</span> <span class="p">|</span> sudo tee /etc/modprobe.d/kvm-intel.conf
</code></pre></td></tr></table>
</div>
</div><p>验证嵌套虚拟化已经启用：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat /sys/module/kvm_intel/parameters/nested 
Y
</code></pre></td></tr></table>
</div>
</div><p>至此，KVM 的安装就大功告成啦，现在应该可以在系统中找到 virt-manager 的图标，进去就可以使用了。
virt-manager 的使用方法和 virtualbox/vmware workstation 大同小异，这里就不详细介绍了，自己摸索摸索应该就会了。</p>
<hr>
<blockquote>
<p>如下内容是进阶篇，主要介绍如何通过命令行来管理虚拟机磁盘，以及 KVM。
如果你还是 kvm 新手，建议先通过图形界面 virt-manager 熟悉熟悉，再往下继续读。</p>
</blockquote>
<h2 id="二虚拟机磁盘映像管理">二、虚拟机磁盘映像管理</h2>
<p>这需要用到两个工具：</p>
<ol>
<li>libguestfs: 虚拟机磁盘映像管理工具，前面介绍过了</li>
<li>qemu-img: qemu 的磁盘映像管理工具，用于创建磁盘、扩缩容磁盘、生成磁盘快照、查看磁盘信息、转换磁盘格式等等。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 创建磁盘</span>
qemu-img create -f qcow2 -o <span class="nv">cluster_size</span><span class="o">=</span>128K virt_disk.qcow2 20G

<span class="c1"># 扩容磁盘</span>
qemu-img resize ubuntu-server-cloudimg-amd64.img 30G

<span class="c1"># 查看磁盘信息</span>
qemu-img info ubuntu-server-cloudimg-amd64.img

<span class="c1"># 转换磁盘格式</span>
qemu-img convert -f raw -O qcow2 vm01.img vm01.qcow2  <span class="c1"># raw =&gt; qcow2</span>
qemu-img convert -f qcow2 -O raw vm01.qcow2 vm01.img  <span class="c1"># qcow2 =&gt; raw</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="1-导入-vmware-镜像">1. 导入 vmware 镜像</h3>
<p>直接从 vmware ova 文件导入 kvm，这种方式转换得到的镜像应该能直接用（网卡需要重新配置）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">virt-v2v -i ova centos7-test01.ova -o <span class="nb">local</span> -os /vmhost/centos7-01  -of qcow2
</code></pre></td></tr></table>
</div>
</div><p>也可以先从 ova 中解压出 vmdk 磁盘映像，将 vmware 的  vmdk 文件转换成 qcow2 格式，然后再导入 kvm（网卡需要重新配置）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 转换映像格式</span>
qemu-img convert -p -f vmdk -O qcow2 centos7-test01-disk1.vmdk centos7-test01.qcow2
<span class="c1"># 查看转换后的映像信息</span>
qemu-img info centos7-test01.qcow2
</code></pre></td></tr></table>
</div>
</div><p>直接转换 vmdk 文件得到的 qcow2 镜像，启会报错，比如「磁盘无法挂载」。
根据 <a href="https://pve.proxmox.com/pve-docs/chapter-qm.html#_importing_virtual_machines_and_disk_images" target="_blank" rel="noopener noreferrer">Importing Virtual Machines and disk images - ProxmoxVE Docs</a> 文档所言，需要在网上下载安装 MergeIDE.zip 组件，
另外启动虚拟机前，需要将硬盘类型改为 IDE，才能解决这个问题。</p>
<h3 id="2-导入-img-镜像">2. 导入 img 镜像</h3>
<p>img 镜像文件，就是所谓的 raw 格式镜像，也被称为裸镜像，IO 速度比 qcow2 快，但是体积大，而且不支持快照等高级特性。
如果不追求 IO 性能的话，建议将它转换成 qcow2 再使用。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">qemu-img convert -f raw -O qcow2 vm01.img vm01.qcow2
</code></pre></td></tr></table>
</div>
</div><h2 id="三虚拟机管理">三、虚拟机管理</h2>
<p>虚拟机管理可以使用命令行工具 <code>virsh</code>/<code>virt-install</code>，也可以使用 GUI 工具 <code>virt-manager</code>.</p>
<p>GUI 很傻瓜式，就不介绍了，这里主要介绍命令行工具 <code>virsh</code>/<code>virt-install</code></p>
<p>先介绍下 libvirt 中的几个概念：</p>
<ol>
<li>Domain: 指代运行在虚拟机器上的操作系统的实例 - 一个虚拟机，或者用于启动虚拟机的配置。</li>
<li>Guest OS: 运行在 domain 中的虚拟操作系统。</li>
</ol>
<p>大部分情况下，你都可以把下面命令中涉及到的 <code>domain</code> 理解成虚拟机。</p>
<h3 id="0-设置默认-uri">0. 设置默认 URI</h3>
<p><code>virsh</code>/<code>virt-install</code>/<code>virt-viewer</code> 等一系列 libvirt 命令，
默认情况下会使用 <code>qemu:///session</code> 作为 URI 去连接 QEMU/KVM，只有 root 账号才会默认使用 <code>qemu:///system</code>.</p>
<p>另一方面 <code>virt-manager</code> 这个 GUI 工具，默认也会使用 <code>qemu:///system</code> 去连接 QEMU/KVM（和 root 账号一致）</p>
<p><code>qemu:///system</code> 是系统全局的 qemu 环境，而 <code>qemu:///session</code> 的环境是按用户隔离的。
另外 <code>qemu:///session</code> 没有默认的 <code>network</code>，创建虚拟机时会出毛病。。。</p>
<p>因此，你需要将默认的 URI 改为 <code>qemu:///system</code>，否则绝对会被坑:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">echo</span> <span class="s1">&#39;export LIBVIRT_DEFAULT_URI=&#34;qemu:///system&#34;&#39;</span> &gt;&gt; ~/.bashrc
</code></pre></td></tr></table>
</div>
</div><h3 id="1-创建虚拟机---virt-intall">1. 创建虚拟机 - virt-intall</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 使用 iso 镜像创建全新的 proxmox 虚拟机，自动创建一个 60G 的磁盘。</span>
virt-install --virt-type kvm <span class="se">\
</span><span class="se"></span>--name pve-1 <span class="se">\
</span><span class="se"></span>--vcpus <span class="m">4</span> --memory <span class="m">8096</span> <span class="se">\
</span><span class="se"></span>--disk <span class="nv">size</span><span class="o">=</span><span class="m">60</span> <span class="se">\
</span><span class="se"></span>--network <span class="nv">network</span><span class="o">=</span>default,model<span class="o">=</span>virtio <span class="se">\
</span><span class="se"></span>--os-type linux <span class="se">\
</span><span class="se"></span>--os-variant generic <span class="se">\
</span><span class="se"></span>--graphics vnc <span class="se">\
</span><span class="se"></span>--cdrom proxmox-ve_6.3-1.iso

<span class="c1"># 使用已存在的 opensuse cloud 磁盘创建虚拟机</span>
virt-install --virt-type kvm <span class="se">\
</span><span class="se"></span>  --name opensuse15-2 <span class="se">\
</span><span class="se"></span>  --vcpus <span class="m">2</span> --memory <span class="m">2048</span> <span class="se">\
</span><span class="se"></span>  --disk opensuse15.2-openstack.qcow2,device<span class="o">=</span>disk,bus<span class="o">=</span>virtio <span class="se">\
</span><span class="se"></span>  --disk seed.iso,device<span class="o">=</span>cdrom <span class="se">\
</span><span class="se"></span>  --os-type linux <span class="se">\
</span><span class="se"></span>  --os-variant opensuse15.2 <span class="se">\
</span><span class="se"></span>  --network <span class="nv">network</span><span class="o">=</span>default,model<span class="o">=</span>virtio <span class="se">\
</span><span class="se"></span>  --graphics vnc <span class="se">\
</span><span class="se"></span>  --import
</code></pre></td></tr></table>
</div>
</div><p>其中的 <code>--os-variant</code> 用于设定 OS 相关的优化配置，官方文档<strong>强烈推荐</strong>设定，其可选参数可以通过 <code>osinfo-query os</code> 查看。</p>
<h3 id="3-虚拟机管理---virsh">3. 虚拟机管理 - virsh</h3>
<p>虚拟机创建好后，可使用 virsh 管理虚拟机：</p>
<p>查看虚拟机列表：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># 查看正在运行的虚拟机
virsh list

# 查看所有虚拟机，包括 inactive 的虚拟机
virsh list --all
</code></pre></td></tr></table>
</div>
</div><p>使用 <code>virt-viewer</code> 以 vnc 协议登入虚拟机终端：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 使用虚拟机 ID 连接</span>
virt-viewer <span class="m">8</span>
<span class="c1"># 使用虚拟机名称连接，并且等待虚拟机启动</span>
virt-viewer --wait opensuse15
</code></pre></td></tr></table>
</div>
</div><p>启动、关闭、暂停(休眠)、重启虚拟机：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">virsh start opensuse15
virsh suuspend opensuse15
virsh resume opensuse15
virsh reboot opensuse15
<span class="c1"># 优雅关机</span>
virsh shutdown opensuse15
<span class="c1"># 强制关机</span>
virsh destroy opensuse15

<span class="c1"># 启用自动开机</span>
virsh autostart opensuse15
<span class="c1"># 禁用自动开机</span>
virsh autostart --disable opensuse15
</code></pre></td></tr></table>
</div>
</div><p>虚拟机快照管理：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 列出一个虚拟机的所有快照</span>
virsh snapshot-list --domain opensuse15
<span class="c1"># 给某个虚拟机生成一个新快照</span>
virsh snapshot-create &lt;domain&gt;
<span class="c1"># 使用快照将虚拟机还原</span>
virsh snapshot-restore &lt;domain&gt; &lt;snapshotname&gt;
<span class="c1"># 删除快照</span>
virsh snapshot-delete &lt;domain&gt; &lt;snapshotname&gt;
</code></pre></td></tr></table>
</div>
</div><p>删除虚拟机：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">virsh undefine opensuse15
</code></pre></td></tr></table>
</div>
</div><p>迁移虚拟机：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 使用默认参数进行离线迁移，将已关机的服务器迁移到另一个 qemu 实例</span>
virsh migrate <span class="m">37</span> qemu+ssh://tux@jupiter.example.com/system
<span class="c1"># 还支持在线实时迁移，待续</span>
</code></pre></td></tr></table>
</div>
</div><p>cpu/内存修改：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 改成 4 核</span>
virsh setvcpus opensuse15 <span class="m">4</span>
<span class="c1"># 改成 4G</span>
virsh setmem opensuse15 <span class="m">4096</span>
</code></pre></td></tr></table>
</div>
</div><p>虚拟机监控：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 待续</span>
</code></pre></td></tr></table>
</div>
</div><p>修改磁盘、网络及其他设备：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 添加新设备</span>
virsh attach-device
virsh attach-disk
virsh attach-interface
<span class="c1"># 删除设备</span>
virsh detach-disk
virsh detach-device
virsh detach-interface
</code></pre></td></tr></table>
</div>
</div><p>虚拟机网络管理：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 列出所有虚拟机网络</span>
virsh net-list
<span class="c1"># 待续</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="参考">参考</h2>
<ul>
<li><a href="https://doc.opensuse.org/documentation/leap/virtualization/html/book-virt/index.html" target="_blank" rel="noopener noreferrer">Virtualization Guide - OpenSUSE</a></li>
<li><a href="https://computingforgeeks.com/complete-installation-of-kvmqemu-and-virt-manager-on-arch-linux-and-manjaro/" target="_blank" rel="noopener noreferrer">Complete Installation of KVM, QEMU and Virt Manager on Arch Linux and Manjaro</a></li>
<li><a href="https://ubuntu.com/server/docs/virtualization-libvirt" target="_blank" rel="noopener noreferrer">virtualization-libvirt - ubuntu docs</a></li>
<li><a href="https://developers.redhat.com/products/rhel/hello-world#fndtn-kvm" target="_blank" rel="noopener noreferrer">RedHat Docs - KVM</a></li>
</ul>]]></description></item><item><title>Pulumi 使用体验 - 基础设施代码化</title><link>https://ryan4yin.space/posts/expirence-of-pulumi/</link><pubDate>Fri, 08 Jan 2021 18:51:30 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/expirence-of-pulumi/</guid><description><![CDATA[<p><a href="https://github.com/pulumi/pulumi" target="_blank" rel="noopener noreferrer">Pulumi</a> 是一个基础设施的自动管理工具，使用 Python/TypeScript/Go/Dotnet 编写好声明式的资源配置，就能实现一键创建/修改/销毁各类资源，这里的资源可以是：</p>
<ul>
<li>AWS/阿里云等云上的负载均衡、云服务器、TLS 证书、DNS、CDN、OSS、数据库&hellip;几乎所有的云上资源</li>
<li>本地自建的 vSphere/Kubernetes/ProxmoxVE/libvirt 环境中的虚拟机、容器等资源</li>
</ul>
<p>相比直接调用 AWS/阿里云/Kubernetes 的 API，使用 pulumi 的好处有：</p>
<ul>
<li>声明式配置：你只需要声明你的资源属性就 OK，所有的状态管理、异常处理都由 pulumi 完成。</li>
<li>统一的配置方式：提供统一的配置方法，来声明式的配置所有 AWS/阿里云/Kubernetes 资源。</li>
<li>声明式配置的可读性更好，更便于维护</li>
</ul>
<p>试想一下，通过传统的手段去从零搭建一个云上测试环境、或者本地开发环境，需要手工做多少繁琐的工作。</p>
<p>而依靠 Pulumi 这类「基础设施即代码」的工具，只需要一行命令就能搭建好一个可复现的云上测试环境或本地开发环境。</p>
<p>比如我们的阿里云测试环境，包括两个 kubernetes 集群、负载均衡、VPC 网络、数据库、云监控告警/日志告警、RAM账号权限体系等等，是一个比较复杂的体系。</p>
<p>人工去配置这么多东西，想要复现是很困难的，非常繁琐而且容易出错。</p>
<p>但是使用 pulumi，只需要一行命令，就能创建并配置好这五花八门一大堆的玩意儿。
销毁整个测试环境也只需要一行命令。</p>
<p><strong>实际使用体验</strong>：我们使用 Pulumi 自动化了阿里云测试环境搭建 95%+ 的操作，这个比例随着阿里云的 pulumi provider 的完善，还可以进一步提高！</p>
<h2 id="pulumi-vs-terraform">Pulumi vs Terraform</h2>
<p>有一个「基础设施即代码」的工具比 Pulumi 更流行，它就是 <a href="https://www.terraform.io/" target="_blank" rel="noopener noreferrer">Terraform</a>.</p>
<p>实际上我们一开始使用的也是 Terraform，但是后来使用 Pulumi 完全重写了一遍。</p>
<p>主要原因是，Pulumi 解决了 Terraform 配置的一个痛点：配置语法太过简单，导致配置繁琐。而且还要额外学习一门 DSL - HCL</p>
<p>Terraform 虽然应用广泛，但是它默认使用的 HCL 语言太简单，表现力不够强。
这就导致在一些场景下使用 Terraform，会出现大量的重复配置。</p>
<p>一个典型的场景是「批量创建资源，动态生成资源参数」。比如批量创建一批名称类似的 ECS 服务器/VPC交换机。如果使用 terraform，就会出现大量的重复配置。</p>
<p>改用 terraform 提供的 module 能在一定程度上实现配置的复用，但是它还是解决不了问题。
要使用 module，你需要付出时间去学习 module 的概念，为了拼接参数，你还需要学习 HCL 的一些高级用法。</p>
<p>但是付出了这么多，最后写出的 module 还是不够灵活——它被 HCL 局限住了。</p>
<p>为了实现如此的参数化动态化，我们不得不引入 Python 等其他编程语言。于是构建流程就变成了：</p>
<ol>
<li>借助 Python 等其他语言先生成出 HCL 配置</li>
<li>通过 <code>terraform</code> 命令行进行 plan 与 apply</li>
<li>通过 Python 代码解析 <code>terraform.tfstat</code>，获取 apply 结果，再进行进一步操作。</li>
</ol>
<p>这显然非常繁琐，主要困难就在于 Python 和 Terraform 之间的交互。</p>
<p>进一步思考，<strong>既然其他编程语言如 Python/Go 的引入不可避免，那是不是能使用它们彻底替代掉 HCL 呢？能不能直接使用 Python/Go 编写配置</strong>？如果 Terraform 原生就支持 Python/Go 来编写配置，那就不存在交互问题了。</p>
<p>相比于使用领域特定语言 HCL，使用通用编程语言编写配置，好处有：</p>
<ol>
<li>Python/Go/TypeScript 等通用的编程语言，能满足你的一切需求。</li>
<li>作为一个开发人员/DevOps，你应该对 Python/Go 等语言相当熟悉，可以直接利用上已有的经验。</li>
<li>更方便测试：可以使用各编程语言中流行的测试框架来测试 pulumi 配置！</li>
</ol>
<p>于是 Pulumi 横空出世。</p>
<blockquote>
<p>另一个和 Pulumi 功能类似的工具，是刚出炉没多久的 terraform-cdk，但是目前它还很不成熟。</p>
</blockquote>
<h2 id="pulumi-特点介绍">Pulumi 特点介绍</h2>
<ol start="4">
<li>原生支持通过 Python/Go/TypeScript/Dotnet 等语言编写配置，也就完全解决了上述的 terraform 和 python 的交互问题。</li>
<li>pulumi 是目前最流行的 真-IaaS 工具，对各语言的支持都很成熟。</li>
<li>兼容 terraform 的所有 provider，只是需要自行使用 <a href="https://github.com/pulumi/pulumi-tf-provider-boilerplate" target="_blank" rel="noopener noreferrer">pulumi-tf-provider-boilerplate</a> 重新打包，有些麻烦。
<ol>
<li>pulumi 官方的 provider 几乎全都是封装的 terraform provider，包括 aws/azure/alicloud，目前只发现 kubernetes 是原生的（独苗啊）。</li>
</ol>
</li>
<li>状态管理和 secrets 管理有如下几种选择：
<ol>
<li>使用 app.pulumi.com（默认）:免费版提供 stack 历史管理，可以看到所有的历史记录。另外还提供一个资源关系的可视化面板。总之很方便，但是多人合作就需要收费。</li>
<li>本地文件存储：<code>pulumi login file:///app/data</code></li>
<li><a href="https://www.pulumi.com/docs/intro/concepts/state/#logging-into-the-aws-s3-backend" target="_blank" rel="noopener noreferrer">云端对象存储</a>，支持 s3 等对象存储协议，因此可以使用 AWS 或者本地的 MinIO 来做 Backend.
<ul>
<li><code>pulumi login 's3://&lt;bucket-path&gt;?endpoint=my.minio.local:8080&amp;disableSSL=true&amp;s3ForcePathStyle=true'</code></li>
<li>minio/aws 的 creadential 可以通过 <code>AWS_ACCESS_KEY_ID</code> 和 <code>AWS_SECRET_ACCESS_KEY</code> 两个环境变量设置。另外即使是使用 MinIO，<code>AWS_REGION</code> 这个没啥用的环境变量也必须设置！否则会报错。</li>
</ul>
</li>
<li><a href="https://github.com/pulumi/pulumi/issues/4727" target="_blank" rel="noopener noreferrer">gitlab 13 支持 Terraform HTTP State 协议</a>，等这个 pr 合并，pulumi 也能以 gitlab 为 backend 了。</li>
<li>使用 pulumi 企业版（自建服务）：比 app.pulumi.com 提供更多的特性，但是显然是收费的。。</li>
</ol>
</li>
</ol>
<p>总之，非常香，强烈推荐各位 DevOps 试用。</p>
<hr>
<blockquote>
<p>以下内容是我对 pulumi 的一些思考，以及使用 pulumi 遇到的各种问题+解决方法，适合对 pulumi 有一定了解的同学阅读。</p>
</blockquote>
<blockquote>
<p>如果你刚接触 Pulumi 而且有兴趣学习，建议先移步 <a href="https://www.pulumi.com/docs/get-started/install/" target="_blank" rel="noopener noreferrer">pulumi get started</a> 入个门，再接着看下面的内容。</p>
</blockquote>
<h2 id="使用建议">使用建议</h2>
<ol>
<li><strong>建议查看对应的 terraform provider 文档：pulumi 的 provider 基本都是封装的 terraform 版本，而且文档是自动生成的，比（简）较（直）难（一）看（坨）懂（shi），examples 也少。</strong></li>
<li>stack: pulumi 官方提供了两种 stack 用法：<a href="https://www.pulumi.com/docs/intro/concepts/organizing-stacks-projects/" target="_blank" rel="noopener noreferrer">「单体」和「微-stack」</a>
<ol>
<li>单体: one stack rule them all，通过 stack 参数来控制步骤。stack 用来区分环境 dev/pro 等。</li>
<li>微-stack: 每一个 stack 是一个步骤，所有 stack 组成一个完整的项目。</li>
<li>实际使用中，我发现「微-stack」模式需要使用到 pulumi 的 inter-stack dependencies，报一堆的错，而且不够灵活。因此目前更推荐「单体」模式。</li>
</ol>
</li>
</ol>
<p>我们最近使用 pulumi 完全重写了以前用 terraform 编写的云上配置，简化了很多繁琐的配置，也降低了我们 Python 运维代码和 terraform 之间的交互难度。
另外我们还充分利用上了 Python 的类型检查和语法检查，很多错误 IDE 都能直接给出提示，强化了配置的一致性和可维护性。</p>
<p>不过由于阿里云 provider 暂时还：</p>
<ol>
<li>不支持管理 ASM 服务网格、DTS 数据传输等资源</li>
<li>OSS 等产品的部分参数也暂时不支持配置（比如 OSS 不支持配置图片样式、ElasticSearch 暂时不支持自动创建 7.x 版本）</li>
<li>不支持创建 ElasticSearch 7.x</li>
</ol>
<p>这些问题，导致我们仍然有部分配置需要手动处理，另外一些耗时长的资源，需要单独去创建。
因此还不能实现完全的「一键」。</p>
<h2 id="常见问题">常见问题</h2>
<h3 id="1-output-的用法">1. <code>Output</code> 的用法</h3>
<ol>
<li>pulumi 通过资源之间的属性引用（<code>Output[str]</code>）来确定依赖关系，如果你通过自定义的属性(<code>str</code>)解耦了资源依赖，会导致资源创建顺序错误而创建失败。</li>
<li><code>Output[str]</code> 是一个异步属性，类似 Future，不能被用在 pulumi 参数之外的地方！</li>
<li><code>Output[str]</code> 提供两种方法能直接对 <code>Output[str]</code> 进行一些操作：
<ol>
<li><code>Output.concat(&quot;http://&quot;, domain, &quot;/&quot;, path)</code>: 此方法将 str 与 <code>Output[str]</code> 拼接起来，返回一个新的 <code>Output[str]</code> 对象，可用做 pulumi 属性。</li>
<li><code>domain.apply(lambda it: print(it))</code>: <code>Output[str]</code> 的 <code>apply</code> 方法接收一个函数。在异步获取到数据后，pulumi 会调用这个函数，把具体的数据作为参数传入。
<ul>
<li>另外 <code>apply</code> 也会将传入函数的返回值包装成 <code>Output</code> 类型返回出来。</li>
<li>可用于：在获取到数据后，将数据打印出来/发送到邮箱/调用某个 API 上传数据等等。</li>
</ul>
</li>
<li><code>Output.all(output1, output2, ...).apply(lambda it: print(it))</code> 可用于将多个 <code>output</code> 值，拼接成一个 <code>Output</code> 类型，其内部的 raw 值为一个 tuple 对象 <code>(str1, str2, ...)</code>.
<ol>
<li>官方举例：<code>connection_string = Output.all(sql_server.name, database.name).apply(lambda args: f&quot;Server=tcp:{args[0]}.database.windows.net;initial catalog={args[1]}...&quot;)</code></li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="2-如何使用多个云账号多个-k8s-集群">2. 如何使用多个云账号/多个 k8s 集群？</h3>
<p>默认情况下 pulumi 使用默认的 provider，但是 pulumi 所有的资源都有一个额外的 <code>opts</code> 参数，可用于设定其他 provider。</p>
<p>通过这个 <code>opts</code>，我们可以实现在一个 pulumi 项目中，使用多个云账号，或者管理多个 k8s 集群。</p>
<p>示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pulumi</span> <span class="kn">import</span> <span class="n">get_stack</span><span class="p">,</span> <span class="n">ResourceOptions</span><span class="p">,</span> <span class="n">StackReference</span>
<span class="kn">from</span> <span class="nn">pulumi_alicloud</span> <span class="kn">import</span> <span class="n">Provider</span><span class="p">,</span> <span class="n">oss</span>

<span class="c1"># 自定义 provider，key/secret 通过参数设定，而不是从默认的环境变量读取。</span>
<span class="c1"># 可以自定义很多个 providers</span>
<span class="n">provider</span> <span class="o">=</span> <span class="n">pulumi_alicloud</span><span class="o">.</span><span class="n">Provider</span><span class="p">(</span>
   <span class="s2">&#34;custom-alicloud-provider&#34;</span><span class="p">,</span>
   <span class="n">region</span><span class="o">=</span><span class="s2">&#34;cn-hangzhou&#34;</span><span class="p">,</span>
   <span class="n">access_key</span><span class="o">=</span><span class="s2">&#34;xxx&#34;</span><span class="p">,</span>
   <span class="n">secret_key</span><span class="o">=</span><span class="s2">&#34;jjj&#34;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># 通过 opts，让 pulumi 使用自定义的 provider（替换掉默认的）</span>
<span class="n">bucket</span> <span class="o">=</span> <span class="n">oss</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="n">ResourceOptions</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="n">provider</span><span class="p">))</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="3-inter-stack-属性传递">3. inter-stack 属性传递</h3>
<blockquote>
<p>这东西还没搞透，待研究。</p>
</blockquote>
<p>多个 stack 之间要互相传递参数，需要通过 <code>pulumi.export</code> 导出属性，通过 <code>stack.require_xxx</code> 获取属性。</p>
<p>从另一个 stack 读取属性的示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pulumi</span> <span class="kn">import</span> <span class="n">StackReference</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">pulumi</span><span class="o">.</span><span class="n">Config</span><span class="p">()</span>
<span class="n">stack_name</span> <span class="o">=</span> <span class="n">pulumi</span><span class="o">.</span><span class="n">get_stack</span><span class="p">()</span>  <span class="c1"># stack 名称</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">pulumi</span><span class="o">.</span><span class="n">get_project</span><span class="p">()</span>
<span class="n">infra</span> <span class="o">=</span> <span class="n">StackReference</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;ryan4yin/{project}/{stack_name}&#34;</span><span class="p">)</span>

<span class="c1"># 这个属性在上一个 stack 中被 export 出来</span>
<span class="n">vpc_id</span> <span class="o">=</span> <span class="n">infra</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="s2">&#34;resources.vpc.id&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="4-pulumi-up-被中断或者对资源做了手动修改会发生什么">4. <code>pulumi up</code> 被中断，或者对资源做了手动修改，会发生什么？</h3>
<ol>
<li>强行中断 <code>pulumi up</code>，会导致资源进入 <code>pending</code> 状态，必须手动修复。
<ol>
<li>修复方法：<code>pulumi stack export</code>，删除 pending 资源，再 <code>pulumi stack import</code></li>
</ol>
</li>
<li>手动删除了云上资源，或者修改了一些对资源管理无影响的参数，对 <code>pulumi</code> 没有影响，它能正确检测到这种情况。
<ol>
<li>可以通过 <code>pulumi refresh</code> 手动从云上拉取最新的资源状态。</li>
</ol>
</li>
<li>手动更改了资源之间的依赖关系（比如绑定 EIP 之类的），很可能导致 pulumi 无法正确管理资源之间的依赖。
<ul>
<li>这种情况必须先手动还原依赖关系（或者把相关资源全部手动删除掉），然后才能继续使用 pulumi。</li>
</ul>
</li>
</ol>
<h3 id="5-如何手动声明资源间的依赖关系">5. 如何手动声明资源间的依赖关系？</h3>
<p>有时候因为一些问题（比如 pulumi provider 功能缺失，使用了 restful api 实现部分功能），pulumi 可能无法识别到某些资源之间的依赖关系。</p>
<p>这时可以为资源添加 <code>dependsOn</code> 属性，这个属性能显式地声明依赖关系。</p>
<h3 id="6-如何导入已经存在的资源">6. 如何导入已经存在的资源？</h3>
<p>由于历史原因，我们可能有部分资源是手动创建或者由其他 IaC 工具管理的，该如何将它们纳入 pulumi 管辖呢？</p>
<p>官方有提供一篇相关文档 <a href="https://www.pulumi.com/docs/guides/adopting/import/" target="_blank" rel="noopener noreferrer">Importing Infrastructure</a>.</p>
<p>文档有提到三种资源导入的方法：</p>
<ol>
<li>使用 <code>pulumi import</code> 命令，这个命令能导入资源同时自动生成对应的代码。
<ul>
<li>感觉这个命令也很适合用来做<strong>资源的配置备份</strong>，不需要对照资源手写 pulumi 代码了，好评。</li>
</ul>
</li>
<li>批量导入资源：文档的 <code>Bulk Import Operations</code> 这一节介绍了如何通过 json 列出资源清单，然后使用 <code>pulumi import -f resources.json</code> 自动生成所有导入资源的 pulumi 代码。</li>
</ol>
<h3 id="5-pulumi-kubernetes">5. pulumi-kubernetes？</h3>
<p>pulumi-kubernetes 是一条龙服务：</p>
<ol>
<li>在 yaml 配置生成这一步，它能结合/替代掉 helm/kustomize，或者你高度自定义的 Python 脚本。</li>
<li>在 yaml 部署这一步，它能替代掉 argo-cd 这类 gitops 工具。</li>
<li>强大的状态管理，argo-cd 也有状态管理，可以对比看看。</li>
</ol>
<p>也可以仅通过 kubernetes_pulumi 生成 yaml，再通过 argo-cd 部署，这样 pulumi_kubernetes 就仅用来简化 yaml 的编写，仍然通过 gitops 工具/kubectl 来部署。</p>
<p>使用 pulumi-kubernetes 写配置，要警惕逻辑和数据的混合程度。
因为 kubernetes 的配置复杂度比较高，如果动态配置比较多，很容易就会写出难以维护的 python 代码来。</p>
<p>渲染 yaml 的示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pulumi</span> <span class="kn">import</span> <span class="n">get_stack</span><span class="p">,</span> <span class="n">ResourceOptions</span><span class="p">,</span> <span class="n">StackReference</span>
<span class="kn">from</span> <span class="nn">pulumi_kubernetes</span> <span class="kn">import</span> <span class="n">Provider</span>
<span class="kn">from</span> <span class="nn">pulumi_kubernetes.apps.v1</span> <span class="kn">import</span> <span class="n">Deployment</span><span class="p">,</span> <span class="n">DeploymentSpecArgs</span>
<span class="kn">from</span> <span class="nn">pulumi_kubernetes.core.v1</span> <span class="kn">import</span> <span class="p">(</span>
	<span class="n">ContainerArgs</span><span class="p">,</span>
	<span class="n">ContainerPortArgs</span><span class="p">,</span>
	<span class="n">EnvVarArgs</span><span class="p">,</span>
	<span class="n">PodSpecArgs</span><span class="p">,</span>
	<span class="n">PodTemplateSpecArgs</span><span class="p">,</span>
	<span class="n">ResourceRequirementsArgs</span><span class="p">,</span>
	<span class="n">Service</span><span class="p">,</span>
	<span class="n">ServicePortArgs</span><span class="p">,</span>
	<span class="n">ServiceSpecArgs</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pulumi_kubernetes.meta.v1</span> <span class="kn">import</span> <span class="n">LabelSelectorArgs</span><span class="p">,</span> <span class="n">ObjectMetaArgs</span>

<span class="n">provider</span> <span class="o">=</span> <span class="n">Provider</span><span class="p">(</span>
   <span class="s2">&#34;render-yaml&#34;</span><span class="p">,</span>
   <span class="n">render_yaml_to_directory</span><span class="o">=</span><span class="s2">&#34;rendered&#34;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">deployment</span> <span class="o">=</span> <span class="n">Deployment</span><span class="p">(</span>
	<span class="s2">&#34;redis&#34;</span><span class="p">,</span>
	<span class="n">spec</span><span class="o">=</span><span class="n">DeploymentSpecArgs</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
   <span class="n">opts</span><span class="o">=</span><span class="n">ResourceOptions</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="n">provider</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>如示例所示，pulumi-kubernetes 的配置是完全结构化的，比 yaml/helm/kustomize 要灵活非常多。</p>
<p>总之它非常灵活，既可以和 helm/kustomize 结合使用，替代掉 argocd/kubectl。
也可以和 argocd/kubectl 使用，替代掉 helm/kustomize。</p>
<p>具体怎么使用好？我也还在研究。</p>
<h3 id="6-阿里云资源-replace-报错">6. 阿里云资源 replace 报错？</h3>
<p>阿里云有部分资源，只能创建删除，不允许修改，比如「资源组」。
对这类资源做变更时，pulumi 会直接报错：「Resources aleardy exists」，
这类资源，通常都有一个「force」参数，指示是否强制修改——即先删除再重建。</p>
<h3 id="7-有些资源属性无法使用-pulumi-配置">7. 有些资源属性无法使用 pulumi 配置？</h3>
<p>这得看各云服务提供商的支持情况。</p>
<p>比如阿里云很多资源的属性，pulumi 都无法完全配置，因为 alicloud provider 的功能还不够全面。</p>
<p>目前我们生产环境，大概 95%+ 的东西，都可以使用 pulumi 实现自动化配置。
而其他 OSS 的高级参数、新出的 ASM 服务网格、kubernetes 的授权管理、ElasticSearch7 等资源，还是需要手动配置。</p>
<p>这个没办法，只能等阿里云提供支持。</p>
<h3 id="8-cicd-中如何使-pulumi-将状态保存到文件">8. CI/CD 中如何使 pulumi 将状态保存到文件？</h3>
<p>CI/CD 中我们可能会希望 pulumi 将状态保存到本地，避免连接 pulumi 中心服务器。
这一方面能加快速度，另一方面一些临时状态我们可能根本不想存储，可以直接丢弃。</p>
<p>方法：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 指定状态文件路径</span>
pulumi login file://&lt;file-path&gt;
<span class="c1"># 保存到默认位置: ~/.pulumi/credentials.json</span>
pulumi login --local

<span class="c1"># 保存到远程 S3 存储（minio/ceph 或者各类云对象存储服务，都兼容 aws 的 s3 协议）</span>
pulumi login s3://&lt;bucket-path&gt;
</code></pre></td></tr></table>
</div>
</div><p>登录完成后，再进行 <code>pulumi up</code> 操作，数据就会直接保存到你设定的路径下。</p>
<h2 id="缺点">缺点</h2>
<h3 id="1-报错信息不直观">1. 报错信息不直观</h3>
<p>pulumi 和 terraform 都有一个缺点，就是封装层次太高了。</p>
<p>封装的层次很高，优点是方便了我们使用，可以使用很统一很简洁的声明式语法编写配置。
而缺点，则是出了 bug，报错信息往往不够直观，导致问题不好排查。</p>
<h3 id="2-资源状态被破坏时修复起来非常麻烦">2. 资源状态被破坏时，修复起来非常麻烦</h3>
<p>在很多情况下，都可能发生资源状态被破坏的问题：</p>
<ol>
<li>在创建资源 A，因为参数是已知的，你直接使用了常量而不是 <code>Output</code>。这会导致 pulumi 无法识别到依赖关系！从而创建失败，或者删除时资源状态被破坏！</li>
<li>有一个 pulumi stack 一次在三台物理机上创建资源。你白天创建资源晚上删除资源，但是某一台物理机晚上会关机。这将导致 pulumi 无法查询到这台物理机上的资源状态，这个 pulumi stack 在晚上就无法使用，它会一直报错！</li>
</ol>
<h2 id="常用-provider">常用 Provider</h2>
<ul>
<li><a href="https://github.com/pulumi/pulumi-alicloud" target="_blank" rel="noopener noreferrer">pulumi-alicloud</a>: 管理阿里云资源</li>
<li><a href="https://github.com/pulumi/pulumi-vault" target="_blank" rel="noopener noreferrer">pulumi-vault</a>: 我这边用它来快速初始化 vault，创建与管理 vault 的所有配置。</li>
</ul>
<h2 id="我创建维护的-provider">我创建维护的 Provider</h2>
<p>由于 Pulumi 生态还比较小，有些 provider 只有 terraform 才有。</p>
<p>我为了造(方)福(便)大(自)众(己)，创建并维护了两个本地虚拟机相关的 Providers:</p>
<ul>
<li><a href="https://github.com/ryan4yin/pulumi-proxmox" target="_blank" rel="noopener noreferrer">ryan4yin/pulumi-proxmox</a>: 目前只用来自动创建 PVE 虚拟机
<ul>
<li>可以考虑结合 kubespray/kubeadm 快速创建 k8s 集群</li>
</ul>
</li>
<li><a href="https://github.com/ryan4yin/pulumi-libvirt" target="_blank" rel="noopener noreferrer">ryan4yin/pulumi-libvirt</a>: 快速创建 kvm 虚拟机
<ul>
<li>可以考虑结合 kubespray/kubeadm 快速创建 k8s 集群</li>
</ul>
</li>
</ul>]]></description></item><item><title>openSUSE 使用指南</title><link>https://ryan4yin.space/posts/opensuse-instruction/</link><pubDate>Mon, 04 Jan 2021 08:42:21 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/opensuse-instruction/</guid><description><![CDATA[<p>openSUSE 是一个基于 RPM 的发行版，这和 RHEL/CentOS 一致。
但是它的官方包管理器是专有的 zypper，挺好用的，软件也很新。</p>
<p>我最近从 <a href="https://ryan4yin.space/posts/manjaro-instruction/" rel="">Manjaro</a> 切换到了 openSUSE，发现 KDE 桌面确实比 Manjaro 更丝滑，而且社区源 OBS 体验下来比 AUR 更舒服。</p>
<p>尤其是容器/Kubernetes 方面，源里面的东西比 AUR 更丰富，而且是官方维护的。
本文算是对迁移流程做的一个总结。</p>
<blockquote>
<p>本文以 openSUSE Tumbleweed 为基础编写，这是一个和 Manjaro/Arch 一样的滚动发行版，软件源都很新。
openSUSE 社区的大部分用户都是使用的 Tumbleweed.
它的硬件兼容性也要比 openSUSE Leap（稳定版）好——实测小米游戏本安装 Leap，休眠后 Touchpad 会失灵。</p>
</blockquote>
<h2 id="一zypper-的基础命令">一、zypper 的基础命令</h2>
<p>zypper 的源在国内比较慢，但实际上下载的时候，zypper 会智能选择最快的镜像源下载软件包，比如国内的清华源等。</p>
<p>但是我发现官方的源索引更新太慢，甚至经常失败。因此没办法，还是得手动设置镜像源：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 禁用原有的官方软件源</span>
sudo zypper mr --disable repo-oss repo-non-oss repo-update repo-update-non-oss repo-debug
<span class="c1"># 添加北外镜像源，注意单引号不能省略！</span>
sudo zypper ar -fcg https://mirrors.bfsu.edu.cn/opensuse/tumbleweed/repo/oss/ bfsu-oss
sudo zypper ar -fcg https://mirrors.bfsu.edu.cn/opensuse/tumbleweed/repo/non-oss/ bfsu-non-oss
</code></pre></td></tr></table>
</div>
</div><p>然后就是 zypper 的常用命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">sudo zypper refresh  <span class="c1"># refresh all repos</span>
sudo zypper update   <span class="c1"># update all softwares</span>

sudo zypper search --installed-only  &lt;package-name&gt;  <span class="c1"># 查找本地安装的程序</span>
sudo zypper search &lt;package-name&gt;  <span class="c1"># 查找本地和软件源中的程序</span>

sudo zypper install &lt;package-name&gt;  <span class="c1"># 安装程序</span>
sudo zypper remove --clean-deps &lt;package-name&gt;  <span class="c1"># 卸载程序，注意添加 --clean-deps 或者 -u，否则不会卸载依赖项！</span>

sudo zypper clean  <span class="c1"># 清理本地的包缓存</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="install-softwares">Install Softwares</h2>
<blockquote>
<p>这里需要用到 <a href="https://mirrors.openSUSE.org/list/bs.html" target="_blank" rel="noopener noreferrer">OBS(Open Build Service, 类似 arch 的 AUR，但是是预编译的包)</a>，因为 OBS 东西太多了，因此不存在完整的国内镜像，平均速度大概 300kb/s。
建议有条件可以在路由器上加智能代理提速。</p>
</blockquote>
<p>安装需要用到的各类软件:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 启用 Packman 仓库，使用北交镜像源</span>
sudo zypper ar -cfp <span class="m">90</span> <span class="s1">&#39;https://mirror.bjtu.edu.cn/packman/suse/openSUSE_Tumbleweed/&#39;</span> packman-bjtu

<span class="c1"># install video player and web browser</span>
sudo zypper install mpv ffmpeg-4 chromium firefox

<span class="c1"># install screenshot and other utils</span>
<span class="c1"># 安装好后可以配个截图快捷键 alt+a =&gt; `flameshot gui`</span>
sudo zypper install flameshot peek nomacs

<span class="c1"># install git clang/make/cmake</span>
sudo zypper install git gcc clang make cmake

<span class="c1"># install wireshark</span>
sudo zypper install wireshark
sudo gpasswd --add <span class="nv">$USER</span> wireshark  <span class="c1">#  将你添加到 wireshark 用户组中</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="ide--编程语言">IDE + 编程语言</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># install vscode: https://en.openSUSE.org/Visual_Studio_Code</span>
sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc
sudo zypper addrepo https://packages.microsoft.com/yumrepos/vscode vscode
sudo zypper refresh
sudo zypper install code

<span class="c1"># 安装 dotnet 5: https://docs.microsoft.com/en-us/dotnet/core/install/linux-openSUSE#openSUSE-15-</span>
sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc
sudo zypper addrepo https://packages.microsoft.com/openSUSE/15/prod/ microsoft-prod
sudo zypper refresh
sudo zypper install dotnet-sdk-5.0

<span class="c1"># 安装新版本的 go（源中的版本比较低，更建议从 go 官网下载安装）</span>
sudo zypper install go
</code></pre></td></tr></table>
</div>
</div><p>通过 tarball/script 安装：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># rustup，rust 环境管理器</span>
curl --proto <span class="s1">&#39;=https&#39;</span> --tlsv1.2 -sSf https://sh.rustup.rs <span class="p">|</span> sh

<span class="c1"># jetbrains toolbox app，用于安装和管理 pycharm/idea/goland/android studio 等 IDE</span>
<span class="c1"># 参见：https://www.jetbrains.com/toolbox-app/</span>

<span class="c1"># 不使用系统 python，改用 miniconda 装 python3.8</span>
<span class="c1"># 参考：https://github.com/ContinuumIO/docker-images/blob/master/miniconda3/debian/Dockerfile</span>
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh
sudo /bin/bash /tmp/miniconda.sh -b -p /opt/conda
rm /tmp/miniconda.sh
sudo /opt/conda/bin/conda clean -tipsy
sudo ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh
<span class="nb">echo</span> <span class="s2">&#34;. /opt/conda/etc/profile.d/conda.sh&#34;</span> &gt;&gt; ~/.bashrc
<span class="nb">echo</span> <span class="s2">&#34;conda activate base&#34;</span> &gt;&gt; ~/.bashrc
<span class="c1"># miniconda 的 entrypoint 默认安装在如下目录，添加到 PATH 中</span>
<span class="nb">echo</span> <span class="s2">&#34;export PATH=\$PATH:\$HOME/.local/bin&#34;</span> &gt;&gt; ~/.bashrc
</code></pre></td></tr></table>
</div>
</div><p>接下来安装 VSCode 插件，下列是我的插件列表：</p>
<ol>
<li>语言：
<ol>
<li>python/go/rust/c#/julia/flutter</li>
<li>xml/yaml/toml</li>
<li>vscode proto3</li>
</ol>
</li>
<li>ansible/terraform</li>
<li>markdown all in one + Markdown Preview Enhanced</li>
<li>美化：
<ol>
<li>community material theme</li>
<li>vscode icons</li>
<li>glasslt-vsc</li>
</ol>
</li>
<li>docker/kubernetes</li>
<li>IntelliJ IDEA Keybindings</li>
<li>gitlens</li>
<li>prettier</li>
<li>utils
<ol>
<li>comment translate</li>
<li>path intellisense</li>
<li>svg</li>
<li>visual studio intellicode</li>
</ol>
</li>
<li>antlr4</li>
<li>remote ssh + remote containers</li>
<li>rest client</li>
<li>vscode databases</li>
</ol>
<h3 id="容器--kubernetes">容器 + Kubernetes</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 时髦的新容器套装: https://documentation.suse.com/sles/15-SP2/html/SLES-all/cha-podman-overview.html</span>
sudo zypper in podman kompose skopeo buildah katacontainers
<span class="c1"># 安装 kubernetes 相关工具，tumbleweed 官方仓库的包都非常新！很舒服</span>
sudo zypper in helm k9s kubernetes-client

<span class="c1"># 本地测试目前还是 docker-compose 最方便，docker 仍有必要安装</span>
sudo zypper in docker
sudo gpasswd --add <span class="nv">$USER</span> docker
sudo systemctl <span class="nb">enable</span> docker
sudo systemctl start docker

<span class="c1"># 简单起见，直接用 pip 安装 docker-compose 和 podman-compose</span>
sudo pip install docker-compose podman-compose
</code></pre></td></tr></table>
</div>
</div><h3 id="办公音乐聊天">办公、音乐、聊天</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 添加 openSUSE_zh 源：https://build.opensuse.org/project/show/home:opensuse_zh</span>
sudo zypper addrepo <span class="s1">&#39;https://download.opensuse.org/repositories/home:/opensuse_zh/openSUSE_Tumbleweed&#39;</span> openSUSE_zh
sudo zypper refresh
sudo zypper install wps-office netease-cloud-music

<span class="c1"># linux qq: https://im.qq.com/linuxqq/download.html</span>
<span class="c1"># 虽然简陋但也够用，发送文件比 KDE Connect 要方便一些。</span>
sudo rpm -ivh linux_qq.rpm
</code></pre></td></tr></table>
</div>
</div><h3 id="安装输入法">安装输入法</h3>
<p>我用的输入法是小鹤音形，首先安装 fcitx-rime:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 添加 m17n obs 源：https://build.openSUSE.org/repositories/M17N</span>
sudo zypper addrepo <span class="s1">&#39;https://download.opensuse.org/repositories/M17N/openSUSE_Tumbleweed&#39;</span> m17n
sudo zypper refresh
sudo zypper install fcitx5 fcitx5-configtool fcitx5-qt5 fcitx5-rime
</code></pre></td></tr></table>
</div>
</div><p>然后，从 <a href="http://flypy.ys168.com/">http://flypy.ys168.com/</a> 下载最新的鼠须管（MacOS）配置文件，将解压得到的 rime 文件夹拷贝到 ~/.local/share/fcitx5/ 下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">mv rime ~/.local/share/fcitx5/
</code></pre></td></tr></table>
</div>
</div><p>现在重启系统，在 fcitx5 配置里面添加 rime「中州韵」，就可以正常使用小鹤音形了。</p>
<h3 id="qemukvm">QEMU/KVM</h3>
<p>不得不说，openSUSE 安装 KVM 真的超方便，纯 GUI 操作：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># see: https://doc.openSUSE.org/documentation/leap/virtualization/html/book-virt/cha-vt-installation.html</span>
sudo yast2 virtualization
<span class="c1"># enter to terminal ui, select kvm + kvm tools, and then install it.</span>
</code></pre></td></tr></table>
</div>
</div><p>KVM 的详细文档参见 <a href="../../virutal%20machine/KVM/README.md" rel="">KVM/README.md</a></p>
<h3 id="kde-connect">KDE Connect</h3>
<p>KDE Connect 是一个 PC 手机协同工具，可以在电脑和手机之间共享剪切版、远程输入、发送文件、共享文件夹、通知同步等等。
总而言之非常好用，只要手机和 PC 处于同一个局域网就行，不需要什么数据线。</p>
<p>如果安装系统时选择了打开防火墙，KDE Connect 是连不上的，需要手动开放端口号：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># see: https://userbase.kde.org/KDEConnect#firewalld</span>
<span class="c1"># 还可以使用 --add-source=xx.xx.xx.xx/xx 设置 ip 白名单</span>
sudo firewall-cmd --zone<span class="o">=</span>public --permanent --add-port<span class="o">=</span>1714-1764/tcp
sudo firewall-cmd --zone<span class="o">=</span>public --permanent --add-port<span class="o">=</span>1714-1764/udp
sudo systemctl restart firewalld.service
</code></pre></td></tr></table>
</div>
</div><p>然后手机（Android）安装好 KDE Connect，就能开始享受了。</p>
<p>目前存在的 Bug:</p>
<ul>
<li><i class="far fa-square fa-fw"></i> Android 10 禁止了后台应用读取剪切版，这导致 KDE Connect 只能从 PC 同步到手机，而无法反向同步。
<ul>
<li>如果你有 ROOT 权限，可以参考 <a href="https://szclsya.me/posts/android/fix-clipboard-android-10/" target="_blank" rel="noopener noreferrer">Fix clipboard permission on Android 10</a> 的方法，安装 ClipboardWhitelist 来打开权限。</li>
<li>否则，貌似就只能使用手机端的「远程输入」模块来手动传输文本了。</li>
</ul>
</li>
</ul>
<h3 id="qv2ray-代理">Qv2ray 代理</h3>
<p>Qv2ray 是我用过的比较好用的 GUI 代理工具，通过插件可支持常见的所有代理协议。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># see: https://build.openSUSE.org/repositories/home:zzndb</span>
sudo zypper addrepo <span class="s1">&#39;https://download.opensuse.org/repositories/home:/zzndb/openSUSE_Tumbleweed&#39;</span> qv2ray
sudo zypper refresh
sudo zypper install Qv2ray QvPlugin-Trojan QvPlugin-SS
</code></pre></td></tr></table>
</div>
</div><h3 id="vpn-连接与防火墙">VPN 连接与防火墙</h3>
<p>防火墙默认会禁用 pptp 等 vpn 协议的端口，需要手动打开.</p>
<p>允许使用 PPTP 协议：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 允许 gre 数据包流入网络</span>
sudo firewall-cmd --permanent --zone<span class="o">=</span>public --direct --add-rule ipv4 filter INPUT <span class="m">0</span> -p gre -j ACCEPT
sudo firewall-cmd --permanent --zone<span class="o">=</span>public --direct --add-rule ipv6 filter INPUT <span class="m">0</span> -p gre -j ACCEPT

<span class="c1"># masquerade: 自动使用 interface 地址伪装所有流量（将主机当作路由器使用，vpn 是虚拟网络，需要这个功能）</span>
sudo firewall-cmd --permanent --zone<span class="o">=</span>public --add-masquerade
<span class="c1"># pptp 客户端使用固定端口 1723/tcp 通信</span>
firewall-cmd --add-port<span class="o">=</span>1723/tcp --permanent

sudo firewall-cmd --reload
</code></pre></td></tr></table>
</div>
</div><p>允许使用 wireguard 协议，此协议只使用 tcp 协议，而且可以端口号可以自定义。不过 wireguard 自身的配置文件 <code>/etc/wireguard/xxx.conf</code> 就能配置 iptables 参数放行相关端口，这里就不赘述了。</p>
<h2 id="其他设置">其他设置</h2>
<p>从 Windows 带过来的习惯是单击选中文件，双击才打开，这个可以在「系统设置」-「工作空间行为」-「常规行为」-「点击行为」中修改。</p>]]></description></item></channel></rss>